{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with normal and inverted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import keras \n",
    "from keras.datasets import mnist \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout \n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network trained on normal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_x_train, _y_train), (_x_test, _y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (500, 784)\n",
      "y_train shape: (500, 10)\n",
      "x_test shape: (10000, 784)\n",
      "y_test shape: (10000, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = (_x_train.reshape(60000, 784).astype(\"float32\") / 255)[:500,:]\n",
    "x_test = _x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(_y_train, 10)[:500,:]\n",
    "y_test = keras.utils.to_categorical(_y_test, 10)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\\ny_train shape: {y_train.shape}\\nx_test shape: {x_test.shape}\\ny_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEICAYAAAC5yopxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFrhJREFUeJzt3X+UXGV9x/H3h/BDmhAMJGJIAkHgtKWFgmw5Ujj8EFEMP0IsYAExVnuip2KlJW3VtpJarRyORKH1gMEg4Tf4I0JFbJGCkBYiCwaIUBIKGwiEZANiAoUq5Ns/7rNPJ8POnc3O7NwJ+3mds2dn7nOfe7/z7Oxn7r1zZ64iAjMzgG2qLsDMuocDwcwyB4KZZQ4EM8scCGaWORDMLOvaQJA0RtJLkvZo57xvRpL2kdT17x9L+qKkK6quo0qSrpY0r9N9h6ptgZD+IQd+Nkl6peb+mVu6vIh4PSLGRcRT7ZzXRg9Jx0i6U9IGSY/XtW0j6Q5J/ZJ+KWmZpBO2YNlLJH2k7UW3kaS3SbouPb5fSLqyWZ9t27XyiBhXU0gf8CcR8eNG80vaNiJea9f6bXQZ4vPnZeCbwE7AuXVtAfwZ8GhEvCbpD4B/lbR3RKxrf8WVuAm4G5gGvAL8brMOHdtlSJuLN6TE2gh8SNKhku6V9KKkNZIulrRdmn9bSSFperp/dWq/VdJGSfdI2mtL503t75e0IiXnP0n6j0Zpn15JPifpvyWtl3S9pAmp7UxJj0sal+6fKOlZSbum+/8saXV6hbovPelqx+P6NB4vSXpQ0t6S/ja9aj0l6T018y+R9CVJvanuxQN1DFLzWyV9K43paklfkDTo3zrVcV0as42Slkt652DjWjO289Lt90jqk/TZVPOzaQxOkLRS0guS/qpulTtK+nZaV6+k/WuWPTU9rn5JT0r6ZF2dmz1/Bns8tSLi3oi4GnhykLaIiIdTGAjYBGwPTG223DLp+fIdSc+l5/Wdkn67brZJkm5PY3CHpGk1/feT9OM0dv8l6Q+HWccM4G3AZyJiQ0T8OiJ+1qxfp48hzAKuBXYGbgBeAz4NTAQOA44DPl7S/wzg74BdgKeAf9jSeSW9DbgR+Mu03ieBQ0qW8+fA8cARFE+Wl4CLASLiGuB+4GuSJgGXAR+NiOdT36XAAamG7wDflrRDzbJnAguBtwI/B35MMSaTgS8Dl9TV8uH0szsg4KsNar6K4hVhb+DgVP8flzzGk1OftwK3Djy+IZpK8TzanWKMFwJ/BBwEHAV8QZsf2/kAxXNgYEwWp+DZBvgBcB8wBTgW+EtJx9T03ez5I+lISeu3oNY3kHQr8CpwD8X4L2tleckPgH2BtwPLKca21oeAz1M8/x4ZaE8vLLcBV1L8M58JLJD0m4PUPSYFzrsa1PAu4DHgaknPS/qppMObVh4Rbf8B+oD31E37IvDvTfrNBb6dbm9LsVk3Pd2/Gri0Zt6TgOXDmPejwN01bQLWAB9pUNNK4Mia+9MonkDbpPu7AKuBh4Gvlzw2ARuB36kZj1tr2mcBv6xZ7oT0mMal+0uAL9bMf0CqQ8A+xZ8yoPhnegXYoWbes4DbGtT1ReBHdct9abBxrRnbeen2eygCckxdzQfXzP8gcELNupbUtI0B1gGHUrwgPFFX298Blw31+VMy9scBj5e0b0cRmudswTKXNHrO1M03MY3J2Jrxu7qmfWeKrZPJFAFwR13/hcDf1I/9ENZ7eVrv7PT4zgReAHYp69e2YwhD9HTtHUm/BVxI8Sr2GxRPwKUl/Z+ruf0/wLhGM5bMu3ttHRERklaXLGcP4F8kbaqb/jbguYh4QdJ3KfZHZ9bOkDaXP0rxxw5gLMUTZMDamtuvAP0RsanmPqnul9Lt2vFbBexAEUi19kzT1xZbwkDxCt5X8hjrx2psybz11kfE63U11z+u2r9T7di/LukZir/JDsAekl6smXcMcOdgfdspIn4N3JI21VdExA+HuyxJYyi27k6h+FsP/D0nUhzTgM3H4JeSfkkxBnsCh9WNwbbAFcMo5RWKEFyU7l8j6W8pwveWRp06vctQ/9bYNyg2qfaJiPEUm1F6Q6/2WkPNfmLaf5xSMv9q4NiIeGvNz1si4rnU/2CKV+AbqNnUlnQ08BfAH1Jsik+g+Mdu5fFNq7m9B/C/FKlf62mKf+pdauodHxEHbOnKojho978UYT3g7Vu6nDq1+8vbUIz9sxR1r6wb550i4sTaklpcdzPbUuxmteLDwAzg3RSv/vuk6bV/99ox2DnNNzAGt9eNwbiIOHsYdTzEG8er6fhVfR7CThSbyS+nAy9lxw/a5QfAO9PBr20pjmFMKpn/UuAfB/aDVbyVc1K6vSPFZtxfAx8B3iFpTuq3E8XxgPUUm2zz2LJX3sF8WNJvSRoL/D1w48B+woCIeBr4CfAVSePTQa59JB0xzHU+CJyZ9lmPB5rvh5Y7RNJMFQeP51LsRt1HsQ//K0nnSnpLWt/+KXCHJT32t1CMv9JyBw5a7yfpuDRte0mzKV4970rt+6QDqmUHGbdL/d9Ss+ydKEL0eYog/dIg/U5UcUB9B4pdobsjYg1wM/A7ks6QtF36OWSwYwhD8F1gNxUHvsdI+iDFVu09ZZ2qDoRzKfZxNlJsLdww0iuMiLXAB4H5FH+0vYGfUfwRBzMf+BFwezq6/Z/A76e2C4D/jojLIuJVioNF50vaG/ghxUGqlRSb6xsotk5acRVFAK2h2Jw+p8F8H6IIn0eAXwDfZviv7H9GcXzjReBUiidtKxan+l6g+Dt8ICJeS1sjMygO8PZRBOk3gPGNFiTpqLrN63rvpth0vhl4R7p9a2rbBvgCxTGMdcCfAqdGxIOpfRrwBJvvTtVbkJY58HMZ8C2KV/tnKQ4U/+cg/a6mCIL1FMdsPgzF7gPwPorxWZPW/WWK3an6xz5wMt6hgxUWEespdmE/S/GiOxc4KSLqtyg3X27dC8yok/b5ngVOiYi7q66nEUlLgG9GxBVV1zIaqHhr9emIWFh1LZ3U6YOKXUHSccC9FKn+WeDXwE8rLcq6SkTMq7qGKlS9y1CVwyk2B/spNtFmRUSjXQazUWPU7zKY2f8brVsIZjaIjh5DmDhxYkyfPr2TqzQbVfr6+li/fv2wz3VpKRDSwbmLKN4C+2ZEnF82//Tp0+nt7W1llWZWoqenp6X+w95lSG/XfR14P7AfcLqk/Vqqxswq1coxhEMozpV+IiJ+BVxP3bn8ZrZ1aSUQprD5h01WM8hnAiTNUfG5997+/v4WVmdmI23E32WIiAUR0RMRPZMmlX1kwMyq1kogPMPmn76bmqaZ2VaqlUC4D9hX0l6Stqf4lpxWP/hiZhUa9tuOUXwX3dnAv1K87Xh5RPy8bZWZWce1dB5C+maZYX+7jJl1F5+6bGaZA8HMMgeCmWUOBDPLHAhmljkQzCwbld+paJ2zYsWKhm3ve9/7Svtu2lR/bZzNrVq1alg1WWPeQjCzzIFgZpkDwcwyB4KZZQ4EM8scCGaW+W1Ha8mnPvWp0vYbbmh8/d7nn3++tO+JJ55Y2m7t5y0EM8scCGaWORDMLHMgmFnmQDCzzIFgZpkDwcwyn4cwyq1du7a0fdasWaXt9957b2m71PjK5Pvvv39p34ULF5a2W/t5C8HMMgeCmWUOBDPLHAhmljkQzCxzIJhZ5kAws8znIbzJlX0NOsDcuXNL25cuXdrS+s8///yGbT09PaV9d91115bWbVuupUCQ1AdsBF4HXouI8r+wmXW1dmwhHB0R69uwHDOrmI8hmFnWaiAE8G+S7pc0Z7AZJM2R1Cupt7+/v8XVmdlIajUQDo+IdwLvBz4p6Yj6GSJiQUT0RETPpEmTWlydmY2klgIhIp5Jv9cBi4FD2lGUmVVj2IEgaayknQZuA+8FlrerMDPrvFbeZdgNWJw+774tcG1E/KgtVVnbNLv2wS233DKi6586dWrDtqOPPnpE121bbtiBEBFPAL/XxlrMrGJ+29HMMgeCmWUOBDPLHAhmljkQzCzzx5/fBMo+4nzGGWeU9o2Ilta9ePHi0vaZM2e2tHzrLG8hmFnmQDCzzIFgZpkDwcwyB4KZZQ4EM8scCGaW+TyEN4GrrrqqYdtTTz1V2vf4448vbb/00ktL26dMmVLablsXbyGYWeZAMLPMgWBmmQPBzDIHgpllDgQzyxwIZpb5PIStwKGHHlravmzZsoZt06dPL+07f/780nafZzC6eAvBzDIHgpllDgQzyxwIZpY5EMwscyCYWeZAMLPM5yF0gZtuuqm0fenSpaXtkhq2nXbaaaV9d9xxx9J2G12abiFIulzSOknLa6btIuk2SSvT7wkjW6aZdcJQdhmuAI6rm/YZ4PaI2Be4Pd03s61c00CIiLuAF+omzwQWpduLgJPbXJeZVWC4BxV3i4g16fZzwG6NZpQ0R1KvpN7+/v5hrs7MOqHldxmiuFpowyuGRsSCiOiJiJ5Jkya1ujozG0HDDYS1kiYDpN/r2leSmVVluIFwMzA73Z4NlL9vZmZbhabnIUi6DjgKmChpNXAecD5wo6SPAauA8je7R7kXX3yxtP2uu+4asXVPmFD+jvDUqVNHbN3NXHTRRaXtza4p0cyFF17YUv/RqGkgRMTpDZqOaXMtZlYxn7psZpkDwcwyB4KZZQ4EM8scCGaW+ePPHTBmzJjS9gceeKC0vTgZdHiOOOKIYfcdimZf41720eyLL764tO+qVauGVdOAstpWr15d2ne0fv28txDMLHMgmFnmQDCzzIFgZpkDwcwyB4KZZQ4EM8t8HkIH/OQnPyltb/bx57L38gH23HPPhm277rprad9myi41D7BkyZLS9mZfMV9m3Lhxpe3NzhV47LHHGradcsoppX2vv/760vayMd+aeQvBzDIHgpllDgQzyxwIZpY5EMwscyCYWeZAMLPM5yG0wcaNG0vbn3zyyZaWv/vuu5e2n3XWWQ3b9t1339K+K1asKG2/4IILStu///3vl7aXXa3r2GOPLe177rnnlrZv2LChtP3oo49u2Nbsq/FHK28hmFnmQDCzzIFgZpkDwcwyB4KZZQ4EM8scCGaW+TyENmj2nQDnnHNOS8ufM2dOafvnP//5hm1r164t7Tt37tzS9ltuuaW0ffz48aXtp556asO2ZpdrX7lyZWn7Jz7xidL2stqOOab84uVv1u87aKbpFoKkyyWtk7S8Zto8Sc9IWpZ+ZoxsmWbWCUPZZbgCOG6Q6V+NiAPTzw/bW5aZVaFpIETEXcALHajFzCrWykHFsyU9lHYpJjSaSdIcSb2Sevv7+1tYnZmNtOEGwiXA3sCBwBqg4dGhiFgQET0R0VP2QRczq96wAiEi1kbE6xGxCbgMOKS9ZZlZFYYVCJIm19ydBSxvNK+ZbT2anocg6TrgKGCipNXAecBRkg4EAugDPj6CNXa9hx56aESXX3aeQTOzZs0qbV+6dOmwlw3Nr7tw5JFHNmy75557Svsefvjhw6ppQNn5H83OgRitmgZCRJw+yOSFI1CLmVXMpy6bWeZAMLPMgWBmmQPBzDIHgpll/vhzGzT7Su+IKG0/+eSTW1p/2SXb+/r6Svs2q23+/Pml7WVvK0L517yfccYZpX1bra3Vj52PRt5CMLPMgWBmmQPBzDIHgpllDgQzyxwIZpY5EMws83kIHSCpsnWPGTOmtL1Zbc0+2r3HHnuUtr/66qsN2/baa6/Svs2+3n7nnXcubbct5y0EM8scCGaWORDMLHMgmFnmQDCzzIFgZpkDwcwyn4fQBieddFJp+wUXXFDa3uyrzJt9XfmDDz7YsG3jxo2lfZtZtGhRaXuz7ywou1rXeeedV9p3ypQppe3Wft5CMLPMgWBmmQPBzDIHgpllDgQzyxwIZpY5EMwsG8rl4KcBVwK7UVz+fUFEXCRpF+AGYDrFJeFPi4hfjFyp3Wv77bcvbR87dmxp+8svv1zafthhh5W2V/l9C+PHjy9tP/XUUxu2zZgxo93lWIuGsoXwGnBuROwHvAv4pKT9gM8At0fEvsDt6b6ZbcWaBkJErImIB9LtjcCjwBRgJjBwGtsioLXLD5lZ5bboGIKk6cBBwFJgt4hYk5qeo9ilMLOt2JADQdI44LvAORGxobYtihPaBz2pXdIcSb2Sevv7+1sq1sxG1pACQdJ2FGFwTUR8L01eK2lyap8MrBusb0QsiIieiOgp+6CLmVWvaSCoOIS9EHg0Imovt3szMDvdng2Uf2TPzLreUD7+fBhwFvCwpIHrjn8OOB+4UdLHgFXAaSNTYvc7+OCDS9uvvfba0vZmlzW/8847t7SkIZs9e3Zp+wEHHFDaftBBB5W2N7tcvHWXpoEQEUuARm90H9PecsysSj5T0cwyB4KZZQ4EM8scCGaWORDMLHMgmFnmr2HvgBNOOKGldrNO8RaCmWUOBDPLHAhmljkQzCxzIJhZ5kAws8yBYGaZA8HMMgeCmWUOBDPLHAhmljkQzCxzIJhZ5kAws8yBYGaZA8HMMgeCmWUOBDPLHAhmljkQzCxzIJhZ5kAws8yBYGZZ00CQNE3SHZIekfRzSZ9O0+dJekbSsvQzY+TLNbORNJQLtbwGnBsRD0jaCbhf0m2p7asR8ZWRK8/MOqlpIETEGmBNur1R0qPAlJEuzMw6b4uOIUiaDhwELE2Tzpb0kKTLJU1o0GeOpF5Jvf39/S0Va2Yja8iBIGkc8F3gnIjYAFwC7A0cSLEFceFg/SJiQUT0RETPpEmT2lCymY2UIQWCpO0owuCaiPgeQESsjYjXI2ITcBlwyMiVaWadMJR3GQQsBB6NiPk10yfXzDYLWN7+8sysk4byLsNhwFnAw5KWpWmfA06XdCAQQB/w8RGp0Mw6ZijvMiwBNEjTD9tfjplVyWcqmlnmQDCzzIFgZpkDwcwyB4KZZQ4EM8scCGaWORDMLHMgmFnmQDCzzIFgZpkDwcwyB4KZZQ4EM8sUEZ1bmdQPrKqZNBFY37ECtky31tatdYFrG6521rZnRAz7uwo7GghvWLnUGxE9lRVQoltr69a6wLUNVzfV5l0GM8scCGaWVR0ICypef5lura1b6wLXNlxdU1ulxxDMrLtUvYVgZl3EgWBmWSWBIOk4SY9JelzSZ6qooRFJfZIeTpe47624lsslrZO0vGbaLpJuk7Qy/R70mpoV1TZP0jNp7JZJmlFRbdMk3SHpEUk/l/TpNL3SsSupqyvGDSo4hiBpDLACOBZYDdwHnB4Rj3S0kAYk9QE9EVH5SSySjgBeAq6MiN9N0y4AXoiI81OYToiIv+6S2uYBL0XEVzpdT11tk4HJEfGApJ2A+4GTgY9Q4diV1HUaXTBuUM0WwiHA4xHxRET8CrgemFlBHV0vIu4CXqibPBNYlG4vonhCdVyD2rpCRKyJiAfS7Y3Ao8AUKh67krq6RhWBMAV4uub+arprUAL4N0n3S5pTdTGD2C0i1qTbzwG7VVnMIM6W9FDapahkd6aWpOnAQcBSumjs6uqCLhk3H1R8o8Mj4p3A+4FPpk3jrhTF/l43vW98CbA3cCCwBriwymIkjaO4avk5EbGhtq3KsRukrq4ZtyoC4RlgWs39qWlaV4iIZ9LvdcBiuu8y92sHrrydfq+ruJ4sItZGxOsRsQm4jArHTtJ2FP9010TE99LkysdusLq6adyqCIT7gH0l7SVpe+CPgJsrqOMNJI1NB3uQNBZ4L913mfubgdnp9mzgpgpr2czAP1syi4rGTpKAhcCjETG/pqnSsWtUV7eMG1R0pmJ6W+VrwBjg8oj4UseLGISkd1BsFUBxZexrq6xN0nXAURQfj10LnAd8H7gR2IPio+SnRUTHD+41qO0ois3eAPqAj9fss3eytsOBu4GHgU1p8uco9tcrG7uSuk6nC8YNfOqymdXwQUUzyxwIZpY5EMwscyCYWeZAMLPMgWBmmQPBzLL/A2F/Rqy0ypFxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_sample(num, inverted=False):\n",
    "    digit = x_train[num].reshape(28,28)\n",
    "    if inverted:\n",
    "        digit = inverted_x_train[num].reshape(28,28)\n",
    "    plt.figure()\n",
    "    plt.title(f\"Training example number: {num}, Label: {y_train[num].argmax(axis=0)}\")\n",
    "    plt.imshow(digit, cmap = plt.get_cmap(\"gray_r\"))\n",
    "    plt.show()\n",
    "\n",
    "display_sample(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation=\"relu\", input_shape=(784,)))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {
    "mnist_2layers.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAAFaCAQAAAAj5zgsAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAAJiS0dEAP+Hj8y/AAAACXBIWXMAAAsTAAALEwEAmpwYAAL+GklEQVR42uz9B5gkV3YdCJ8X6cp7701WVlaaiHfvfS/SZ5brqupqg7Zoh26g0Q1vB24GYzDDwcxgvOEMPTn0FEUOjURPip4/tSRXXIqSKK7IFUWKnqJI7Yor7a709f+9qOoeAAMzmAEFUOwXXzUSaSIjX7w4cc255wI3x/8MQ0G9xtdf7RMvvRcP3pfwuZvjxTPv7c/kzbm8OY83x/+wBfPlfMYttpvjSxneF8xc7OZc3pzHv89A5L3mE3cdiLrR/RJAdv0OGEMvOl6wZIB2dLzmO2QXMshh6kuGzb/vF2psfxZnkEUOaYzun+/4zdn8EudxGTksYWz/mZvz+HfqJCaQRPw1QZ6HBOJIRBvwLN6LGJLRyfeQjE7+3mtJAD34KG6PnrkOV534WhyIlskrjc/fPd1nDJ7AV+BZvAu3oe/maXuNIxbN4QKO4BG8E+/Hc/gKvBVXUUF3dGZuXq6vbR4P42G8E++L5vFtuIoqem7O49+VU5jYh6K98aWcNAdcd+Di86w4vADOYhjAz+PDAFL7tl0a34NrOLQPg+pltj2wi+9DXhOfxBH0I4VlvAMfRE8PoG56FF/0LcrN9Sl8EI9gB/PoRjsGoXERX4Fn4N+0Ul7DPMZwDB/BW7CLhf15DHAe78F7oW+A4s3xph3XF/okTuFBvBvfjMe/KCfXvcfgEO7G1+KW6DTXoTGLJzCLOMbwWHT6m/g4Po11AAP4QbwL2LcEZ/Fr+BP8e2zvQ6OzNF+8OatzCkfQHi0jYAofR/55kPpeXABGYmUVKlGsSC14i968N+PNeqPetJpWk2pcjalhNaz6VJ9aRuvvd+ACGMF78TToC15rxzF8Gqejc3HzHvLqkNePZ/FOyBe81oZj+ATO3YzuvblPYDKKxZ3A1+BXcW1/+/Yv6qQ50HsG/yd+EZ/DX+FRAN+Br8Ek/hrfGz3+SyxgE3+BX8CP4M9xDJ34CXxFBHpuzxk8AMK/wIkbDu/LHeFjeBjT0fcdwUORpegA1lmjg/gE4mU0EELAILjHFYSo4AQaWMUB7OAiPh751n1qRxUUeeylvbQ3EVv0Frw5b96b9aa8SW/Sm1DjETwy8igjD4vDqL/Kwf0dC1/04atxf3SLcTeU2H7WMbZvjxfxtTh709p71XmMowefwaNI7c+j96J5XMHXRGGcm9bemzgysYEfwX/BNfwVvhFXcB5bmP+iUgTuHR/A72EJwNfg36IPn8FnARzBf8HP4c9xCsAv4vuj934DfgWd+CE8G4He9cxrJ/4VjkcLqQ8P4uN4Pz7wgu05fBDvxWP4XfwGOhHHnbgliiLe+H7v6xbrdt7PhVnJcoYWeS6c5slgjEbDYRrgPumhLmkvpKqJdOxO9UmsgMAooYQKSijDooIywui/dayjhmOReTqFkiK1pLRqqqaySpRRpIwK1bg36o2pUTWihtSQGlADqlf1qi7VqdpVShUw+eY918ATeHA/WKC+4FJORDeir42sl8TNS+MVwzhvwVMv8JFePI8L+CqYV41V3xxv0GXQgU/gL3ANP4lbsYC217yH5/AN0aN1/A7S+BC+LgKzd+EaPgJgCf8Kf4jvwefwe/hzLOD78P590NuDvVH8VgR6LhWyiAAFFF+wFeAjj7vwfbg3uqNewPkbS00l0eZ1fpt/jkzg27RJ05IuCnMoJV3mGtWoFlapyhVTkTKXucShCcmSZWOssWyEpEg5s8yLei6YpnEesYPFXtNN7ZnERuwalgEUcBzHYSEwIBiEEVDWUUMdVTRRxRpq2MYBXMb9AOZwFwwY3apbtXltXlcEhx2qQ7WrNtWmUiqlkiqhipFd2sIK0siDIjt1789/lSkv4diXeqnu4gPRGfZe5haWiG6A78PoTTLQK4aCdvBhdL7KPLbwQUzdnMc3I+TN4kdwDf8RV9B149nYa4jqeHgOXx09Ooz/HYv4aASBHr4V1/A5pLCE38RX4SQu4zacwQj+Md57A/TcdwziX0ag90qWxSjeEeGPF2Vun4ve644w1gOsjn5zqUEhh8aES3bYT5qYHzcJneRU0EbtpXZq9ztMl/TmBngwGAnHgolgmmZlXhZkSZaDFZ03Be37mpkNh1ziiq1Lk1q8ThuyJk2uc5VL1gobTb7JhznO6iW7YObMDE+ZcT1qhoJB0xd02w6/vZjMxT1lIje7hHVsRnZkFRVUUUMZFdTQQg2VCOYciGro/UfXQa+Il0/qKBVXPpZRAoNRxQ52UEETdaxhFWvYwRaO4ALOwkJjDmUc3ps4L3LKPojwZS9V3KDZPoWj+6vj5nipEIHCh1B9xRnai4c/Fd2dboLemywYO4NfxjX8PFb24e61Vjm4dz+H38cC4vg2/Bt04DP4egDP4E9wB/4EH4CH/x++N4p9vB3fgbbnubd7nx7Eb0VL4+Wyt+6IUhG3z9unvzyKx100LwZ4arnrR7NP2nVaZd/MUtaEXDd1zvPwWpyhYWCxCgOBRRMhStEzzrVtook0VjCkCoq9olfwTIxjHKe4JGxCkpzkpG4rdxR6Sn0ypEdLEzTN8/4iZ3glKEogTFacBVkNqlKVitu4ylWKNuMe1ajGVVMiQyy+znNW0v48z/BkaUyGiv3FHu6k1Hoyk5hNLMe0F3rsGc8qVlm1oJYwgGt4EC2sR453KQJRF6usghBE8Mi4Gk3jU/hKfBf+BNdeAF5l/A0uooBl1LCFWOIpoIp3RhSfVzrH7jwcwlOqM4OUWsHN7YWbF/96QPAeDLzKPDq7egtPRqbEzbjemwjyRvC/4Br+CSa+5EyTO53vwH/Hr+PX8Z+jjNV349MQ/He8O4of/Te0UMZf4Dfxi/gveByd+PnIvU3d+PQwfj/KGCa+iG/a+7cLj+FDOOnt4q6xX8h9Z3g7n+YmhVTjdKmL2mjE5Llp1oyVlWCU2ymhlcVu9Ok+1ed1vJAKsz/8CET2NhtZXhz97dlsVdQj+NnAETyAX0UCnejHlMqrrPIVqwVvN15MFNp0J3dzb9hvhwojPKYnTGRTcpqXJct58VkHTNaUdFXXpSVrtMEbtMpN06CaVLgkhkXID3xfCjrHy0GGFoN5maVpnqAxHgkGuW+lx3RVOwptnNzbKKkTEqe4iRlPvFCNqDNYwXoE9FVoFGFQA7wGotDAq53lWHQrfBsy3wl413Bze+GG+MeA87jtVe3gPabB0zc8lJvjTQB5zkz/blzDz2D0ywi3OkvsWfwMzuCDsNEz9Qgn7o5ArBuXo+SnH5E3WxEtYisKWX1+GaRwHLOvYWGofYx6SL0dh4PHw0/xQ3xGNkzVLJmcaXLR75v2QiwlwlnDtiJNLpsMDZnOYuJZWKzhOGJROmJJjezv8q/xg0gji5UXgR4jQBOLL+dq7tdaOqsriJg6OziADaxhA+sooR4lRiqRa1u5EbELbri02xEQG68Wz7QHXWFPflBGeCyYMnO8QBmTo4IERtje2Jzr7SKTzqKscY3rXOeGc791RUIyhtnXBZvjDKfNvJ4xkzxaGJIB27vSnetOdzWT3pMO/dSr1EbH3Gp4WlUcEaikbm7P36zX7tb1I2i+qv0WxZzxJMo3Qe/NlH+6D9fwm1Gq8UvPMLmL/zP40RtQ+sKqWPU8mMIrSguo1wi0+4NH6ZP0Hj4j26YsZZ2jXrtAa2yCsXLKubI/jaBHpqwvNakRB1l/zPRySkcAdAUjKuel1dTLfvcS1pGJgjevNBzoTeMICoirpEqpNtUepS06VZfqUT1RZrdP+VHkjlWgSLVQURV1AAcU4xBWMIpWlCpxsb4wivc1oscNbGIVNVRRwrYLfCodX0mGqaDDdgU9tlf6eNAM2ZFgXCZoUmb0rD9vFsI0ZcyKKRiWEtdoldaoJWtcq1V6vjZWAFKvfAmqnhiQeGb0zpPTHNjize35m/G1f2K+42uUBhKvMo+RrfdWrN4EvTcP5BXwx/hrVL7sgLXC/fgQPLTtQ+ce9yu5f6fbIyFfL267/vqLj+a1L4pojx3xOuSkfFBfpluooYtiuESTjyBMy5qpBHPSmYdEqQNG0G0XtU8hV4lpmSelVye20UAV34Wqx2pRjaue/wGxlwQ0utSIGlfjalLNqEWVUQveRGzBW4wtxdKxpdhybDk2G5+IDXqpyJa8ho9jNUqHOHgNkUcNATLYAZBT4s3HswndZjr8Lt3L/TKkR2jMTsoMzdKsng3mzJIp6pDKtbX+b0gUgY5XuVgHPSD29ODF1QV2F7pv/f1LvvD3dNv79W4efFOk/Ppi6qOO1ON5X8St+anIv7kJem8C1zaOTvwwruGdr0uOLvZG5fkmcELRkLydHqYztCtNkzezXCcutTVAi1KWcrgcdlexDhMD1pyz6ulemqEil6QkNliRaT0QxMpgbACY9tLekFf/so9rG/PIYFiNqSk1q+a9BW/Km4llPPKsV1ZWLalkZPP+FC7hFA6hivI+ZcU5vxS51i4SV4pVkqa91BX20iCNlMdp0kzJtJ6jRVmmvC6KNoZKzu2VslSCMpXIihgirX3K8or2hYTFPVXhaq068umOJtD3ipegUoNIxtveM7DTbIfHUeIn3Lc/l6M8cWN/a/5Pu13/hS0IliMOp4mSYS5uM9/W6ul+JnkAaH810HN3uCejoM9N0HvDh4tKHMff4H9Fz+tQKPPiYrX4qzjLiedBpIqkCZKvmf/vRd/ittht4E15m1yQI7ZKFVuudHPWbPJMAYBMG+IK5f1ei+PIxLMxRLlPjUVlB8wcr7DRLrta5BnbU1F5lLCLnGJv1htXbS9xTEkcgY9e1a+G1Iga24M1z8GaVqTYE88lE/JeQ309ruFodOk493QVTZRAUR7W4FZ045Noehz3k+X2cnfQT0M8ZqZkVi9whnNUlCIHRguxGGOMDanEpbBMIRtLOmCX5MhSmhdNmhbtTDhuB7kn1yaxoVg6XukMB/VkkKEVysiSFA2xkbJu1cKJD6Yux+LpV7mFeQpLbc+kdxrEVSOStROl7kasGDkFvrecyCTmEjPx6fh8bCG2GJv7n2hzv2chNh+bjs/E5xPZRCZ+RA3AYghBkgdojoti/cZ2bugRdTtSwauZAgoZPO1CwjdB740eDuY68EPRNfn6JNO/sEJXfdHH8oWPXlNMD+iPlfvlQb7KW7zJOihQo9IuI7xqypk2wrwXjOiC1JlpmFFH2puJuaqKOTQgyEMnuFdPygozV6UUFmg+15uJ6jWAjLfkjcVGYoPegDccc9BmlVE5VVZ9LtiPf4A7IkjbAzYd2WcSWQRZbAJqOVFs97upn4dlXGZkQdKUscvBihSCgNkYCqXKNamaMofsiNLMWhe5wDmd5SWZL83QJI2ZYRm0/dRrurhT2vOpcmIj5qmDWI6+zRGZawhSwYCZMWnKkaGalE1AK8X5YM6umIADYgltWa+XZfnh7k86BRCHay83Ugmg7UT3BzKJEwkzJmkOyHCVQsmbtD/qt2n4sFF0vqGWvGHvt/4nujQm1bCX9rbx/n27+yCCHjsjWSKpSIlYCjKTHQb6TdenOgZcVE+9smmxu1+odpOy8gYPx5C7Bf83fgk9rxNbXD1POdad6N3nKch6+7G966+2RxH7vXufe2Ue78a7kHuVu+HzEyB7n9zGW/FO3O3qcRcUNfkhOikHqK6zPE2r0k9tpiDr/pxzGAHbTyvctCUZy7r4nhpWQ2rCW4z1esAqLAowKRowEyarra5KjbWebKUkyr5uYSsCNcfxcwy/OXwvTiiOmaS0SUexRw+YUTthZ3WaljnvHE4pmwq5i6SkncMZitXWPW2JfckFyzYtczytJ4JRGeERGZJ+0yNd3EGpIBF69ciVChEgiAjMLbSwhY39y1BH6Q4om8z30IRZInJ8QHY8wdD4NM9D1F/pDHv1tORDkpzJSY7JlrhKreBA7cDQd8XXulT7y1+sXpuHfu/tw3euBcVgIMkoo9ipB2VclljrkMtS0QFPU/d5bwVlHEQNosa9YdX1kpbxm3+MokP1qUAFakrtogqLBVSSxUFadEEBKhvLRT0nI6aPk65YqDysa1uFtk9gp029ws3DrfYevDtK0N8keb/h8TyFNnwO16Ii/9frdDxf/Okz+MQNSFMvgCwvUln5qX1ysnvvAfwe/jn+Gf4kqtGNv+LevRv/9uMr8Ha0EOJWfJ1LahZ75bI5T9skJjTL+T6zYeYCBKO8ysa0M3bxZzBd4YI0uGInHCXl7TiDNZzAIzgQyQrsUX1DLHjSxgOSoSpvm1Vb5oKZo0l/Ri9yVoqWNIthyyWpUI2btEpNU6MyGU1U3AM0O2engolg1AyV+ou90kWd0uG3FVPlRDVeimU8lyvOgCISSwP1KHK0hvWojuI2OLupQ/V7g7Fxj1VZzeJh1FBCFY9D2mmEF00x1FSSBrW4JD5n7LQ/yF22jbwidKo0wQUJpUq+mZEJybI7XjKW62aVDpa2Mu9s/xoketTLBOFVMg7EDvd+nYw2Ov1A1jnUw6WI6wf4cWqv9tEEL5MxLa4JS04mpM0Rpl0k7D+A4crrYor3d7f2plv+J248YsRVwsVWcRdaEScTMH3+AgUccoOqFNBCccTv5lTg7a2PI0ovUVMaPP+/edO3pL4JHTGlYi+zYt1aPohn0H6zDO3NEc+r4j/ilzH4OpndKjLgu7G4D1qZqH63f//VnkiY0tE05/a8UfxoBHqp6N2/hF/AIIbwOfwiUhFz0PuCLRbRkTtvWI1deBp37ZfMKczh2xH60BW6wtu8QTku0VKYlDWTK8EmTZbqYV89cjoJkpJpavBGsEjtlAp6i0N2jKf0PC9xXgIx4iyiuq1xTdfNmhzmM3xJ7pb76ILsGCsZM8WTMumP+kNhv+7mDurgdtumU36iEOdY1RtSvSD4kU1o9+nOzkI7iFtwDe/CN1yvmVDtqoVQFVRe5VVODXr91ynTUSnZMRxEA1CtlOmxo7TIvqnxKteoREwFmadR6eZ2SQSejyKWYVPhuBC3pC6G0mGfdMio9qVsCpzhQlDmitRp3RzSx8u3zHyz92wOnYjFrjPEP38mvUQHoJPfk15tFH2qxMP2cIlbvOrPZROCDTwAHyHuBCVMO/fznPhsuc6rzOFc0N9KSlSP7HLle7e6fFSjbCND/o0ey2jCghDbvwVzxJ6sYV1VOswoZ6lCq1QhMVk7XurkNoo1UMIWtvfqX3q0pk1t/HFOcm9x/ej0wFu9j1ecWFDsCy6jvcpbwmeRvWnnvfFj7w70dlzD4y9i1X05e3wIP4dfwX/CL6AQFaU9hgL+AvcCuIQ/wxpi+D78X/hP+EfoRx9+FO/ZFxFN4IkoOu4UK/5VBMIvN4bxvkixwosg+9nouGP7TKgG3jsH3ctn6DhXzGY4L6uBT710xmyZYTtGNb6HT4iLbVlnkXGZj5m7+BG5TAeoKmUqMbPPK5ymWZr0x4qD1FvqXmmXJHs6zomwTfdzOgxNSUhnyoMcW1HVCMxWcS9+Go/gETyNd+HX9wGtCYUtVGGwFFXTOpsuBx8LyGEBi3AUlazKqPK+Bayjqg9Xk1tXvkfxoM0M2VldEKES1ajFddKcpnHqXWhfTpB3MIJUho9AcYeZNURVWTNVTq/0SIKTQTcXbNWU/IXiWJBzFcmsTZlbvElH+Zy5zd4z+Uves4iN4Xllf/tR2SeBMPkDM/e0ssuDVOStcHhLsedPUEW3/FzQ5XuRCJ/6JZyBoAWtluLptmDQLGprVrlOoS7SdKmTYr43E1lH90ff4QII7tf7EQr8jxyLmMAKcsi7s6M+FMVcK5iHeBIPBm2amcrS4gYXZSromU+ydxhFEC5H77+MGihGoxTaVesHveuwCS7IVjhC8+VS3zepTyDR/xLzCCDEP3CB3ZsaK2+GJIZzMP8J/mvkr8ReFxgF3oNreAhL+Bf4aXj4LD6LGL4Bf4Jb8Gf4TgBfj9+DYBa/iW9HCj+2LzjwecCdxZ/gayMbLoik8Kov2pyxcAk/GcnQx3ARt76gaE3FvjFTLWXkIr+LH6H7+H45Ro/zOctyN18h4qzk+bDcJWUz4o/KmO1baWslaFRb05AFv508l4B4B/5lVC9XjRRUXH433K/KEJQQglFL0bjkpcTrVKUVGq91caLuGWw6DVO1Bq2yajZSN33hYCwio+ZVSQnaFdTv4xi20YJxFqFXjFOy3CH9PK4XpEAhr8qqKYuz5xZKI4XOTjWmBvDYjYheCYFHyWKfnSGfWrxKJsjKUBolpZO6V1a4xXVJS1++T+e5xpqzhk3V1HhNtvkwndV30SPyrsVfHPqWZIiuoec7Xgk1mLyj/4cXn1hf0QFXZES6aZNDk6qDUe4TTeti7BAlDuMgoMY8F9C6ts+DfBtWUeqyU5IX4SavarZpHi13UtLEbgVjM5LTXoNR2edVwvztjRUsYllptQZP/RYOYxVlGEXxciro4ylakQpvUCUgSvtDQfKtkSwERfFfqC414n0Am1hWpY5gnlvUpLRJMEoqHJVt0iYe5lzSyzYmvrnrm+JldMVfMI8YwGV8TcRpv9mv700w4lGZ2F/hx6Ny6dcrifEh/FD0+Bz+PWbxsUhlpRc/hWv4CQxgCP8KPxwpMH03/gxj+P59aSm1n1RZwL/Fr2MGCgO4Hx/H+16kp/cBfBDP4mn8Nv6p88pwJ47tOxD7oJv6lpXby0Uu091ygdbISL3Yw5t6XMNq5jAZoIriIJfDJWkLoyzK5Uh4wPSQoVXyuVfHQlzDjNfveSqmCliISMCyX5SWUErV8GTEVHsalKRR8V3WlUuSkzHu4dQDUfbWqZk0I7GAaTWr5tSSWlYmim9ddBG5CLSWUfaClHRSbzDEs+KyrWVTlqqpkwmWzUTYPR1HVDV7CNeQVY7O/xA2UILEuKPST7OsucI1qfkrNHjYK8KHaeMBKuimNE1xqT1IyajRVDXZcEoXXc7RGl6jTd6lQ/pWupsf5afDryz+4uDn8FT8NIp75ifquFt9fPxz+oHSmt6g0MzJBi8YUEEO6DlJuDxxMSHL1OKyP2e6YjB4GlW1rOyew6gsjqKJMspYj1W79RwJReo0Euh5PcjdYWoxip1u4XYkFKmcSqtJZV/X5X0Ow5hXSyqvKuoajiCIpL8aMWmn3uI4Z9mYCtWkKvlgLNv2TxFE0dIHo9o8KMaMyqk+dcBZ3gl/UPLc0GUa5eh82G4WOiADfkpqhsIlVzFdPbjysZ7P4Wl1JjLlF7Hg5hEfx9ujoM7NWN6bwrl1LqFzbh9+HTVdY3h/lLpIYg3/Ehl8BF8f2ZCP4Bo+EFV+/AZ+Gz+On8fP4Bsxhx/A+/ZBz4uc07/Gr0SqY69sdz6IO/Zdhd3INU8goWIR9I31fbvZtEYMnzcPy1VzjE9Jyx+lozS+Cs6YapAqowBOcYVawZhRUDOxXm/Eu+ZyoZ1U1C3WPGITJRzEulpSexGg6+OWfW8lqXrVsNpU7q7hLMKgg6b9nFS4QVav+JO6z7QveU1s4BoGPUcA3ok4eYzblE1Kp/TyME2HGS6SmCo1qUKas3aBxrh71zMR8bWGw5hVyx55U55SD6ABg2bcduqhYEF8LnPLiCyHYya5J4YQtNuRMCt1Xg2K/mAAv5MWdI1LNBWOmByVKeAVW+YG12VHbqFT+jLdL+/gD/I3h28vTyBU9+Ed+BA+hmfxOM6pqVVfHqBjpsENchf7GvkTKPSZplTMQArZCBzstCmZhqyYgTAe4ihYrai3R4pf7apPDSurxnBHROf1kWsPxzhjNdVNQ0TnaJYGbVeYfEcUHHA9ArSqqGlvVAVf1hLsB2FKsSqoQfXVkcxWiMOeaQ96aUynbZFL1KSyi4bywHEvjOjGzvUN1IDqVPHojM8rUVBNF27ooAlnr1pf925HeXObpHmzRv4HQT10gFZkgTeoSlt80d6+NgSDe/F2fAgfxfvwBM5j5mZr0jdT5tZFx34WfxmZO/HXDUo/hJ+IHj2MP8QIPoyvcasZ/xY/h99DCx34Lbw1ep1wD9rx/XjmRvbW4E/xdS+wRBNfsLmUxxx291X+3C/4cFTuvYeS8cRzc58uO5WSrPblsjnFp+SwXNaneFMe4DKN8wE6S2k/sRAnFIe4btMZj5DxjDcby8WgNJbbJGcaYvU0pxzs+N7sKzhgPWpcpb0F72wkHdqE36FnWDsVPhG9aEZM97zKR7Er00ljZpbTJs/MJROyJVctkTWT5T4b34wC/k6YoIWkEm/Bm47Nx+ZiUFegnZusTLcd1wusqcwlEsnS0FR8OooACnSbjMuyLnHVCo8zZsCjHHCTA7/PdusVLlGRMxRQxWqqmTWzq0/ri3KFH5Jn+Gv4M7xz6/U8VhLte1PpodDPt/M52pEqV7i+2MHCpVqyDlnhNZPPpXax5O26Co0+1tIQ4WnbTlgDq7R3PVo3gAocIWjWC9RRHEYYzUWji6fIj/QKy8y0TFPhsHQcjCKeh/ArqGLFW/bm1Zhafw1Lz2BCLahlr6ZW8ECkQygIY9RrxnlO8hJy2VgRWdbDleRSFDdtwMOCN+uNqK7Iit6nraiMdy2KwMgAL+sKVyndiFfQq7q9FdCgVLhmRwh6Uq/LRDAt62xojQ7TVb3xvus7Sd4oxLzZG+NN5tz6+M/40deNobd33bwb1/AJPIz/GAnF/0N8M6bwe/gZdONH8MeYwTvxX/BO3Iu/xA+iA7+Mj0VqzR4G8Zu4hk/j/fhqPB3le71XpKzE9h9bfAInsKwWUOr94NTP0Z12h1d1yEU6zvfzGlfCXj5QnDZ5uUwlTvMxfpgPUcFoMyNzdpO3/WlnKTmL7QLGlbt4wjbOUJUqvCTtrsAq9ObUS983JtWCmvSWvUxsIZ6L7UlSiVNYSdlJJjkgR/kI78gWr1OFSAouRcJzPBH26SRHFlAtqpqdiVQ7JmIT3mRsOlb2yqoZqebd5pV69HiYYZZQKqT1QjCqU66qwwlIF+AneUyvWGsrEvCMJCooxXjWlmjNZJttYTsXuUJLesrkjJhATORkrutb9Hm+KFf5MfNO/kp+zAzmVcLZytd5lDEv7sXKSpiv8iYf0EUman0QnOMNGTDQg2x1TSYIUH78gIt/dVJGSlzijOlzcb0TKu2NvWDOKhhUo96CV1C96rYoVpqHbQtGaM7kKJQyWSJelkka8NucVqCbl5TSyqhFb1o1X2HRDagZlfbEY4VIjKGGtFfqkhE7awpGyLqoqF7iqWpv2rOREuE1TKpQzXuT6oXyEVnMeuI5aC7HZIK1VEWCybwyiKt8vAU/borUlOxKrAle5o1iHw3TOi9JWTbkuL5U6yuoRGJfh1JF/kr8Zr72zeXcOqLSNXxq39F9ffaq8Az+D3w3fgOfxkiUAryCFn4sEpAq4odxNNLr/VX8Cr4F8+jEByK591Sk2vZt+CH8WqTF950YeoXUyuc7OuyB9QoexNvVM3hg/tvCb5B76Byts7V5ydNZuU/ultM6ratLkBFuBB1LMHN8nFs8Z30pMsspfZVPUI5neNoMrCeW4e85PIqmjCP7FoOeMo5APAeI5ejSGFEz3qKX9qqec3gPR9lZJ0TKCb9fJk2W8jYrBWFtqSartMGH5BbZZDLTpsNGKseCKpZjS4nZ2JLnolkDSqs5r+kNq0ZUnFYAddkZzglTWRvO2wUzFCRd4drbQNhGiH7lj3IuspWK4Uyl0+036KGCo7LwfK/KxKXIDUr7fbJsRVYCbXxTliav8Q6fkgt8O98rT/LH5Suo+RS61Kyb0hsCWe0YxltQ6KJj5lapU90uSiCNBVBGdrQDO+h5rjHrdotCLBtzR70U40nRpsbE4+dh8efIeKNfsK6OYlDNqUUv401556NivE0XZe2kUV6kHItUxLIvWTNlu9oi4dcm3oIV5XrajauFG/txSaZpb9Ejr1M5K9vFGfMxPcgLlDfEZR1ywMtmTgbKiTIEZdzl7pBexpv1Jl5CTKKFOY+UCyGYdkqT414u274VpyWgluIuSimTVNOGBwXd0Cxb0m1G9LqdY6GyHODbuSzoVO1uSd6Yx5tA8+YCPbe9H9eiRFr8ddzrh/E9aNvn4TnqcwrdUbvjPYbdXjPuMUztm0rtz+uP0YUh9KEbfVGDx9dWvLboFdC7viCf4CfNBdrmsgRMfJgPmiqf5dN8Xl/0U3aGa36ncwcDw/MBbLvfxe08J9t0hXYkZy3XxcW+MnbWDJcSRyC9lA6MWQl7BL1KYuxkAtSxSG3ZoIGDsbDLDMtMkNE+lbkqIQlrypu0mbKDtivvcZT9LadkQC+yo8jUtJZ5Gjzu6aiuw/eWvCWP9mNLCRcnmpIVcTp5QgWZDgapfRVVF01UFc/JFxTBg5R1XT6owJPUMwvjYHfUiDQN8eQRpJXkeY0K3GVGqMZ5miLSRCRkqtQyh/kU30aX+QF5h7yPrwQDeSTVC7uku6atPWpM8YqclU1is2GmbJ5rBjJj1nnW/Sa/i4qyyosGO5iNpT1n4Q3BDHJWKlymRZ2s4AIC1fcyZ7LXqcp45CKjTl4rUoIupML+0hgtii8OSqrWNwt2pNm+FOXNV3EVRs15I7F5j9WRKFpHKCruNZOSETFVCZl1jqdpyO/yY041p4HHMaKMWvImvVE18ZJH0q1mPV/VXWR0gH0nO6ZnuNO56gU1FVuMEerJyEqec5HfMO7o3aUO2y/rPGqYa7qiD8mJctemSqj2m9jyJgY9RxX+Yfy1i0e/br2uHOh9Cj/2EpGM2A0X+nqSwnvdDP8bdmqnovP8frnEt0iDa8G8NeZePuOPy6rO8q1yh6yYY7zpJxi6Sxo2PBwRZ63riDbJTda2Uw/aSV6weTa6FiUBiHxhWTOb4us2iTRPGq4Ua5JXKKSQS6ZCVTacp3kzwUO2J2hb8jiKw63iKVzDhDfvdatTqGIT+Tj30KheNGIqXJaQlwrd6Yi6nINp53krXHYXrs2aCe4PUgdRQAWfwohXiA2pVRwB90qeKlLlAk3Yrj2SNaDnqEJ1s2wHsqiC87RhtPSWE2K5Tv1BmmpmiUviMrc13pJde0ou8lV+RJ7lxzhcU21KRQr8zx+dmFbXoLtoh3d1kwvU8DuNy4rDDpqG5H8BgatGHZWKqXF3iLQaUiuegy+C7bRTYrlhfekMMIsRNaBMRNh5qbGIMTWvMmrFW8Wv4nRk3Z2AtFG/jElatFSoTKEmXtB9yttrxRRCo5HiUc6RpZJ21m0+mDXDttvGdyJRhwZ+F6sq5y2peTWkXo4RyGhXzhqtYRlmkp0lXJAhG3e0mlBl1KxXcQzERVmTPHU24aPQSQ3yOZ7v4Y1Sv6TJxWbX+CQFN3vM/11IYyzhz/CrkWzo6xl3WIQfAdv1QjH1vFxs7HrM6AWvf/6Yrrf09l4z2MYQS8b+EmaMnpYH+FbeNiWpmmEWfpSvSNEUbZwPmppd5ofNbTJcgo2bkNcOJDbVRNwRFGybkLRKvQFyqMV0KujQXYUBmrDTpQXNclKe5GfkUb6VduigrBMF6WBGRmnAdOkOTpY9E1EID2ALPwiobpVVKxFZZRwDmFHLqqJS6g6s7nW5SNrOcFBmKaurtM0bvE7b3KQcLwSjpjtMVRWhiUPOBvGWVIfacKVf3ZzhGjcD3x+XTuuFkUJzuY0zsqqrNBd0hMggXDBbElKvj2BRNoPFYhcZ1jJFZRYpUZU2eZN36LRclrv4rfS43FrqPwDvJa9Wwq7qhc6Yk7JqrF6iRi7ORGKhu7gpZRufxy7CVLhi12XZ8cqTjpuoutQOCKVkfsAUaTUoFUcuR1WsUA6g869wGosR/BUj2/BoJNrQgk5Ih+njSb1kimS1o1eT9l1BHYXEJifzxRHdFbRprwnBAceCV6tqWS2qGZV62W/S++smxGGU4afskjR11cxLV1EJnoaoZZVUnagg3+lIQXqsiCtYhYzyTrAEUDdt5vvttFTCLJdlSw7n2gdvagm8yUcsatJ4DV/3kj1PvzwL8g2xXJ3sebvqgNmSt8lZ3jYtvWJYakGZjskdfKcUuEM2ZIA76BRflVqQDdop4IafrKHdS3p3wHo0weu04nj6cHKcSRqwM1SgGjei2NxBPi0PyTvpAjc4FDHpYKTcfnsUp3JVEadxR0S8cDA/gBrO4RruwrvwEO7ECddEJnql5bh02EEhHg6T1i7ed0wfk8OyKeyPBnETadY19is0jiGLXBulqWabzHac25YjuHMkC787ILNmjB3WCcE6aErWqUYD1iv2mpapcTv18yZnyhNSomVTowqtmzXaoF0+LXfKA/wkXWEpe3SjJ/ULRw7Lahz5Llo367Zp8pI3DY5xyBSimDAhN1baVvAbmIPf7RRiCgNVZ+yoGeRUAdccwVcVO4NFrlND5mysElmllxDu9Xd72eFkHJZUlzujiiIidhEBxuP+qAn4oLnVnJcLcp5OSlPS3J1DOYJHcuVtXpvqUvMqwBn8fy+7/2S0TyfH6ooDpUsCWhdrR4NkHlsuC6wWo1a/TqjVLPEByUniGcD7IIJp3pWZGkodvGmHZZDX9TyFus6HJacjUeSbWYs3u6V3N67hbS+qh3g9YM/7Mo7pS9nDjXfHFVStj+7hy7JhGrKmZ7nAV61vqrQqj4c5PUvVJzGjpC51XuZ11nbNbOg2V3URxExsOx5M8Sm+JDWrpcXrpmyCME3jpi/bJlh1FQcxGaSG7IoN5iQtTKu8oWuaOa/naVR3S0JixstFl5Xdc+ciW9bx6Fpgz8RrnTLDRanKuinxUmlQEtpb8Siu+3nRlGTd1sQPpsvt2vNjpWRp2hizJkYms6nQs9hBw7nCsfIwWd6kgu25BINVZUakzk09ClRinOODNFFOUIHWuMdZgnbO1LlELW7Rhj7Mx/hWucJPyEN8RPrPv4ydBzilvRnviBNgPSru9jArQnmKcUUXLabhyMnUbaMmQ8Yzc7wZ5moJlxvVqoRMJMTqMtTNhB7jil0zee7yPRebg3KS+s8fBSwh7+Yrmiu3hbCK45Q0I5wmza6KpMwr4Xi508YlrhM0QLMmME1ataHk9Uy5l+OFmJPrdzSeaxFo59QKMi/oG2yxFBVHiGvtlCiNcknWg0KhK/AElwBVQAZZ9KijOA+/j6qmUeku45uR9LSSRVkP+jRy7WaDp0vttmFnydVoN2QraL9yE1P+DkT0YvgE/vsX1XnsS0uS7AFpd8RGVy+yA6+/rtB9o5343msTGP4iLEb1okc9zjjA6B6NhStyPx81G2Rpk0bskjxknE2wII85Fj1rDQU2PF5VLhZm7pK3UdPlQaVqqtqagDb5IjdL7UFkkVQiHr+ObAN474/iSdZBTlXmODr28oCZNU6cvmyqpkk1E0iaxqjXb5d4I6ruXERRldv9cfEjqm/JFMxIJnZ7VJhSiGajgiv4IJ7D3Z4/IGljzJacpNNy2qzL3J6WM+Oa69GhgnaaNTXToHQh7jvJqVgwxBVeMzNlVL1gUjbEbsF0mCZLmIgytpOmQpoatsGreotP8Bk6z/fzg3JKAh1Pv4QA4vUxhnkFFLqlYrdMkVddPCuYMx43Oe9cRDvHO+Gkjn5BiKCNy7JqRrU6DqMyaMM/jGDsGracK+6K9Ne08YfLjuvnsuBqTs0grbQqK1f+fQhOzGlL6bikpCeY4oLUXSMnazhjBg/EitiMJAxMBFpltKLbCreHk1wU1/1uVYe0FA7bTpvMeDMIsBp1E7WKFKkZLGJFEY657LiSDprnhmkGC5l4fa/ke58SrdU1NBCmOCtbdtH1vutSh2HiItIIXe49KZs2E8akQYvhtKkZzbvBUubLJFTfHP9jQK8TP44/ioyR+Ou873hk3SQiMP04PrIfq/u8kHxs/3WFPnwWD0aw657px/vw7/Ev8QTaX+FKxPPkqfbAs4b34Dk8hw/gfkeTkW6+Tc6bTWlJTjaln0Tu53PFLlq0m1LlJ7gsnZw2d9NBP0Mhb9Ad/H56TBo0G7RvRFLtPR6XqWoHj+AXMO2llKcy0WXqqksTql+tI4vyAIfU4hXuQUSXKOEt4FS+tzAhSxyQ0zIxbJzgMVup0arZkLIsmp5+ZKO6zg+6/hNqyptTvlryxjyoVQiWYtJlhk3BbJjDvGrWjBOMyusZ6grifpw6aCGo6ZpMb3jlSPqqNEAia3rJkWltn4g9IINp6FlzSM/qTlvnbHFYyrIiNanTmjTMpuzyWbmdH5bzvB30u1K4V+r1PY+c8p2ttyHG5KTMXXxId+dTsm6y11wV8pg5ZBadXTXpuapaO2m3uGi6BG9HViX35wxqEZsQFFI6Q6u2wvPSHcZauIZe9ZdRDXEFQdx2Up8/KVliKnOLSnpZj1Y7v0tVotrkQ5H8k9v2QG/vkYkibU4C1iZMr8wYn+vS4FAHsshDuse0nVd76Se3Uu4GoZAqDnBRWlwuj1yLklhxFYtWUz8WlFYNXFThqHV1J8kyRjHnBSh3uMQYJQTlFG1IsQEiCe0AN2WZG7qpOwLom+G8vwOgN4R/h3+OsX2tlb+tmN4pHLsBdS/O2br62p/Gc5GDnYikCP4/3I134P/CfdFzn09sPH/z9jWQ4vvijNv4qigD7Sp834KvRt+2Ip8vmJapsx9M0rosmIPyID1o8uY8teQO+aTcaYjzdIlLYeIWJZA2PkG3iJPHS8tAkHA1mLTI25QLkk1YlVE9+4e818myTw177iIs9hJRUwcyQokDeBaBcraXUxOuxop9nJMNuo0uyzk+w8d5lfOyKFMyxkNBT66NY6PRxXgRhyOmX82jXp7RRKtUlZykJOL+VVJ2lnLsc5N2+Rid4zU9ZCKILaI0QMTrnMvHGZKiRVnn4iqog6vSqMfNMO3wHI9yhRa5wiVuSos3eFcfodN0L1/ho1ysxAexrL4gjbS3Rc+3YdarqKBbLK1Thqt6Rg/KZqWNuvmAZNJOOqtbWpLn2CamvXmvjvm4IbMmUxxzoDyjrmeFu9SQ16Nci3U9Y0pSo6XlLgfVNU/3yYROcyAVV3NMPi8U+x/aI/rgafSqSa/HM5Gz/FKjTQ2qXk8UIglTFw81CX/c5JiozHWyZoXmaIQ6q05OKi7DgaYGBbo3xBNw8rHXQ9wTWFHXEMB2G9+sy7SLmo47MhFMPzfZd7FGbjMbwiFoUtfDBIVUtIEc0IvFWP16auRl5vHmeHNE9Ar47/ipyMZ6PaOvMTRwHk/he3AHOiJdpTLm8KGofHUB74/Wxkl8C74rUkcZwD+O2oCnomN4G26P9vET+A58gbzb88Ygbon4firKFX8CC/uFbO5XPY67+7DUz+f5Kh/jM3xaH+WH+QE+pZ+gZ8y2HFlR4bI8wKs82uySejh0BJnUtJJ2roqYEWaqk+g5O6BBKSlRXY8T/jOy3ufxfM9+GVOs7nFB9m7yuc6BDJ90AfUOmqSMYXbVCbo0bdrvgI9lXFSFfpnhFRIpS6it60sr+WCWh7ir3CEDZkyWiVk4XehZByPjrSQyiVw8dA14EjJNLli+ww3HtaMcjdOcsK2aTDnpJOLtDFe5zn0aMskt5jzMnFnlfr1ANZoxVUs65Ca3aFMf41v5LN1Np8yqHq4igwO4ITL24jMZPZeF72lIRqrclFHeDLtMhlu5eGmAD1K6hiXkYhJKKewgzMWyagnLKI1Kg0wwVMJVZDwXpZv2cl7mRnRTIP1UDY7rQ7IhtSAQYZa0Hpa2bCQ+X0ZZkafVmBpS7V8kaHSpYTXlGWU8RPTuLGys2h1Mco4taRJalS25RQ5zFpEM6GFA9XtWzXizqoYRRV4J657MmwZRMVlCwRv0Cp7ATJpVmmOQJylpcdiAHbQ7fgdn2dIst4yV7hXkVe+rzOPN8WYAvR1cwzdFFtPrmbv18D5cw0/js/ibqKr2e/FZjOM/4Kcwjp/Af8IibsFf4PvxrfhTnEcHfmJfWur62MWH8Ns4HbWL7MEA+jHwom0QY3gnngFHru1x3BMZJN5+E6KuxNcFbPL6JD8pd8oROk4bNMsn6EShnW6V9SgeAw54hyocijU7pqeq5pMJVWoXK3mNoJuW2JiqoWBqOM5TElKunmhi2UvcmKceNa3KyngLMUQWicRNkY/xcXbusw7yZpkmbCpAGR9BwVvyFrwuVd5v8F2AbeMhO2sWaY5yvEqnzAW+Xe6QI1wwPZXEduxhVUcdG1HEygyI6+kRBjMTEZ/PdvFIoPkcXeHbqB6M59rtoF2RiszlMeyx8AGZmIEOubEUZ980gnGqi8+BDqWl13jT7PBJuqzP0qYUbKKo0urGCkggjw0cx2kcQiUiMu2FHTCuyqqashUTagrnpAEV1EgEhRHetbMZLCqAiTZ0H2El1qFyXhNBTGd5jVYo1UQ27k6ri43uqqCDRmTR+KbAATV5R07JSW0WOoKo5fmAGvcyXtobVytf8hLswpCa9la8Wc81r3TU8BXwJG/wGTpGW6ZERe1TzkxLPyeaUXqphqLnKrBpiMtUl3GNTyHn9Xnjah06I1vheAiKFeNSMaVNr9Jud8x0OGSbMkkVrnEaWNmzGPfmMY4c1nEMpyIDfurz83hzvPGgdwnXIsBJvM6ElWfxW1EB2ofwB+jDJ/D1UdLsj/Bz+CM04eHX8f3Rez+Lf4Nu/NC+XPz1rrhfif+G/xL5MoO4G8/hGbznRdt78XZcxe/ht9CBOO7EkRfeSxPfkr29qrWlq3xZzgRWNsQv9NGj4VZl3Oxwi69I9yegSSZ5TIpykA9Nxu7CUqKKepyJK5JkFOIyxFmuSI2XeIkqms1ADX5syOtUw96iN64uRjnCFmpdMis5G4iz7Vp8mA/Z7JRy1bfdajpm1bwaUP2qX02rOSWKvJV4JiZ76rueHuOA6romzDlZlkWTEyM1W2VDGTPJ47REhiqyVBo4DUbBW4lXodt5mVyB1RQPyqQEdFLulgucs0k7bgwHlFpL8BqV/xDGco2HpSl5Kmoia1qyyYf4FnMrX+EtXTHDFgtqcC9MoHAUT+OduB934HZcxVvwHjwYCcrF4bVjySvDLLqWQGaCmQorMV6lmQB2mHf8yVvQ560iWKa1YKSChVifNx/bjlVgh4h0ift8NGJ2TBZ0zrimQlaTZO0MDZLnmjHZPspxlcRMRUV+asmbUF+uaXQNY96y9w6EqHbIsqlQyLNh0tGapZ3HzALlhV1FCweS4dmgz2k66wWu82Iu1cBcYsibVzGVhi7SBg80kYsHHhkOw/iI4rJk6qBNO0U5qZGhLmDBa78eGT+Ct+3P46VoHt+9P483RQfeFKD3BK5FSYTk67rnGJ6LdFUSWMe/fp601JO4FinnZfGb+EP8MH4c/wb/OxbwuX1pqetjAkX8IH4eXWiD68EoUWec52+uXPNxfDNORnfWc1EZ3Y1Stq5k57cUj1riPLfoXr4k98hJcy/t8Dp/hs7xaT4qz8h7yCfmezgXTJmaPCT3lgYXYbuW2k5D52jd9FAEaeux0lCwFBTJl00+YtOuA24x9iRKuIZqF0+aIlW5rJ2CyTyP1ZKEbvCgRM6u313CbbCqf58OklATyqjNqNhKp/RMYNjFrxap/9S+BZhDKSXdPGLGzIhZ4WN0r76DztCWLspCOOsPdqAV50UxesUM1qLIoe6UKm3wikzKMp/mR/mMDMmibPGsuOw0+QO0LitSJCLikrTCddnmE3RRjnONfI5l1X4NwQKejdpQz9/IpPfDx1l8FBdcgkl581jyKGFqkuVa2ENrekj30QEzFLqKjC0aOoXxmAZPcYsW6pjzai7Rg0EEKV3hS3yayqzZcI6mzAh1QZlImtXVDvYp54rKYLAsFVPlha24xQYWvWG1/CUuwHY15RXVtnOT+8TnhhUzE3Qy7saCt+CdjM5sDZR0Uq0yrzUb8c0G3c6n7YLrUeKywml1BbkElSSkjm0EMQX2peInGVZTxYB8LppRJ8tKK4tIe/tX1Bzeg7dhDfNovzGPRdyKD+FSdA3chL03PJXxMfy/UVwt+bru1YHe10cn+Ch+Bwv4KL4BCp34PlzDj7lkGH4TH8YqdnEEJzGIfxxZm21Rle5FZKK9rON3Mf8K3zKAu6PaXhWR+D+C3v1csbvXHh77xlqT664PGV+QY1a04QFz2IyS5ffILm3KsLmH3sFZKdG9gaa8bcij8hE+b4wJTZk0n+aHuU4ZrSlLs3Zcz1OBy3yUr/Jx6ilBhniZiUqseUGGdPdK8mxUh2sRqBp86CQPCdGmWB6o4SgmvW5vWGXUJgw6FE8Z4boJ9SL3u35adaSU9YxnvR7vG6MsMMUkLXVjaUYP+z0ywAtUNAWq8AW+T26nJs2b4TC16ekls6ons54TIeCqbOo5f1xu4Sd512T5LJWjjOO0rIgYa+tS5jXZkiN8TF80dS7zSIjaXqVMDV+Hnf3eJS/kSM7hXfhQFJn15hUhnKIS+ZLjYTkwj2CZ12yHDx7TW/5AQrEXwHRTTfL9noxwTjQ5ncCAinSAThfnD+O3I8LJakQicTSSaTWoZpVRTkbRgjrsuBiXZAh6nHiDVX3q7GtcfinV7bWhhjFYd6wNyenBZryIdUx4aTWqhtWCYiVqVV2M6EJRHjglDT5FVZM3lptkJbBLBZeoqenlshcgGxtVXJBqmNSgGT5AHTxOW9LGVZ2j0KbiKtibszK+CYfQ8xLzOIu34rnXUcvo5vgSndAEfgB/5foHvq4sPbfn9+HPo94vP45/jjg+E0m/fxJ/gm38u0hF+Sfxc9F7P4nPIbHv3qaiNMSv4pfgoRs/h38aubqJl8jdOqmezmhp7RFjYriC97nGQFE2ptn7T/JvCVepLlpmqMpv4ctyTpo8I6t52FVzGx8KB0txOiu32t5gThrFmEm4JAY/Rgd5Vvf4Q+EIC98p67KoSdjqIM9ZMbzFD/LX8zfJR/lJucAHAuYsz+vx4qgZCgaor9ZdaDfJIH7GcyXwo6AuPUslHRS6bCR3BBWOGM2rXLJp3V9KFdB0VA5v2Ovy4hHx5jTOwfQZkTXRerASc7nLzYjcu+7SEwd4lZdoSpZM0Wo5xA/Q3VIPpovdfpq3TXZVadgFU6chMy6XXFGbPMlHzQ5tUIGtCR09Wx+gY3SJd1mMb9SO8uJRVdg3R0YXbuiC7HV32HPHOvE2POvYy8qro6SkahapTr1hUfT7IUS8EqtChqm8mvoByJAeYyuP8l0snDdpGaYebnNRs3DA1RpPJguY9ga9KVV4waKZVFnVrhyXzyR4kH1X9MbDTl6qEVV4mC9i4RFc/cY6WsglbNq0qEYLQaerAXkGQ96i6v58+AMJZLCkRr1FRShOyqrOF9oI60o6uYcmacX1veAn6bzM82ihi0AzImHSggb0ejC87JkDtk+WjWifMgFyXnSzzeI7ovbIeJ6w1OfnsR1vwXsjz+RmycYbCHpd+DX8IVZeZ5aeO9HvwDX8Dv4Af+KaJ+C78Sms4b/hUbjueq6l+Dz+GH+K38F/x+3oxs/uu7fuKDbxp/h3+AP8adQtMP5FUGP2ROZvx8fxiLofbx3/yfy3hBfoOLXIaDEr0qCjss3OxT0l50yOtvlWcyoNf8kc4nqQlorOhjiqLIKATkjdFCQetenu5pIZK6pK3O+w0yTUoAPSlBW7LLfJu/m8NMNAliQbEJWpyavUCppUoypXTIlCHZJxskZU4HU6zdskYq3rYLGsuyl5S9THthQJBj4T2Xbu/+qQEVOSVc7qjrISfKXq8uA5UWg7olvUopHCHgAq3cZWDumF4iBPis938uP6GBVZ+CKdsG1Br2yawRVFB+2irPKddEGu8lk+xzuyRjt8iE9QQKXyUIDhWEqhHR+LChReKpm1d4G24xmcdO/odLJLo1KVWV1uupje+EGYGmXG4+Gg3uIHTZNrXA0XZIDKUrdJ1yhyAyfR4ejNKCUpR1tmcTdSrGWMv+huO4JlxequqG9G0CYL3JCmTh+PrUZ600rxfkbgxZgxAT/i4DkZiC7obtGyJqY0pBM2WkSklm+04rsOevnoE2UE7VSi1XCs6B1ykImDUaDhBOykHJRFf4gKtmFKfJLv93NBe6mdVnlOwKHkl9zjKVMjb9GdJzdTH8X6y+iP781jAk/j7OuoUH5zfAmgN4w/wm9H1Q+x13XPHj6AH4XBZcxGzyxjHgv7LU+TaEYwO4UzuBS5sgkU9+W09/5mcAnno8zhF1+R4R5P4hZ1G7RU7EfoCT4nO6ZkVlykS86aZnmQN/0l3jEP8x1yQp6lgzllOFgknzdki4dzWItvQ6pUNktm3S5yfBk8ROfMEWOpqcNgmUc248VIHLQMmuYTtMs1Lf4ktdm4qDWQl0s029kJFIzQhMyYOb1AizovDTrH75QPywfoPmlJiWrsoNEyUTFYkYyZs+N2sDIqBX1I75hMuTOIi6KYxMrqPhS9sNsYqgdj3WA8B8YKginZsitHPHcsppPqIpmkhsny3foYZfgov4uOcdk8YKz4+gDNaGNKckhuo4fkEbmP7pdDusiFwFmZiUHgHjz4iqpvscgW/BhWzgLxdzknVPQsF2XaTPMxf9aE8hTfIiRLOpTDtjOE9SxChBneqPQZeN6CmkEWcXUch0BD1KSa9Lj6km41jSGMveDLFpCNSt8cXLFnJ3RJ1k2u2m099wlPraiZFyzWZWTQG5FgWuC4HpOSrEnBdhdV2nVAUK4d0It/TJdbgIrAnszyphQrCWfmBvDd3KrPwiqTNathrxPr99W64mU5FmaM6y5yr1wpzZChQ9QeWJqigKYJbV4sGd3OH3vFtj+xqBnqh6P+gDdtvTcsjTGDv8GvvWrlw5cCe5+JpKW8lwUu9TKPnx/o9V4jhN8g7fFd8qxcMke5wa1gwfbKKXlCjpkVtilQmc/LAdrhr5ajJHxe+jnDx83xWmwJD7vi9maQMT18ii7KISrpkC/TTj4h2FGVvXoMFVeeClFtMxWuy5IVahrDE9zWiEre5yMlZINlcJK7eF5bqnK+3EHQo9Q0G7TCvZWOwiBPywJnOcc5Idrmu80jcgftcsk4wdCKVKQsZAo61EfoEm/YCer1B4N26eRBbtG6GZGEVpKw09wMZp3VyINS1cMWdkqO6H5/QO4wFT5E99EhedCckwt0zBGb7a3yAD/Fp/huCe1IvvdeTw3ig5jveKUbzF4U6h7ctu7qZRPUbuf5lKzKIxTyZbkUDtsl2grayHUdmaOWpLYxHMsrHzJvDtFEDlA5NRbZtK7XqA+d5Q3JUNLZe3k19jK5V6gcXKPIUrdEkgo8yknXZPIaCmpPqHEei8rxQjSaijooTU3bkHkbCyIphvaXQZ4pDHi7CEDdEppVGiAnAR8ttyREMSjOIW+Y9jLGVZfrVDIjm62USzPxEq+bIVOQx3lTjsjdUuMjpj1om44bFwT4cITW6hVj3cCduON1FOy9OV4z6GVwDT/1OhNW9uyuO/DOaL/PLzmL35CUerG01AtT+d6XJCy1/7l4vOx08d5K98kpsyF5qWihtK3pS3zenHNKcNziE6Fikg9JRXblIbNkjDwqZ7jTdNGIFOhhPi9Z3aATpmm6oYRNVdoVsrHrfbo6MK6+1blNad20E5Tkeapzk/KVER13zXzChD9MK1SlddIylvNK+D4sqqoTIBhi4yJNYU866lOrk9X+IMO2tJTrdCHQYlu+Rw/wMI+EI1KQY3w77VJRVthSWSxtsutocU5KVkugSU7zPRSWRnmaNvQls2Q7NcsxGZJhc8gfCPqM5DtMTdiumqNyQe6QB+RBedSc4oN8WvtmVW+vZobvTjyBjiOvbFW7fobV5DOL6fosW2pwnS7KBte4fBBSlnGnQ6I3daoRO+CES1eD9v+M6dik91YUR3mLl7QH5Lxxtaxm1aA3502CusS1T5+AOomiN6cm1ZSaUtMv2GZdksOb8+IqjaWkZEyTqzRPvZPeAdctxFuMWe9eVF1vEHfWVjn0J/qcMq2a9wa92RftbSr6m3AC9t6KI61kaVNWBMcw4Q14s2pKzailGMN2ck1Xm/HAdRyOpWFn6aDfX1bTiqdpi/vyMW1k4VBcTkTVPIekRtWCHOzvOua9Fd0LrzKPUarj7RGZ62Y64w0CPY1r+NzrrrDyRrrs0e/Q4F15kk/Lmq7SMs9Shc+Gi7Iqa/w4lXmQL/OGBh+kU9JJZbvJhi/KN/H7+RBvcYFHpFkc0CjAZGWTC6X2MGdK1O1HlZXxqHZvCJ1qLmYQDnFDDPeQ6xjhG6NLpI3PZTI+BZOnPIvDOIYpr8sJTalQnXZcmxFrbUmWeNrORR22iisdroY2GwmYLyvX5pt7ZJFtsBQoHdEVlx1Hb8T17woHM/Fif7mPmM7LwTDHy6Ysd8lVtpTjc3wfl6klTzmKND8gTblVjsiO3qUNOiq30IlIHn6T7+e6kJSKtXJj4qs7jgLpVz7/XhfQ1/W+2TM2q+f8rk3Uu22wFBdjO/QU1atOMMpKwS2nGsiX8q66H8APuabFKSrLsrh0BA7gLE7hHPbJ3PO6ThmbqOAtuIZjOIYzOPe87TzOwSV2jmNPNaUKM8FCJb1U6p2CiaS8gkQwpgMucSHsdPt033IBZ3A6+vTzt9M4jrvhYnYGtp8tl8IOxgLacStO4Cxui/r1cgeXJLuJCUdnVkWYIdkqDDoyeTXp8uAGPM3NXIyX9azfrXUZ2bgMBdlGfvjZ1ImXsy5fcM314a0RZ+8m6L1BoOfqMb76dbf09vYef8Ed7pUTEl/YOOW1l+14+/ZkTMXzSvfQ3XRJDrjUq+TWO2Sdr+oSp/0xeZjKpslP05wM8hW6wrt8h9SoIMzvlmfdkg8X9bI5SlPOaQzb2HDDzJZW2Ob7CjCeO9DVqHkHVNa7hlBJkas0WYrXkpzTt/BtchsfNUvlVClKiM7EFr3rtZ1TajZ+QLkWkMEMneb7+YoxlciFM7ERr9ebj7lTEvYEPq8ZS/2CKS+TyMeqCAbYcFPPrqFTzUOSwXJQpjEnXBV0E4WZBWdFar3qp8IBPmezMsVnZZ63aVPW6RyfpNvpotxr7pFHeJd3ZZsWXN8Nv1qr939VgoGOV74ElQNt7x2J1WdiS11Bt+6VPq5ywV+iA/WkLovh7lIbb8oyp2Sg1W4asmF7q526l3ttT6vNrMsmD1ZTpT7p5R7poR7ulb5qe73TNmXTZMKOYkr3B73UIy+5ufdzL/UWOmzCjpjQrokx8+E0Z5zCoeTLnToV9HAf93LPS++De3QP9+vuWsIOG0uHOduI+93X3089tk/3lJKS5qOcraZK/X6v7jMpM0unijPlzrAn7JVVU2zEzKjZCUfNiD0sfeS4kL1Bb7FrrvN9sdjTXiWSNXv1m/KTqN8EvTcO9C7gWpQ3TbzJLL3XfjSxF3wyFkILX6VDZl0KrmsCwFt0pxwPXeuZXePzR/lraMOc55NyO18QuwxBOkFn6QznKWOK9qB5QEw4zt1l5PrESEAVvVYYCqMq0jWsYVRZNYt3OhsAZoHvoDt5i5dp3MZN0rgeWnXiYJ7aXR+NWZWNTceyMZexTMftrIS6TFlJS1ZEh3bRCQukYysxgd8eZE2NmIZKsJhRs94BZ/fNcmhWynFnSZXht4slS0kneGQnZF3PGwQJtkICHuQt3ae75ZDfS1mp0TStcpE3xMWgjpvb6U6u8VUpsWtXVOJyfbXvs7EC0P5qoOdBJZ4ZeWgjX2wElaAiwht8n16jq3yEDD2sd7QOVukRvSPOFgvpKl+hUFvtKh5ck8c7+G5ec03JdVmX9jaukCGiW/gqX5LNIHDPXH/tpbag5FepqgOdNU16TL5CnqZn9UV2TEob1INX/KwuUyVgMXyc7pTbaVUHVArK1/fLFTcjThyWj5KmCpV1mUk2zSN0RIjLJHyJr2rSwnfyefb5Pj5Kx+gqSVAKyn7Nr24VOz/r7LfEq8xjFOJ5Kkrp3QS9NwhYntxv8h3/W4BUL+pYuyckdQ5nI8bdXmJj779eRJaKRSGy2yK/5PnAVcZtr7Iwns92ikVssrN4Ck9HzU7RFSt0ymm5jRpSt0uyJGGtm3fpHnmPrvIlOSQr/Ky8zWzxQb+LK3S6NFWOLYOm6RRVaWwS3GF9fkA2jEjZzldcjUOBt/jWcEIjSFTj2utxer4xM2LzUmfH1mrKITuvsYRljzAYk2FKs5WK5AMn6ok119UhaWaEQ01zuqcUtfK2CZ6UAmkZXnZqKxNU1mQGZh1loq3aqVMDMZqWA7xt5ku9PEGj/iBX+Ky0aI6madpsyGWzTtOs5QpfkQI1+Uk+SWV+gk/yEX7EHuUHorjfeblT7gzukAdMnY/Itl0hy0YqulKv9H06Tq8Oep3unDwd39roWB4MBvWwjNAg1YMSTfFhGQ7m9S2Z4aCPVuiYjBTHXCKFd/RG0OsPB4P+cNBf7CLiI8G8dOsRfygYCob8IX+oOOIPFTuDESrzUTK22w4Ew8HQS2/+cDDsD+a7aJQMb1FDAvYDoQ1Z4+VCX74nGAqGX/bTw8Ew9+gxs0k7QZa7iz3B/lG4rTjMQyvdUpUdnqFOPVwc8of1AE/TcS5ylwwH/eTTER7NdeuAdoMB0noz6JdjetYf9N0vGFwe2OiIvSNi6L2apedFV13jJui9caD3dlzD/X8LoKdunFQvqvX4IN63/38vbgzkkhqD+Fl84EZk0bmpQ/g/8JP71ONXsgVjz8tDvx/3wilBHsTHcRkoeZLm07LKRg5QmY7Iw3yFzvAD/JSumZ1iLOzhh7nBF+RWWaazcno51YyXYxJIy9SknklayKwc0dPWQYq1WoxU+Fa6jxcCLMFHLUXz5LPmJTtS7HTynuV2V8uZb9tT/s1GeUYzyAXdIGNWeJGFVs26CE2VB2WCFuwSZzkrS+TzGt0pj8pjfI+0TIE0heSaF/pU4tv4bjnJZSGqiZgmXZVLxqkPZ5n5ojltCzTKmq/yFo9Kge4ibSb5LFuao4M8ZFaDjLESSktatEMX5CyX5R4RyQZFNlz267XqxGc6Djpq8CueTtUJr7P7A3PnSjM8OKyqEZfNdOiS30Y5ndPgImVdTC2cYVtFgG4sK7ImX0CANVRx0Mkk9EuD5g18rEdtfZwt66ou3OuFLi0mzPW43nA7KEWvlyOpVsdfPAwT9RK23SYvRhf0qMSday8w3TwrZMTM78kKHMPO/qeuf/4ADiNAFmbR1nihpAxWUY/62O29ftAJ93tsuPigamETJWw4aak2rtKEwe+7vfY7xiEj2yblWm8+wS3dZedNzo8ijWOop/KT1fTIc+1H8XmJrpdftd14Kop73AS9Nwj0vhr/NYoTv96g55p2d2AWm/uFTY4sNRDxkxzoLUes1DaU0YwgsR8/gq+4ITjgjutbcA3fsg+JsSgi+MLNweNoxAFUEZD24l24dIPnOovPom5cG8UL/LDcw5f5Adq0OTpNp22SDtpN2dG1Aqgpt+kxPmkaps7vpPUAS6oUs76Z0Ets0ykNM0v1uqog20kTsiIls2veIh+lU5zmNTkmWxxKtjSrZ2WRVqhoMtqXU3wXHWFHE65RnapS0oZW5QHzfnmWn+X7pGGWgrzrwkjaFKkoRZvWc1zny3SOj8ml4ACni0PBiD9M3brIJ02Fx7nNtEtvro0neNcUbVfTKyfCDrsmbFJFhH20Rgs16DbepGGG8c1kp6fXnFqIbvKGnDQn6Crfz/fTQ6bEh7keLjhNU2eFBqstmXkm9bBKNRExc1825poATPydM4VGhhqyzmUp8AJ3a62Xi3FelZ4w5ap9Q1WOScWIj3R8QFE7tSivseANeWkv7x12zve26CzS3oSXUWm1GP3Ne3MxH7otXDDbVDysgIXYsJdRbhvzJmOTatelMqapKms2x8N+kvAjEK8QM94B1MBdelqHvGH9cq+rcFn2xr3R/c+Pe4teC9wna1Qzg053Ohdbjr7XbUtqITaoqEd2LEvSyRwsq+nYrGfapWWWWyodq8by7XxITwsoxRXDgxBt8tPgdR4ujupl1tKUVb92dLTrFB5BZ+VV5jFSPn07Jm6C3hsHet+Bv4mk1F5v1eQYHsfv4Dfwp/jtqMzyE3gX0vgrvAPAI/iPCDGIX8Zf4y/wa1hEL34M79kHvT0m07/G97p2Yq8Ya2zHO6MOLm6s4d0R/CUiJxrwO79SSiJ8kB/iW2ldL1K9NJCOyxXe9odlXTS/W9fsAN9JJ0yDj9hA7pPv4ouleclISx7SNTkpj/HRQMtlekCXjRVji2J5gy/LR/lz/JPyIXOWVpk5TytSFJ8KsiLLdl4mKCfH5RjPmR4eoG7u9bO8btYlI6M0I8auS7U4thzLx3WcYnlvAHrQQWMwMOpaVXcGy6YhxaiptDZVPegE6p+DYAGSN00eLkS03eIIr8ncpLN0+qlaHDEwQ3RCskGXPkWn2fBjcpIv6Dv5pL5Ddl1Tc9uSY9TiAt+la6agNQdGTJnXwkrhcvc3Yfg9iHnq5SN68Rjabh/88F0pR6ox3Xacs9q1H9/gB7XPVa5a6D6pO7l428Grwdw2ZuIt+Elp6uUgUnadxLBXhrTbKhknIupC/tev+xS0OuQEUbuFZcMOM6aVpxJRPW4ZmwnJUJMqMiedgSLcDlYL0cFmsay6lBNrLCR0nynIqpTDUb1XCaZSCspZnVQwB/SCn3By8Gk18rwfNu0Z+AO0qdOHFDCnFAbVGUiS6rx8BmPejGfANcmVYcBjXGp4eoQO23m5ha5QSBWmYCEYks5MagFL3PutqfExJF9hHqPVfRvu3S/2uzneEND7NvxN1Lor/rrv2enpncMIfhm/ihi+Ed+MGD6Mv8Cj+Ct8JeL4bvw6ljCEn8f3IYkf2dfTi0dW4X/AYdyHn4321IlNXMBp3Pqi7SyO4z78Ir4xkh69FBVJJT7//W3fVjzDgSZzmzwYdXe9RR6mbbNBn9b38p18Vp/gT/PddIGv8p1yDzX1tJzk75YnpBxMkvBZOxos0UVuSVIqslHrKA5SUTfNNoXhkHTzjrzX3CZNMjYr47mkxEjNooQ/isrJKjHKyGqln6FnXddcPbYYsw7SUFL1Tl7QNWnYlUpnGdKjS7whMxKP+jPgKIBW0mb4Ej9KNZt0/dhOxuqQDqmbctjhSLfbStKyRoOTscUUFeSiNGmOV/lJPkclucq32hk5o0Oe483cqG9o0lS5QWfpEj8mB/gcVWhcVjgwoZSkwqv+bqsx+t2J24FU7OWuQpewjs/Gnx1stXy95lpdu1K4IKbbcu28KqepxI/SLqfNEdlwHdDMANeCgRDdMQ2ToJYsLYFUBWMY9qooxUibRjHlggDLWEbv/rdklIP6sheO8wZxJhWigRVV6TM+b2hbHOF4PCKHk1p4QR+1YWRVr7oDBkW13EaL0qSGzFdSziV2ZX28JtZ0NHAGI94M2iKKXGy/++4mgknesOMteKqgutDnxCISfj3IBYA36oXgvAlaXknJkFygUFbkPjrDVb4tmC22c6KuVl05YRf5evvURPIp7043W+qVkm2T+ECEyTcrMt6w8bP4y8jpfL1BT+FD+J7o8Sn8Pubw0UhzxUHdNXxfdOr/FX4O53EWP4Y/wyS+P4r5pSI77ScjGapn8OOR3EA3zuAJPIiHX7Q9ivvwMH4DP4J2xHE5ctIT+wE+BSS/uXBrWfNyYOiiOUQbUqEJOiydNEtv4Zqp7sR0ju+n49K08+aWoOW0qwLN75cjzP6A5LRv4HsSUJ7beFUu2DJzMLMYW3P3fJeCyPM9dITI5EMyDQdiMsQp8SiKUIXKX5C7+SFboa4sPow62lWgepTLz0wg41FPuGJ26Ha5TYqc8LEJz9NqOjJ8bB9VgqotUklKMrLlup6NyJYsmlSmU/fwiDkk9/OGlE2FzvCDsibzHPIVzoXQPpfzMBlZoji3eJyP8hFzVe7mq3SO7tCap80pLhmnT1wUTTWuc0vv8kG+ve97XTlg6iWFZJVXUeuIPT70kd0JndLDukLrVCh1pV3tAmwb1fUgT/IpSZPh++m0lCQdVuUWv9co8RjsccvO+1j0AjWLAe8auuHn9G5tgKKai9nI13OL42BUR6GRS+g8r5opPUCW1qTInRlVjiplnT506SUW3DCy0Wdd6VotpseobNYoY3sksA09fhxlxFQuEuG+HgR2rcRZccFslfoYM96KKmDUE/gxqpg8RfJh7Ok83xpkjOaG3CNnwjmumoOhYm0y2kUYQfFgVMqyoQuFDt2pGx3f6TK4yZcW5N2z7R6N5G5v2nlvoK33a/jzSL7p9Y7pxfB+fCo6uav4LSzd0NN7K67hY1Ffvt/EP8P34ofwOXwCM/j+SGWlE8A2/jN+HJ/Ev8bf4DmM4JXiI2+Nuri5sRU1sYy57i4R9M0Pfbtd54qEpPmEy8LaXc7xCB3w24j4tJxi34CIt+UhqgjLZb1IaMR4h65QUVzNxG20UknoEbmdnqQNOUy2iRx2AZVQ7d6Yxwjm5bAcEB2OVpN6wPhO00N8M0MDPCmsQ502ZBs0XY+dx7SXRht6saKgnBY+d8qSHOBVqlBFiCcktRs1i9RxWpFWMDXvuWIvzvIRPsJn5F7b1DlTpQrvygN8yiwGI9wlJX1Y9zJWungtmGBImlc7lPHluKT5Kp2SK3wrHaWGhFLWG3TGxQ3NodKknuecsU7IXpp6XXb1ufLxzCdTP4iRHsS8Fzhear88Uakznd/pkid6VYbyMJ2GZF0bPR60CWiR5ADY+DOE8pA5KrOSYct30mXjmwxP6k7qoVWZNDiB8/gGDKkVdRBmnnZkwvXFzao90MtiReXUORC2lWmnUB4xD0m+uSf+oqB815zxFcYSWvjV6J0ZJ8/aLrv8pLmoJ/1ULXJmjJpW9+y/d8wLYBNizDp3ABMe1EW8H+wI06E2pi3oCxZ4WZrysBzSQXGSRDYEnDTWjNkebgRtM4o6Oc11aZn5PkUpyugDB4anbo9/LyY7kfrCedxriXUBXxm1OLhp572B41fxF1h63ds/Okvvg/jZ6NS+A/8ew/h4ZOlt4C/wg/gjHEcM/wJvj94b4iG04R9FMb22qJzyCbwPz+KX8Md4C4YiJeUvTGSkoDANEyU6vEhf+QO45UZStzfxmYWPh62gygWeljyfpqtynN/iZOP15YD1jhzlh4OpKmzZrMgVqfBxOqMTFLMDfIx2bZ8/JOf4Y+ZuqtrxIEslf0zKkoWa9nqirxvHkufDH5caBVLiUAZc625qI19OyN1yHx/VM6Wu5Vi5n+uSp84WptRibDZ2EIuwPZLjNaFWwlVzlmI8RyVTC5ZkUjK0K9vBIs+6eB5VjeZteprfYS5y5FTafrPOmYKrO/Aoz+ulDg3qpV1/xsaF5arJ6i1+iqt8njc5T6XSAJd0SS7IJXqCmlrLUXEdgEPNVGRjatySbdk1x82dpTszP9D5o23558WeYjcuzIHUA32fo41Q8tNmWK8Jc7eBJEyWa0FNzxa7dV368p18cKU9r2TZ0BIIH4IckB3J6pBaYskBbkHa/DYdq6KBOyDwB3idMiteQjn5TSetuuVK/hN6SAJZY98fkSxXaL6YFIyoJTX8qrmzGPqQV8dce/FeDqikp32ngdLghbDb5Q/eiqKaUlAznkbQaSoSvhdruBO+Y0ImGynu5V25YILIQfaNL2fCBSdyUE7plukJPMpxPQT7flb3coFXJeTJNayCJ3iVpdpBVA1mn+r4RwlzQ/3n+fM4iAfwVVEK7ybkvYERvTb8Lv4oErl4/WN678Q1fB3ehv+EjwL4h/hGzOGvIon4b8f/iXncH9l8j+Ma/iHa8Ev4yIuETN+DX3hFeW31PJdBRbbjx3AOpAjlzs/M/oK5nbe5ySWyNiMHeJ0MTfAOzdEhfoRup4P0sHyFmTWat7jJh3UtAgsUofN0m3nIHJIc7/A7gzWZDbuDLu3kN3dprow5LxF551CLsSJKI7ZG0zxNVRPwjJkmn4mnpd/OmpKtcbm8KGNBXVo8ZnEAIahDFk2ZcuW2KVAXDZoxPeaP04Ip84PyIfMcP0RrRlPWzpeHqdeEcsAfYnAnFaTIDb5FpgJcUQsxE7DdUWmPZumCbIYLcoQe5ZoRuRQO+ROUX4tR0xTlor1N7uHTfETqwVjgunfkKRNkuMglE3Jd1mWXTsppe1k/bp72f3T0Jz3XHXHoefb6HFrtHx3/PnPS2KKLAy6/FaJ5nRYcZeSk0pNcYTGHZROwiyT3gNu4JekKlrxaGzfM4Dqq7eGIzPKqeUQOcZF9mrOjtjdI+ljyuCpFjo14mUSIOsLucIaclnSRepq431FahqhGZSdpfwx5LxXdbl4e9GbVhCdOLmBRmuzruAtFkDITYk09zMsoJX2kVCZhoHupLmkDq/x2GZIJnSFtme/iK5I3U7r/cKIK7dMKYzpxRMkqLQNOULTcpif4VqpzxfrlHqfTZ/uIeNMOcaeUjE+lll1+x+APx908Dj/v0OawinfjaQzehLw3GvT68Yf4ffS/7qKGzvp6Br+Dz+J/xXvRDYUHcB5r+G4sIR6Jwx+NhOp/Eb+Mj6MXXXg7TuB6n4ZEZNudwTMvUZz24lv787NiE7gX71LP4qGFt9pP8gN02mxZI3meE6YrdB/VZY6shizxUd70R/heficFcpYfp1u1y3d+lqu8wGt8mdflqCN/BAt8RNi0zBKPUpHrcguP+JjxsL+el+Knwf2mxos0Kbfx/XIqGHeRnilVxjqo086YLBU4K+tyu5SDcV6QDTlognDe5oyRkCqmpstB3mT5AN8iJbPIWQklMBNQQRetkPa7AdvmOyn1Db5Hr5o509VMuAynnqMFWaNH5ZhMcVnOFcfWIcK9fjcf5WU+z2ftVd6lzaDAjl14RB/kM3pC5ilwLS4l4IrrpyuHzHm5Xe6RR/V7ww/pB2N34f14ApdwGidxHne7C3X0XPUMb+t1Wi0uGGPqqx4P8pqUaDgLH8OQflPg+2ldpmQn1xdCxnkt7B7z8oomzValh3BLpPYfjvFpDnhOxLXWYTJFmjHDZpPCJViXDFgyda5Jupo0OImW6vcy3prj4mW5xUVus5iOzahxTH3BHdr5i57KeAeRQzCmy6YaDgrKatyb8YbVNprgIetLk8ROuLgfD9KuCcyATVPAwlUuczGY0tv6wHHXwh0+HoFkpV6J7FLXJSXvaXAgVZrmO/k4zVXbQmcBxnnBrDIDNM7rdsHBn16vHJbzyat4H57E7dE8nsNdeDfes9dw7iZR5Y0GvV78Af4Ag38LSq4ePrEvZPD8557/OHGDt/RiFrv6ksrQ9vbUvcdI4LvpXXSRD0uNSISGghzt8j1ygi/YVhWU5TMyu5igC7y5GBMrD/BZc0S+in+anxSWVX04XJYznNYIs2aG2q0RY4rCdFhu1b0ZjHsDmPUCr+aIJJ1M/DjfQdMyZ/IU8LirtFjBP0Alrtu5x3fWZEgX5dPyafkU32HKXOCMLMiUjOh+amPwoLFhYDsJeeQh3XrRBHyKHuADEjeY8vqc9HzJ5gXBsKzzJXmXPMlsZqjBd3BhxjX3LpWd4IHLJc/yPXLYnOEjRnNO5qTJJ/lxc047zeUtKXDeZKVg2dQopFXZNIflLF+kB+Rd8mH9pJ2MwxtGHbfibtyLKziMYhvaELT0RXF9eDfMpMnLpnQvQFa4xSuZRBmrTnxpns5r0kfpUjhQAme4FCRszIeZ4dVscj627GXjTegxXqt2CfwU98kMOy1nn326wPfKjrPFw55alCSa81Zii96y2sCcN++Jqy62UuPZZZzAincc8RsZ3+ugN67SXsWRaYq6SUszaCAda3eqKV4mNhXbVm6vvwKelhat8yl+iLcky4aZMnZcukoJ60SjyuPemJeNLcaWQDNmrdwRU8UY9+v1YvJ+UEGcOuGmHOHEAo4pjWCIS9zgcXawuB2OsoPVOh/Rt9fHUvCGUMOZ/Xk8gmK0+hM3rbw3HvR68Pv4o78V0HMxve+PSMTJ6HTH9psz7oVzEzeK0VS0ENQXuLHqS+jDG31CoTMGpef57XwXH+cGaVoWbUq0xfO8qw3fS0eCcTopFzgmM3LaHPZX5VF6xCzaYb7Cz0pLZumUXJANfpy3dI7vMBlCMGAWpaCbdJXP6M6it5zcxiXofs5RyAtm1LDoduwqDuSYHOGyZIm5YqqmFOTMCq/zST5g1+QM38Or7NNyaaiecmVnWx4TN2VhN/anqMdMfCmhUfJsyewQmxUhvVzt1CPcogPk+nEUqM4P0a20LiXJS0uPWQS9UqXxYkpO0L3Ecpc0OM3lrQRVqSxX+aqc5SZPmFDuC5ZlhAPtS2DFhLRGa2ZLjtKtdEUe1s/ye+TAXDKeePGkd6pkrDjAJ/ig1EPfrNIgTdK6HrXgYTZck7EDsLE/hZSKk3qUL5jznNczQdmOhWgl8yDLocaM164ysTxMmrf9Po4II86iavaK0BG5yu+hs5wln1f0pO5pxRwvrokCQm/JW4ldwzZkVjdYbAcj8Maj7rKxyFVxa2XZc8WsMs1NHXJPAYPeYizrHVRNlKExAknxIM0bX+fI8mPyJJ2TzWAJMad/mINr7c05WueumBrw+tWMKnbTNo8BnADY8pIs6BLfK9Wgm8nOFBWwEqMVWjVZTvlOLr8edlCBS8yyKie5Oe6lvmAebwir3Rxv4PAihaQ/xu9GDXVef6N7BkvPA7PrvQLwgkicd0NK8Qt1e9WXsESU6+MAr98bUbLDT9AJ3uCQKzwnQ3SObjUZndUjcqfTLJbn+LIs0hVzie6QI3RRciFsLz8olzgw/dQMZjhD99KalOQtckAXnCMkVd7lx/mKOMrqABelxfWgYBcowzlzge/RTfG5KgflIp+WBR6wfZL0p6Qq1ow5W2PaaRtvszFzbKVmfNrkE6QlKahg0RuJzcRq0ENcDTKEopO4DOigvJU/yU8GZZ7hYV7go/6ko23oAj/Gx2XE9JuDvKVX+BJfonGpSF0gEmT0ab5Id0nNWMNymup0idJ2zFRpiXKmrNmUjLPbdvgWOSt3mbfKW/kST4w7Yq2334Fkf0t4Y2pTcdGc4iazLPCG6aIB2QozjHqcZnmVOYiXEExzy4fp56OsqUBH+HbTU0APwoRpmkWDJXUKy56BXqTtsBNogQaZTFkKMnyn8of4MFf0RFAIQl2nktY6a0aDhPutdUDdiwr8Tp2nVb14GluYVw70etEPjflYFaadrTTN5IRXxKw67Zo84jgK3TxLRWKqUpXZLBbn+DCLTvkpPUuGy+FyLllEHpzmjaBDY8zrVxNqwqO6zRAeVgHEyp26JnlqyWoFZpwb0uYjHOE1tjK4gopHNQkHPcmJ4SUqm206pvuc7MCNefT2Z/KmW/smAb08/m/8wv6p+dv+NvUaXlc3ttcKetHycpR40ydX+Lxs6Lou6JrMUTtfpEvmRNhtBvk4sbnK/0ge4y1Zoy4K+Q59udQuHlf4Hra2ZDa4Lg7YDvIoz/EBGuJxykvIB+Qu/j7+Pn5U7uV75EBQ4CW7Qg74htnykWDcj3Es7JKchP6Y6RaiipksJyoYUCtxKHb7rEvxEHiUb6Xzskk1bXhR91yLKkF1mncpV5wQonUqBVk6bm6Toslzi/Oi6TCNbEBUoVc39RzP0QXzcX6bi/3xFnWUeq1ZifEun+db6Tgbk2WfT9EjmsXZuDXt8zgb1kYHLanaNb3Jh+Q4X+T75W18D5us6lZfeMvpwKxqIeiiHVnjEhme5o1Cu+nlbdYGh8DdVNSbPF2GqdPSQZhlU9BOQvUk3ytF2+0qdGmTpkaw4KUxEiuAZ6QeTpLlZpDjIUkWAbWKoNs0KN1C0K57iyMu2kbWNKimi3Y67J2OEQgGMsxVqUlvHYI2FcOYWsYvwy7Ihs5JOyPAB1Bpp2FOG+EmV0UoJzNBP/WECYqbqhTL3h/ge3AI0m2mWOyqSXNWyty+irFYjxrCNZA1soKleH6Et83DhnTfdJKbutOkTM3OrIONrNOUS+QEXWabeFVxjg3PSUNKfFT0wagfyJdx6745/lZBz8f/i5++0avp9d6/95L51pfPxH75NJnrSUcVixmIz1f0Dq1ThSZtyLmVOO/yXfJBacoFPhEmuUlvJ0frPeJP00F5RkKDoFMflK1Kr0nz/aZBCMb5DPu8a45TlgJj9a48Ik/yx+Xn5VPmqKlTqIv+xHJiNBKItyO8roddtcIKOE3301O2RMkirmHSc7bJjGr3CCZlc3wXHTOTlCzFuUNPaG3qusTrchffp1uajC+Lui/bzVXicoywAklKmR+WQ1yo9UqfPks7tsh1usvu6CU6JPemOxnmaCSOdDf51HIEZ70j9/OdVMwl+CKfMX0yyRVxkFSyFddVTbb4KN/Kd/ATchcfKvTkXzKx2AGNZTUKmqEjZKlOWTMim9vJoJ0bLKvKIKv8EV7VVsaoeQ3SLS0zZkAJPkKHnUiT30/DtJHpbOI7cRD5FM3KRXpEz3O7o5HchbyaUpNey9GcK8Yed6IFjmYc0ynTJSMmQ6FpukbdpiiTHA/jZsGshvORKKmqIEgayxXpbzjpgTSJLes6NUTTnD9gOkxC1FIkROD387pN+6pbZdWs6lAHQCjGy128QU9xK9ef8lYjp1svmMZczGZNTVf4gs1mXAsAEr8GmqQwGOVNCvxOJ3UgQ7IVLBfhaDncRyWytC4HyqnLN7HlTQ16Rfw/+Jm/ReP780A0FCU81YtATt3QShmN2jled3Xboq0jotB/8RFK1wnXuhi2S2r0gZN0RF+glgtYB/16ky/yFTotZ/mtvuY153DycT6c76fbqCWGH+cPUp8Ba77AJ4IlPmY+I/eS5V16jLblGNdkkVZlS2crneKxyEfkbtlgscsmsA1e57Itypj2+bieMDEKqB5M6Qmucynb9TY8iG5VV33KKQqFw6bCa7Jultlb9la6zYRkuEoP8fvpIXPWrEuaetJqKSEtE1VbrcZDBLNsTbffxyW+jz4jbyEt/dpSwE6sakdatMsfkvsllMOVZLhilvkgX+XLlrikp/g2PsNtOmeaZkpEJAxsjauywbcEp/mMuY/vpdOc95V+GbpmFgtqEtJmrN2RtFRlsjxkNpttolhzvdwpruQ/IVlaldOyFELSUluNEXSP1PWgnjMtV7Ngqr6ibta0ZoS7g2UOXSOf3tgCfiBafMOeBcVIeKPQEQDqWlQz4eOUCmImEfYFLvER0jo1eYVzcljWWm2+Z2bNCVM3aU20wU3NkqHxTCclxNuMNFgejdZYAbTA2+G4ayLZG3XkGEdGpTyGHZRGOEiT3OJmsJD1Sl18hEKzRqH0mhwHjjBuR3ljJBbE9Ca5DPuYr85j1NmrG3q0iSBD1XIbiS6ytrsyW0JM3WSl/H0FPfUCaamvxVfdkJtSNyJ62NdR6cf34sko1+tFOeXvwf+Cn8E/w1Mv05bwxWC3Fy88hI/iK/BOPIdnMN7mGkVP8UneonU5Kg/Kptnik3IIiuqOWMBnpTecknNc95kOCZnb5YfM15mma5god9FlGmWfn+XmhsfDvCotviI7vCDJEnxseRZc4reYQ1wisSOczCVlnPJUEp+O8Qfk3XzETNqUxHWS07rFaRuPCptQilORV82sTukROi338CEqE/srsm3WpfNutLzAuaCh3qUHeDVM1b1FLEKnzaae1ywhb8n9RthVPJznk7k2nbAtWZc8Pyh3cctcpbQs2pN8hs6J5Yze4DOmwltmgaukTa+pibYFl4umVd7l03yebqMH5bSsFdsnXnaK0/gYtCLXdbdpVsMZc8AfMGO0YZM+KMfbNOxHtbC6x2zzI2E/xbjESyUlIJ/KjkAZ9oaheTJKDOWzCT+yvHRRqkEMGFDYL7tx+oR3wRR4m/s1etWKMk5GRyESioqcW5RR6TRzbKRm7pTn+FnzLj5sylKkkbm4gUaAyvW6XGUxixFnWXuS40Om3yKmAqzvN0ueUBY0KJvh0F75mhk0FT4l7+ULvFhMGdezbV0PZqA9vUrTWaUr9JhksokUDqHgcVG2bE8E8K06mEn0Cm1QiVP9N5Hl7y3oqX2Z0Oud3jeximRkSMSjvz0brj0qPHNJuB/f73vrbpEl/AGewkncH+mzeDdCwS/e2qO9xPch71Z8Mmoj6cYlfFt8cMfTvXyan5L7+SSxKVNvqZ3u5lvLk3yMrLyN38+rcic/TPfQ/dyyPf48f618SgLZlKZou0yQDJ80rn+G02o5y8IxcnVuakylVBJk9Bmukc91qgbjrgVkJSHLeks3+BTvCplVXiNDiyZDB2VLxrgzmJGDsisrVKA1rtGiEb6FVmiQiPSs5+STplWA0DMFPhYUddY2rTE5PkkPyhoxT/AMH/BHCRF3bFd8Pshvk6cDLQ0uM8wynzJ30mf0Fd4MhsiaE/RwOKLH5SLVi+N20tZkXgciRFKXdd7mW+g83cVnzI4snED+FU7mPEZUAYOKAm6KyCwfoJTM8nq1zZFVZEsmykDsEccmPCT3mnEa47LpMmoNQcnM+212gY09IE/x7bJoh4O2MgQZsKayjjsbL42h690BVM1JAKzxJLDgsYL6CHTUY25FcZI7uJ9mbDpY1utyr7yFH+a3mLPa+Eu8GI6brqDNj2dcRSwMruEyFmJl6KSQNLLJKpLK/ZI9ZtO4F8IMyE55jHEOZU/3lCZDlrfJ7VzXvh3WXVzhqSy2YNNEupOr9DCnQ9RjQJDQotdNew40RweWPZk3FZozJbMhowY9N2N4f29BL4ZtPIjn8JN4PCJVncQmlvCtcD5UAV8LC4W78MP4cdyHFAbwo/vSUg4W78bPIY18tD5f6bgGcA6j+9ZeFh+P6tbdHtzn7ux+Vy1PTd7me+mQOaIP0CbdI3Vek0+be+m0Pm1m+E5+gA+Zqk3zIWpWvAUXBXyOjxuWe+whOSorZoDP6tvoLmnxuFg+REXGRFSRsaQWVTOuDR01FTNqRrgkq7pm1pnyHUtoxCg0fgPFRGnELAdWh/oif4Sf40/QHVS2hmfOejpy31ZAR+kdbF03jfH4tLukUkJSg5I49wWzdIw+Tl8hp7kuozxFh82Uo3rIjGwGE1SUB+RhCh2dWg+HC3xBW7mbN+mInKELcq9cLnebPn6ID1nFK9Typ3VJO4XnsmnQJm3qI3SH3GHWrSm1uUaMLz/RCxjCgkcIh8lITZbtNLcazn5aLbUxikO0HswDd3ub3mySDskas9nRaUE9JYt8P21K2VXe2g5e45BC3aAF6XGtgaLMemJErai92MeAmlUTMUAP0Dov7HUYsTHq1ANmgrNiTU0qbHiZWbZ18O9hUOiXVV6nFV3gkutKRoEs0Aj32lRVHd4raiux2cGCN+LNqJ6ozByY8gJQHx8MJ0vwk3qIfFm1Pm1KLoCJSd6W+Dyf4p57kYNtmRpV5DBbRjq2AerQIdkgZmGneWexw0xwQ4ZEuG5ykmwgdxP03vSJjP8HP/23AHp7tbfX8MP4SvwXfCWA78e3ow+/h/8NWfwSfg9juIw/xTfhU/gT3I8UfnxfRNQhymdwDb+F/4ofRS4qlXN9opeQedGWxQLejk+gFTnIp3HlBhXa2YZtPd+hT5UCXuLD/Didp4u6yUynM900zfdzaKqFgUXIDh3he8WI5stUfBK6g87xW3SWJvgUX5BPmYfpBG8WYAuOs2+3+AJN5TGo2nANC968Mi7O5Vp2L9KMHDdXZLs0WU242tgKqCpbMp4b0mle4CbdJffyXXyZ7uaNcIlWOJCMHbTzZk1Yj2gtOUmVcBSmTayU9DAtSYVLVKJTWgTZVGGMD/DbaZcWZZTL8iA3KE0t3pRYM2Z2ZY3P8VfzPXSQcu0wB/gufoYesNuSNpdoQysuk5YRrnFgCyy6JBvkfvkxvmy2TUMma+hV+Vc8oaOu7M4rIfAlkDoPS2AqBkLcCtoKjhrSEs7H+5z4/bKs+H2yxfdzYHMSygGzTWBk4gYyQeUwKROmJDVdNKOLcSJDEst5896cKqkx9Q9QwWHXNilJB6lBY2aRhEKuSklWzGxloAWb1Dld4ikf2luKa8zEXKyPJyrIJcw4L+pAqlyOmpyPU5qP6iLBYj1Ke0x5rAbVfKwC3SubxbFKm3YNLWs6sAk9TRVK5L2MZ1DslzNSoZLM8lG6U4KggyrcZ7y608FepZXbXIXJpBwKBivdtMNjssKGwmCA4Cv/JrK86Skr/xU/97cCesCz+HV0AXgKf4xBfARfGynl/Rv8Jn4XGin8S/wABtCBb8Xvowf/OFJZSUVW2qfwC7iIy/j/s/cf0JVs53kg+tcJyEAj55yBE2r/37/rRBxkHGQ0cjfQABqpc7i3u2+OzDmToqhAipIVKFmWZctWsC3NWPRYlmeoZ1vBzx6v0bM8Hq/nMH72GH5rkZrZb+1qsHlJkfdSovis4eI56/bd2FW7au86VX/98fv+Nf0tKqQqukHvplfp9W/4vp1eoiP6Q/qnVOpDSy1/HX+aE/6xoctphnIZG+qiO4yxRHPyAqfdEvTpRVlT8wMBVQ/mGF+DyBpO3AupgB6Sq7Ihq7jNi5KV22qUL/OqCutG0ZzBtlyKln2Qip1R6qPeYAslLOH3tNzC9dgFRVKrNTKISR+3qQE5lftIo0uyPK05ExQ6dXhQRnUKPdzLEVyUG3pfad2l4jqvx6UeTbKaWJABYRHdrmusVtVDiYJxkkrJeA2o4TF5KB/iUwBDehpFg6THeVK5eNqd4bgcy4Tcxw2eVbWYl/u4LXcSMYwk2lWV5KSfYwCDxywzCG9iHys6q9104aQjXy/0vmnKULuTCHAJRqSfJ1ShjKI7Ryqhcm5hhEYKeQQ5LvcoWsEZtOo+eQ7v59yy1edS7oBHjcGos0EinBqjPpJqjiIn4E49q+MpCjkTlKQ0DQbdC16LDGCA07gmR3C5B42TBcM0RkIzxL0yCh0tSpIKlDuV1BW4aVmGm/10kRoLP5+hbvLKpZN7MM33ZBsRDHndqj5eQr5XsDyQokSJmlUeuvWIpLyebCFIVSKvazWVOi1OvIDHuEVsxcUhfwRbUhcf0mrSghJ0yZx0+97FBr2caE6Ql4t1oVkyAhludeJOszPwltfx+5//dp/HOIp/TL/yXWFbD9J76ZNW46Jp+l3q96GlAj5qsvF1uhj9Dv0R/Qr9Ov0u/V3qoV+gdz/BSQ6eQ8xv07+jmF/0PkC93/C1ml8vvUIfo7yf47dFx77Q9MeHQ9WFpZ9zFzzP96mN44a6zuv6oZqSdRzrrKxhRl7Dhg4xMMIjnEdKnpPlJLkX+KZ+xPNYx5ZHaJQJ6eYj3kAvhgWYkqdkszHYH8oEk4GMjTa2Ykpu6n608yQGraGENbkq13ibB1SB16NnkfCi3DpBjU483GjTXWvgIq6b9KBkuCtdyk26Ww9pT07k4/JD8oyvU9YlKF0gIm0p4jCRVGBOlO6TuEzjSDqHijVwhyd4WE7wmnic064iMOZxH89YgAHs4FQ16j55YKFTrfHn1sGyYih4yMmUnlarsi8JnZKGDImjv/bLhc5rZJxzYqfAV1NX2mgo4JJ0slaDkOqgTHuNc44aUVkVeoaqgxiG6Epdgx1c93q8GizLMuKoHSpS017db1JfwAusBCUlw17AJqvESnWvFxUt+5JKh7mKu6BUihPwRKFParhYR7yELhGqC7g2w7FO0pJGk0crNBDwKECVVE0x6rIp3UGvH+MqNh3SFA+OWaCBdk5Lc7IYrWrYh8ZPWQhQtEohV/MGr7hRRNzmmcA0DTteuR7XrZpGnQZHk3bBYkMUSexyLFHPI3hWJFmq25FBc5K6SdfJvG4DwdPRWDEsdEFCSnuoK9D0ltfx+5//1kLPst5+7i0jpH9W8/bH/fZF+l+o41zo1dGv0n+g36Ruaqbfo3fQOM1Tnq5QDf01Hzm5yA9unFLUj+NO0b+hN7MWKmnH9+M5vs76YR8tptB57NPbbf6R1KSbQpwj0o9JjGtPD6rL3IKk7Mkmz+kM3oebEpUj3MaOm8CR/II8J7N8Fc9JVlfwMVaYEr16iGtl0u3mPk9xTjbwXswwjYRyxLU6qUa4GyLXkcWivo911S51XjWaEXWtad3Pc3KU6LIZYY2Baup0OkKK+omFn8UBX2DKUqpQt6uIzbmTfb2id2WSYzwkM7iLOW50L7hkYa68OY5JrxrEMtcJxQqR4j704ml+XU0hr45Vs8zglkrzdLYIU3wf75MlHpYHenKoTE3gFmZ5hiOJAc8Wx03LrFrmTR7z2DK5JgPNX4Ut/GZcw0/KpywhSV+g0ZFsrBU53YJ6WZAL2lJgJ2KOJafEtH6gZt0enuEaj1CPKXF5lHulHYlMeCjQGOwLSAmmVEsjacpaXJUqYRzi4/wsZhF3W7hNagYKPYtrZzGkSXfLou5KUDQoLkbRPxZMUCrQ6pehBXy3rv1EAr6HsFqJjHltmiYDkuYxlE/6pOKg/4WSZV4Tt+ouTspleR/eoefcPhXu9gmLYkEkdWw+MBisCCjHq5UMqpBEAkl48WCSFCPt9uJIbulul+LkVktedyVJ9WE6HbTUnBKXbk3dgcfQB99wHZ03iMHva3x/AYTeog//9N0QekRvp/+dpqiR/gH9fSqgz/jn+Smy3uff9zGV/wr9DrVSgH6afoGC9Cu+plfkvxN/h/4FNVM3/VP6FR9vJfxN8PRsFUmp78MLnZezXaKPUs959sqVqt+IPJ2YUWPw3AHVLRdlz9v2hhK1iApxk8zJnC5GL56XKa9UMnyKXSzwCX5BvyKit/A0b2JWPoVdDOI6VmVWJtEOl9N6UZ7DjyGtC2WUNzkvSXbRg7Tso1G3YBSDPZShJMUIEbnJT3EiUS0p7tbUGqxwGn0ixfiwSrgtbgvPY1VGkNIxDOtVJX5ahoVKH3KjsimIt7kWs+06PswPMJ5ocS+ojFtncZs5zRvs6klso7YrJAsqI4f6U9iTK1qpUXXMK9KdLMHLPnX5Bs9karDIl+UQF5V2WSa8WV7nNTUoaVSkaCDQ87U7woaErtAdep5eood0SgtU8rVEc4dqAzWkK3kaNTzlFWEA4wOhbMhLYIQH2VZYxGXRa0SrCEKpoNLShSqkkPVmvd4eGrI4ypYcaI0tunNSj3OSo9KhBvgaH7ga7db4GKSuQHMw6bQGaoJTlG7UOSQAnUDlCP1lX8CFvwFwoJpanfYgqMNxu3RGGCMabsnHqD3Y5nQFWoLLZEEgIuVqgMf0XT2HNt0Hl3Mqx0q1qxzGbVIMqDXQS3pcxvQohtQFlVCt2klWcUbb1PAJ1eclvQQimEBblFINek6Vcx883aZHJJQNDDihN17Hftql2/Q8vUzP0DVa8l09ge/re//thd48GfqR75KmZ/H0fp/+Hf0+ZYjox+j9vl55xY/kGtqgBvon9O/pj+jf0zJV0K/Qq09SVjz6ffpX9L/SlyyE+VvkeQaeJMiEaZHeQ29z3k6v1n4m/oPegSzpCSR0Cv2JUkzKZbmNBX0gcyCpl8vIWeRkuShZpPh5PPRaiZCQd/IsL9icPq6UbnmfGo836UuywZdlVA9yisflMn4O/7P8ZbwTh2oMLAPStOmoDs6rMBzWXnYqPE56QCW9Bq7RAzqtc3Ix3p+k2uAYeWEviUyywetAGpN6FbsyOFbmJaSv3SGnK/hzFCnQK3hZNTC5tQLexktIoZ0HvSTu4pKOef3Ykec9SdUjgTaXEsC8TuGGblU9NtWYP8o3sczDPC+rqRKexo7MyjUeQ1LmcCh3cRmz3iQuwtKxRRZpMPAGfaSPXqH30A3yyxUoSZv0PH2Qrnw1w9J6HRocIc/FMPcgx4Rh7eo6jMh9XOTK/mCSvEqMKo006kcsOsp0pFjC0RrM4jhSFy/CMLLaw0W5g1iiWVdxORdY7SkRkinPQ1RPQg2VJ+kShZ2Q0+jkaJpUhh9iupsuUk1wwLEgMOE/Eca3C/AcssRDF+SaPok1J6nHKXFKnf/s5z0lW9SIGokP8hQGLNB7p8VmvqBrpQ1zcgcZiwoY76i32ZfXJOJdGCU1LNoLxoijLBjTqoOy5JUmuuU676GfG7yxZGW6WKa9Gs6qWqHBx968x/67LnqJ3kPXKU8WojFF6/QsfZAO3jIf4fuf/z8IvYXvotB7D/0StVHeNzptCnwdNdDwubE0SG1+EvIoTftJJ0Fq8+EVvwoqVU0TNOHbCs5bnOXrhV8jJWjS6e29oO/xq7ylZzklfa6otPTrtPTzeiKmb2Mv1ckzeJBoRh1uyQmuYkLtCYZpOchbat8isWACaSFATrk9G9SKp3gFcRa9jrvYkQ39C/IDWOEJ1wJNah71cvqKvocUhmQTD+Q6lqU3ckFKBwp0NfdiWq4h7pFukot6gT0vhZiuVwWTgXiprMgL7KYpTiVBCowS9+usRHAZtziBGK/F623RfbyAR3hAl4gnL/G7sKzS2JetWBVPyYvaRcqaV5jFHB9yRI3wLbmBB7yOdTAK9YTysC03sY01WdZX8UDf53m3CWkONjtNTvCrV3mRPkPLVPOGOhhLy9RHz9N7/N8r8PiH9GgwLJNcqhUi0sbP8XaqTsqQUd0xag6miUvg8o6rMhZJpV8npMxrBcsDfEotSx+3a8slEkPC4hVP0hFFqDO0SblSb8yt0yUqxtOSTDWW2BIz4hY9jSiXe8KZntAK1TuD1Hx+S73xY7OhyDkir0Em3FZdxTlORUtsWGO8EP3emDfitQ8Xsot4g1Mf7AkSrdE6RS086xTq48W6WbpUXJ6Sz+CiO6iquEllVRkoXsqLvKDb4w45E068UCW4X5W4A/IQly37W6rW7WE9Qnjjq2OePk2rVPN1sGol1E3P0vv8TNLvl2t8Two9+/P/AP3an/Bq/Ekdjb7Ju+9bb3krk/p8SCvFh/G8nMgiZ3kM/ajTrhxjSvW4w6kiWVDJ+CC/TX5Kr8sy5waK4mlsyw2paiTVIoda3Kjs6xOkUYxLuKYvywpu6Os8p0b0jNfbaQEl++XjuIcxzrqxaBUXeeHxACvMSZ8sy3V9Xy5yzEsgq7JIs2WfPcGn8Gn5gByojOrzLnA4GlikiCODOuu2aq2SA0UWGYSHZQXCnkrrMV7kba8KtOZ4IXjuIOqhsa63UVRFbix+kXvkBn5QVnlBbqounOJpmVBDaOIjNRQNY0XdxBRPyDM6LxkZS8T0olj+3yu4gjtYw670R8il/51KfaObrtGHHiM1PUHE+epLJUxL9DmbvRwIWQ4pQ0mSNplDkl9jL94pk6kLoEgBj6oej0CPKBlQSX5JxXW7jOAZWRKWPn3BW5BrMjAcEpqyvrYxRDzqCPTSqH1b2QDCBTWF6jyhSLq9EUlyv0phJFO5Z9OTg8qTqWwpU68zSI2+zf34Y63G36ALjoWfSvRgKd48QgukA7pXJnVUIjyqtar3gl0O4gIJdDg1jk0VtdlQukDGVV+C1qyuWSlTfMftl1qL86du4EjHUM/buKsrO2jQAmGFVZYH03Y2w8hII/ZxR0V1PhEwRM6HqIMC9uY7pY+fY8x+43UM0Qz9iF8wEvq++PneFHpbdO8NGGLfCC311Xy6wBugp94o9v6svKD+eWocIZnDU7iIvIhKAInSWJXc5ovYSNShGgeYUoof4WVJyg1McqMaxauYVzRpTbdVZHlD7eOT8hTv4qKMc4qH9Z68gIQEE3SBpgKaeAIvqFWVkGGVkSx3DwW9kB6V+9zDJEUyClc5WcqHdaXuk5TelXfgE/gYrvGopFQGWZ1EGgc40Vo6VR9PyTprXtbXeEyGVPkceSWyx5fd1gGbICFY4pRA96npSI2i6AU96XZjRK5x58cdnucEP8A7scgnuIgP4jgXxBTuowyFeg59mODrlgJSZjGFNT7k53gHU3LCaU/pyoEAOS1ES/Shc9bhPwnxFfCJlz5BdVU+VxkKuTmh9VN63OuDpVTvRA7FMYoEeUz6vXJvQCBxuYePSiZbmujlyZgDZ4hiJWqSJzmn23RIU2cRT3BTnLqdpx9LhMAsuVU8LfW2SC0R1hr35VBF3CJtjWbrybTVvdUe1Tj9Tsm53Gj3hV5D4AVKOzKE6UQV0yR92uYLVnsTeEr2vOZZEqoj15VkksipdDr8GyxJMQdax9kCdZUwJCNL7tAYZXzgCJ6RatTzCT4l8zrGLlqyFZLlyISFQ+jyRr0Ctq6DRntlE72JGjekiYIFNjT4cb/K6JtdR/vEjdPHvs+S8b0r9L61KfpWpupXH7U/E56eHRd0Cih2gY9kW0Z5Wg2oYZnS1ZFC2cYVfEg29UUsbZFXJtcxgXo5QQ7Md+QnvbR3QcZwE0fySK9IH+6qOZ7DBaTkDl/CJUGj0xAopA4nRl4Ic3KKCYauT1cnXKzpQ1nClKUPBA0TNI/rNj3Iac9LLMiKW8ukB+UE8zLo1rjkNfImT6AFPTxo/UZyiJ/mv8QPMS6Kh9WE3Oe0bsUaFnkDz2Em0cQlkkk0M8WKeANLyWFvBC6sCT7LWRz6HBXLch/70UZ9GZ+TdWRwD4IhTKhWzvEMruBQbuBYdpBQd2VSoCdk1k0tFhf00Q++CXuD49fQ79OjwgLPQgWM86hus1BaXXaVkX4HIzyvW7wBHscjWeVBDEn1MsmKrMkFj7TWkRTNhFIUb9c6VSsjktIVEUpZ4K4LMbK0QI0+1aQh1MskVyTKJYM0F3mFOqYnxHObdFEvMXETT7ntFo6gxQ8aXKB2qqfawDihEJDs5YBHAwEul16dQ063HlCsnae4TxViUEaec8i5EHicDVUZBElUTzJxSLXyNAZ1GydQWEzFjleIMbR4QQzwDd1P5LbxsIK+JddYqQ4ZkA1pjhXoCanzKrU3WCpKJpU33Ho96HTQp/2lfMvrSESX6IXzZJbvf77HhB59A/LxW8Wtvl7EPa6t/dPmNn3tjMGQQ4QoDmTWsmG53SiTGeSxA4uy8qwe4DEANiHiCKIjapk9WcAH5L/Xj7TIvE7oCA68gnitWuGn5UMYEeWxZORQdTMVOqXUE2ggvqC3eR0JpNDr9elZWWJBXPY4x5VuAw/isrzAmWwFtKRVYZxiISHp4DXOeiyzlk/DRgt0sapP9vEMrnsqWaZzmIl3uhHe4xF0A7yIz+AL/BQrieCm3k7aqOMjfo3jrHheKhCTe3pCz7nNbo0cYUmNpi0E0i0ZSl/AIdJ6iW+pOb6jL2NFVjHL63Lb/os1DHMSaclheXS88gcCi44T+tZXO1gcoMbQuxt2pqJuUlUmKUXREJJemrtwDaM6jhu8o3u42q21erOQDiw5biPmMcPdE4V6EuVWHysinUafECKYxsBQSDoxFiuMOQ2BRgpS1AlbbJYWnGJBdXlBS//t0UQB+pHTad3DlUnicp7Tw7kAOc2OFXo91B6YsfxyY6xzpAp0rRvjHJJoaKYcuYE0eWWA7MuahS1oDfY4NujRYvMNGzE5GOAqC5uvarNBnuDmGAUCfWRRr5OFECzaKP1YYJh6iLUkuoulTQR3cREDfFnWuQHL3GBTnnuJu2Jjc4Ol76E1CgTf5DqSQ3X0um/Rf1/X+x4Uem+t/X2rLX+22+GxvVNDjdYRHw4UBxpDmFOXkZW4Zf3yxnAoB2p5lDAoefbkkV7EAPa8e/o230TOLYsXyDV5r06zJ7dVhm+oa9wmB5jHZexIM0cTY7gie1Iy7ZQ4VdQUWLfF9osyyinckGtemabekAypbf4wv4xFHRkhVYw1fUX3rVBfoMUh6g+MUbzZzfC0bFmSRjWMQe0pkQRWvS7xzX5uVPN8B41x0rWIyIbMoxYsU9iRtKrXY3gn7ul+8fi2TMoafkD2eZKvuKLeJg94ldNK5Ahz8W4sx6qkhrUqkSxrnuYVXBFbDLfqRvlIaYZKcCY+mcLA7fIfsjkgbyL0qChEVLhZ8a58iChWpVp4CFEZlaclKxOyzWUjxV6Wa0CvEKpkXlqbaSi4GOQkd2OcXXcAjEBvcMiJV/AkN8YpVqsykkal9Cl3OOQFGh12ZmjCEux4vIJFXXJEjcEiJ+PYYH6MpBViaRlRp8u8lMVGJOp1ap1oIEJSqUe8vmSh6pREYoSHdbmiFHU43U7IaQmmCf36ip5SMSlPETmDTkWALPTpSOyC7uJxjqZD4xYhOZanbmfBUWXIcruMSlRc7tK0HegI2KQby5g7QRxTw/MkQ3IgEezjEHHE0cv1w+Wt1KRLfzBU8+bX0b9L1+keFXy/TuN7U9OzGXaFfk4d0U26TsFz6CjnCW9GgZ+HZ0m+b/l8zMEnqcY/TD9Ll85z8N7sDG8MebTSVXqWnqX7NO1QW3CQpI7XsKVOscYXMR4llKhb6lg6sa8nsSwflXvY0NnEIM9hFIWjgXgNntKn6EYXX8YWfwEv87Qsxtt4RNI6Klm1Io9kepmaA/9Pag9GAv0kKX2b73A/18kGL7LLMTUoMRxjC908hKSekEkvxqVlTleInL5AgyNhzOAGt0k1b+K2HGHYq1ReojtJvcHmsLEFURMyLavYd9Os9RiX/GdKkB7FNWVh5Od5LksZsmVP3I/7mBoo5mU1KS/gFAmc8lW5AsvE8VCWMMt3OSebMq+nsYAJmdUX9RWO4hB56bbMt5xSY6Op5neHrzkF/W9xtzgORcIv94xkOZ6Dx4y+eCVHkFLEgqHBgNcsK1zdG7rkJJplMd5iKB5QHci0hDghOZmWmhmnp+DDxB2YihT30BJ5Q8ixK3npjTrDYWXB+j2e0t2jpHpkyauqcvpCvYGOYE+oO3SXJi2BUsyWrkm3ZMFuAVE87JGul1FWbi9nLJPaaGGCyOkLdYU6gg2BvlAHcQSLiYKsNX8n0XMSMBQLp8IYVSNa65yq05Qj6cE4l7QHe0OXSLmY4VHu0jVqJFbKwUYr8iZ1aDw0HJSYTKVKUCbjuna4UGa9WjRh2JbWqfHZvsoTukbFeKunzqEIvUSd309e+d7W9GwKxKvn1N7OG4BDvyawaujv0Qf8PD07E6Y/pN+iL5wXrIXfVDsMnItRm1T7fjqiNCUoT++nu6s0G+Jm2ZCH1gPmdnEau4olw+/RjzDFc7FCbsaGjMkJBmVIjpH8LCEkE3JNspLVp7wsOXmXpPQi7so2tGoDqyk5xKvxfqK+gllCiLswhmNZkqt6lidkT9ZUk0djlCnUSZ7CIV+XhGrhcWSleJ6GC5MULea0eALc0/toTTQkG90ZPJSRcXJpKNxkRd6iJGVY8r5uttFVPEq5QLxRT8oMruoTrHulRLF+bImrljA5QBiSOZmV7TghJdvSl6zAGu+hzevAVqwDC5jFlOxjW1+TXdyScRnlHXeIGR57nJb0SKbhU8VTFuDpTZV0p4KChcXvrF/MVPeXdT4OLNAmiZI6bdNVShPWS6nzNi2bVKOa0KXagjx5qAF5HbIsE9P0j62AIR3l7pSPMZMoRY9YdrJCRdzMSemNFQpFbeimHxkVGrW5cWTF0jJZFD4hL8QdMiwxWeLZZKGQ9HhrXk4NqwG3zvOZ1NI0TyN+De49Eko0yZiU2JEuwQI7qEwhkxfDFli3Z8gCoOoCFq6ynBopUqW4pJNSBYLLLWxBrfollXIsU51XxclEsUfugFJJUqJqbUIzLIpfMFKdq7vweuE8UWXgLa2dInqW9PeF3vee0AtSN/XQCN2lPv/vOA1QKy1TKYWphOZpwOepvUrX/EKyavpr9Jov9GwE8afp7/ljnqFP+366Qr//679FFKR2yvja3mNarHfR6pOzN9KnG/YyMckhx9f4FFu4JdN6Wq4mKrlRTpDlvB4EoR05Tvo4Kyt8P94WI6nEVb6Ly/pI1uKks7icKUEKuzjECCI8phbldXkXilOUrNIjsqKBNK5wTtbiDXGSTiTQkqcEqRjf0D1DYW6CpYW0BDwNTMkGy76mlO7WlgycUxbEPIc+GZIUtwvFS2QXqzyM1gRFwrLIk6xHSnQZX8GKro8V+MCfTZE6PpSJRCtGO4JuDd/WSUzFqzAkz8lgjDCDe5b9SxYiZTKEbKpZj2CYs5zBmkyjS+9xSg+BNSDxFFKj2crPhFyi4rd4WC1OXPDl8o3ZenSpLu7hHvQm2pDAZWmXnGwkLKTTApa9Vt2nmyWHAx3TTVrLZa83US85fjcWdK30SQ93y1WtuM3r89rRyowTeZZXschJbkp0cA93cw83y7xc1j3SwT2q29e9bW+PdCWb0CXAuDwlz8hNvGTDMhyT1mQruvyxdt8udCd6pImTfFWiqvXxMROt3M0zegEH/KK3IAPc5PV43WjnJV5QTTKg23U7npF70quaJKu20CXNPIkr0qU7ud2asyKqTjzZlw7x9CXpSPTYOaludLkdk/UF7/Hzo99K6Nntz/peve8Lve8poWd/2mfon9GX6Hfpj+giEf0AvZNa6T/Re4joRfrXFKEB+j36I/rn9D+T9isy3ubX3TpUTr9N12iHPk5xKvyWet7jszxFa+ftaXrR1wrDPu0kUU/9z3kLOsE9SPMlnlb9nGkPJ2pkfLog0YZpmZDr0ijkQuKckglhvCRPqXpE+RY/p0SqcVevx0qxj3FpkKRakUkZVElelFvyC3g7krgvx3pCi25RnsrH2vmKqEixG5dFXpYFmVRZWecBXSVdiEma9/k1vA3vwDHnxPX6uSPRo9fxUPYkhk6O6jHe5KfwGTxjiQTR543IPZ5SEVnEM/g8XkNCx/kEuzrND+Rn5VWGHMmejMjH5JGs8SGW+JM4whC28BmLD4MXsSyr+im9LPewhZs4UIe4xWlZxiZ6db/q5SGNWAqpkdGKH7YQK0Vv8bCWBsgJvVp3faFHPC0CxcxgicoutlQ/rsq6jrKSa3oTQ6JlWM/LHckk+vWhXJSoHsS8/ohsSB9EYpiUm1p7rtaIuAPYxKfw496G1+PFtFasWEEpRGUTFk0mplmdfwELd48BHtRJPpSflF/AB9WcAvoQY63xZD8r0ofUDG5xTg8rsXP1RIsMeHG8ID/DL8mI6gW0TkSxgBNxBXC9GF4SS/9uaX6OOc/dss7XWEtcFBRuYsXy+cp1bxJx3NLjHIN/Ng3xIIv9JT9s0SJDbyX0rIFrGSu/L/S+54Qe0fvoy7RMHfRL9LtUTJ+lz5NDL9CX6eP0H32z9a/R3/GBB/4q/Q0qoL/pAw4UU4Au0N+nf0e/Tr9J/4Eu+6GJfXqFnvG9dW/8vkAP6Dn6R/RLVExBOqL1J6aw/zYt+vzQJc0QCC7zLWzLCt+TJNblgczqfZ6Re/JRjEsMN+UIh8qTdfwKfln2eFIf8wPM8Th/WG7LJp6W69hQ13BbRsUGBE7l8/gX+Ed4Dy7rcU4Ii4tjuc4zeJY3pUd28B55J9alR8/yI0xwrxtHmq/iU/gsPiWHnMWA2yeDXr/akJf1iUTR7vVAcAef4JtyWc1Ki61F1SmvUjplhd+JE171kjzu5r161ngJVzEll71Jt0UeymaynKc5Jc/ITLxEIvIqMroWuzzEbXrWq5YJNSCe1hhRC9zP9diUIeljloRK2KgypzOZ6k+GPaLSwJtmzDpF9rK+FBgh6gynQ5lQPBwPxwuTwWSVjHE1F2MueSEa0JXeOJpU2CuYDnA/TyQLsmU8FQ1xwb5lkL3F3fFAKuwG4UFSAQkOVWFaM1fpSX2IhK5IBmNhFVbheMFgUMKAJL1w1u9xw7GwF5ZgeUDa2dNz6kiGpZ5ncVWPIJ6uaHQyITdsvyosBSMht54npHnESRdwOB7m8GgIIWnGAvalO9UAC3Qa0KFEuTepmxKODieKZBrXpYooFUY7xpIhdGDcvTDoSAEC0Owi1Op4cUlmHCjlcigejoRjYTc8GtLB2gKiwLOWAiXohN86Nes5vzTz+0Lve8y8DdD76Gf81jL9IXXR+33AAcuVYejHyaE2+gP6R/QSvUj/kP7f1EZ/xQccsEKvlH6HfpNqqIJ+mn6fKqmUpmiTLtLqN3zXaZ6u0v9An/Wznq7SxleFnkPF1lL+3PBmglnp5mSfzMkKxjmt99CoXNnHkppJlmIdr4kaLudJ7PMhT0HwMt7NCZnDmF5M1XITnpVdHofCqCc4wiVO4CJf5znp5x/BZ3mVJ0USvfEKKVKiWqVSZjkPlajhOhlPRCed4To1z10SwyxOhFGsYzjWczrtdg2HNdsHGq2S4o5EFMu8l6hvd1DpskzJsdsF0p0Y5R2JMcULMKdv6B7u0zsYH6VIib6HQ97GxR5yO3mZF3klTl6VbPBYhjilW1UxZrhGZziLMb0hyziUIz1miZEwrPu9Hj3kuRA3Hc+NZJo+VrRJFHMCb3W31FW8p3c/HXMHE00ovUju+dcb0F7WojlnAw6Ia9S0rtBUGkwS+lWulcSVYaFPOPEwRrEkSsI+b0WaW6Sfp9CeCboWQTonExhxB8tphgzt+chi7WRfWzO0Qn9IbPkvQtKLMc2isZJoE8rQUIgzel6GkOEk6oYt9wb5RJtVMm4dCuT8bSKaIlCkTJI6K/OqU2iQ3CJhjKp6xHlQ+dSSksU6ujW5lArrXOSCW6smdDmoJCiEIT32qvULNsnYREDXyhjKfF8euZQJxqt0hxsb4eb3Fm47TvhNjRP/OjbQ835ByPeF3vecT+899DG/NUl/QL30Afph/xxvI0OfJssW87v0t+gj9MP0UXqBWuiv+iCi1ry9QL9Pj5P0R+if+vje3+rmsH68mfMMvwnfJxigUMChUCHRUP1P6mlOitX1InoB03oqUa/aFTySUp6Ui8kWTWpeLnoxhn4ZD1AHcpv4aVnhMRyqjM4yqS450MdgmZDbfIgXeAvTXveJrUroxg/iOTUDUUpSKi2aN3QbxvGU1w4ap6QDxrLE1WW+I9Az0sv0NMVJN+s5NYwIHuCO1HNAyrCsHvAUpnVDnC4GNA0XqBnewKw6UCmkRLVabLhSzmAVd/kEixxyyUthhef5BcZIWN3gJT3jNaLD28KmjMkl3kUaz/AS9nGENRxjCZdkNdmGTpnXtboZMYsVLeAUJzE5prqeLXydisttdvC3jEQ5oUJypoOv1FTmLKPHCGd5RCW4N16jCiNhnUMdE2cQcekCybCMKyfgdAYmyY2odLYck9EScYTQKQnxZBJFLomLVzydKc7Sj1NLcISGL/CMNEkS415NhNaoh+oDBSQBS/x9kXqcRKUGT6uEWyateko3RinsDAY8GnTERTpeEmtTE2rM7ekoBMUrMJ5oa6e4E3Ms5YobxIDOczvHbFVGo1MZ0KQDyVp1Wd3hEk2JXsxYmnZVoqmJ0AOJVvFUrFpRcyhB8QaZ1yUxQjHGpUsRtOrVwUgJmr2oZHmELUPJ8A8GC8cCb7f14s6bPUth/4l4xcdI+L7Q+54zb99Lv+2XSL6L/iXV0Mfoh/2X93+gz9D/RteI6HfoXf7PvkivUzH9km/eFvqz+u/or/uJya/TP6Yacvz2N35Dfvij+cnZKultdNl68+whQ1UFn+t9d3pUMnDRq1u4X47kmO+4KWzIfLKQy7GhNx440Vrs4JYcccbm8zWQEOJyyt0qh6uyy6PxGmzhHj4KSwm4hFfwdKIwQh3Ohq2+XeR3yUU9KvFojVshnfq+fE4mvUGsSLsEpUbHsSfXPXhTfDNWp6gtcNPXQUaLZIx33bhq0KtyV07Rjh68zJ6isVCzpauBEjUoF/Ukb+M4U5qyZfcZ7GMwViHbeifRLIIXoSXGV3idfwgv6znsY0/uYw0nfKRmpQm7iLudMpmu9bQ0cYqzakZ36X2scUIri/MnEVbscZYnvXFv88LPUq/NbfyWT6FTFuxxCm/VvzzTFi2TYIryIVUX62YFy7YR05OyyRdQzOOJKku4LXGO2RTg5kCWOCZaxzh2SlWBRJAzbrM0I68zIrYU0KW2YIzaqTEQJbeLx+JB1SLzetgrsik0hQFL6s1pNWlZLDgaLxlyvH4ZGygboTLHIu5VOWWWKc3iKVcLefU6yVkoLOp22OBLUJHnSDWPSS4Z4EYe9YqIOh2iYkfbUrU80tqTKclli8VDx5DPqsFZNahzqt5QW+inKFOEcVQxpciLabhhYb7isaQwrZMYVm1cYSwHboGuTiXKPhcYfFOv3uOajNu+Ihv4fp7e957Qe5kM/WX6BH3ZD1H8LP0QtdD/5UOWfoz+K3XTAf0x/SWfSeNHqYi+SO8/T1mxABj/kX6aPkZ/7NNChr/F3Jwn+XmP/22jD9IdigUGaKL0x3p+PXmVlzDiJrTouNSigxMyjANl/W/XJMYar+I6NK6Llyi0Ik1ueQ0upYp5VJYxpFdlF5/Es7IuozopJ37J2RXZ172rFHR6nX4HZXJZTpARJUkeFkaM01jnKHbkvXIkeYna5BXZl9s8q4c6naZArdPqU31LWq5gWrROas3DMoc7egp56bGQR3C1rfwdiFG8CEvI8RgGZQEvyGiiDstySUS/yn9TPZARnMCCTb2XN/kaT2IsVSAxbMBqIhG06xJMoVmvYlGdyG3cYGCWlxIXUlW6y41BaQ37TWPSXRrJdf5A0WtfoMrQt9JRQmEiJ1nwyfqesXZ3Bl68WYoiPktZFw0XcQsG5Qi7YLmIq6jjClWBEelx6YO0TNqSPU6ryUjJQHDYidchy616FXd1Ewcx4XUo6gpYx20RxYiH1EjOGS9AQiZ0fdSmv5RLj2Tkjix4NExchITkVMEM1Z97IEuohDoDQmjFQrxtk4Qi9XxbLiOmWlSBS26IIzIrXSCuRT5R3U29gUIKUFMg7UgWQ9EAJuSBiulhVsNhC7PF3byI0WSzNY2nKR/gUdWvSvgCu/q2pFUWt2TG69C1s4GkFch0yVEV3I/R+PjnCkqvht9ZFi771tVHIR+t/D3UdS7+vv/5nhJ6Dr2N/gl9lP47n+3MkjJepEn6LDVRkFroh/yI7hX6JfpVetb3492lufM5PS5v/+v0N+nmW/ALfCO0VDHt0tsCH6B7zTPJu+oer8iU8mQIfexpLZc0e33coUlNy5jYFN2f0c9ZwHUZUU1IyytyPRJUASgc4VRewpI08x6mZE22bTDDom/KPo4GCgecKuoLMKlenOhFcRm4JodSp0swJquc4kvyCra5kxUvcFp1IY1VFZmn/sKUhV2aYA8DsoNLaPBIymWOmQfVFI4SjAzuYJoHuE6ifEvGVIc3pT+Kn8cDlcCCbFqQATyLERE+xTiAvUihGsArOB0uzhTJTRGvUI/KmkTlFlb5WDb0Co8ig85kBVZ5BMNIImbzEhGRhMpKTiZkFhuJzfpfoo0CKgt9k0fRCdhoeHnok3X3F/uijYbQI2OSRi9X2hIsy62xRKkyPYfGeLM1p90kFPz8R10upf0BCxWAHUuc3R7GBTnAbS4eLrWINJlyPc5l/4p6A7PkOB1OlCQnsJUZsSqZkEnxkBQtNb0OJ1Q/l8qYZMYDSWoJ1PmlwuQjX1kcQk2qjue5GyXIep3VhH5OIaHTPKfc0aDY6z5roVyHAxYnptXRhH4kUgUywcwEF69wwi16SOTodSyrKs/CKpSjUs9iD6w8nsRdJKScITpLS3SVPHIpUYh67WKMk6pSHDUwGSv9EdotoPIQBQf+5N1a4FskH6XF76Mof68KvU/QL36dTkbf8Ff46wTWN87sq61vf17n5kKhX5rBUXkeV2SGxzgjcanPlAjLQ0yqNXRJtb7OK0Oluht3eEQP4oQ1XNyVv4mXMYVJuaQ14ry3FMqUyDqu45P8gCPShRFekxckV001TiOJo4KSxB725VqyK12FPRzKuuyi3SWp1lN6Xg55F0k9KBHMyA0MJ0hVYYdXEpLoEuIWzMsEX1JaLOiA5kP8In5ZHlpMPma56WO/QLa9U90jrZjmK9LH3bgsKSa3ErfkFp5hKSZZ5wVOYEZex323Q67gtorxIcbVoNKqEgl4vO4NeFdl223nFrQkeiXKsDUVkuRRTOtFtY7LsRcu/J3gTP1jbST4xIlgYc8DQaKaotdqPzDdE+/GqLgjNpW4DZ6MICaNseAUUWDIUUOIK0oGJceNXCs9Mo4bMiZQMXRxHRZwpCtVu0qJq0bjlaOOVGLSiyJiAxsSyFAhlQd6g8lizui60UJuUzbH7rqOZS2uSSgSUsvY93qscSpO4zl209fuqbhzm7IlOmcJADxKhDzKlciC3JKLGJAGCSHKgwnqCRY7RDWBAccrw4jXgXGtWpxoAQ8gxS4LyjmG+25UWmQQCiybOJS47uot9FxEmeIXkNHVqcC2TaAu013sqSxiXJqwSImZeEKaI1OlPxtcbPtm1zHo54++Trf+VKZtyAf96j9v531WTMuO/tI5UXGIXqXHBCdNtOJjUwb86PDjZ6qWln0kRCLXdyLZTw+9eu4WitHcOXZiO90+fyIHaPGci3qZ7p3zCy7S7fOx437U2c5p1q+gsq0sjfnbiuk2LZyPuEfL58/4MW2fP5S3z1mpCy1Cv99qplep53zs6+fEELX0ot96DEOc9PsaaIUek48k6NJf5ECGQ6/ST/iJyAX+sR/fAoXnFOCPEZLDPuXjY1iBN+oYjp9rV/BnABwIUSgYpGBNsMjBCu7Igo298hAnGH1BrpMt7MgnsIMRTMXL4oQsVnU7BmRbZS2cFH4e70JUQ66Jwr4+Uf18hBFpxj5fEy2eXtT35W26djDQEOwNuja5+SFu6DEcYFNcTCONpM5nbQWAq59J9CfJLUE3GFm5we/lG3heriGrojKsU34e2qdxP6F4AC6P4A7fwCLuIC82c61zmNw2ZLGPek3kuCk51tflmqx1hFKEdV7QMTnGvDwr71SQDryIn8Aaj2EjWoY27lZBmdKuHGAXdyAyoGelBZ3gZBzDXkRHxLWePj0ueazLDo69Y/6Bxn9YeO/8cfg6LTqYK/9880dHJZbimFvCUZnQPRaPzqvVw16aNXfrYk0tIcxIc4vjtVgDNElDpK2wt2SWHly48iF8jOfQq4Lcy8p6/lRQK2Qwo1uFOgKDgTmaIE1uh9zQMwLVfsnqj5pH3doEqWbMymV09VBfsJXSX/ezV1AldTmNQa+Ax3kPSRSNEA9jHD1EmUJEJYFd3rwcGKV5Uk5zoDv4iyRpPWaJmWwVh7rAKZSni7UnR/IFPo71wno+LSfbkiqLkJBqkPHRMBcqT+KgCfJqJYI0J1R3X5GQV6IF49KMGjWSYbVR/YvFL3yz60gZ+jjd8J+8b/++/r7Q+7+N0LNTbvYjr99cy3PegLL3Zn7BP6s/0TmiWAUO1KZktKdd1ay6OQOFS1jDlL6NqOSwrqu9BjmSp3EDR5LiQrFFU2+Ti6ofwBZfxBfwNkskgyxEtmRWXD2ObfkIjogGw0Mk3TytrvAN2ZM05tDJFC2Ai6u8ZpNcZBIHMoF+RBDhFC7z5/Fb+BnZlizHpFvXJrplwe3HcMLzenU/NngjF2TiQVmSS7KlpmVPJjCGbnKUBTnaFheNvIlNbwh78g5k+BIWcEt+DAdKqRzuo9XrkbvolTosei5OZJ1POO/luSVLyMsmlAxzk+pVMXeYWSdE86ieljwuYo+v4wXv7XhHzXvoVToipgr/JVRAzTRHD4Pv6HhbZopHXU8PSzJZyPU6Kxmpth6tTAl3s4cMoqlyqdOJlWA0DM3cSQMFKw4Sul9RhJLFSGITH8WpHrLJ13IdEruQKoiTbsEKz6GgN5im1pDugAfwHG+NBgepM5SnTIEMqAQvYprL4+VqQXp6KRYYfMO9UUM91Ob0BCTI4xBD3IdVngBzyx4VOeQom/pzaNnQENM1lkTll0m38WVJRMsy5JahUTawAdfycMj75Xk1j/4UDZFXIGm0RCkXVsUyE62POqqWNYe5A14iixiarCQZIu7HGFRTkDuQVoNqPJGSvZr30it0SvCvo32BN1GeHtLbfUHxbfNkOBR2wsFwMHwc7g5TOBQOh9fCCFM4GK4LPx3uD1M4EA6FH4bjYSccCDeFL4Wb/RGF4fvhUNgJO+GG8Ha4LRwIO+FI+JlwUTgQpnBn+FG4MRwMUzgeXg8XhUN+32mYwoVhCsfCG+FSf2s+fBKmcFGYwlPh4/P9psLT5/tNhOfPW1PhGX92heGr/lY74iS8EHbO+5bCFC4OU/goPODvVxReD7Pfqg0/CHed9z1zvoq68IPwoL8yJ/wwHHuyspZwIBwID4cPQ3+BNb0/ebbgW2x/I17y177On1LXe1yTQRVOCyX7ZVfPIiVDIl43JvGUHGIzSdLOc4jJM/iwXpNNlWXwPE8kKlXIK+A9OdFRbucjWYbCy5LRcdzVh3ILR/AkzRf5BfwVHmSSCb6MGXjY1puYc3v0kWxhyB3kLXwBn5W818wjfJdHdK2nMIEbWEAvrvMLMiaMQfFkU7Uq4gJckrs8j5F4KVF7wTBJhm8gp1ZkTG/JFdUYpUix3scGt0oO2zop78LP8ylWeDYelWsynC3GnLxd5odJspiUXXxa1i14qnLdIenkce6Sbbmh24ZKpAOCYb8SAWK9bqM8w3Nqma/wTXmWn/Lm7xeSomN6gd5Br9OL9A56Oz2g5WDDzXJexZSekGiyU2bdxnXHalISWQh4FnM4jAYvmsiKkjX0KEqVyBi3EQ0HpFTG0BRvVNOINFss43sclQuqiT2+yWlkID7R4gMe7yLdZkkauQcX7hMGRNKBlmB7cJZSpEfkJua8BiGukQXVBmoJfNU7UkkN1OX0ByYtWVKSaDEoA7yLq26DRcqrD3Y5UoUxXfK6I02ISgqiS6WU7/CuDMmgSktCr/A+dyUahi/gouxGA/ELKis6WqEY0VWnJ5gkzvJwgiYIUzwFtrD4yUqLmWh50ZDiLDfmSDxOqSZJy5ha9UZMgFw69K/g6/QSvYPeRo/o4jl4aOBP8fYO+kmn2741X0qFdELwe6pp0z+azXbYpFZfsDbSNerwhWwdXaJi65igVrpGrb5d1UHb52HCBtqiKj85LEanVEIVRNRNaz41AFGajqjE3wrfy17ul5DOUQGVkEMzvt5W7mPJzvmAhjbseJEcH8t1zKewK/f1wDGfuKuENnzdtMxnXsz4qyimI1+DK6NCWvd1zgoqoEs05BecNtBlavQdAo6/btvXTDeo03+yK+gZKnT+Agu9wJ8Qc3/+Wt3XH+Nrt5MTDB7STIAn1I4rnNEX5XmrK6BGruCOuHyqV7hJLcpdjKsjbva6sKeniW446JQrepNP5JaspUlFZTdRKvVIYQw3ZN5nvt2Tvyn/AK/i3XzKExJBUk7kEEccxTYW0IM5CB/IfsL1KFKCDcwiKsucigWZUIZtWbMGNG4i73pqC5d0h9epbiKhKBYgx23iJazrw0xlspiXJKYtEdEP6ddl0J3CDenjHD/DncO1clvv81Uec0k1YUZO+VjehkPulwNe5B1emApJFmncVVMY4hlucpswjrg0yQA8i/7CSUlgCrNiSb8P8bQ8jXXpzNO5oRQh9mv0++wtHCYKALIKLTkeSNbKHPd6xLVe2qKUWDRiezcnKqWbZ+Q+R1YIDZJOl7lBpmSdPCNzqnE41EMcxgQ23aaUrU3WIlyjO3U/hnAFPykvewtexCt2CX4SMqd1ZJj6nLkCq0Xq4li9pTZqCSQu8Kw0jVKRYwF8aqmO6py6QNRSOnnD5DXJJLMq5WqM8sAyxQPDxZiJt1kgAlCSEvWS4cvyQ/iItjHZHtUgjTwRb9BUHRCWK6rThmai5ejBqdrOUIszENDtSKQoXuYtyB2Oo0UXJ2masvQs8aCe4ogqzJNMwItW6qQn3pgFnbj8J69jxbkx6nzbAs8ppExg0ZkqzO/lm/OUL84X5g/zknfyhfna/GG+PU/5gnwwf5jvyQfz4XxT/iTfkQ/mQ/mq/FG+KB/MB/Kt+ZN8Wz6cD+Z788f5wnwoT/mW/FG+Nl+Yd/Ju/ihfki/JU74nv5t3/FYif5AvzRflnXwmv5GnfFme8sn8Rr4wX5x38vn8+pO+hfPWSn7ZHxvML+Uz533r+el8IF+cL87v5LN5ypf6fdpfRXH+IJ/wW2X5q/m2POVL8oX5k3w0H8gX5BvyJ/n2vJMP5p38cb7dX1lz/jTfkQ/lQ9ONC/e9/5toeo7/Lul5k3OEaegJg22AaqmZmqiJGqjq22YTeGwot9Im7fvF3FQYGqFYGa/IEa7xpm5QCUyjX0/ye/GARU8kSjMkSRnlLN/XkEm540U0JSpxi19wBzOluKq2vAu8q65yUs3IqdzBPT0iC7iHj8nfwx/y+9SqTWdRnUizK4PonyWZlFtoEZJyzouWBb3AednjVXcgFpilrpCQW6ktE9k91Z6rwCY2ecSdxnU9iRkwLMbHAdbQIb16T16VcRWTZfkEP4cZzqt16UIvHwiD0IsdLOk7PK6y2NNbuGITlzmv93UkTTzPh3g7Dm1aNULSwTs663q4oBt0WsfRoxICHpFRzOhFXsGOdwP3ZVcyy07PNwPyClQEiXQZj6kZ1ccZtzdRzGM6qigTVp02GMGh2356RzepAsnyEad5iMd4SJHbp8f1JKZz5FJvIE22sIundHucdCEmoqE+8hpsmrOM8/t5T+Kc5RQs0XdZtkRPSM1gSKY4MhwylKVIKcd03m1IlMuErpmiIqfQskk5ISdFHNe8EYDwpNcWCaasInJBJqz/DUrFyFFNaggiIxYJFq/jHjxMSixWLBYiQnukihkyqbMo1k5zIEq6hpd5BLlkGTlqElEF5OXYa/YcTe+lzoBHyUrkOMMXNI0U8KQMxYtVgqNaYUENE1V/MxP2T0X/GPAdbb8T+K/0nwvPTs/az+is5Kzo7PaZdxY4KzqrP7tz1n1GZ4VnwbPbZ4NnwbOCs7aze2fdZ8Gz8FnN2a2zkrPgWfCs4+zeWftZwVnobOjs7lnhWcEZnbWd3TmrOys6c868sztnpWfFZ3TWf3Z85pyVntFZ9uzaWdlZyZlzNn62f0Zn5Wd0ljs7OCs6Kz1zzpbPds/orOKMzkbO1s7orOyMzrbONv2xobPts/HzrTtnC2eBs5Kz4rMjv6/M70v7qyg5u36WPaOz4rPysxtnHX6r8Oz2Gc4CZ4VnjWd3/ZWFzpyz22fdZ6Gz8Fn72b2zrrPQWei/tJ09/dsm8Bda6DlvCNX/KH3mCQiU83VR28eczX+dXvZBdxyqop+lf0pfot+mf06/Qi1vQaPiPPm3gA7pI3STDuhF+igNd1NNSDplU+57eZnmIzXNOziKlbnlvIlpXsD4b5EhVtyiEjyGGN/jj8sG5nkLN+Q+bEHZJ/iRWsMV7KglnsamPMIlvci3AanAO/EF3sE0CyLw8LSexYZckUk9xi4XxYhjuIVVrEpKreOGNAsNBIpoOZQkPYRnZVKfyF6izhBKeEriqQ4ZlRu4hnfLizymWYNvyVNIcS8O9Fw00BRUFvLqOm6qixxqD/AN32u1g1PL4yEHalZic8Q9OJYp3JJNthiCN2UGFu7yOYy5JV65KM6pFnTrrAyzVlmMY46tnneEO7LGk8Mlp49/DOfr3QsO/VdKWbbeVp5QWe5UWelWIZ3hjBdIkyqxLwy3wVhvtsMkhXpMBtAuU/y0usqiS2OEIU6nqCvINFykPLdHjaAxQiqCXWQkI62RAtfyX9zkbLTEq9WDALKcxpzcwoEMdztxmnGGfdgoXccTytWdekSVp6jSaXDIZssNsBdv4zEIF9nCMKJpxyOuYPsK2tNZjEhKXO5WpbF6fYm3BkpGScrdCI/KLC7FSxOOFj3M8LrnnLCjaaiKp5Pl7EibzPBTvC863qTSNnprr8eChbeKYkba2Rba1WMm3p4uRMod4LiM6BwK7nzT6/ine3Ls+FbnHwWN8+Uis2/ajGNKTbE5MWICptjUmVPTaRxTZELmmhkwIVNgWsw102lCJmxqzIkpNSETNO3mumkzBSZkBsw1U2SKjGNazTVTZ4pMwMDfr9g4ptfsmYApNY5JmgNTZkpMwIyYS8YxFcYxGbNjik2pCZg5s3nelzZLxjFlxjGrZsUETJkJm3WTM465YByzafImaEpNibliRoxjyv2+pHFMiSkxhyblt8rNkWn3W4Xm1LgmaIpMg7luuoxjwiZgTk2Xv542c910mrAJ/3Gbeerv/59/cc1b5zwmW3b+t4UeC5+Tc38VQspGbR5Hiqrp1/wytEJ/W45WaZL2yNAX/Ehu8Dxf743fgO+/eyOVzQm9kyoeR3Bpjn6qPemleNQDdvkBLulJGVclXjemB8OqCWMu5EW9zU0clet8WY50Btv8w/hb8qwSXlHzWEyXxS7wNezylBSLkjm5itfk7Vj2WrI2xtiNH8FLmNJpHRkoy9RgG9flB2RburGLazKnRnHZG5JC7PMBMpiNNzF1hiKEGpmSbbnNrgaACssRy42IaM0n8tfxE3JLp712mVA9iSBO+AUscrFHXqXMYJr7sY0tBbwsr6hRHKpxnkvUYkBe5dvJGlXHqyx4mt+GS95UtgAruI+bfFPHVVAN6Cnp4QpOwPN6MaJdbYm2Z7CILb4pWzqvulM+8Mc3c7yOUJdTSqsBL4oxHtM1yHLXFElCT0eK46QdrwF5IFFo03k9R3dASwgDcovfy+Nus4SjQU5LzAZ/5gl9HB0oxZLkVAo3ElHt5J2PUmMgThjDqvJSwWGSQCKUKBRXnpOXOCsJaNXPddHCePCEEo70cRpZHusLezQT0lZXm7Zp1uoC2a1hr8RtjUc5zcAm3itXuGEhqIMtNECqXvLYRLtHdYHPUp/lmFtXu14cq25Ml0tCSvudDlIhnnQ73IBXrbvlRN6lL+qyRBFGI+Fh55PkOVyLSXgoslYrd2NZGrIFekR1qV7JeZOJ2qjvdAp+x74ha7Z8yTH0ZcfsmGZDvhg4MnFDJmgqzLFp8fvIHJlOQ8bxBaHdj0ypOTSFfqvRnJoG4xgyXebYFyVk6s2xqTBBQyZqjkzIhAyZDrNzfjSYfSteDJmk2TBkygwZz2ybgN83bdYNmSJDJmVmDPlnWTKLhkyBIbNiUucjVs3E+Ywv+X0lfp/y+4LmwIghX1Dvm0Z/rGOOTMRfWbU58VcW9FfW7K+swZyaJruer9SZ+7/5F1jTC9EWvZt+nP6APupTpdygbRqmv0uTfuj+12iUQvQy/WP6XXqNCqmKftmv23gjU+i76J/7Dtxvff800lO+Jmj3iNKHfLdq6HwtG42fT49xmiOsscxLcHmK99UAL+COrOMGlrxRfJifYZVo5UXs4xpG4oU8itckxxa3OMrJFCXqsYE7fF9Pyh5W8Bw+BoxQKFBnKWw28F5Z1ikIJ2WIr2Px845MKFcW8Dp/UNb0MG7hWSWqEq5clF1uEEpU4QrWEVFj3pxqxDo+w89D1KAbxSQewhsM8AKmZQk3MS3rMia3MWczWbGCPa9Ku1gXjQ+LJf25wouw6G6EJbmoeuRAPqMPVFpGxkgW5RTP8Ak6kOGHnqdGXdVXqDtkgjvRxTkNSatRnuYZXrQwChhncLiNhr7FZR6gOPXZFde4KWYRVaxzujNh6SonVbVHi5QPenEvn2xNhECpIOZwRZQOyaCehtITPJhs1FNeHVOdM1KELbWAWb7uNsSKvXEJNARaHVsYlqiSLEf1uNQKRR13SEYmAhxFIlvOvUpJGpMqo6O6TUq9RgjWeAlWn+uwryVvIFkRrVZ9zBhX49pjVxrdekzJBa9ZT6JKSBw9KBkRrRAYpiEnGIhajtxskiwvnKRlz1McmrcQAiw6XqMyOiMJ5KVUGniUr6FXWbD4Es2SjzVY4qdMAMPIJytiIRnR3V6jJzrJ0Whw4M+j1KI2QFTX2vClBtP05Xpz2cRNg6k3bebU5PxWnzk27Leazen51qg58fsaTZ05No1+n/K31psGw77OZ1txc2J6/FbO1xdta8jsmgbTbBrMlLl63jdm9s77Zswl0+r3LZsd/wwNZtpMnbe2zIZ/rgZz0cydj9j1W/Wm3eya2fO+K+cz7jCH52Obzb5Rfp/VPjN+a9CcGpgG02CazKnp8/tcc+rv1/CVDvPUF//tX1ShZ4/2TjL0E/SA/hP9BAXoZ+nHKUT/E/0zGqQv0W9RmB7Rf6DX6D79a3qViuhXfbipxzl9VndL0lfowJ9ZmDpoiPr/xHeI+ugOfZaW/P0v+3uHz72CRAWln4svewLXHeCLfCA3eIUv4pQbEz2yIOMyLiFU4opMol6ieAH33boIpQpkHntep2zqy7LL87oZu9iVlzDPXfq6HONQ73cVjjsdQSKvBrf4OibZFeZrfoXFgBrHA/TawnrM+mkqb9MzHGXWGb7FDyTJT6k7esxWpup9fVs2+KKa5hjqMGxhqhKUcdpIpvi6K3qT53kHV7DAozqPV6x2I/e01tN44JUni3BHHmJp+ALG5B0yigjftBTZuOkNsfAStvhlzvs1p4d8k8dRDwUv0agBzYN6FDnM6EnkeZWvSgZZy85W+SZ3QA/1USygiLtci02HdFAmVSeTasUEt2qqcaYIdXoUiusTnbLMl92SJKkCHuXadJHWOiXjal01ea2asYKdkWCyzBv3LnBEuePUHyBqDmiSCBi1aprblMLkQEm1M1SAkUTTICl6heJFiUYdQVoymhHFhDwl2+zy09gXWOGInNbSHakcCVXb6EEQGn1RGiPdjVlp1S48XSOjqM365xul4RCmuFr6JSWEPhxxDlGp0a7eVhqjuhekWQZAKUpG5IiTukE18aiFqU9TxHovmTP9QRXijBrkChnhGCe5hGjQ+XMQegcBov3WG1+6bY6/fGQemZvmyFwz++ahuWEOzImxfafm0Fwzh+YZc2qOzaE5Ms/4/z81180z5po58fsemSNzaI7NNfPM+f6n5qE5NCfmwFw3D8+Pdss88rfumZvmgbnqj71lHph9c8PsmdvmKXPVXDMHfmvPXDcH5p55+nzEPXPP7PlHfsrc8Udc8VtX/XM8ZW6ZPX/WD82d8/M+9I96zRyZh+a6f5QD88g/wrE/4xO/7+hPrOLkK7fNS1/8zb/IQu+99Fv+OU7p31AjfYA+Q0Qd9Af0n+mfUISK6Q/oL9MA9dGP0b+havpFetcTTc+O/in6km/AWiyV+/RJej998Bu+H6b30H36f9E/p1IK0TEtn+9//in4/NBu0o2L28vNMsFxNyXl0ieZ6/R+8jzZhmiSbrmEG3LKWdmW6XhABVCvV2WMm9Qab+OD8qIsyoi04y6exiQLb7CFD6WmQLsjpFJ8B1O8Idfdjmip3JIflGWdS6jxgEdqkJ9SrbkCnlSNiOoRWcVfkt/Dz8qmZAE0MMkOdmHZLtbxFJbY6w5lQpmgLuBxXJMbqjpuy+HjMi4/iH8gTwOywT3cyHvuMJPO6EvcZmOM+Cv8IsdkQjptQjQW9Yl8Aoec15Qtwgv4EYmMESbxgoyoCwAUBpGRJE/yqJ7BMi7xCEakL0TDFh7kTT59VO70O4Y45fWokVj/WFDy6HBJ6pDXw3mnJ6QoSmoSj7DZE3C72NVBbZODJgdDQpGQgJ/DJ+RSqs0l7SZalcNtMu61cAqVKRoMkNPlEPForDpehRd5s496qSMUpFSFLEpj0PJtWJ8eCRnSjVCSlT35FfkDfAwzklKDw+UJi31DitYoGogHJSHJGmpzBkMexZvkeb2VIM/zehW5AUM1DpM7zHG3TyZyRbpQOFo1TqLxCJ/Wl7jdnkd1y2i62HW4VOceBNLduMu3uBPUE1wit4JHkZinVFBGoIgwqgckwa0u1TqDfx7PT/MTTa/+y7Vmx8RMrak3NebIJE2VqTPtvjlYbepNrTkxEVNnqk2vOTFDpsrXvo58Xana9JsT02eqTa2JmRNfa6oxg+bIdJg6U2kS5sjUmzpTZ4bNrqkxLabC5HyTs87UmpzZMRdMi7lgxs2WP7bSzJltU26aTbWZMnlTY5pMuVkzF02FP5MVM20qTYspN9tmxp9nnblsJk2FaTVV5rIRv6fOHJgRU2EaTaPZMzFT48/q2Ig/T2uGD5tq/3x27vWm2vSZUzNoqkzDV7rM/S9+x+btvF/u/92Blno3fdwnBpqlf0J99CH6YV8Du0vGN2Tj9CX6I/rb9N/TP6JfpG76BR9Pr+BcT6unP6T7vj+P/DqOYir6hm8xldAFekSvk/gevnW67vsELVJIqCRUWFL+ebUkHrsckX5M4jquyGkigm2+pNvdWpnT172o7uVTnUxd0FHM46F0Wj+NDMpVvoVnsazqsSoTeg/vx00N6ddpLPMLeMQlqUB9MBbkMnVRXpEbGOF9HMZt/cQGu7IrrtcqU8jiMs9gC1figxiRh7iLGbmNRxiTYR7Su9jnVV7gUW9Q4riuvXih5f1SaexLFMNyCe+W0UQP9vCyzGJd9mVPjnFDbYyQquWXMBsfFsgLfBxrxUU+ddswiqsscgUxn/R7UmZ5Vw3JpBxjEo1Y5xvxgWin1gI1Klk1xcvYw4wahubSNmfQqXyLHzRMXc6I45bLmNeoc7ouVYY5bhHiCzKJWIri5ayR8CJwtXbbkUrVpANsr+aID/qp0K+XsaNY+ljxxIpl2ejSkwntxTKhRMBQiZMLDBfINnKIQ7MaLCSKhBMkzTzeHIwTl0qddPIwhGMqglH9HB5iV17FAYOHAGHp5VZUjYVjhBbJpgrTzmAY5NVLWiuOYhWZFMWDlg1kyFElekQLpgbKkqRb9JTbL8OcwxELrPiKqn6ekNIMjToSg6t7JI1huEjxQJbcUp6BilNXACmd6CUBD0hE3DZn2Bn48xF6FqiloLXgS0Um+OWwuWI6/fBFkW/UBkyBH6roMCFTYoK+aAg8CWSETYEpM0em1BT6IYBrptUUmKAvOApMsQmZFnNiavw+ZY5NiR/I6DI7fuDhcSCj1PfaZc22IVPp++8umUJ/v1mzachU+FvzvvfQMRf9QEaxCZiLJns+YsNMG8ef8Y7fZ0es+568IlNsrpqECZhCU2KumlYTMCWmwBybuL+KBt/ktitzzLFp9/us8dthPYRfaTJPffH//Iur6VkQ0Z/122v0R9RKH/BBRJvpf6B/Rr9D3VRD/4xeoS6KUYYO6AL9whOfXtAnyfu3ftFK4E09vY204ysott1LH/VH+KVrxUS3Wj6dzqqUxL2I7nELvBhGJSUHPIAduc1x9MvL8vO4xgk5EnE7fGLsV6QDHTyGA5WUrFwZDo8EcSBbfIOflmXp19CzOJBPyaym/oINGgjyFj4q13DCKeuPyhZijMexiM/JR2Q23oOEXGaRFazpWb3j4/VV8xYuShQzmJY2vYaP4bZ4OJQJPYWJ6AVX8dOyIFEZxnN4hAyY9xU0cTNexD0k5RKvYRI/iPdAvHrOqV1dnCi2mYG4iU/xJWzqoVgIK3IRa7gnC+jHhEzqUV6VHNK4IcsYVJ5kJYcpucjrMqzSqFfUEnjrR7WeumjAZsR1WKpuLLgVqMN8rFmoLyjass3xUKo4S0HiIU7JGsQXz4yneUU6UaooRCLwVC8LbulMqkhIt+tlmffqL1JzoCXgEbfLiVxWlChiUTxqdcWSZIkewzZHxeMkEiriNnMbwOtyJVkB0nEr1NUQmtDJrFKS0C7SvIsuLu8LKUINMtyZsGnEz8iMV7FC/cG2gEcQWcWkV6RJ12NXb6th7uEZt56ph6TeHcIN2UKnhHOFelnPIKEamUYJzQyew5JuYZoIuimxkK1xSaJOjXBZ/5+XyDuP/rY6Xwoa+jKZTdPmO/4D5qqJ+q79MnPVd/fbIMSh37IBiiO/5ZgCc9UUmIAh02SOTYO/tc0cmYC/f4O56gsrMhFz1YT9vjZfwNlghJhdP9hgQxobvlizgYy189DCpN+yIjFtxs5HLJqF85nM+kGLUj9oMeqPCJotkzwPZKyZbr8vZPYMzkfs+AGKkHHMoRn0515pDk3r+darpsqfe4M5fhyi+UqRufPF/+s7EXpWi7pKxo+ahr8LySpvo/9ERzROf0B/mwro8/SjFKbfoH9BQr9NX6QgfZZ+j6bJpV+jv0qF9Ov0vvPobdD3B/5Pb6B/DHyLb/gJcIHdc4E+RrnHbuDCOzW/Eb/jzWKEE3pQRVi8ASzpJh7whjSxq6fE0hju43WIErmOIcRxiL/MP4dTSXBOdjDEJ/wUa9nH6EAYlkltQtnitYv4qPwwKrtJ12BW1uQmbvE6L8DWAZzyulyWHdnnZ7Clhi30kg/8dAc7UrVJA+EYuVVqWi5j13UlpZVq43HcRlq1I6mv40f51/CMpHWfTLjdI4RlvieT8bBXrCNyF+s8KSucwsfxsueyVqv8nEr0F/O2nmBXDvSgjuCqLMl75XSkLEG8jHu4BfEa1ZRawAI2eZQv8SGPCvOompElb9iLIxp1YoFB+nYeVltV2BXoIk6oQdWCGSLdyXPehcQFpLAja7YCt6+gJagoVsCQV3E5rrhb9cmMTfToCfU4Uo4JqdRBROR2YkQi0XK3CXt6PFcwFN4ibxCTUq+GVc8oJQt0nk84wS7b8MZlXtdV8cqfphyhzWPO8irXJigWJgLLKmvlxkqFhgt1teqW6+64KKQxLIvqSPWBXnSQkHqvT8aT1YbckKrjXZkcKOZWV2EDV6RllnTcU6lgNNgVdEmaMa07vSiS8rycoMkyvw2Gh8Jxkj7sywIPShBDMpULSSum1AUZ5SYLkTVA3X8+z080QBRpVV9Sxv1yzByYcRMzMeOaayZvIiZutDk14yZq4sY1N0zWxE3MZMw1M2oiRpm4ueFviZicuW6yJmpiJmdu+FuifvhCm7iJmLy5ZtjfOmIOTdTARMySOTLsn23WHJqIYTNsVs0V4/oj1s2BGTbKRM2qWTVRf+uuuezPJGa2zPr5iANz0T+uMvtm1e+zkeIR/7hWv1z05xkzh2bCxM5XMeVvTZprb1iZNq6JmhFz3YyaqFFfUebp78y8fcxGa3xCnYI/d6Fny4X/D/oH9K/oN/3UqU/QazRN/4dfkjxD/5Y2qYF+lf5X+hf0ezRG5fQFenguwKzQe7ePrvztaKuBN6QmT9Er9Dq9g14ue9Z9t76ulvSoT2HThxrVKRN4RuW8Fe5Fnb4p80mbpb+MRS7iPn2ACWUJZ96B90iWO2Vebcmc/Jz+gCjZlSOel2PfbZ5QS/wc/x1cQyse8A1JY1Ee4RDbfOi2icg8HvHeOEm9rGol69iTFObxOq8Ph6KBCqcvCEs1/ojXcMiHlmJQizylGIM6zTfxKbFR5JxkceobxlP6Dm9GC6Kl+nm9wKPyaexhFjc5HCOJ4RCHuMzvxMscx7LNBFTTMoNbcgMuR3ELp16jFMssv8xTaJUZzMsO8tiU22pDctbY0y3IJQsjTnOg/5sl0n7T7LImJ+6oIp7OlcmQpJm8XrmNBW5NBrkNS2jTNE1Spgc0e2v6dZ7WDlNqUNLdVBdoCQipdpmQEo9cT2wAYBy2nvnpeCtIDSKRuYByFeFrmLbMPjwthxx1y6OFqUIZUS0gXOBxrXU/T3N9nHoDnU5PwLPVIjnuxYREe4lJ68QAOVLONTIve0h6Slvmsstc01MiHZKRShAu4ljiOq2SagAzbj1I9SObKySn2Gl03EqZU6WadIPckGfccTfmtfUHRy3leEpPuEVcgrgc8KV8kEtk1iuTYcVTNBTopIFv+zq+xWc/QLTXev1LN83Rlw/NI3PjSQjguh8gODIPzoMSh34I4Mh39z8wJ/7Wa36Y49Qf89APDhz5fY/3P/X77J7Xz4MWR+amH9ywoZKbftDi2A9kPG32zXWz74cvHp//lrnvhyBsIMPud2r2zT1z1+z7R77vBzKumz3zlLntH/mquW9un494YO6eH+VpP7Bx+iSQcWqumofngYxD88D/+9QPX9zwe479lR2a46/cNS9/8V98p0LvGhl69bsk9N5Nv0B9lKOqc6SEGqr30SKsAdrnp5qUk1DST0sJU7O/n/PElmr8tqsw3tiuozgx9YyFxOOXsCFTMpoYQNxLJiqHbXBhDev8o3IHET3C/aBYk+zyHRzKgU5YdEc0yUPsSDxerXYttY9lJPNqMMurellu87QS5LEjPyX/X/w63os9jCOGVb2FmOrzIrCUkSfYRG3cIrTdxIKM8qKcYEHvqswJbQWS5DXzMi7yVelHBRb4eTnVo7D/TfAdsSSSjXoB+2yJFVdkD4vujL6LH5HXEZO8dpHH66pPkTQhKxPYww3Z5Cas87GO4zrf0Gk9mqXhEpzg/TKnIjwriXiNTOAp5JDBKB/jVK/hptyXuWQ1cqpRqDdAPvP0N62SdvwKzjcU9zdRnRMj1aBnWsnCt2sXq7w0WqDJWF6KEbAM8bjSumE0IB4vIucNdZMe0b3WBxYLjJMelJyEYyXIkYML3IKo3JR3yLZsKA1PjyKix2VFV7pFUZILkol3M82QVMqIzuic7nUrOYdWl3oCJdROPU694xUg4UalDB6neUS7yVA/eQHxdAQFZZQo173YFUtLPoq4WCj+63iXzKo+XcsFsWakChy0yZQqy1CnU0wrxDnuyAYlZRk9UB8vVL3eqCT1ALKaU8WzjpDXq7e8acWYR7XU8cxAuD9Q53R+62rzb7iOb/kpCxCVtZZ/qcJUfrncbJgBU27KTY05NNpv2WSPYb9VaY5Nl9/qNYd+3wVTbq6aC6bClJsBc2h6/a02yaXGb/X7oQrb8sxVU++3us0lU26qTLnJmd3zPs9cPu8bN6um2u/Lm63zM4yZ0fPWqln2t5WbGTN9PmLLjJ/PeMtMnvddOp9nndkzWX/mtm/I76s2R8b1Wx3mqr+KCnPBHJpqfxX9vvFbbi58pdzc/uJ//U6F3nUy9Mp3QejZn/kz9BvfBC/P+SYoesE/pzM+Oc4B1YV4Adf0NFKSQJ+0YkLEK9Db2FYiJ8rVFnX4EjJygEnxdF5PxmslkHZUBrtI4Ka6I0tC3KEve22ZQpmUPE5wkzM8w7flvfJB/D5/FKsyqSPI4S6egfXavZ2nVCcO+LpOIIOL3DMawgoywnpF7nkDUYrV8B42MaTE14+28IxsoVuG+WmcepF+SoZiVvd7iFtocsv0LAZkFp+Xn+IjXsUJr/EV/aqeUA1s/XFXMKW9fisYxiQq9/EuXsRNlUAf8rIqTVylD3GdR3gJk6qKV3EgO7IsW3KLT3BDLckYojHqCDae14N/3W9SQV3US63fUDvjw1MTlVvvW1RFmeU1qFhA9aoxLlwiNGBSHshFLh8MHlKSUiWc405Oekm0qTRXDNKFIAcyDqckqohjDLccfYjjMn4Nf41XVK8q08USyjtK8YCi6VA7uWWcV1qsIL8kT+l6KVRjbleE2gINZIVeK7UHDLkFOouhToezeJVZE0oxy9Fk8HVnw3mWZDRZ55EuQkmsHnE8x/8AH+WcHtLN0Tqe5IpMiYyhNUqdgWCwn9we5el2TEmvKI620igxeYVet9yUExUbqhDSnWpMlY2F9J7ckRZkuDpCDQGbf1/yjdexzL+ObU/+/naf13CAqLC16EslxjkPZJBf83BsXL8Oo9KcmFYT9BOBbdadDQs0mGumzU82rjLHptyvw2gy10yT79/rMacmZMpM0DSYE1NpCo1jXHPshxPI9Jpdv6qCjDYHpsj3y2X8oEWt79O75Ic5yOR9P1+lH8iYN2TKDZlls/wkJTl9PmLdTPvevbDZ8f181X4f/L4Cc2A83zNYZK76vrpyEzLHJmocU2hqzalpOz/bsWn1PZSN5ppp8QMZDeap79y8/W4KvUnaekLFTU/qKL4a5nDoa4U69CdgFZ0/Y2Dl8TmcYuulqpBdvco5VpzjQRTxFF6VQ73YTsl6Pe+JbPLb+RrGcCVWoTvUJi9b/N10qT6Rl/RgvBHHvJOsw648zYdqAYfYlwdY0xflNobYkefkb+BQTUpGtesRncQaruI2b3C/rOIL8hPeJEfwIt7Had2khiShb+F1GeYb8ojHAI7oATnE1lAhAtjSd/gET0WKU7Ysrl2vc1rFZUNe9qZgCSqv6yIVlft6Tyblql6yZ+bneVG2ZVxXZAhLvKhHsY0i3S8r2McNXJUN9jDnVUkB5tW+TOKqH8dek0OcYk1u+YbuQzc2XJD2A+nv/9rrqJw26V30LnqVXqXX6b30nB8df/KycomcUSohtMqryHGNGuULJeS6vMtjyHILSjmJdDo0Qr1BIokyR0Po4zGsICHU78CpC+gq3sUsRvEIE9IHjXlpV6d8KsJeqt4KD67CFNfPU0donHRIjchVHovXy4CkJJPomqLaQCdV+yKmlSwXR54iBZyElhTXe72yiR3pylHQidg5KE/3EBMKeCChMYoXdFpFeVb6OYYruCZKriA37PQE4k6WGsPYkBke8S4kqvUoV7vUFFSUbMCMakeJiklalnlV1aSJB5QnZbiH/eecWvo5KnKGHwu9x1eqlDbonW+4js+T93UlmN9eRQb5FRm755UWQV8fIl/sHPnufvJFQ/e5u//UtJ9XZBydb2v+ai2D6TEnfijCVmkcnwcIrNAr8FstfkVGyBd6++fVHGlf6Nk6jITZ8rd9Veg97ps9D24smyU/BGErMtLnW9fNpN8XNpdN5rxvza/IsO3HQs8K74Pz2QV8oWdbNi7ddj77r4ZoGn1BaAMZDd9pysp3W+h9a1P0rUzVP7vYOxd6DpU4IN2lt5HXOelSCbmPaV3hNfKBPPIgx1jtCbkhnlYpnuanlWWmvc/jiQI9qE9xiktayzh/GC+pVcwBGOEIduRleYee55p3EiyTwufxmsxLBkrGcCpPycpFwji2vRia+Bi7orCLGzqNXmHk5Aq+IP9KvoA1nXGjqOZa2fG2pY5dHRcl190dNZ8mVOCUt7lHxfllPFQpnsAh2hPEjfKsHKkEz/EkP63XvW15JA+wIgqP+FW43gTXuwWyh+lEoxTILF+V21hCnC8p8cr1KEZ4W65jBuNYl/t63wpTLHFWRlO1YbJ1swUB38lwiT5FDyhJLVROxVRFfbRM76d3+s4qp8SpdfYpSpESlUY2MYCUvcayAoUEtrEkhSCPeoLKwxhKhCodJuS41rUAWmk8I+NemxaZQFZSfIJeiephqZExVavIbcep0rpVcpJzeySMDklnwh65Qa+RczaJPB1wi/mmzCpqCNQ6nT6d2OOPodqgoWyRPCvpBHmNfEmvSTRa2u5okmbJ6ZJ4JduKHIVm3sTSQlCsOE6rMpVDo5pWl1nJJI8ggg4c8am0q+BP2kSUXlBJ4COELl70mnP+60E6eRfz7HIaKwh71SojvZhVPQitElH/V4sv1+mT9JBS1ErlVESV1EeL9H569znw51vf2R0Bou7Wvi8Nms4v28y1pGk3A6bZ3DA502S6TK+5ZWKmzQybBnPDeKbZdJohc9vv6zURc8MMmT7TbiLmjhk2nabZeOamaTKDpt0MmVumz3SaJjNibppWf7+0OfaP0GAm/CSXPlNn5s0VU2NcU2smzKFp9nPmVv18vohpNotm07SYYVNrts2WqTf9fh3GlD+ixlw2q37dSLM5MjOmzsRMg9kz0/5RbGrNhGk03abT3DBR02aGTJMfjrEr6ztfxaC/WphW02GGzW0TNe2m/SswD7/4H//iCr0/JarENwWJCv6p0fS+1nJqaDjACYtjwnvYURbprEu3qVG8jBd4QE1yu0so9NKoRVJNevat//PyWR8H+Qpf4QO3CmHe0Ru4qFtkUp7hS3gWHwfHqSDoOn0B7MqHcVlmpBeD8ioe4BA7PKOPpDtFuhpHeNntTRXouVS/DHJWH8preBqfwj097rqcwh2ZxqL8iDxi0bY6NyG3cQU3rYksgzyKAeXgQN6hxy2zqmzLEnLyw2LZeYc16TQ+pOJci2f0C4kor+FERvntuI1WDmnLn9EdJ9TzPs9jTD/NExzlEQi2sY+ruCJRtYcdiciINyWLPOiFfRC0MnqB3n+Obvv1nyX6BM0WOxT4O5QIJ/pkVoY7LHMcsIQhfVdvI8gW2iDDfiTdVm5IFtVLJCHu41XdI8weX5JP81Vu7Q0/Zf1mzXpESuWU1yJlqwSbepzlLe6ZsLgraR53o5xHHwoQ0zNoiVlW3TlMJYYwxjab0vlqyKCDeqnc6XMyAZVhsOY5L5sunApq8KQ0SoEaUz7ppIr1FCYKJau2400zNBgQ+9q652ZQqcajoXWaoNEKdvEOvEeNIcH98LCgLsDJBVQvj8RLPKoOatJNekyq2Ba/Pc0rOqq3kpUxipRKDmNSE3gszsroWQvF8k2u4yJ9ihae2Dlv9tkIEG23Xv3Sobn85UvmgTk2l8wVc9k8NCfmstk1V8wjc9VcMntmxw9Q7Jhdv17jwN+6Zx6ZK35U1VY6HJgdc9lcNY/MZbPn9z0832oDBHbkJXNsHprL5orZNtfM02bHXDGXzHVz32yZA7Nlbpin/PNf8gMZW2bfbJtb5q7Z9kfcNXfOZ3fX3Dwfcd/cOu97ytw4H/GUuW62/fPaIIxt7ZiH56u47AdXLvlntiGVx2d75K9n58nKdr5yZF764q/8eQQyvltC7xtzWwve5KcOUNE3pM2UnkMR/OlEXojaqOsxZ0xLiEkKsM4PeAuLnEIaT8tJslwT5mRMT+gD3SmF6MexrGEf47zPD/lH5SV2MWUBMnV6lHQ5VuQmfsjnrbjmk0VezRROOl3BNstx8aK+r0ZlXR7qPr2Au/IBWcOAWuY6rwS3cMyH2MSSXGet87gtPUw8hVd4VuKyKsOqVuVlDAs4VSk9wGlck9+S3+ZbEhcte3rMcl9gD2u6U0/Lu2VUFjzrJ9x2Q3HCCQ7lWG7oPJeMFMosK34odzgmLFvyKexwJcd4TZWrYplVw3qCb2BD76oZnsSemlM5vmq1M51BTk/IRcykKirK6d10+uRl9UZYh8dMc5+ki4MUq8eIzgyVpIgruU/l+C57ZcQJ7vwZShJHRGw4yC2VMsRwVU2J63m4yateS6Kun9Cr9jklDaMhu5dEcBWXvOS20xeqCoxTvFKPY1xFFmmKotXco2b4OeyJmyPQViAa4ot8l+u4HpNe1QBZ7GR7g3RSLw0HDHlRSbiFnMUz3HuVpoOauFLG5QFuuorbY4XKwn1lMQ2W0B0qDyySDvGGuqS3pMya7KocXXpZr7vh6YJkgwzihqxzXLRe15tSo8sSBUxSyWNoEFKFSKkONyj7+grHvQ5doggdepJj62EqonfTzW96HR9zZHyE1r6dvNg3AA7QuXkb8Evwo+cG7LGpf1KW3+H3VfvgAl8FHHhsjloPWa3f6jAn50ZotZ+STH6e3tH5cdufmLc2ycTx+5I+uECxn7G3dX6uKT9Pr/CJeRt6kqf32ND1znPyLvqAA/Yol03i/CgXfdPczuDAN3TtWQ782T1exaA/pwpz4oMQBHzztvHc5D31V0tfqfnzMm9f/q5peo+hskP+mZ6hhxQ8Z70IPOHFKDhHcy2nF2n9XLezAYkV+mX6VR/r9c0B5YNvAKC3tVI36DV6Oz1H81QYJS6Tfizr27KFFdzDfCtxr07rtngblrWW2/gwrijlCbb0kT5lyVK2XF/HigziSK/KKi9yH+/zEo/INX0JF5GRZX4NGZfqA73OaFDm8RDX9DUZxQ6eU3N9IVmEJ+v67XhJbeJYLNusqBk+lVUM9tNwkAjz2MGeHMtlOUajWLTjZySKbsnhHo7VjNyRObnM8zjQi7wjC34q8t+T5zkjG36R/aIewWW8D9CDeAYjRJjhaRlTS2OUIDeiH0oeTdjkZ3kOY3zf1XqQs6pVZmWJD3AbC6oF1zCloxA3hZyMYxaX0wul76Wjb2AqeUNFn+84+1Dj0oQb6+510MjgUdZSHa9DLlYQq+QpXbfrZAqQlyV0s8aYdjGC6zzeRyOFPC7hFPUFvUKd1GlktE4X60IwXxEt2muIkDjsDBHHVYxTcLspRrqSLdDqIyVuNypaAmCJJKp5Sre5LZJGkZ1UKSWok4adNKELSa8caUaiQrLSSIRW7uGL8hKvul1uGKQqeEzHxZN60IBT7hhCDFGZly2veTigmjDBjBlpW/LBgxMdohMWCnVfdiSOlB5JDEpcdtSwhBAAI8EkLZJMh7mP05LlQVSkC2PeZLTgOZ8F41tfx0b6IKXeMnhXFCAqaS35Upkp+LJNRO4xBabClJlTkzCFpswPUPT4rSJzaiJ+nUOHuWF6TJEpMY3mxFSYElPkG5CdfmvYXDdlpswUmg5zzTT6LZvtd8EPeQyYfVNkLpgCkzaHptJUmAIzbi6ZsKkyYZM1u36ktsAsmG0fuipscmblfKvN2CswF0yx2TCjJmyqTdhsmVlT6Ede9/w+O2LTZE3YVJgKc2gypsCP2Vqj2u5X6sMM2PW0mOum1xT5szo1/U9W1m3rO77SbZ7+4h8HviOhRPQa/Z/+j/Td1fTs0Z/2aUbe6NEIvSF6W0NfpA884b1dp/9IP0k/Qf8f2n/LxOnHMVvH5xP9CF2hHmqmDL2Hnh9u98Ywg7hexAHPow3jWECrrOA+b2CXl7lSFvkZScYrMCQPcDtSlwhEHI7LFYnG6vWmXJJ3y2uYlBmM4RGWeVAleY4f4tV4uQ50hIcdqcMr8i7vGMe2zEnf0BnOYUMW5V38AcnLiORyJbAJIi9hNU4SqA/q4FQIp/IyL3uTOisu5uUI87imZmQOxwNFw6Qht3ELu6oaF2RBx7ApH8cWj+EU97EPrVz9dvw2ntFRtcz7ehkv8ovKwyJavFoWvS4ebEJFIhpCPa5Kki2PRp5PsYYxLMhF3YUtrOg+ca3bX2cwzgsjuZ4PFn+KKBByvsX9FC5wqDBX8fnejtFalZUxjnBZjKwHzx2UUa9G0nIsnhaGXMWualCVqUJFCEIshCf3InuFWkMWSQWZoSp0Y40PpLeaZBxziCI445Q4vQ6X6CnUQWMYXTKtBqO2bmJax5DEvl5acZiixRjliNKKC51mp9RJUFdAk67iUR7QKT2sacSmHR3xgo57gsVYRSZkEZeth9DtQT8kQa5TFsg6fWU8iln0j5Gelas8rqv1kFJusM7JWZ62PMpULWfR5dIyuSXeBR2Xe7yglFIWQwatXitmh4psje40oQka43F+paBup8jWHQW/1XX07+U0vYeqyHlz588bAhm2qKv5iY405Os+xWbf1+ocXx9qONf0js41o4DZ9zUlMnXm0NSchzQOz/eveRKqGDIHfo/dunWuXbHZOR+rnlRfwKyejx1/ov2l/VBFqa/BfVXTm3uDVpc9D0Zs+H0Ffmy387xv9zykYfXA+icr6/N7bLpN05O+0nN99ehc0wub29+JpvdYg/oo/TFd/i5UZNhfbZhStEKv+O81h4QGqdXmklAhVdKe79KN0CN6wec+soADj/MF7Ux+if4f/jF+jX7Zr9IIf5NvgW/Kzvi6XtDP0PvAY8Tkx29K+nDXh1IzbpptlusmLuMmX5RDOXKb3EHOISUTnmVRiPGyJf/GGG/KGoo4HAtDyZZc0fdk0cYQ9YRcxaf5HhLSqTTGZQcf440xGgznCXF5Ce9X1zGPOTUsl/EpuagPcDJYgnZsKBcv431a8YLclIvcMUKtoVFya+UUL2BbFFr0FXwU11WHG8EpTqUtEXADXiWexXNqCnm8gik3wnd4DhSpkRflbqomU6Em5IOyoLJyKiuqQ9+Rv4Tral22sYJr2JLLMiGruByvkWGspcpQzYm+Mi+jkzyjtnBVaZVS15WCq10o1pLCuIynli98zolQoCDwLZVqpyBIJc69uvv5PreznhTVB1El7bA1r7dkDd0yx1uqKlNApLTr9lGpMxAud0YKWatUvBBZaZmnTmt0Rt0IN6gNtQaJ13eG9Ywsc1UVJQPlDpHuEKUa+DnZRpEhLxSrkEyyiCf0Va21Rj+KVkgzxjEvLVFqdRJOf8ALiSAvI9w0QaoOcQU1JUe6SXVIjMO1wYuke/gF2YhUcSZR4QYrHDhRQtzWzGxYGiEbZErqRi/DVURldhaCHm6QCW4fp77gYBCkytW0tGQpWsYRXFWQiNySdQxJn27UZUwecUl8OMdFHycEgsE3uY4UpCK675u4b/bssmUdb018KWmSX/bMoZkxntEmZW6aJeMZz69RmDXaaJM0t824v3XS3DR5o03CaHPLJPz/z/iVDnbEpLll0v6IaXPdZPy+ZXPDZIz2t574x9dm3Zz6+3lmya/cSBrt++Q8Iwa+163bDJhes2QmTLVpMlVmyVw2QyZqImbDbBsYz8AcmU3/XClzaLbPj3JyPs+0uW7WzvuOzdz5ym6ZeX/EmLnhr8wzCXPLJP1VTJubZsaO+ErSPPjiv/xOhd4H6Y9p77tShhakF+lf0T+kL9K/patE9Fn6CLXRf6EfJKIP07+jXkrQv6R/Sv8j/Ssapwr61fPaW6vpPUu/R8u0RP+j3/dma3xAe+fJUXP06FxABh+bEdU/zZNISNRr1S4vcoIzcZIeHdM2JaJdb8lSkuJVfEumvWbp0zPymjVaksXs4SYmMKp3VcErhDsyi4gs6z0ZVXHJYoVfxedVQ4pkSg6xKy/jKexYzYWrWHAH92QnVeQSXLkrY+oIp3woCZ7DCTcY8mqxL0tqE3tywEe4yAOowDrfkXu4K1Vdjg7zCK7hiBf5RTxS01iVTXVBF0lS9rCAp3iVt/V+hLpLcBebPIbdRAsznpIRmbVxYBxY0YdezOMR8rwk9zgrmzLtjfM8L0DFa3gH7LZLH+IirHUKE6O65/mi9/gOMudbexJCYaLwXNHbmstyVe4gM9sILDiuW1W/5Ll0iMRzBz3KOapQTUEXUGtgIPAsrZBFMpQBL6kKVKAzKITLcsDlo8Q9PKX7dT32JGuoO9AUTFA0qE5lHQOS5656Ggk32qrje27qr5MO25cO5zjGleiUCe+iVBGJEw2IizX23FpulBRnEZX6tK3c2Of1aOFkqDE4EUQaKdWPe5xleoWyoaQTL5c9jLmVyHAG1S6pITxCf5SaQnOEOsm6w2omUe/5FcFEXrlekKEoJQO6ULJus5AXtZSP3C+uaM4iKdFYv3FKsgUfCFcSBQLOm/m2beXQ835q5Le+s3cDRDutR186MXtfvuLXKOz6rvynzJEfsrjiAzvtmkNjtx6aPT98YSsodsyBX5tx1Rz4ez5t9swVs+dXOjze/6rfZ8MbR37Q4sBc8cMXu76AOjH3/L5dc83c90McNqTxtA9OdWKum4+YH/S/HzFfML9hfs38HfPz5mXzTvNO8y7zDnPXHJubfljkun8UG9y4brbMkbls7pub/ip2zH1zYi6Zq2bPD9Hs+oGYp82RP0+7sqtm199qgxv756vwV/OVG+bFL/5v34nQs2M/RH9MV75LtbfvoX9LWaqmn6F/RhX0Q/R5H2bqK/TT9O/pjq/H/Q0qowD9Jfp1KqG/4dcAPxZ6vfRfyNAf038m+GUAJ/QuetnPePra9xV6jV6iZ+kP6O9SKQXpiFbfAC3lEBV8dvhykjmtPbePF7Eqy7Kt+uQS7+th3SlJfhZvwxLy2OMB9GiNY/w4X1WTksMsptw67MhzMqPXsIpOiK3u0P3iySyf4m/IJ2QXH8EBUjiSO7gonupUiWQ3nlMb2MGUtGMEV1KDuh/PqU41oMblRbmlqnEsLycmVJzXE4N6ATspklY3xUm+rC/KJSl3+/Ci2PL5e3omTzwvz/EMyKvmh2ox3qt6eA2vcJcQxnhJzfOzSIBUhu/zia5QpOclH++IEBp5Ho1o51Vp4wVZlhk5kD25oizYwp4Vd55ngfVEdBq5sUTzh4p3QsH2N3etBx2H2kre1nMxF3NF9UiTVMeKZn04J8SgOeyV8yz7IBGqRKYRH6SeYF+wLtBN6NZTWFJdO5QsEsVTei5VnrHQ8jWsOY0lPvn/MfceYJJdxdlwdZgcd2Z3ZnZyzt33VNW5nSfnnHOe2dnd2Zx3pQ3KiSyyyEkEAwaTjQMCmWwZEz6yjTE22Abb+HOWwPU/90xrkIyQQMDz/d3P7t493X3vPbe7q+tUvQEPVDrBpVy3YhsNNDsyAcP+8guudhfV0ynyhwHcDL4Eq0D5VISJlJHETwqDXcnb1OFIvqoQV2F2L/RByF2RiHO8GMxu9bR5MMahJuACmlAhHQpnmESqhba4BVuwFhMRit1WPQ1Tm2MLZLlUCw1RROX0QpW3zGO5mlKphxsLgTwhLwUV1XooT3dwJkMIyEXpKo+LscEf7GnYf5NnEbw1z3AdwQWlcJMhO7uflpGRVpz+SLpkPZpmGBlpkib7ZE3YVOYOyorUS5qkS5ZsSKWkS5pUypoZyzRyBA67Ic1wGarM82pkQ3LMa2vM0th5Bcua7DePVsis2X+axGRBDpjnOYyMNMmWNGmRNWkSEp+074W6B+Vbsnv7G7kq98vz5IXyPBkRyzBnHZ6ts98cmZZ2s5d0mZNyc9RcWZaIOc80mYvPYp9BIDqPlsiaNEia4WSsG25ImuGaOFcg87F0Of7rL2+fC4/9VoKes/974I1mqxv+EqrgPnjAHPE+EHgZuKEcvgrfhlfAK+Dr8GMoh3cZaakks1R9HXwJ2qADPgtvgwRIAQ0d0AKtT7q3QTuEYB3+AO40ZeMVmI1LUZlPU6Yr6Q2+6QD6muwSLFZ5NMV92MuLXIb9vEG12KQO4+voPFZgmz7MdY4nLj+PPoKXOMiVuEyLeoDfRveTn3r5FM3RETppd7Bmp5v7VvoP+ibfQcvcwp10lnbwJA/TIXoAd9Qoj9Lb+JXcRdV4nu+idR7XTRjhUX49fY0f1JMYo2Ziuhk3aZDvxENo8bLuUpqO8MvpPXSZgnYzb9EpXsJBPIRj7DjtPkeFVYVu5kN0sxqlFb5FK1WHR2mIJukchZWmPpzH47oCAH080pzmy+fhSBo1YJTz7ZBdQ9Fgiq6mITpA+7lIl6gKriO0wxiJhPa/JDkMkPm0nyWXC1zJLu+N1I5hNxhvMcf11tG4awTl5FIlGiiJWnVGFygIJHCMjJF2xFGmc2yF+mnGl8w2aQBdrIIdDuQFhsF/gBylvaEcIKWjdlY1qDr0oWPN01GdaZfYQU7RLbwvCj5jLGYDpQYLGR2oOQ2qNDrHWxRU9VZuo5eMk1oQWpyyRZ2dR60qgRqJch0NvrbGtHqPv4p6MDeQzpdxHqsxzZkDAedSJObRWbqPCnSh483b4UBwgCEAWy4MUbUNQQg7xpQ0DZaHAlTmVDR372ju4A0nJt3kbd9VhXpGJOlFU/RxPyMjI03cjybKknGN2OUtWKZ7mi2HpEg8hhHhMDJccUZGsSRIkgkhWZIsiVJoGBlJcUaGx+zjZ4wMv2yY5oFLamRJvGZvT2RkzBhgMJhlqCW2oHTJm+VD8j75oLxBviQ/lf+Un8q35CZ5ntwrz5X7ZFxYOo2kQHucQ7JoGBm5BrCMcZbGmmhT+0sy9TtnZp44ODnJdGqL4+eyy8hIijMyEsX9WN6vx8jYDXpvh/+Grmew3nm2wlV3w4vjC8+vQTU8z0hYOVVEMcGwHr4Ib4PTcA0uwCEogN8zmV6KMQb6KszHcU3ffErc2M+ooHeAHf/wROD2vX6uNxGA8x7UXSrA6PhrBfL9OdgeTMN68llgF9EsD3KBysFlHhn26jpcozZs0qnUjbfrAV2nE3mNpjiPNnCw1sulSMqPDsbNQJnxEo7iB+i1NIFdbPEoLWMTzfK6CmArL/Iyt9A5HGPEIRzWYRqkFqXVYbqfn4Mvx8PcglXo8E1X9QQdwRXe4lYuswK4g7/Hr+azFKUJB+iib6aTHKRuehO9k7eYdZSOqiPcw9f5d/mojhiR81V8P15Ei6rxHP2+WrZqcJZOc5S6+RL18xSfUsN4Ws/wKR7EEJ/ECa0p4qgPY5RiOowRDEXas17jbt5tGD7d5yXbA+C9vn+7vdavkfZuTtG0Cbv5KAexjofxmCMKhX6K4A4NYhMiOei5ZsV4G72SxtGnyFK8xSPUjBqR/NTMS/R+uocGLCKfUhihI9ROddjON9EprbFeDdI2ooXEREhkkU8hxnCd3kOf4efTEAaVhT5U5nRY+XQvbZNt19MA3oqbbGEjT/MyNiNhs4ryEr2DXqpbqRn9qNEixg0cVs2o0KaT9GaaxwZl9oSKLF6lBW52qni6Tx/nADXQGG8wmqPtXQbFFnbVJ7/cWZm43c9Y+AG4DO1PG/TixkCPuMX9qGOpU2raDI5k1C7sI0fWDFDFbVgaux4ZhaYX6hKPgYI4QlQuKTFeGrseGRuGjuaSIiPZ5DKMjDWjg7fbyHCZdkNAlowt0K4zxm4jIyib8RpctzwoH5UPyUflzfJVEfmpiHxHrskL5bnyAnmOjIstXYKyKbE452LGMDKSTNBrMGecLMumueFQ5xYN08Lx31g3Hhku03opN40Rt8n0wJzxppSJS1yPZcuJXz/ofQD+C8K/Mfbrk5e398BXIBdc8Dz4LmTBi+FVxinjh3Ad/h7OgQv+DF5uzmINXgqp8D4TtFLADSnwRbjf0LVvhq9CngnJTyUs5ZgTZ+4R2FLhGmw8DmFxF6X+bs31YLtqUYpLdLHjY4GjfIz8NOlHXUvz2N7uJUcoaJQ2cAk30LacrMXLM/aU8vEWntTDDP79PGV3UCP10wna4nN6lGZopfkAO8JNv0cnuI8VdzoEfjpHEwSqFe/isQaw82kbr3KFP4HG6Qiv6066goN5wH18jbq4jda5kRdpvhUwTKdVrWrgLjrHMcxAR4xgnaf1Pi7HmznMc3iFU337aZTHuYH7eIY3AzlYSTu6jWrpFBL77A4OkaOtTHqQWyiBC2maCu1C6rEyuZ3qKIoNOkG1cARTONPOCRVwmVXDTaSsEIVjsX0PJDYDpD3Dl9XhbLivpU1tZFlVXOEr91Xs3v3lvkp/PnXhjK/EV+jvsyabC6kSi7BOLatQ80Gu5HJfIfpxBZ9DK6pQlVGZVU3rluUrUpXNB9FHg+oCvoUXVYWviMqpiNpoKrCftXauXL1V7C/EER5pKvBVqQos95U0FVINRtQaP8jv5ufSAJNV2lTkL+EKf4W/VNXimkXWQasY2+g4zmOJbqAVVeUv95ViMfnoDn4VL1ntVM7FqtxfhIPWWHOBv6q5yGqi2+kqD/grdTFXYwmW0ITq9xWqcipWzbjMvuZcZlrGBi5UlY/Pv7nCX8GVVtlGtve5QJngcnueOehdcszjnibotboBwsVtj7RL9FFHMmpQwtJiWBXDEpCYtMhR6ZagtElIjkmfRMz2MemQoLRKuxyTVmmRoNlynhOWPjkmIWmVkHTLjrRITGwZMq2CmIRlQA5LSDqEZEy2JSBRCcmUQQW2GBmpeckxS9SQPCBvlbfIg/Iy+aT8WP5G/kn+VM7KDbkq1+UOaZN8CUimzMuk1IgltbImU4LSKbZsyZiEzXEPy5iwtEpUjki/OStbjsmgBCUirbIjXWY2ETkm3RJ7wsxij/XKhYf/89cNeu//LQa9m0Hg4/BB+C8DVvkdeDk0gMD9AHC7I8kBw/Af8IfwDvhvuAdS4BNGT2+3pncM/hM+AO+B/4aLe74XT093c/7eD7fBLdDqsmE2+XXVb7cPqWGMKZtD2u/fx0ktbtWK8zSEr6ILjhAmDXGuLuZj3KcDOmZ364NNEHAF8x15Jw4EymiVtqiEVvA4ndIdaKsZPs934mA4axh8QNl0K99nD+tOLNQzThcWj9C92ImW3uTqShcfpwWap+PUQpN03D5BbU3JAagH6qZZWiJnMXwY+7mVRhweBkdohKfBZYNvP57Wl3lSd+hzapl2+Bg1IQTcdoxW6HbaxgFfGUPzAdrgI/oo2kFn6TaId2C/BVYNnaRaX7rqxZJQNg/oXG7BkGpTU/79FKYtiiDqGEU5qFn5ya+ZwioaiR64P7kFYN8z0ASdlVvyrZnt0YTaxKCrHez4AtARcG9wBYBb+KAG9LDSjYWgXC3gy6CWSI7jMkHl1MOpXMjrGGhOcpaOqpRDjaC9XImdqiwANIpnKYKltgfBn6yQbGRMxwPY4siP2gk6auWzI6HjCWRxE4e4V18gWyXQBh2lqLPgDCTVu7Sz1ERsdJbfqgoDfqBaVjoUKLUBwZ9BDTyOF7HUgGFam7LAkWuI+ZMZNoD34yQOWW5s5o6mZAsmgPyWT8MQBMFy63Y+GIA6D2mussB215rlvW2uQCeQpzqxJTHtakJXFqS6vM/0zfDCJQg8bdAbdwNMFi8+siRzj87KKcNRmJV5U+6flTlZNK2KWbN91vAdZkwjw2FDOM88J3MyZ9gRTtNiRmaNtNO8ed6q4WE4z9qUM2ZsVlbklNnXjGzLaTM2JxtyWU7IKTkpx+Wd8gX5rPyZfER+Rz4nn5TPyXvld+Vz8ifyWXmPvF8+L582Y78jn5I/kk/L2+SyXI/fD8mMzBuWxu4ZO+2YQ/HzPG2aJ7uz2N3abWTMmvM/Z9giM/FGxozMPbYsNz380LMPek5+lARfhH8y2pC/+aDngtvgs3AZ3mEaDI5+smMLf49xLDsAt8GAqfa9Ft5ssHhpsGIEQN3xBssQvAleD9M/J0Tw9B+mBOiGW+BeOJJcGGU6zWPcqcOqmmspShHar1JwkpZ1JfVTAJnP8cv1Yd2qBzmbamgYZ8JpGvy5fIzOUivXUwfdznfSoBVrTKQYzeglusQv0qzA66lzWKVBvoOWKER9dAst6gm1xod5hapoFW9Tx2iSThhr7Q4coTv4ui5EKPZUu5IB1/EWXMX68kRe5N/Hu+3ccAkep+3mbHRHXarE4VYw8xU+ryN4nm5rSmLAJhzEUTqEh2jaTrYTeB4HqZ6O6QGVT1FCNcsbPM9T/jq9zS/hCQryBe7Va7ShxugYEjXTMmJThi8fc9UBu4SrySJi1iFsa7GLnpu8mfxMnyRvkstdlX5b7UiYKcaWKtP7KE0liFNlM5r9mE0DlFELgTTdq8sboCjhAcd0sYOzsQYHQ/u6IOrRxH3YQvltoIBt3coBioTTAk5YOcBbgU4KYMRxeFMNdMHO90MYuJw7KZ2g+SC2UzoWYFi1Oh61vE7dg1AAlMOrNEq1TNSOfkoPFlJHiZtA12CrnVrqHKeLTlS6oh6uxjZFuEJ9HW5wGjBlqtNG3eUvUkAJ2ECtPOTAxRVwo+6ldKrnYI0bINfb41ItzCaQNmMLGoSxU+Wrd+skp5GhazGALTEr72LCenLCMxTInbVINdwMVU+PS3gSTm8sjr9zkGtNcc7FSlyEwBnLj6PZ1vbGluP/OirJB+KSAmvxsTxZNlg6kEZZiYsQHDD4OzCYvIU4m6NOjku/TMmAjMmfx5sW35cvx7f+Qr4d3/qWfHdv7AvyP/LP8lP5UzkmF+SCXJJrcfaFg9MrjaMIF43einOffcLMas2/WbIalxkAWTGVPeeM1+MWkN5fr5HhBJNU+Cb8AxT+CpI3v0rQewl84CnFB9xPITLlelqVvF9Z5GA/gIdHcMPu4AC2Bvy+dJVN/XgS13msKRGzaRHbVAPbegGDOMkndDUSnufD3IjjOE2LvM4rmFvo4SEapFW9zEEc5jk+yYd4JZza6TrgCJmn0Dof14t0mFr4Fr4bu5IAW1VYd9Dv4u9hOwWojQp5kLbwCJ7EmAPY6AKVSyv6vD2pp6mPp3ABR2iGVmmTd6wyBTqVT/ECx+iGHqx360W8iRyhhFpepzHq0x04gj00RbfzTbqBxmgCF/EBPI8rNE2H6bk0qRQv622eoDVdGaygGGeraFdCQyI2c68qxFryOUomhORHRUprDlmdEV1/IukFkJXgcrmeprKekAHeieRbqlK7XKqA6kjrNmpB1PVUrPZRmk4MAlWSjoFAcx52YpYfShLY6cOepD6HiFrkOMjl21rXUq/voD/ZtsmxNIISV56r2u0DivIyHrDKVQxD1K7DVN7oafZqsCpUhNPCadpBIoawNObFGh7BUUqNwaybwKrRCxyzcnQK+bifznKTlYTFHIumdbqU15+ExCHVwUGKtqYS0SrnT0Klp9pF8CDgIh/B/SqFAhSkBkSVNAUNTr64j3ZwxIZXQblXAzVhWKAI7CyK+dMb3P5UleE/YFVaPu28x1FtYWV9DkFGOPF+t/PRcz0DD2oELhmg1S++3Knx7m22JD2aKRtSJV7TU90WLSnG/Oew4SgckCTZliZJkSwpkaOmj5sqxXJIDhgz7TI5KmWSJanSJIclTQ5IijEAPyjZkiws25IpueIVn6xJsuFShGRTsqRAkiQqp2Valk1u9in5ifyb/ES+JZ+Tn8i/yk/ky/Ln8bE/l/8jP5H/MFufkn+Wv5Z/kk/ISbkkl+Sy3JCQkbjyypS0mVlkyKaEJUlyjMet4/SRJ2myLSwpkm1kBpyZOeeyLfWSKplmFo4WX+pjNb8eI2O3JvZt+HvI/y0EPScAXYQHDBQzIf5mOyrHiXF5ncQ4DW0XaLybpT1ZctEZ/9WdOzzmlV635x4I5PA0j2AHat1IYQpzjIOqGufpBvXSJI6EvQxYhK2NaRzSPVrhEr2LPkJnSOkRDAUq2aqB+kSc5DV+Pg0z4Rb36H6+Si2NkOEu8CiXqubLdC9u8yzbeobO8yFuw6O0yM24SqvUhFfpRVo5fhU8oC/aDT6gDNrgMT2Gq7qV1/WUBeynY6odF7iX1xjVEt+pu6xKmqPjtE5jekZ308v4Y3hed+sjdBJb0c+340t4kaZ4jBWN6gh38REa9DefdvLBY1aNBsdJw38QO3QpzfAQNalhOkUBbFK1VGwXYYmvChuVz4Emc4Q6qCvSl/N2VxggwfOLPgYed6Y7Ny3hct5GZ7O/hrPYlKTsLCq3HaRakEKMVM15PKjqfWCBLsAQJzWC3r/rvIY5Gko9qS4NZHOJSsZFWqR6qsaondjobnAVuJtcdjYOUp8vqSmXLnMvV1FHc7qjOWu7VJQO6whrHtMHVDIFtc0t/vxmB9nhIpcvkRyNnDDWBoCD2K8a1QRvcMkU9LotoHodURV4FGdDoCpxSqsWTwwQPC4CK1e1YSG24lGKXAWK0oFaKHeXussAq7GH2+zmcKIfVKFq+R9ohuZE3cu2LuBmtDHsrBWwURdaKU4XesaF+Wx1WSnP9Xa8EZ7GA9Jh4CbBJeh7ptXVkzK96Xi2BkZgc5eR8Xh+B3EGA8i+PW6GkyPBHpchN57prcfHckyAc7bqn5D9Tce3LFmMszQa5IT0y7TJ9L4Yz+X+bi/T+0v5hoj8j4h8Q/4qPvZNk+n9OJ7pXZKLJtPzx/c8FudcgBGf391aiDODnVnsZnrpT5jF4x4ZuXuMjJRfr5HhMd3Pf4NvmmDkgt/8LQOy4f/ZLc+ptxTaU7qbghggRw+vnfNUAbfr83TFqsFeHSJoBmqmdRzmRbuT5lQHLvMVjJGPj3IPT+oljtAydtABPsOHyCKmHjpC1wK5/a7GRIJgId9F99EK9TrqKuQo5jmM2jk/qAJcUYvoSMWfpDFs5BY+zxf8B2iVb9hd5MdOFaJBWqBxe4I3+RyHmHmN/pi+gMds5HGa4zN8Kx3XAXSIZsfoEJ3hs6pUZdjjevG4K5DFO7TAHcFcG5D4HK35coJJOsgz1EcL2Evj+ADN4iIt2FX+QurhsixXIJdL7Sb0oZ997CfFCgN2i+7CwUB7w420N0BmsfsXfF1dSQ7cezrjgXB+IB1ZtxLZRTHnR8MATzgV86iCnLynC4/rAFVivu6wCXM5RvVoFFIwh6E+odTV68ERjGGIR7Cx1UOKsQUa3F5XiWsKSGOQx2jQzldFFONxxuoErOAIaTVIQwsuTKVx7sEyDFHNmKvSfGbZddBlp2OouY78PMMRBVSCizpqB1Bb2VY6DXMP6WAG1dMEdlKIDkaBXClQ56Zk3UP7rWxqo2G0aIIbm6DWU+etAG7kPgCfh9q4QeXgANZREdfQGG+xTbau0yX2vm6vBQpsp7qbydU6RFGrAaB4NOFNkFPr/gVoCJeBzU/D7ZD1DBpEDiODi8OPRCT8aEC2pE+CpuVwTMbNVrthMDh8hYgcl14z1htvBoQlYJoWIQlK/96j/XJCYhKQoPTJjrSZsQnT8HDGuuSQeWVIZgxfgw0j44SMy4JMyKx8UL4lX5NvyMPyUfmOfEu+Iw/JZ+SH8rfyI/mk/Kn8WP5e/kk+Jx+Ub8gj8nX5gByXs3JOzskVmZGAOadt6Tdn3GK0WEKmvXI4PhaV4zJqzqkrPgvnbI5Le3wWx8xsQ4+1yoWH//zXyfScoPdf8PVfoW726+jpeZ8BFvNkirbHSBH86rN7PHd0A1S7AILNNILDtIETqoAjdIY2AtlNoBhjlqLLuIZMzdjKq7TFR6g6AJ0uHMNFrFIHaV5P8m10BwVoEs/RUarTBcQqpmb4ZbwBEHTTAZ6h03yDj/KyGuRN1Wdn0GlepXms6fLSUTzjq0Sic1hh+agD5/FB+hS9nmcpatfpZr6fz+Ag3c+bPE3nqAMDdIaeS9O4xWN60ZEsClTybTxI81innbrU83GBJq0pmuDCduAGmscR6moqwgrawT5upAW+lVbsCjpBd+MIT1Enr9AoQsQhy01jPYW1tmupRJVxHTdiIysKqiC1cBcPq6nQcMnbk68XOrrIP9828ngSPABNKa8v6euoV5gP4TRs4oijSI1p3cCmYIvQAve6fMmseZUaHSkpvoA3U5hyKDPkuIi1YYYClUy1uIjrZdABTqAgp41w0Ac+t3NFVSb18kletMF2mh+d9AJaxyZd1pAYAGykqFXJx7nLKqew9ua5cl2OwgRDmduRz8cWKuBT1KVquRuzbLBzsZrD+ja8yV/s9OUply/gPPn9yT53kqvc3QGKdT0XYb8uJsA6OsPtXDgEDLoS29hNXsqlEjVFd9EM+8niKG3gwZi3GwLQbejhNrSDnRfw6QgGuMIPdrY/NlySfav3tg54yvabx6x5muBlhoL59N+GaTfAePH8I0sy/eiknJIVmZA5GTYOFSMyLZNyWmZlXOZk3DQjpmRcJuWsTMuYzBp+g9MAGJcpORN/zBlznj9h2geTMi0jsiSnZMTY+azKqfgRluSinJLTRgjqnfJl+Yx8RT4kH5Cvy5fk6/KQvFI+IO+S98lbZEtmZF2mjR9Gq8zIoKzJG+Ud8hb5HXmpvEM+JO+Xj8hrZEGmZEUm5aRsyITMyLAxBx+UOTO2GD/uaVmUMZmSSTkjMzJmHj1jGiDjZmtKxmTmsRW58vA3f71MrxH+G/7ktxT0nkpPz/VLn5vrWSjyuZ4UNr1FnjrH534Wz+AId9FJ3auLVRUFqJqL9Qb3Ygwv0TkdAjfV8lk8qkpsd5GbMqkNu6gXd/QwZivCEV7gK3qVVjFIloriKN1K7/FXRVPpAm5zqz5BR+1pCqkCPklH9RHq4QF+Bd1w4M10K7+Ap2kO6znEa/Ra/ji/lZapVTdTC9t6Chetfdyqj2KYlmiMz1KV7ZTKj9EFnsc2PKen6JTq+XfANNXNz+E1HaMNni1361y6wF14gOt5gd5C96kGrObDvEm9ahRbVBpN09gFF0/gceqzuvCMtlURZ1pp/hLl135dw/W2A6ZTHOZ27uEhXLRWg4eKP5B4zbSZPKZIsPt3/KfI25r5yorN7uamMl3PPbqEQadgKWqKKYtzfDACze4KL7h6nGI/qvJqQMJxdZjbSVEEw6qWunjYX4kKkbOVVoUxd8StFLYEGkhb6eQucXcDJ+NFblcHFVIB2qhwmC9zoCnFD+T1A87gWSud+2jOSgTIdRn9MGAoh1JPOehyOkkOJe9WqkYgjw24nxb4FNqo7UY6yJr200k1pKHBU+jJASpUQWygPi5oASuV/FRhF+ggVekmnCWL/RhTAbTUHDqCEAUtQGGd5wdw5bnZU+oegA4Pl1GQoujT+QEHomxzq13IjS28//mp143C6ZOv426Qa4Xn/xIaKwApxvc26ZEkSX40UWakUhKNa+2aKPFKojHMrjQet8mGkeFIw5eYLa8B/a4aMXavlMmGlJpXVMumkWpPMC4U+80rlKxJutlzicxIgqSJR1hOyJRMy4x0ySPxZet35GvxrR/IW+Qz8pB8Wj4oU2JLnwRMr7VSQlIvQ/J78sfyYfmYvF4+J38t35YfyIekyYCpE2VaGs2x0gxOz2Mg0IvxWaQYN7YESZCDsm5mkSTJpn2RFJ9ZhXgl+bHcX395G4FH4b2/taAH8frdbj82CKEnHMe116bYbVUkQxs0xPNP5/9ZsG2EpX75QOmKfwdOwDmYdTQxBfyZmqmd1/E4zXENtRI2FfMk7tAq93JnyIupNGC362U+iWEcxCVKb/bWAdbjCZ6kMVpqdHTfTmF3e5KO4ADFdLm2sZ9W6d30EL+QXoSrGOU+PsMbRjzqOH2I1vQkL9BRuo+6aYPOkE1hGtDTOqjP0ZzKoUt0B0axgw+rfjqMQ5Fs3crbtE2H6DbubPAEPMFMPk2nHOVkPMv9fIrGmzKb9tNVWuJhDFAf99AmPYjXNGGzbubzdJZjHKPeYLkNVgOe1s2qmoZ5gV7C85amVTqNBQScr9GB7qhCVWorsrARbSuMYd3JA9iPs865Bo7lvRpebNKY/10pOJH02objrWwFOaJy9QFqwWhVEkNzAuXrJh3FABU5H6ZyV5Vn3e3PwjbsYmrw8D7qac6gXCrGEm3pG/QynPE3UIGq4I59LgfsQSUUozGqZWjwBNJU1GqwW4jUOTVtFVMmA2vqoU5VZ3gmQbRVjGe4XyekuizXrtxiOdRChTsGXKqWsIsiGu0Y5YeSOEztatDaz0AFgUY6o+YJVRiJmm5AkyeWQJ3Ur1llOGwKLsXWYK4qUwE+z6+iJS63y1ShLxXrMSLQXIgx7EJrxpXvLfKcA4RIst2AMQ5QhcrqBw1Y7tDumpOonqKaoy0FL4SXmqrdk2/74QS8BPQzgrCMLpFj3lyc+kiGeB9NkhWpFI9kSpIx+/ZIiuQaP4wEyRK3bEmtCSEH5bCUSZJpEWxKthGUKpbDUmTCX61sG3mqRDkohyTX2H47zIkUyRC31MqSkX1yCxuZUAc80mvaF07T4qvyJfkfeVREvitvkc+ape0HZFPGZFHGZUe2ZFDGpU9W5D3yMfmwPCRvkE/IN+TL8i15n9RLolQYypk2NTsnmAWMxXeacer1GNGqXbNvpzWza+ydaRgZ5WZmhXJYSiVZPI8Vy+lfx/fWa6oLPzECAK7fUmHt8XzNSetfBS+PiyrC3t/uvfC7Dz4ItxicnseIRP0Z/D38BfwR1Dzjr6J770ipcBbuhEkYgCPwcmgZ3IfdNGBpbKUxNazGdR+dwSXMwTxWGDayTaAL+DR380Gu5xa6RFPsOB+00ASHVA4t0VWe415eoUmrH7fpCHdQkPrVMr2Gvst/iXfSjG4jhbN6EWt5kea0oh26yEtVHq50JElpsymbp/gkrestPUO5CFyNZ2nCEXrSk6xwjN5M13Qh1/IOP4+1D6wE6tIrepRupuFAEvayojHnMbqDm6iH3ohLqp7v5B3qxJg+wJ28yll+0GN8yDpIeTRiB+kQv04P614HkRhJxwq+YA9xDINYzumObBMGsAKbKERKBbidu3iEHBGDY3TUnojVgGX8HBYhBo1QAwh9cApeAOspJd21OEgBXY5Rf0mTFxuph+scKtrrHKHVco5Rq1VLCRqyHZ+PBdppSe5zAXAdBRE06AOqFf26lWe4kZWK8I4exwos7PXoFOrEVcpBwCjHqFYfoSksUT2YhrDPHcviVs5RAb5EfSFXIJEu0ABVMAe9IfO2N0IF1LsrwM6jqCqgy9TJENhPR/mQdUDXa0ZPqZuAG5Rj63kBewO1NMQVCBjkVa7ecjWnqxL20xGaZttu4AjPah9HiUNeDYH93GJnHnKdBd3MV7mR4JhTwcxBog5Gfx4nO6hAlcJhbOX8iGN47qNa3a57hnLAD9fhbliCGDSBc1V74SS8AA4ZpMQvpQceZ2S4xP2o4y7xOCNjVXwGAJIpy/Ex9x5Q5aCsxcc8cUYGSLERet81+153rHUM+2LZUM9AfCYj3B2bjgtAKTkpczIv89InnxeRnxhQytf3Mr23yp/KJ+Rz8mGZlzYZkzbZkiUh6RCWCXmfPCS/L5+QN8qn5a/km/I9+aARB00Rh1eyK5CVJEsm/HkNZOVxRsZa3Ow7V1YN18RjYCwZe00Y53muxzy/nrSUE/TW4adwz28x6IGBxezemqFuzwLoZ2p6iZBs/s2Bj8CdhnvrjH8Qvg0lUAN/Bq+NW0a6nuL+uAqgJ759Gs7BPrP3RCDv7zRcDg1iFJGR52lFjwdiOhMbsIHA7/QdhxyCEoV5lAY5zy7VTFv4e/QAbmMMfXwUR61efiO/wkK7Ehexi6K0hlMU1P18K52wDtJz8XdonnrJj118DK/wWTVm1+tTvK2n6YAGPsELdJlfRs3UxnfQrbqqEhoSDgCH6A68iQ9jtZ3LS3Sv3uZ+3qLDuM0nMC9QwnfgiFXI83ycDutu8nOM3oB/zhds0m3k+DLs6MFDrpAH6/k03aQJHbPrEFfiNr0Kl1UzTzph2BG/8uXQNt2NbTxKHcqjs3VYhbAodJADSus6FaEIxbiHJmmOD+lV7kHbXM1MaIZNuA434BrcBhdhGArAnQJWJrei4w2cSy2am6A5gyK61c7RoKEZdFIgHzV3UgMVqrAqcSROw1DmjbgYKaAt7KKCNgfM26QDOkWlWHm0qqJoYwsGkekUHqYhWkZNpZxDbcNuVUAdgbQsR+qzXtk6zD2qxfYzqjpGQopiIYIjZcJQ7qqBgJeVsjBsVWrWDdrGNuogxgDlVMImUDW357uwgm3ltDMcNbwRvkJjGjGCUSaeoF5Ko6RAvt2mMwnYq3y6w27SbVhgQdSz5cZWLEXL8vvydEi32XWcqTy0yz+uoW7diAlWhurjykAJBnUX+XJ223iNsGF8mJ0/F2EMCszP9y+HiO11A3QXDz8yIgOPOo2HaemTAemV4zIjPTIgg3JMJqVXhqRfTsqEDEifjMhxGZdeGZQhOSWDMii9MiYnZET6pF8m5KT0y6D0ybgclyEZkB6ZkePmsT6Zkh3pkSHplAU5ao41IO3yQfkb+br8rXxCPiZ/I38lfyt/Kq+TP5IPyR/KO+SE8cvdMH62S7IpS7IjD8r75d3yQXlAPiSflT+Rz8vbZFIGZNS0T2bjs9iRBXM0Z2xK+sxZnTBz7JchOS4TZhYDclJGzSxG5YSMOWOPjculh3/66wW96yBw4rcATd4FnWzCm+DD8A/wduMXcBm2wQ9fN4DjIfgydIILXgzfhx/AyyFhL9NzuLdZ8OdGRRlgDr74tP63hXDDOOm6zcL2XhMEPbsZpKsv/7WRVn+Y/HaxyuY2UtRBHfoATvMGk2pkP1/gD+tLSDSBO9SkbJrgJXopXnd4AdoBVUwGMmiWx4LZDUnUTtO8jZd4lBdoLbCPgRrxjXxFd+loqACdcvcqneDX0HHs5VVap0E9jzvooyE6HFjWp+kWXUNQmOgHrKCX0CVuw0N0gkc6vSpCp3S3nqcY7dAL+WV01WIc0pt4Mz6HbFXOq3w7N1MPHeYN6qJFuk1VMFhpxIy0SPN4Gs9xRCMto40R2sZaK5GGcBXXaYC29BIxJWEnnbPb7NxgRtCHUawkH4XZojZqd2QA9AYtYRu2UdIeb9QBGqVCGqQ8Li6b5xHQhRhWyNpOpqiKMbArUMNd3Nju0XAF7oagO5Rkd+AVHA9l+DJUROUGoN7FpXxV9VueEHjcRe4WQFbs+J2pSrbJ1ZGkc1UdT9KH6T3Yx3VWAXvYSH1SI4cXXAGgAr4WsDTUJuAUn1d56EaiCLX4kh3t2ytQ5LYAK7CdWrAIwI7xdWoKQGMCrfBimYshmEsDlBpzUQemt6ZxpWrms/RZfL6KWiX1GdpNWRjDFAKVw+0qT0OBB6DZFczWJ3lBJygHhO63muqBauk4ncBy7RlyTUI71EJgn45ii5XT6LBoRrBEHXSY3myTF1xPuo6pP7uOv3SNesQNMFw888isTD46boLKhEzKhGlpjJs2xElZMo2KScOgmJBxmTVtAacZMCWnzd/jRtDJaV5MyIJpX0yZfuwp0woZN0bdk2a/i6b1sSiLMinvku/I1w0i713yNfkz+ar8sbxUXiuvl9fLA7IunTIgnbIsWzIi4zIsh2VbRmRCRmVbNo1h0IAckctyRs7KWbki6zIm0+LMYjk+ixOyZs5zIj6zKTOzZXOeM3uzcGY2Y854Tk4aq6Gpxxbk8sPf+PWC3j0gRk3P81tZ2N4GAvdCH/wNvMcISL0BvPBB+B7Y8G34MADcBT+CGeiEv4YXQzJ8JM69dUEGfNnQzwBugm9AIbihAuqg+n/da5xiDqzDO+GwaXgsweKT1GJcKW9omiCmoApp1K18WvfxIq1yjR6gbfbZEerGPjqqiLx2Iy5Ta6DSBi7mYzhMxKO8TeMaMJnHeZlWdKeepH46yXfzWF1WN3R4wi5ewvtwlDS18kVa4AWaCtXQHK7RNL0XP4odaHG3HdWneBoPqSU+QoUEkUxco+N0lXaojsb0Ih/Efr1Fx6g1YPMqfYa+zKew1QgOlNYn4Awu0mkcUI4271k6hKO8hSdwAAt1j92ip3iOF/ksjyqiIS7ToJDmcJhuONbWbPNR6rKSaJgv61YkGkClQ3YdF6qgIlbsCIt28CAu0rJWdrvDGEnYBSe7/xc43GXsd9wtoCqJdZND/rJ8ui2YRKBTKUqt9n6fW+AiqHLqtfO5gNqtAHbrVk5BxhbLcTjLIih05bscEg7ZmgZdXY4R0EGVRo0c4yWKqQ3eUKRIR3QPHVM+Xyb1UJUuoihaaCMEc7nDX6baLG07bYdxR7rKghqXD4IZ1IWDVoHK4R5sJh+39IJvH4cZKejkp3YTZ+gx2qAwRy0ftvIZ6sFxGrfZKrWSiLAWgfdzh1XQDuXuTEBXO1C9xbpc91KhztMjdlC3EVlZAYtbG9OcYh0mUq3udbx5W5y6ZK+Vow5iGOswimkdcGb3Aj5RG9n1q7r7PQmnNx63e/TISpyRkS5Le0aJa3Fcm8O+KNljZLjjisiP4/kKZW3PAnJpzyNjOW4BmSersk+KJFty5OPxpew/y+fikgLflXfJH8nH5CH5kHHGyBKXtBi7R2ePg9IfP2qLjMhBQcmWabkhF+WiXJZrRltl1xbyYNwCcsEwMpwF9nScfeHeY2TskxWzSHcZtGHS3sLdPO8xl+z8OstbJzy8EQQ6fktBzwX3wR+Z7XX4GyiOq6wUmPfxU1AOmfAVeCfUQy28Dn4AefCe+PLWOa/7QeACXIH/hi/BAdgHF+Dl8Hx4wf+6vwieBzfDX8JXIN3klWPgeqKenvf1DfPawmYuC+VTEuXbreTVdbrc+QLRDg/bXga2cYxmaIa3OTgABZ4yUAE1SwM4opDm6ZCtcINmyOGrstpw3NAwEAK3J+wWoHw8i2s4oNe5le/A23nIn0lBfZUv0Didw0ndhLfQc/gwndNkRx3eLCXTsr5N9eA8DdNR2uJxeg2exFW6pmMcwFt4G6N0kdb4Eh4h246pTjpNl5tTjCTpEZ7XtdzFLXyD3kcXdC+PKuYWcpots3iEajCMa2jxSb6sO+394WSaoGPqJGsuRkflZYYOBavsch3lOu3HFmyhTuxSk7TGhAGrGozLY8JT82KgDMpcCS4LOMDNTp2u1YOV1KPyGh1pplLdQ3VWGtbods5agk/BsEvvY83X+YZNljcEqoD7HVeLPFeWq9p93QGLNOhUhXheR/3VGGU/gj5Aq9gVyOiAWCa30oZGbNV38DVupDRu0U0cUPttaPKgpduoxh+mFTrYDAfcLcBRXrDr/BZ16ELlnE+jsaT0NaXhEL0QDxkR00NWeW3y90GX6SXduQbhDG63m1SzmsMdnRXI4bAqtKHUkwj7HBZxter+vCvmEOum6AW8FihXKQSLsAxURy1WjrWPohirS0Vo9mATtVuJVIgx6yB32IXKaC974Vlyiv43IyNLEh9NkzWplgSjbOfoGydJhpGRqjCuFklySBokWdKlJM5lSDE+sY423q67RJmkSZI0yLakGh5GiWwbPb0kYTlkvC8SpNo4bbAoaZKPyk/lv+Sn8rfyJ/JT+Tf5qfyFPCgflA/LR+S9MiIp0iwFMiRD4pZ94jUeGY7BeJKMy7Q0SUzqZVmuGhraRbkmQcPD8MiURMQtWQZ+HJYEyZBs2ZRSM7NUOSRoZK4KDdfEmZlXtqRGkiRNSuWIVEiqJD1WIWee/fJ2V3nuw06L87cS9HalpV5ksEmd8BWohefBq8xxjoMYPWQ/fAG+B5+Az8IX4D1QCe8xenqP97XugO/Cp+HF8Fnj5vyLb8fhLBw08xk1C/VEo8jizC0z6008oNlSrDRTiBt4hJZ0KY1Qi03czhFVVAGBAtzCUWpDhf1WdR0Mu31JtM1Xtd/K1z10Gz+fuqiNcrGbjuEIHuPDuNCY2u7KdDkfbYrSaQe2zKuo9QhdoudhJ53G25tTsYi2cJma7SBd4+OKKczr/Bp6B7+OVjlCUT7J1+goTVEAe3hdR3jTEbRXBVVAHfhCPsyMq7htj/JZumCXYh1fpFZmfECtYQDnaJhW6TBv0wSmBh0EW6tVySfoZTRLPRzwgX8fj/FduIEVhDqialU3nsIQNdKO7leF2iZHkKWDWmmI1jlIhEFfog2O+OUvYo2WQQnUuupcAcfkJ1/V6nC7yy6hYS4fgyaw3GzjUZpwqlzFCeDSoPdri7r4KPUq5StVSVxLoaAHvQkQBfKoDJxnx49tkGuxFAPKU+02UqTD2KGLu8BO1WjlqCaaxW1qUaiH+AHs17n+AzoNnCyOGXGB5poTioDLaYe7CLGJ3VaClYUHuIgu8h0O2Q7HcYOGKJdqnGwulIgWDVKfzqlzdYLeTzF/Nnc5Elt8yg7YyUUQgGrPayCQbre3ZKh9qoE1LtGiasVKTCU46Kn0kOOBd4SWqKABFGAyhrnjr4AO6vZAliZd3wK1RoL611dqe1KmN7/HUF2PMzJS47JLu2Ml8RxpK/68pD2mxX7ZijMySvcMwB0vjdQ493bjCcyNUqmVCimVj8UzvX8ymZ5z+1t5p/zhEzK9YkmSLuN3BibTG4hv9cmolApJoczJNTkv5+SCXDPsC6/h3jbv5aG7HhkuWdljZDgyobseGZtPYGTkxc94K87IyJGTzz7Tc35/kuHz8G+m3vbbCHpOpvd7e5neQXgOvBIAKuHL8AX4GjRBNnwDLpkwh7AC6fC78e6ts7haNIhXpw74ECSbwLmLd3ri3enzVsACpMTPvwSeD82PH1zAc1PJiyKtGFUW16kif47KoxKewyUcxlfTOarAIB7XR2iQxrDLTtZ11IfLnBsCDtIRXqQttY37AVQr99JhegmzXc+HcFh30iXudvqK1Z5/dMQnb+Xn4gb30gDt0BzP0XGepZsVBYGO8g3U1E0nadoeU0Eco9fTt+mtahZjdhVt0xwN4oQCjtFZR+Qd78HAGAS97Mf79Sle9uW3A87zGR6lO/kDfAmJh6ibx2jUl8mgW/nFOIcRS9MkneaAtnmBS7iZdijGTVhFc+qc6sBiyscePMfRQAbN4SFL63Ga0Q3s56AOcjfNq1arAqOYmQPoqnnat7MMGqDCWeJmU1cknZo4chfY+7FTNUTATqcY9XKUyHRhneDSyXUMKk91ciUHKRio5U6qsaHaS8WaOEoKh7FKgzqKA6GEBlexu8bVlKiiVq2OYHMAsIFOqMYg2EUY6QbNfIzGNFGIg6ipIuBIhXXzddVlJ/M5fZQi2GAfpCYMYpACGKAtWtVZmEuRDpeVQkN8ZM1hNUfIR0x1Gg64y90afPtph6MM3EsdNlKU6q395EiFOr5oDdiGjYh21EFlcxA7sMgRTFWVKsit3EcNFtgp2EqBAFh51KNzqEnpMrflqnSl/Sa+PTE3QHtx7yP90v5ou+FhtEmPRE3TIiod0iGnpU9ajKjUSRmWmLRLjxlrlW7pk5PSK13SKj1yRnqkXWKmuRGRXjN2SjqkXaIyLqckJl3SJuNmL+MyJkPyDvm2/B/5pnxa3iPfli/Jt+RheZW8Td4u75A3yoZ0yrgMyKZsmOMHzZYjWOWwdo/IlIEbH5Nb5TZzv0WmjHRVWI7InDla1DQtItIhbXLSnHGvmcW4mVlnfGa9ZraD0mpm7oy1SdtjI3Lp4S+5n3UeBlAE34Nvwb7fSvfW2eOt8BO4DPPwXXgPeOBBeB3kwCPwp1AOn4QvwX54EXwf1mEMvgTvN9JSzzXLW6fk+274Z5iFS/Df8eztmSHJzvE64YXQDfmQDQ3uc3kfV0f0gHKcsHxscTNVBVIiQP1qxqrlbm4hVst8jY/rZnLUUcqY8BDfRWfpKMX0JGmsRWqD94JeolEa5qP6KHewog7cpOtU2Ogu95QnYJiv0X24Q8vci7M8qrPoMg/pMXoVHeZFPUs30yv8veg0Mgb4Al+herrK13WMB3GF7qPT1EXn+aRVZfn4BN2DbRo4nXfUGVrT7dhLG7jIY9zPz9HXnYwFZ6wYT9GMP7sRaI5uomGupGP4HJpFm8e5kAFb9ADP8jZv4UgIdAYfpQvkbwPdzhe0xmY8QmNOJ9sxLcNOGsE2/0Fq1XkWlLoRap7hLa2ECmh22xAotvvK3UpjKB10OjFFqZ0b/DDgpUaKUkhHlIVZUahN+BJwUFfUgi616yhKJ7EXm4nsGpXTCIUeDjp2mFaswtPomYUi137HVDEaSUKNHdxHs6qgw+Vzcx2OaX84kcOYzUlURJVYh41oUQsepdfRK+l+Hlc2NlMj1WK5nVsN2Kjrm9KoD3swF90JTj4+i+3UTmWqgGOcZrv9rkSXzx1O4Xl7hAe4yoZCLxarJkujn9ZpVTVjI2V3uTFERexKcDcAlusARzhEUSwJQTCdwjrGEax1VJexnw5QCfUEUtDV4Kr8zXx/om6A1uLuR3ol9miLoWhFTRA7KVPSIh3SZfqzLdItLYZV4Wjo9clpGYgHiVPSLe3SJv1yWvql3VTbTsWf3y+npMuMOYyINuk0j541XhSOgNM75JvyFfmGfEreI9+UL5qtayZnuyI3ZNMEuIAsGtmALonIpmxKVLolaiy8A9ItthySBWFhCcm2LBg1P4dyNmc81FrlhMxIzATekzIgMXNWTjhvMaF7d2ZOcNzdenxmbdLy2JBcfvgL7l+joqfgX+ATJhN3/VZqetfh+/D78C14NzifhDvhLHTAlyFmQNF/BhOQCW+Cr8FX4COgIB1euecX6jLi8Y6Y/O1GVNT1tIt01xMqJyG4BDfDVbjZs64m9Umc1u3Eyo8VXEYNqo1W9SrNdCVZ2XSM+pvSENiiluwEFaEuQlrh1+J7+Jx2PJ53dJRH6DCN4wR1ko/O6oCv0CJ0AuJ9dGEAxtzcoU7jGJ0yKK8A5/Flfjlv4iT306vo/dihN2gT67Ebh/giX+YzXKeA6vQZnqLjPMcB7KFtehufdOQw6aReobOaaIBegK00yrN4E96tTwaJ1rizHUjxeTpMm6odW9UErfHNHMI5R8S0eT95cJRmyU+H8DhXBw6qHDWC2ziFA3Y5lVC32uQux3TRclgeM7xIG7hGjsx9l5XJQWpS0ODOcQTPn/HmaJCVOZaLzRTSYKyBgIr4JE0WJnS5FHR7sIuO0RRnIFS7Sz0VbjuTegKZ2jHqCdAhegEvY3nMi9Dt8TmKdte1H/2qFMHnroACR44Asd6/n87TqK4gny8138UFeAezBVTBwSYIQwTsNKuMHYumDfpD+nu6n4bYpkZfXoPXoa/ZGVa7lc5u2sbVMrf2cD6hrxbP8BhmcJt9oAca3ADZrkSgAJXbM3zWSqt3r0MImvYR4XW6i0a4Ltcxj/IRVTiz8NrgB2rQh3nDrquFJm8EVAXt8FQ56DQa5aJAGnb5stugwt0Av6Gg9+Tl7cITlrJNccGBjadc3ub9r+VtrmxJThyntxkfc8TkH5eWelyEIEuOiC0RiYqSh/YaGZ+Pb/1IrslpuSYX5VYZiltFsnT/3PJ2yJh9u4y4QNueeJQdf8Xozy1vna3cp1nerj9heWskFx7L/nWWt0721AP/Dg/+llB6TufqbvgdOAiBOK8iB7LhAJTF3d2LTSXO4zD+DZIvAQ4YFeTHb2mgDBjlV2FkuA1AGSEMlQnwGRdO4qJuxxZUFqtqKxs7eZRqaZzvU2OqhfvsbIc9STXUj+1qQw3jmFVs1dOOHlPlXI2zNI03423a0uv0Gqeny/WoMGoP8gV6N3XpAN9PGxTQk+oyLvMqzdEqvpgnaImXVQGt0BHe4aN2oyNwhRfo1dgZdNUkAWib7qUrNKlacZuuUDW101HqpWkO8zJ9kD7LpyjEZXScB7CGrtNh7tfpYY8qoAu0E8yyMjFI99Fn6GbViDV4nsMWUAN36QY+w7fwkFLg4go1Qb08yf26npsci0fVgYPciQ7/txunaYt2eIf7MM1qsAMBj3bXxCldv8wtG0o9ygkYfq+LIzRn2XhAN2JLLE2VcidWBzL8hdRGyvIGoNFj2AqzaFOEa1Q61vKo7XBUKJCsylTULqYYdzPqlKCLIcMVdncAbdIY7eMK7qQRldOc6ACIOODPa/DyKLejX7fYQW5kP7bRbXieonw/rzNzg4UU4aj262lWlwCbqIabqdkGYj3MIdwfLOITFGSo9yJUuPNdwXx0eMc+rtStmBHIo5jjsUvdlOXPIWRn8T/U7rHB51GAB6gVOZhN+9jmKKaSc3b5gWIeoFlVdMCDPVjYDCUeMKSi38jNaWRkmEZG0qMZppGRaFoTh8Q25tiPNzL2mUZGoyn37zYyHJ6DY/a9z4hM7TYy0uNm3483Mg5LvuF37DYynH1Uyo60SpfJ1z4a9774G9PI+Ff5qfy1XJfzckNukttM0yJPvAaY7DWyVE4jw7H9TpZpicVlpBzYSpIRw1qRlvgrHLNvrzmvDQkbdsg+Iy2VKDl7jYyMeCPDEZlKiJt9P97ISPt1zb6dTG8ZHjNLyt9GRc8JQi+Pd2+fjE7y7LXy3U9abD+V4t6z5t4meAQwTQ/bwxzjkCok5gu6T4Paz/24TCdtH7Xjsq7RxYh6gpYdqpqd74MmsOt42GZVT1s40ZhK5bTOY6odYziGrXYJaxzRW/pN9CP6E7yXlqiDlJrkGWqgZRq3Muk43URTAFiiX8jrtMP3E6l2PEcv5pFQQptnEOwKfjFfpGk9Sqf4eriIiM7QDrfoEB/nd+NL+QyGsIV2+BDdhMN4koabIZCkl2gSe+gktVIQb8E27qV+WqNZGsJZ2qYYKh4PZNvJgQpew1fhik5RoA/wIT6lMJypO2kSB3iIYmoTnVcd5lPUq6uoNZCc5ap01xh1sV/mlgXZkOxKhEAi9gZLyUdXdQAhBtqis2qE9x2HO6HJqfshteicAQ83UIg2cRRTg+5Z8IFqpBDvtyp5ji766y2gTOrCBaywoNh579xs62E90uB9NdB+nqEBDHFAl6gOPott3KkPcb3Oa07xFesQTfElVYjAQ3SZ2kk1ZlEGF3AXbRPSIu9gLdXoNpt4iexQqgVcTMu6mysDUOLNdqyN2miGmhVku2nMaRPpg1iqehxwchDqE3ShU8FlChYAcK1qx4pAUhtMACdTNR3h1UA2OSosG3gksA9ttJqg3pPr+k26a/0vyErRnol3Y1xEdCkOY/lZuT9P1vbGVuLyUAdlNf6oA/tw70FWUvYgKwnxRsZhIaNt4tuDrPx4D7Ly93LdZHqXn5DpBQ1kxW0yvb74UTuNH0aCaVpE4mc8YYyBnLGJOGTFG4eswJMgK2t7kJXVPeDNShxQU/A46+QxePaQld3e7V0gsP1b0dLbvRF0GAqaey+APR6WXEbOalddzPuEx5/4nnt/ObrOU+iVeRy7wmKX3yEkjVEH19MUr9uFOsxnaC6cQaCauA0b6By/jI6yEvDX8QW9ibXtLp932oE8LNI2LdJUIC2cyFs0Ek1VIZpXSzqmQtjFW/wGeit+ku6nae4INPGA2qFrdBKn1RKdw1HewA7t5zvoGlZRCC/SUTyEm3yJmgA4m9fxGJ2jKbK4E3foQTpJ83irCusI38vDKhtX1CzNE9Ht9HpecoyJcIAO0V3YghXYjBN41GrR0JxJJzDKubxDH8BrxDSp8rUDxAjSWTXGtRihST1EBzgd++gGdVAujeKkXqAhPU3bdEyPUTtf5Eob6jzg+uWD3n7YBwmQ7radmZzXEcq0Q3adXUUtfk2dqpKhwr3PrSAEuokO42FLWxmUptt1zhAUeutcVgK1qSLM1sPYxEztgVLO4lGc9KeXuKJJqoV0h9cu5VBzGh/gML0V7+VmsriUInpAe7lJVxcCBsjWNh1iTcBuTuM5niYftuhyR4hUZfkO4KyqVA3UxN30HnWzVe7P9uWpdvRiDnVytUCKi+r0OlvBdEXUruu5jVrS3RT2V9S4wm7tEkc7WWEqHeRhOsOTjVkENhR7Kl0NCWTrCNoUChzkkF1BGbxFU5VQ68lw5UCuMXT5jdyGDTh52oCTJ+S4ASJPPAGcPBUHJ08aBZI5A06ek1OysDf2MyDyLjh53oCTJ83YSQP9fRycvAtdPitLpqY3J2+Xr8oX5MvyCQNO/oJ8VT4ut8hNcotcl1vlqAEOj8shOWTA0WNy1HheTBp3jW3z6JgcM8xcZ88OM3fUqL8cNy2OiSeAkx3A8ryMyKiMGsavwzRx2BeLZn8TRsR0Mg6xNjN7bE4uP/xV97P8GXGC3jvjKD33bynT+396S4JcVxB8FTRAa2qRumiaO7mGlQr5K6leHcdJnYX1tMAhmqELhNyG26EDDOFUDuARtDCB5uleOkKtPMkXaJLm1SoPckCP8lVcoURc5nfzhu7U4YZcntJX9SJt8Qv1KZqkUf5dfjNu4hb1qD46gqNqkiN0TZ8D4Cm6m9twlhb5NodHijfwNlpkmw/rLVptTFWAxXReH9Gb1I8tdInLsZ1eS5+kU44xJeXrEbyNqxG4Wc3RIZyhMapXLXxCT6pOXuMJaseAwz7lSVpxSGzUjTZlUydepJAO0qhaozk9r5dI8Wlapha7REOZmyEfDj75Y+B+AtnvCbdSx9rB1QGBbI5hG7ZEnJreTTTVnBKEulTdT8oH+W6rzA5zWNUzUScWEtj7VV9nAkCe+yBwAo/o2UCKDYHEYB6HKcbOjxE1A7dYFuVirQriSVywGijGG3yZlXLXwTiQwob6BFzEaSoKlOIwDZGnHQrdjaDLaFlFmg84WEbbRsA2vT8MzS5M4zl9E09pS9t0kudVsy4L5lM7VxUDrdkLtlZtVoNOJw+DrsWjVH8Bit2prgD4S6k74mpMUIo6Ag1sYQwpsC8IlEL9aJWBgFWG59Tic8E6oAd1C5FznXJcBHn/O+z9guv4jLd+N0Bv8fAjo3Ea2owhZjmKec6WExx2yVpDRidvXPql19DQxgy9a0hOyFCcwHVcRqTX0NBOGJJXnzhB1CGpPU5DG5B+GZNrck1ullvkpPyefF++I9+TP5d3yJfls/JFeUhOy5oclS3jbtEtw9Ita7IhPTIsXaaR0W2Otimr0i0j0iVHZCV+xtuyKj0yZihnizIow4ZCtyR9MiaDckIuymk5K6fkqjzP3F8gNwx/wxG8OiXjZobjZma9MvDYuFx8+F+fXcDalbv5EjxqfuL/H4enpwyTrmcF7HwCAj7Ntc8VAX8aLegNPcpTdh93+LN0Jo3RBVpSWkUs5/f7IC3hiKriZoriNp3mZj2qe2yk0zyhB+jV9JKA3Zzor6SA8pMDTh6mZZqqSLDBztG38W2qH4OqhS7wCi3jSE8Ct+EqH+NL+nl6Amf5DroHL9FdylJBe1W/kV5Or8KjOqYa9BHeoEke1YAreLfapCV8ASPBpLOsu8hH6Ahv8Bydxkmc4ytcp/qxkyJ8mE+oDb2CR/kiI1bTaTvKoP18iTp0v92CrXySWlSrHg7kKVfAsTg6oqO6C1v9+3iOD3EPduACr9vleh23LIV9atgqqYEKV50Jeu5fdMXjzSSBTJdjXoRFNKIqAkCW2lY211ILHnSWhXYCd+AstmGQS0OJneAHnYOtOlqa6G9G9QaoSlgHK4PGaU4lovHWQMdtto436e10K4+qoNLot4qsGg7bhRzCVEY9Rai8CKEE3UezDlDcOqBbcThwQEGCq9RVBzUetGjMbsZ8tciDvG7XEzRBUy526pnQPqq2fYFybOVcu1aj5ajurPFr9Iu53S62korBMf5B8NXwURvJBa5mV20itnGWXUC92qcSEBqhMZOadNTud7QN/a4QNDvcF6Z6HMKNpuQaD7Zyiz+RoMxV+3jQe9rr+Mt8F/YsID2Pup5CcCBbluMWkO44W8FlFrBlxgLS8wQLSEdwwGVweuvGAtKh7y9Lxp7gwK4F5D65KufkrNwk6/KpuCLyP8sfyX/I38m/yl/IIRmWZZmUHRmNL1bDEo1vDZtGhrOXbjOWbNgXLfEznjJjuxaQvrgt5IqxgPSKR2ZkR5ZkVRblojxP7pN75HlyQw5KjpTKAWNP7syi2KAIXeJ+zPPsPTI85kf7O/BtQ/d3/VaCl2M7lPqEvbt+DqGeDElPOLap6UDS3jMzn9TY+GWPmwIHIN+B4eTAKDRlqU6O0SKv6V67zGrB63pJHwBQZWTzGPb4E61KWsJuSudCi2mZPkCf5tMc0xWU51TRgmm6m8apiQ5gP52kITqOd+KkL70bch37SI238RL36WVu5zv4Gk1aTRjiu/CGL0vX6SW6qOe0xRdwFG0rRIv0Dv5vejePUVhbtE3n9LzuY40X6DA20Qm+Uw3cAphC8zRD83yBb+PbdIgO8SXVQJDhtlppmSq5G9vpFvodPkMW9vAh3YF+nMI5PmzlBoH92MvTtM0tXK/acVxloEcP8ZZupxmNup4XeBUnVSGN0RHyYyu20whN6PIQJLl85mu2W0SHQrBhCEagC+phX/ydcR2GA26HNq2rqC+Q0+ny52Mbb7BlO44SrbpApaPFEZxRQ5Sm4eOQ4ALocwx4Gqgr2KA7qAgdjZJ2SreKqEWnWan+EuVDJqQZvp/ejBO6glObXM2OWFMzn9PFtqOC40gCtFAGF/MkrfozsIcmNbNij9Nvzod6dx3wAR3VpA77D6CPD+twQ4ZdRjFlE/mTbcBuPmF5CeoAE/R+8uFVegddpjbyk+Y6zKMkLKPYQ4ANiA6FW2sdJD91cO4A5JkszYZJ8FfiAg/ooK7SqeRH6/2gPDhBC9TckFYL6OdWO0NDgavuZ5/1FCgEDQPmOjZCThxa9ct923alpVLi0lLLcWmpRCMt5TYOErvSUplGWqpmT1qq1CjsPS4tlSRFe9JSNXLIPD/BSEvlSIp4jLRUshnLketyUS7IVdkyNb2fmEreR+XH8j35R/m6HJFxA2dx8ksw/eAWE+qyTFd21Oi+OPW7sKktOgGuz0hGpciyxCRZmmWfLEqPlEiNpMsRiUqaNEuFbMopOSSH5ZBckRfI8+S58iK5IbYoiYiWI1ItGZIhRXJUSiRJPI8VPXtpKa9xIvu/8O7fcBPDbcQS3XEB+vPG7jEp/qXxxs3vPHGwsSN3cH4PY7d7HrfBVvw5K/An8DCs71UEf/ERnxhU/XABngvPgzthPiurYx8N8yBpx0mCxnmH2ymV/OxTaWFXIFOH6CLdTUuOTxidUs4SZgabaI5v0u3cyNpZloa9yk1TuE5nORyopkW+xC91lo8J7lrXAFQm0hifoBN8ko5oP/XTaXwF9+s5ugvLGOg4nsItPsRH6RAfMii1O3EMX01XdIzGcJku4iZN0Uf5lJ7im+xNnNQnaYW26RqF9BS9mEaXPHqKb6GLgQQCStcxPU43eE13c39TqgrqNTWNdXyYPoy3qGpN2KsUbXCsKZtAZfE4HlM9SuOc0lYytnIPTfGKjukB7ad23GSbbTtMzvgQTmB1BcxAmsdog7TDTfA8uA5HYBtOwb1wD2zt4jD2eZpAex1uK4BK14x9tF95MIyVlMSWPsWTWB1JCwBX6H4uIPC7qtz7PD7QwJk2OT8y6BDMGjBXl+t52jItplo6gGFqzQHqomMc4LBSKi+YhH5cwKKAOx1s1vnKppu5rxz8+3BUTahpagkk7vbiMqERfC4NwSIaw2mexHAM7Hw+RkdD+eynkoDL9lJUzdVnY5JdgSHWPECnA7mRHN0XrA7ma8UhGsAT1BYoiOVSu6rmA47MK9UBaDjoLnSVeNoh6lVIXbWJHaALtNJHaUHtpySMWtU2sOIeqgy5g0XUiQcVJECicx3ToQUuw/PghrmOJ+FeuA8Ox6GQv8x39mcioimPOvKbuyKiqbImKAmSZLiyVWZrV0Q0SRIM58IZSzGQFUdENEHKTY6UYERENwwdLVHKZdUYCiUIyppkmD0flJvlrJwx8gCf3IOs/KH8u/xA/q98W7ZlVFZkysCkvZIqCRKTVnNGHhmRISP6mWRQgl5JN5SzNpPVeWVWWMCo401Io5E4dTwynJxvV1j0kEzJnEzJOblX7pQ75F65WcqM9ZHDEik2GWuxERFN+PVERJPidLCrz5IZ+MsFwAU487+yvIQnQWbeDg/uyYS6IQ9ugMB58+g8/AReCC+B/zb2kAmm3/tUd88TckQXhOHlMGYYGlVwS9rLaE4P6yih1URtPEOlFMZmnU2OWWIv+7TWh/lFfAGpE6xmXMEQ58WAUmmex6iFDlOYpuiM6uB17s53YT8e4kk+qg/zXFPKNIAL3ZOgCvk6342rOEQT+ixN6Eq6iWdoky9zJzoZ2938Nh3gYTpBa3iOYwpwju/BObzgmH2rPrxAA9yLa3SVzyDreX6YvkAnuZtW9Ala4x7dStt4RndTFg5jL7fzCcdDrS6RwJfNZ3nItmiVxk13uRZP8Pv1tr+I92EFtetKhOB+WsYBbKUd3cpVOkIxPOaPYQmtUz81stJBauVO7qYRWmUuT8xyrtttcC8MmWv4M0zyDrwEliGlEWqyOIy2SlTF2I0WgO3UA6tpG3vIR8QdgSynN1oFgTLutUpb4ZKjo+x0tBKtNK3oOr2SJ7CJwqypHEf99QTNidTE1J7Y4A5k0xy16mz0Y8Re4N7GPGrlNAJ0JCDCFOCoOmAdoBXqxi3V+lew37XLE8mDUvd1x5nOIaOtW9FQht2gW9iP8zQRdBoudZp9hbzJPRxSJaqQ5inU5FkCLtAxKgjAQeAejFgVFNVEis7za3iJizilzasgAtchAv5EDmFHOKnfXZiQAbqW28jPRIs0q9NKgID2YTuG7GzaT71cDe5kR9n0NrgPhvdk1XZP1bmO63sMoqe/7crFLzyyJFOPTsXl4mdlxLQvxuL1rjlT4h83QutTRqvktKmGPS4XP2u4sGfMY5NGZWXMNDXmjAbLjIzuycVPybxclZvkilyTU/JO+Qv5qnxTPiUPyufk4/I5+YhcNp4Xp+SCHJEhWTBNix0Zk3kZNCorQ2bPR43yypIMyo6sSbsMSIsck0XjhxGSowbK7FiKH5N5iUnUAJvPyVE5JkfkZrlP7pV75D65RXrFNi4dznk6i+cRObNb53tsVa48/B33s1p+OlnXq0GM96z7N7iorYc2mIXnOl8RcIENAciDUwbTmgs7BsREcBfcCz3mFa+FV5ow6DYZxlvgH+FvjS24Gz4CbzPPeA18NO6J9vN3t9H07TILdLehob0QfCZPNDNKvLv8ldGYFSXmJpWnu/Q2d9AxXtPluoOnKMb9VN3uxWEcoE49htscOeiuSQh7cB+t8Dlu9O3nHrxId2CQxvUw+bGFVnkc2/kMDU+D3217Zpxy9jW+nQ/xHLdRH89oi0+hswD9IH+Qw3SMtgJRvc4jdJlfZI/GkpTXztFH6F5HrpRW+Ba6WpfERMf5FG1RK97kIPbwJB2hi9zFJ/keXNf9die9jB6kM6qFx3QTjeKsKgwkcQ8O8BifoXAQQhncwW18mFZ5AAO0hCd5kEs4pGf9GZigegm5k4/xAK1Ro5Xp1B6pmhXZpDGCbdhNY3oBj8V0NsPzYeEJ3fVduh8YeeJrrtPVhbZtUSCLgtiq9ymwk7mI0WYacBBtCIGD3Me5PuhxtlMcrq8v3crRjpBVALUKqWN8Dy9SuQKGdECHulZGLRQMuQCqPWFQDTilQgDBg3oz4Hj5DmOQitjSS2QR+NJpnA5FM2gajxAHMgLmxOqhCCKuere/HNv5JrsYlT4WsBrASqYRHMJyu0wP2S3INEQzQYdvO0KDnCng84QdZZUBq5bqbSsIAdBQ4RhE3sS34iQqCtlEDarEl4YHKOQUGGwY8JRAwOI2TNKO2eU8hsmmBtwfAxusOu6mKp2LHX2Fyc3wPFh6yutYAlfhDGT9L2ODp7ppN0CgOPpITKKPhmVTBk24aDXLy7DhNRyTIWPkEzPWP2HDetgdi0pQjktYIhI2TYM+Y8EzICek1Wz1y450mMcnjEVQyOzv+fJmea08KC+S98nX5evyDfmcvE2+IJ8yoqHzhmkRkBU5JBFzd4Jq2GxtGAEBZ3tFFiVsCG5b8hxzv0fulEfkB/Id+Tt5v/yl/JP8k/yDfFy+Kv8sPzJVw6/I38nfyt/Kh+Vr8tfy1/JX8iH5kvxA/kq+L6+Ws3JDbpZb5YKZY8QYA33R/Swrevvhc/Bjk27/poKeE7424V/gG/Au+FezsH0FvA/y4f/C+yARXgH/CY1gw1/DZ+EP4QewCgBvgtfuBb0DcApa4T1wm8G/fhIWTbCbgj8zIGbvUwY9N2TANTgOZeb/wyZgJpm9OXaSmdlvwgG2Wel63egEAW5tSUTFZQwqi45z37hTO9pPS7xCfdSEw2Q7P8d2Hh3D43SED+l8cLzS+ukIvhz7dT8PkEVtvI53WpUd7o+AOqjWaIXO044eVYQH+Dx9gJZxkZY4TOd5C5fxCI7zBXYWrq/i7hhUeIPAQ/wgXeIZRhrB83wNp3Edrzg2QryuswLAbfxCfUSPcqFdTTeYeYjuIge9N4BbfMHuJSdIPh9vQourcBs7/NlWIffRFeqzgGtpjdqwgg7yDB/DDtXFp5WNDRTW+TTC7bqSpnGJatmnfNhMmiLYgl16FCftSf8d6W8AilsruZ7QSHJYzs4399S+57ZU2ZXcQTUh4FRVR2EdtusDGRbYzRQgx6E2j9pVls9lFXO5tmiTDukQN2ITlehs7KESyqApbLObObd0t9Z3ja1RKHY3uvZByEWp5Cg8d1F7ILMOmrIxys+ly6qhMQHDDe5QDg/zCLVQF9rYrZvnINExfoJKVz5gFrVxDMPUZcdwhrnGbZVRY1UC9fIL9CmsCKQ0ODqGgxzlVm4cdTe4yqHQTRBMwCU66vf2QIFXVZKF4xgdBBVlqyFV11GTbqJBOkZjdgWX874OR1Mv4ktSYOViF2XWAxZZiDFmKo1BdRKFVKQjp3o4+TUQ/kXXEcDYGaTtAbV+OZze5B77Yk0ansICsuAXWkDmynqckfFEC8jHJZvqZTU+liwvlffI2+T98pI9Z4x/kY/Jf8sP5d/k7wyDokJcps+7+wotsfjWwB5Or8eg8/YbbsY9covcLjfLbfJX8h/yQ/kveUh+ZPb7ExPodhGAn5d/NGP/I5+Vf4sf97PyHfl3+Uf5d3mzrMk5OS4X5IRkG5xe0rNtZDiBRsMP4I+ewXD42QS9v4dR8+9PoABugY8Y26i/hXfD92ECAB6CPzbPfRV8BQBeCa83r/pZTe+DcMOoKH8GZs3/R+HLUATpcARuh5vh2pPuV+EGXIIj8C34U0gFL2zAqOlJx281Lu9r6qZDyMzNdnWgkvfjoO5DB3k16PRcMYStZOkQLlP37wNVYSceYYuK9DKO4iQpu0nVNYIArWPEV0TneYCqUHGLnqLb6NbD4EvC03RJt/MCnqYZtcLrNEE7tEQnaIoAa+j5uETH+Plqh7d4h67Qpl1Q59XZuMkv0Zd4mCbUFC3Rm/gWnCLiZbqf/ALsZeQX6OO6n8O4xsd5geawtsJDC3wPnaJqO9eO0m10B65zG61jJy7TC9QR1GpTLWFLIEZz5PeDqmXfhMsqdJat1M/HuAe3uK81iep5luqoymEjE2uNARXFDtXPg/ZG9ocTwnGV6p9P4hMTvBmJSVfzrvRV1WQGs9lPLcrGMkoOQAg6odZNMWqgbLuAe+mEblWKAoEqVULdumvQi9DmpTbtAyAvNxErH7cGSlSRclQOo50JtR6Hd1vpQuByZya4GoYmt67T7FwD1c7IQxTFCBVEvHQOBygN23lW5SwBuALQ7NpwoY8WVR3u44vcHQRUmqiXuslHUzhBqFjlI9gH9SXqIz9lFLmK3HlGACqwnwe0bTVjHvswatepGOd0uijNbtfVAUcKvpzHSfkPar8OsMWzdAz9lIc5OsblDDFQjstHLtVRhCNc3ZjcVBoIp742sf0XXUfzY5wAV0zR5uk7uT8z+06Om30nGJvsbbGN2ffBPbPvZNmWZkmVLCl9ktl33pPMvtN+zux7357Zd55kygG5X94hb5J3y4vkT+Qn8p/yE/kb+bD8UP5Svi/fkqAUSESKZVJmJUEKJEHaZEoSJE8SzOLZaaOkyqwMSYlEJUOm5F65Xe6SG3KHfE1+JN+Tf5KPyl+bPf+nCWu79uAfl781W/8pD8nfy6Pyn/If8pB8TX4o35MfyuvkkFyQU3JRzkiJM4vHauXMw4+5n8Uy1PkFWoPH4DnPCv77dEHvBLwLMsED2fAt6IEr8EGTkd0MYpgfWfBt+A48CG+Eb8A/Qz7cD298QtBzQw58GK6bpfBnYcrscwz+HIohybjutf/cvQta4RS8B06ZGS3Dwp6engtc+z2pb2qeCSE1YSVXBGq4Cf18lKd4gF9EF6iBmC7hi/Eo1vO6WqUa7fQQ36bfh2eIdbveJI3j+hivOMR8WqGT5McCcrw1evgIv5cu0hl8Fc1TCwZonpexEZf0kACe4wVapCqq5OfQWSriRryN7qRN7OU7+JAf1BTdSst8mTbohjqv+q1iPkr34jJv0U16OB/0Pj7J27xIHXSB7tAxPhPocvqBHKH7cZr6VJAGsDvfkVM/obq5Xg8bEM2maqdteimtByvwMN1D06qANI8HklU2hULpdpSCdoFu5R3qwHpqosZgLTczoe1IgKrBaHvRKzwnM8H9C8zVE8DjTQdPdfJLDobaarGLm/AAO7kaDLowlYupgaIOcY6UKqcozftyC1w5oKDVIfnFHJixHRhz5XmaXJjMbbif03iLzmIpAQUYEfLdBx2wiLsN6BT3UCmNU5hsX54GrKJ2yuN2fDNO1CZyo26wau0YN9MkdoIry3XQ3QaBPJrlGPs5pIuV7dvvz3OgQrqQ6qiDHTGoOgxhN/XqYj7JbRrIK5DtcruCKdyn9xFwH1+jtjKgINc3uErdFtjZNMCVupLbVRYCQR/8AyDykl2r6sjmNb3IPq7F/f7E0+AsfClJl+oAdgwczDjjvZQF4HW5nuZbUgH3QPUz6U89KdOb2MvgVuPc21RZifMbnLGD8axubW9sOf5v/h5/9WeZnuOk9ri01GqcpZEqL5P3ytvlA/LSJ2R6fyz/JT+Uf5UfGAaFA5FxMHOPZ3qhPe5t756IaEscsjIsd+9let+TR+XH8hN5WP4lvuf/I/8Q33pkL9P7vPx7fOzz8j35b/kX+W95i2zIeYPlO7Gbrz6W+OwyvcdtesTkZO7faNA7CQ9CLnggB/4S2uFm+Ai4IBMeAIH3QBokwXfhjbAAx2ATNiAFHogvb117db1dyfg0+BQcNcvXNfikMSX8xUTQc3seahruMb+vifHecEv+GwNtGNSaWTdYBym1CvxenMMpfZAUtVEEQ1jNndzG+6iTo4R8hC/rc3iG2qiIo3qGhugSnUPCNXwZj9M6xbCCbOrHNXoD/ZS+SXfxMnexn4acVgQdx1m8QSexj8f4VXSn3sYta5xW+TTdhQvaz06J/Ay+As+oVlrAm2kQe/VwZxIdoxPINMv9fFlraqeX6x6O0GWe41Q9S0dpNHiAk3mRztEKOrXHsZaEerAO6jU+RSOBNA3op2t6juuoSnVShCb4LI9QH55UnTzOp60QT+hhleHL5F4OqHRVyFV2IwYUW0y2DmFnMKrm01/nLc52Jf6Cr6qzIEjygtuztu/aQF5jGsOW285XtWRxmFpIo48P6hoa9aWJUzKo4u5Aag4oz34PgVXE59RgOZS6slzFbnR6q2EO6ahu0K26cdxh8VZrqHSXu4OA1dxNUWriUzi/CEUQTggkaE01FMY5HuZBfdYuaQIqwnbuog1VmgEHXHYCdetFbFNkJf+F0wM+QxG1hCPYqBDLW9xFXgJ/MV3UY9zIvTpq51hQ665wjbipVRdle+0WZnKgNjFUgURwHYQyTxv4svA0TYRSBeo8jW5lNKFVooIMl27EAZ2nKllRSLVxgJqwQmXaoEDl+HXqK6A82+Vxu56+nr5qUApP10QcdQOMFc8/siizjzrS8A5cxPEoOyMbxp7RaUs8PnZOlmVGpmVJzsiqTMuszMhZ8/e0rMhZWTavWJFzxgvX2dr1k52WTdPwcB5dlHvlAXmpvEqeI2+Vz8qn5DPyUXmd/LHxw/g949LhHOWYnDRHmDbti2nTBDluHp0xNuFHTRvFEa6/Q26X2+UWuS1uFvRxeYN8VD4tn5JPyjvl9+Xz8mn5nLxVPiZ/Kp+VP5W3ysflT+Xz8ll5UD4sn5SH5JNyv9F2uUmuy2VZco7x2JLc9PAfup9FRc8FBfAZ+GcDRPjNBr0t+CG0AMBp+C84ALfABwDgGvwQtuA78HwAeNgseJ3HfxcAXv5zQe8DcLN5/M1m+QvwaSOI8FRqeruOoulwYK914YUzcZF554YZf1B/MdiJHURYriuROYIBHOR5Hq5NtPbTKRpsd7QJEggxZgfpOM3ao8H0qIu6cdyyVAGt4oQ/ycrFkziEORSiFu4nm0Kql87QA7hDr8M34CR3oM25OMdnaIGW9SZP4hSt0iv5QR5RC/w8uovP0n24hK00iA+S8Lt4VNk0zC+k59BxPUy/Q9d5Vd9GHcy8Q+/lj9F5DnEVr/M2DXBUlzs9Y97RtziSn4w0qKe40r+fDmOnqqIQlVd7aICmeNzOI6emdxprAHCWVvzpXM5DWMDDPIMNyLSstrS2g6yVj+rtKl2jfBigkNXZxmV3JN8EiVVP28l3ewE8kYQbpZUtddRmeBSkq3A/ZVJyo7sR/I7zWaweCt0hl+3DTpUUgFLHMBGxG3uwyQGA5LqDUAa4Tutdjmp1FoY4bFWpdivPAT5zIbfaBbjNS5xGmoPHXK2ebEez8AY3D7q4C0dZaU3d/nIupCBu0iFfQgNYNXiJxlSz3s/E3ejY+Yzr2kI3btJCOXR6Aax91EO5/gN0RYepWoUCybUuBcpHIauaeuxqlahBV9LNaDHkuFLcJyGaxC3Y4cgIAFR4WwFLdT9lIVguzKP2hlTHxZG9lKqy7CJspACFqcVqGz+QNuK94k0HcLlcTw8XC8JVg2L+xd++NjdAuLj1kXbTyNiWQQlJi7AclWHREpWo7EiXBKRVgnJMeiRsto9LuwSMGJNjv90iAWmTY9ImAQkZNkfQPL9TdkzvlGVIjpranNMEcWhgc7Igo/I++bH8rfxQviq/K9+UP5dvyGfkiEzIiszKUVkTv3RKQOZkw4g+tRoxqt+XD8mH5c3ykPy1aUi8X74iP5Yfyj/Jp+Xz8mP5a/ln+bC8Qd4j75L3yktlR07JcTkpl4WkXpQUmJZKhdRJkxyTRsmQTMmUwxKRZqkVX3xmscd65MLD/+Z+VsFpGH4CbzHN89/s8nYJ/gf+Bj4FPzEZ26vgPeCP+61dAYEuIPgX+BZ8AgTuA4B3wVufFPSy4E+MZLwLfPBd+Dr8H/gbo3jkeUYRq919ZMJZuA8WYBzOwP3lV4OHaYpaNeowNfsyOZn6cIuYp/DltEmN1MZ+gFASNdCavcTzfMbOKYcjLkxhzW18VG/STH2KtQ9neCYQcMy/+TB3qyBOqus4FgYifAOdpD7L6YFepiO4hmMAHOZb8bqvhIM0g+doNtCIJ7GfruC03uQH+Ay/Gs9RhKbpZjxKQ7TNN/E0LdCOttnPy/x5+jzvENI4T/I5fAm1cTMP0O/wN+km9qsufoVe9Ss6Q++iy2zZdehTM/RiupV8WE/ztIqTHKIh6tLDPIBh7g2l6ybs0A5A4yC3Wak6RefwQaygOrY4rILMFFLRWDj/BcnDWaaL8QzrreyMO6omOwrxIKdjQthdDzawuUehAzpcSMrn1PgQsFlFOMFxasNAP5BjrNTs+Nza+7hVVakgFgbBhgY3H+QYDtqtbQnhBBrSvRhSJRQLZwZcOkKWBZkeJhrgQBhwmBeC0JRkOcEtYqHuo7soRl46jmcwoG2KqjpKrYWCJHWBCziN++0uLmuGQBp2UikD1jJjObXqKb8y+sfD2IWkk1sdWE0ikV3vOC1Vu0JAaaqT/U2g9lOXzrchWEDd4SxHFVqlUmvgoA3scgRF2XHMhVIgDyVitirrL8u7M2kcXOnPfB1z4IpRLHf/EowM16Mumd1jZKwZHWKX5Bj2xa7d44aUm7HC+JbHOE48zshwnGUd9kWlbO4xMtZlnxmzZC3OyNgvpw2Tdk569qSlfiR/IP8q35d/lr+UKSHpl5Ax79m1irSNtkq+eKRN3it/LH8gfyhvl88aOPO/yB/KD+J7+Zp8Ow52/qS8Vz4uH5OH5fVyXq7LTXJNrsqgdEiv7AqlOjqBTnBmqRafNMhWfFlfJJtmtq7H9j0bnN5us9wxBNqId0V/k0FvBz4J63AZhnbb7hCCeliGbPP2zkPEoL4uwQ3oMMd1ev1PhBZ7oWNPvL4GrsLlvaXrL0Nd2w2dzbANZ2AUMgR4jFYdUXRdY1dRFNep10qxM+0OvaCPKsUBvoIX1JhiK0nX6su4RP468LktR3DgHDc0ZOOsfg5fwjYd4EMUUdVqic7yIG3TEIMGn5sW6V4aVWGaVV10g6/QAh2iFr3Dd1KeBt5UR/A8n7M3+RBdoCt0K01aQEt4Fy3weX2ONxwgcnOKDtJ51a4P60G6l08g4zVapEXu51Kdz22qlib4HjVG69iNYd1NA9yGNxvzoTYrn+v4OL1Qb2ut6vkQPReX2fGNfTl30BC/gad5lM5ZHRSifr5AE1pzyEK20KebqEHXYxMShzAcieW+Mpl2a+dPd6W9LgDXtYTONk+pN+qu9LYm9iVGk2oSaxNrE2sSW5Msr0rQfdxou3Wy8lohpIDPjnLasDfstlIxEiAuxRG7nj1UTIM6tckbSySPlc7IO9yNg7SFfkrWbmzQneS206mNmjDARF5uoRbu4D5dqF2NCTrRziG/7jSOJaf4lThPIaqiNPIWe5RbMw3aUd2JlYEs6lTVOsb1AXd4vx70ZyhHcmCAtu0gb9CMVaITI+5IEntUA3VSIiXrLo5igd3N1eStSQx4dblu11XUEShUnkgCJmMPqoAnkFKT+Pi9K6k3MZhY7wm6ixNaEzxXXeHdePWMEmgXja6k+2kZGcnFyY+ki+fRRFkyndMM8cqmWMY5NlsOGZtsB/S7JVVmzJGbKjZAZEcxL0uSDeh4Ww5KkrilSg6Jx+wjX7Yk24z5ZdPIOXmkSM4YpN+c9MkfichjIvJ38gfyY/kb+Uf5tsxJSIalVdb2GBkRmZESaZD90iu/uxf0Pi3/JH8l/yh/IH9t9vJT+ZJ8Xf5H/l3+xwgY/LH8oTwkr5OzRpL05r2g52D3xqRduqRPjouSKvFLvWxLobglycyiSBLF9Vj+s2Fk7ComPwLfg6rfsKiUE/QuwCf3GNfup+DEep6CrPZUAcz9FFu/osSBBkylYT2CAbbZR108RK04jwvhbA1YYnch0Zi+xOeI7W7e0T4O8qmAv9qFirsopLaxhYbpJXwX2+HkKi918jYt8hm6QaONyStQ5JkGyqMjuIQrtIOrVh0N6mN0N23RJF/jSarBTVrlW/m11IAhuoxvwps4GxzA8Dbdx5e4jS/SC/kkjliTNM+beIiu8DUur3XTON5OJ3lZoV1F83gID+tudvThLvIRrfQ83UxBAky1bY45asqcSRnO0hvLQ0BMq8pqSsZpmsQcNaWnAgmprqY07qb6Ti/vtw/wQV1CFVYN1wUa0IdkhygUbc16lbsJIPkZvqyZHoCE6/knun0Y0xE7bIeefNdhsrGTz9o9WqswW3yV77UDzDqso6y1Ref51fY0N1FMMy3wIZt1mCPa5mYc5z/m91EPNXOQwhiiIzTFjRzF++iyRkS7wzEw50He0dqOcFiT9nNET9HH+Kd0j+7UAe134MvkAF5O25pvpju0j9HuoZfwNvnY1kf0tE3OkbmJT/EX6IU6aPtMbVFzN520O9jmICu+zK/gUd1EER3WMd3M0/RymtKOcSbRMh9CpvDPzTyswxyjcI+V9loHi53g/iXSjivPIPWR5gZILU5/JE0yH02TSamVNEmTfbImHFfMW5F6M5Zp2ArOVqWsSZ2kSYakGaaF08etlXWpMo/WyIZR5EuTalmRPEmTVGFZk1yzv5J4pjcrvfIx+Yk8Ko/JP8hH5Z/le/Ij+ZZMChm835JMSoqkS4pEZEiSDFgmIu8yy9sPyVvk0/JD+Y78o/y+/H080/umfCe+9Rn5gHxKHpbPyBuNOt9VuS7XpF/apMuAmEelxWyfkDopkBopNmS6dHPGG+YKZDyW9mwaGV7TExV4teG9/ib1VbzGp/aBeJXtcbGox+lnrnjlbReq6f4FanmeJyjpeZ4Zy/QLiXAeALerERpzaZhj5EiAL+oaO0z9FNIOoBR5G0fA1QLkpwV7ziZsphAd5pfiKdymPqxHxUfUKDjE8lHupRlq1R08Sxf5Fcw+SHH3wwE3gW7iq3QPrukBPY8X9VAsAa9QP3fQR/mdOkBb1gL56KLjuEFv52Nlrh5vFGiY3sIXeZ0DdJQv0bvwVs616/A4vZ7WFbS7uIlezTt2I68aZb1jdKM5GUGX8EU6zMt6TV/WVQR+t2rgdT5P7DAC1CQd9pf6U5lph4KcTzM0FSrnKZrjQkznbh7nA1aFruJaqsMGakIfow7okLYxROHWyL6XJVrPnOkZPYLr3g6AsozG9KbM5mxftsravWOmc/dlq2Rdo0fVfvayTe3UpoOc0pTdnG6nU8gowAzZVbXJlG1nqiFqVkmhdJWlm+kwbRiZ9kad0ZxKaaqG+zBbB7ldd9lWsQcjTqFCZVGfqqvz2mn2AWrENjpJr+Xn0cvsCbKxMpzpS8v3UBcqzuNJNaJLfZnoZG59zSX+Kuy3Mn2ZgWSVxx18hGb5jBq1SnxpdrqdwT2MzclWdiQNY9wbYO7H6qbEptzGlECx7sQW6vEXp7i0ogHKaEq3slQmZqrM+Myzm7Obs5oz6jMOpgJ4bnEFADyuXyLTu2Rq37/4ii+4AeaKNx7ZkuVHl+SsbMmirMq8aWQsyKppWqzLoqyL8+iGLMuSLMtpWTGPrss5WZM185ozsmweXTeC8GvmjzO2KguyIadlQVaMVfdFU2M7JdvydvmG/Ll8VT4hb5HPyUPyWfmwnJVN2ZFDcsbYjTvVveNyWAZl0qisvE7eKW+X35EH5HflM/LH8ll5q3xAPiOflE/LO+Vd8nH5sDwkb5CXy2vM/XnGGvKaXJersiOHzZ8LclyOyBE5KufksKzLIdmS87JpAM9O68X8+9gRufnhH7t/xZDg2AG9C/7TQEI8vxWpgf+faLZ4ocDV6eKDNEknaFg59js9vtRIBo3zSVzkZt3C1QoChfqs7lO5ukTbNE/Pp3fSGQzaVVRKWzhPKb5E5TjaTlutqoNm6RgfxTmV/hVIcVV6OsGfo2/lF9E6TVE7BR17aTrMCzROh+k5egnX8CJv8gkaplN0L92JjQFXczqu8/PxitVH5+mFdJ57eYCW7U29zC/h441eXwIt4Xk6ap+yC/1AC3QTXeTmUCr345qewlIcxGU8io0qiu2Bal6mCRp3vNhUJW7QDdqkajpDr9Jdup/fwJPUo0/xEh7SMUQHZKHLscyqwGpVzTVch02sdYSjkUjeC5P6UqHY5Xqm9zY99faiEfuAlRdMj3nqHbURUKYGkeUCmDLfYwVUozSWcziY2gDa5kYb/Ek6SHZzQj1ggR21S2LQA6EsHQ0m435W3M8DTUmtKfYE9yBxjoZll27ACdV0wB1J0RxgOwDANpfZaWTzfl3juBlzL93BfSUuuszHyMkXiYroANm1QC36gC+L2rSNNSGgPNWCI6FsgqiXyznAUxhCUNU4iVGuDaRwkQ6UO3XJREIKFHjawDpIXVhJYKdwzC72AZcrmw5Sh0oX6IQeeDV4XCWuJgiABQTN4AdfEu/zF8T259yWOAyuHNczfkfS4bKpVv/iby+5Aag4+EhIQo/asiG9EhBbwnJURiRgmhWHpV9ssSUkx0xjwZYuOSp9Bkpiy1EJSFBs6THkL9vwKY5JxDyvV45IzOxlxFD/nUc75biRh+qXTnmvfE++I9+VL8qHjcjU9+XP5G65Xe6Tu+UeOSELsimzsi4Pyz/IX8oP5WPyiPxIfiA/lM/Kw/J9+Sv5gXxMbpa75E65R26XqBSKklJZloBUSZXUyqqMSLOg+GVdeoVFS0COSr9x1WiRI9JrRoKyI2Ezi245aqhpocfCcu7h77p/5cVtG/wbPAT7f8N53s9Sd9eTjud9hsjk/rmGvvsptn/VPM8LnkRXpafSUfWY56O0jusqFyPqHM9jUbsnsE/X6F5a1916ksK8gaftZmrV47HMQJW+mXrRppO6j8bosh5T89hOCdSNKzSHs9ymd3Awy1XuaXaFEridz/FVcmwGg7qYTvMH9DBv85LPySCfwyu0pO/ls3gJd3CZ76CzvUCjeCev0Bk8Tmu0gjeVJRPRSQ7TWTrDZ3EWJ/kG9+CKGlS9NK4HeY0m8D56GV0hRTY/n+ewnu7i99FZHeEt7KUlulcfJcX1tMonaYLb9QwO0bSeROROKwlr6FowlaAxxc7U+apM11I9Nii/Qu1XpJzubXtMF9+ZdNadVPq03VuXN8nt5aSbqyncrNopTGg36BKVq1IL3UHoMGjySneVlzxeoBl1tCQBwPbWJ+kAIoYxWOgqhpYEBp3D7eg74mJgpHXS2oedmOegda1S7tQN3MZ+7UVFZ6wDg3DO5cuxb2GlgDJUl6NPzXO6xqrBgN6gY76UVjc34WUespt1NSo+Qy1k+22CmJu3aJGgKaEddAcdoxSdxc7iVmGM05u8PrAtDFETD9CiP1sB7aMWVgD1rjIPAR3ATvZTDKv6oDbBdtxub9bVfodX7K50j0EvhCAIrQlWJudTJftQU0y1dlRlLXpPp6Q5q4xn+MwTXDVMI/cvidObMrrBLoPJe5yRsWKWli7jJJEfx+ltxLkZjsKyJ47JW4+7UBQanJ7LPO9xRkbDnsJynmxKtTRLo1Q/wSPjZ8rJt8sVuVNukTtkzSxsAzIkn5MfyXflR/IJ+av4K74l34jLUn1JXihvktfLW+SlEpMi0VJpINZOEyRBVo0BuNNAWTDn7ja8khpzJplxtOHubFP3DCrNHB/zyrFfbXnrLCeT4Q3wGBz7rdk+un/NkPnE8PerL22fcPR9CQx4kHqxhSZpQnfxYdWFjC1Up1PLE1WxIrrKH8QzSKFUZDys7UAquGIe7aMZ2kbkbBriHb6o/LRKL7QDOkDjfr9uxRW6iwlAebGVb+gRvcGO1c88HeNBHebDfFQv6BQuw/v5JizAKrpBt9ICE2/TG9kxk7zEMVqiW/koj+KOugtncF6fxR3so0X+DH+RTpOmXprB63w/b6sI9eKL6A18nkKqXy/oKerXUbsXnQVht24iuymJHP/ZOVXiKELT+UCFDTxJiyqLSsihuG3zIWqlMAfIhw1cwWVWLdarevQ7rAwrojpC4cbN5Fe78twucP/Ct8+V7M0A92LmrbEDTpfKl4NVjqGiCZsW1lCZndPlVQawjAXYTT12KUAwwQJrvz7P/Y5fRqYrBFWefsAMbtGKKjiC69TAdazugSZXpbvLQRzWczI5MgrDdgU1RpP3uxBZYYBqVSFP445qtTmwXxH30GFuKIUMt0qkUV6hGJcHDlIb9fBlpbFUIym2sWQ/NB1wCHt0SA9ilZWKQcwLQ6G73h1Is9qtfBzieaxV1dRCDRtQ7Sp0J0Cpxw9NyXwaJ0MOkjghnExB7EHbStjtU1MqHaRKbtCaQmQTcqMu0alLkO6tjCY9AIUul8f9tLx3gEXYeYYmYrKRlkp9JN2Yfa8alZV0SZct45GRZuShqsxWsvHISI77YVRLsqSYVkWGpEqyVBh3CUd3pVG2zR6SpMw0NxzFFS2HjPl2onmtbZi0LB+Vn8h/GUaGw834V/mJfFfullvlXrlL7pGjMmFED1blT+Tv5C/k7+Uh+Xqcw/FF+aI8Jj+Wx+Rzcq+8Ql4uD8jzpUMqJSB1si5BSZAsyTBcXWc++2RTys2W4/5BkmTYJIel2th+J8bNvncty6ucWfzqHhlOSInC/4VPQf6eQslvI+ztSr07QagX+vcMvB/PAl1x+SnnfMbi5j+7Z+c8r9c0WLymLdIL9c/QynD9r+aH83rH/nsFKvIAC9U0DSJall6gWeXnqLW/IYPm6QRNUj236xG2eVaHyOYhXtXhYFKT13JjAm/zWdzgedy/H7CEJo2nxHHcIs1+u1WP0t10f226VU8vpiPcoltpkTasBp7hMSzja9oRArjMO3yMtniOtukMvogXA0Gcxrc7OD09zhp78S5+Dp3S/fg6vBmn9O28o4mP80v5brxmdWApH6UxRLwbW3iGWu003cHLuMhKL9FsLtiAnXgPH+MlXyI6sJsOmsAGXe5YWdMInqEx7qVTxnLoLrYoqnqj3qYkzOICrme/rsd6atRIAQpQhNpVX2vbwTe5FwFSPb+IG+X1FrjSi1PvK2iPNapWqsJdEVCPlUWFXE7NZGvnZ4GxmJCmfWk9Ht2GWdqh47XqCoxyvYI6N7gy3XVeAvr/eHsP+Eiv6mz8zIzqStpVW2nVe5+Z955z7jtFGvVed7XSSlr1rt3V9ur12uveC2AMmGJq6CQQCBA6wdQQ84WEQBppkITkCyl8hBAbOP/fvRovNhgXfuY/w6LXd+Yd3ftq5sy55znP8+zCdTqlSnkXrVFHJKHR2wTpUOup8VE7l6gSXFbNpN1BN4PzuBV3Uxtfx31cpDQX6h46RHU0SoOFPuXJ9TaCKqHDGKYgb6oydtxap5i2eBuLqAxbxn2uom52cIz3h3Zj1KlTUOrzQQm0gLObVqnV9epeuoxtIdhvpPPBYNS1ydiumqhJd7i7GbjJNM+QojFVpmoxjCHHrLROleo8lVYIphWHc9BxOvqK0y+lbISf66vfvPPz4VZwXgAjw7SsJAg84ZHD1jXCGGavXGNkrFqmRZIdK41zbzfieVOGFQz12RxpI57plVk3tESLva5KWpyRsWpbXMAGUb+woDTKp+N52/flK/FM7//KjXLWNpncLLPSIJ1SLS3yNfl3+a78p3xevhM/49vyV/Gjb8j98kZ5vbxJXi4tUiRKymRRgnE50Z1Mz2PFTnPjs1qR+rgb2rpdWaLNYQvibOGNuNl3npx8MZme+VOkwkfgp3DyJbFg/9Wh1RuvFybC/VZ4ICFuBuSJAxQ70lImyH0Njl4LV+a2Av8KXfHwvB/+wfJ1E58HrfVdC3k5cAUuQj90wSw8kLsROkCTbkyFVK3ei93czi18miaxhJA69ag2HynQlTzPC4Zhyf1u216PH5h5njYwRJoCneZbfYEYs+mUqgvupiCH9DBu8tv5PfxmehVPUzc10QjN8mXe5kV6HW3zfp6k36Pf4S7aT9frc7xO27yhBtQKvRHfSu/BLWzFJbqFBvUQH8A9fJxP600+qw/SDVhJmeoEjXEPbtGiWqI5Ps19oeQwBPPpNC/xAs/oIV2FwAf0ddqo0TVTlMe5WdXxFr2Ot3QFm9reuDb+sMdUX2CX2xwqpE6aYociHHRLsZDrMMiKAkzY4sS4A4d5UG3u/pj5ArJ9Kc/WmWx8R05m3zdQWpyiCpXmNiS9NwpBiEIIqkEnuru5gIp0F52nEVTkx27qY6IYZWsTXvqD9VHAhFbwA9dxm1Op6pApSLPY5viavHs9ACmeCXCT+AjP+hPrU1Utj6hpOkRdOmYgGD2ssot9uEEb3M3tdIj3mYmdgwpPvYdCPMbtNELnqd1um7u5hFDHTGM2zVHUKR6BQAGeN0qA/gTDut3jGfU0ZfAs91IAta42bOJwlgulXr8vmsidFGqGJuBGjroujylkRZpX6ahqpFLcG9wV9Q5AO7DJa726iiI6Ro2BrJp07El+l9X6SfyV5RcPnIXj9ov/uTK9CQtkLD2+IoefmLFAxmGZt+yLVZmWWTks56yfxYJMW9Bixj5+VhZkRuZlQc5ZeMIcn5N5OSzTsiTnZErmZcZyM2Zl1rYXn5UZmbNVOgMarMuGLMlbbG3uS/L78lvyFSst9WG5R+6Xl8mDcp9ckXNyWc7IWXmHfFI+Ip+St8m7bcvKp+Wd8g75lHxMPilvkVusJOh9crsckWXZsODKup3ltJyRdZmSWZmxq5ixwMhZWYmv7KxdmXneOQu37KzMrOLwk6ty+bGPeV/E5g/gGAh83LJjfb+hkGcZS1BjBZ980Ah1sOuanXg2ZNifpVAcb3L5qt1o74TDDLgDnoT/hog9vh1+DD+xElQJP7f7ecbd5IWZlqTmsxlfGpyH49dIa7W73l97NdRGMXSIKUREi6rHLcBerDM1G73i9jjpDFyhtrA5CljCMTqKB3mETjox8wHichrlC3wUQ7TId9MxXibXdN9jj56hN9N/0V/oO+kwdZDGIj1L2zhHCxThDlrSlziGB3iSLtCUrqSLJkDRUbqJtlU63c530DSdpVW8SmexR5XSIj+sb8BVvFP3Bj2NHqrkM7gdrMZb6f1uH53RI5jY4mVNJ3hZF1WnUTefpGN8gvtwVbfpJXolnmN/qJEXuJ3b9GFWmOLUo5+y1AHc5n4aoNPco/u4rTEBc3STDrmNbiU1qBBrCnGrESUNTocnal+e/qhB3j2/+N6w8kg+8E1lvi5YH6nCLp2zH3S2ClIrR5ziBk+r/esugoZgBg1SYWCXKlGV1EDX08uoTVVzeWgX7uHuUDEBZmKbG3HzQ4aq38g3qyZswjoHGj0VkOVxwSmhaRxqSFLQ5XMj9B56kCp1mtEzpjwcom4cpXY9R8s66HgbAWAKKj0NEMp2zVXppVHupgFqpsRu0EmYgf34YbzCBVEDOZSoReoOpRfajLPYk+lTLZzPh+lkbaKGSLKqok4O9ppWJ6052ePkUY02qjWvpQlVwZWcwxnscnOtabDzAPiNM24a1XObimClThsDt9HpHMoqntv1eiiJWzL80nUEgENwmxWXeu5PbokXoLy48vEaKXqixG5qC6TGmjy2S5FUSK0cFUeKpVYKLWhRLOXil2PiSIntntuSWimXUgnIMQlImRRJSI5KsX0NvxyxjxZJmzWIrJZC0XLMGm0b2+0PyX/J/5X/lL+UT8p/yT/Lf8nj8mX5gXxffiDfkM/KD+Sf5AfyVfmy/Jf8q/yX/B95WN4r75D3yhukVbIkR7JkQvolSzIlX2alX3KlRnLlsPRKnlRJqWxIlxRKpVTIpgSkQGql2IIrRVIuDXJUlJ3pPtkStGM7KyuVoicdOfvYv73QoJdgW9d+CN+D8G8szzOvuggfg8/Bd+BbwOCBq3AS/PAdqyqxCv8MjZAM74bvw7/DB6AQPPCHcORa9heBT8G98GW7IWZ4DG6Bb8H+58z0ALLgKrjxkNoMd9gZJMZtjyL5b3I7McoYLAvmuImBBO4kf9MeOsDzepYIXTzKl/UKRWidDnEjIk7RB+kzeIFiWKPGcREP0mlapDY9inOKOKrbQo3YoofoOnwtIZ6md+AUd+swB/kCn8YV3E9AzXwn3cjZLUDH1DKepttwmMfpBL6aL+tSBW6Ub6d7+TIO0wRN8hS/B+/Bi2qQjvKrXNcxSGCOOs/n+YIl3Z/DXj5E+znCJyhmZI4wrP10B31V3+CvUQ6tU79biKXUh6v+fASnkVap2c3jvTRNr8M5RlrVRLkYxQo9wXOsqNLdq+s5jAr9prNNt+IgjdCYOhIbKL+U9Cb77njqA+r9eZXUcyzjEd0WDWEDZepODgn0A+1S5UaRjxvaE/thFqJZNGi8MoxoYlOiinCAerndqdIRbEPmTto08qxcHvMRFIM/ESOGF2K4FJj7ZajwNYMu434nSe3FA8gUcQfwAC7oXi43bw4XeIJPqF1qgC7SOub+CbDH/KYQRLyDHorRNl/SezFIl7jOzCG8ixRN4SE8yG3kUpse8hv5qB6dCtDgC4JuMFkyuRjS9e3QAmEIpyFxtz6s55l0M7ZTgOt4jEm1UBVCAPbCAHCYmtlKWukcDlGHwnCuP0kD57r92h/ag7HO+vKjSW+wX93Pch3huA15L6Ci/jQgwyOz8W2eV1YsI8OoDq9es3s0ysk74gLr8bF0Wb5mAbkeBzcqZe2aBeSqlXkHCcpK3AJyr2xIQLSQNNnmZLGb2i/H25T/Sr4uP5P/FZG/kS/Kj+X78mP5mnwzvvn9trxRPiYfko/Ju0VJkjSKRw5aK/BdkiAzVkI+ydpCYtwCckG03d4mXxNL8FzbuBt78pJrKyuKz3h95+jFbG99Vrn1j+PKxIm/oSwvyXIyBG6CMvgUfB088Bqro/I78B3YD9+BRyAB3gh/BQFg+Ba8BgC+DNvXqna7IR3q4XM26GVBBuyCP4WDNpQmA0IHxKD1F+4dEIV1+CjcGheYn4rPYUdlBVLe7B830lIUwqjuxDbswgt6XA/pV/JRrCDjebaCi0ScqQcxhKy2aYQVLdEAV9Yk8zIeDnqcNDrJQyUe7FFL6pjqxSge5tu4k4Dz6Ta6Qt1IeAA76CKepU2+izpphu8gpDw6gkf4Mj2MmmN8mt5O2wCO9xDQ9fguPMcLFKQRvo6O4jY+wLfjKm7qFSdXJ9Mob9Akn9Qz2EcXjBMXv56+zBcRg2XUhePUy0dQ8YzuVJ10hkMI/hQa5TH26xhNI/Eyn9W9ar8aor6mvZRIg9xvK3yt1M3KKTL0LqokR0dRcwt34gBO4KoaVh1tDT4XHoZzUPW0WqkHUqEXXgmngpmhUIA54jboJGrAoVApQQQw0clziLupIZCH7YF8Ba0JYFp5+rkeoSeJO53skE8l+dPYoZP8cp5TjutwJe7mDm5i4F1IPM5c6YmAm+e2B7KdfIwat1/M1u2cxnW6EyNau0XcQmWhXJ6jQVqmk04hWz29Kij0aAAvtejL2Ifz3ObuYhcdt4xjKkKd0VSnQTuqgE7QNDc1pXODjtQkalCZPKT7sKrcE0hWHdwQznSbSFGErqd7aTJUpJMpkb3s6CYHqlKoW4WCHoDXe5QHkRD3UlR3cH1jmmHxah+GsYeyOUO36QDGukp8TfAquAC1zzAzSIEueBAu2r3Q8++zdjwykh9PE+8TSTIvFbbalSirosRjxaVM0PNag5+nGBn7ZNP6ZiRaRkaGFYQ31tmFln1RLeuSYNkXO1bgKeIRxzIy0qxW3oY4EhItQfmkiDwhIv9sLYL+xzYY/7E8aaWg/lo+b9XxfiRfkz8VkR/bR98gH5XflY/IO4UkUeqsR0avddBIlDkb9LLtGNuAbMh0rkWgU+O2Rbst18RvTYNyrfuHT9IFZFVK7MqMkFaxqVI+WSCnXkjQ28GLSuCrIPC+ZzQA/yaC3nn4gN3OOvBXwHAzvNluZ78IP4X3QBKkwt/Bh60M2e/C30EOfDqulPzUV1sQvgh912RFv2lrej7YA0fgXrgFbvuF+x1wE5yHv4A/tHp6az/PCz32f0lvapiJKmp0C3W2k6oTAdK9PE/zPT4q5f26081Fj8rGiDIep2d5QXUMGM3fGt2rXdrCTT3iZLjlPMDTeIK6aRANLNFPR3m0Bmp8BEx8ox7Sk3QCF9wKZwSXbG1vkib4HfRqFVPreJhq9A08T6v0OnVJ5QGoJL6Cb6czegAX8QZ90U2mBb7Iq3hGhd1jdAeeo4vKxTW6iW7kB+mgnqNJPsP7eV0Nq1I3nSboqg4wcA5v0hL14GGlsQvbdA0fpzfzFleyz0nFBZxyEp18WtMzHKFpasYs7qJBPMfDxn0Mm1FhMNhKHdhlTMO5G8OqnRNTTXliDu6DW2AbJmAM5uA6uBvuNHTBXUb2qtVfwkF0/Ukqgzop5k/zQ9ioSCeGUF/CyaZs9imjUjeEVSEoSGCjVdxTn0QetxHbAjmcS/1UwxVa0QIdN+CDzscUdvm4W1WUwEMcdcPc6ha5CRp53KkIQjBJtxr5AbqLerWP9/A0HqIxmuJOnWhQrkJQngbAQhqlw9zPK25EQ3gPncYz4XTVoP3JEE3kDhp192kfB7CNUQ+SbvbQKC1hYSiVqlyHhvkc96kmKrAYdyI3ciywr8vINzTXeua8Ax4yeoHNypMPOpHq+AwvYZ7rPQAEYY8u40H213kwDzsChS5isNgTv44PwC1w3F7HWbgEd8MdEL7GM3++W1pcTy9ddj+RLhNSaxHObMvIMBhsgSxIgz3abRm35tEqWZZ6SbeMjGVrqJMutbIkVfZ51dZbLN1yMwwjw4xp65ZhjkotBoziSL18Jp7BfV8+Lz+W/5YfWx/c/5Efyv/IX8rn5b/lX+W/5avXQIu/lbfIZ+T35TPyHolJumVRTEmn/V05csgeZUqaTNt5pkuuzEuz5ZKkyZSdcboVQA3aM0psW066XYfhCGfYGS9LnVnrk+ly7LH/8T4PdLGzka2Gr4DAJy1bwvsbgzBM0Lse7oEk0xkMj8Mg3Ahvtn/mu+I5Zgl8C/4CPgGfhc/Da6AAPve0TC/BBr0v2KCXaGGJP3seIMOccwo24mscgrNxmcYd8ay8rLdyr9YU5mbFpFy/Kgn5eQknVBZV0hL2Vyaj7Q6jo3pRTfGF1syHQSeHDOK4hYpzaBpfZZTWuJgdbMNmWsGLdJmH61ME8rzlEE3QXbiN52mV+vQinqF+N4fPUhf30avx9TSFS3yOzptwxZd4i27h+UZDm7+P7+ZbaEvVUZ86TUf4OC7RVdxiolX8LH4Jj2IER/kyTTq5ug1P8yVVhqBqsYt6+CSt0jnt1x5VwSdp0NmHG/RRutlpIEWjWISNGHYyqYAGcYq28ADWUR9HdTp10TLtp4OoeZoPkl9XYZib0QhZ9dBBdFUjdQfSLjzFyUiCEByCNdiARRi2Yv/mz+FrAZXLHZiNddgbTFfADdSta6PJCCqBw1TtN85lIYrxYDhLw61Q5C33KcBqnKI2coPJhqTvFnBMpUey3NZAtruPGlWEWsnhFX45XUdT2q8ym4xxpNmon8EC5SGgIppxW3WxCughHovsoUE17dThAtaEATz1nnVo9vGAGnMa+BQXYJAO6DYsx2p9gHqchAFfsYe66Ljfpw3G6tXFuo022VRWO5WmNiJdo3arOtIhH9VgBBNjRhy0QLeoARzVyQzVPvBoCBhG9jCTbnVVKJfCXOFCMzRncITbKS8Kqgp7OYOakJVXbJpmr6OGSViFDViCoR1zpRfcvL/gBVgo3nz8qKw8sWJ9JJZlTZbkjGUrrFkIYsPyFozi3IaVbF+1gId5dEPOWTNuc2y4FCuyIuty1j5/2R6t2Gduypn4qx2R87JuGREr8gYrBfVp+R15p3xdviB/Ir8n75WvyBfkD+VD8nb5gnxaPi+/La+T37b3t8mdcq/1rL3bemMckUU5JcfsKy/bowXrfmvYHDurOG19cdetQ8aWndFSfD2rdmXr8ZWdl01ZfdrKVp/cluuf3ez7KdOchPilH4K/sIp2eb/RkPdUpvdRm+m1w99DDdwKb7T6x38LX4V/gXrwwLfj4lEEC5AMf3ANvX0q6P0B9FwLel+/lrv5LNr1zLuh0ZXDACTF+/vy4T5LCYh/UybdV/ZwtJViOoDFoQIsVEV6RF/gKI3ww3xSl2MEp1UDaeoq8lENncVpHW0GY7lDYb3f4Lk0RvfSdRzivTqfutUGDuMFei2rBkjzjkC9V0Dl0818B67gHDdzPW/R/bzMW7gQTNPNeDct8Bxd4HP0gJ6ndjpPb6A+eiVf0nN8nofoBl7XB+mP6RKP0wXe1nO4oZqxhS/zLG7Scb3gOtTPF+kipR013f/NvKnLaFQf0ifoHG1yK83xih7mSVxUw3gwmO1Am9ESWaJ79bxbTi2qF/dhGo3QGWrXLRQhpiWcogkdQnYURd12t5PHqEkXU5eb2Q3Znl3wrO4NtiK1F6q9BJxHnc4erFJD4dwQ0G6MhcKchyFdO+8NQgdgDx1zu3Ut5znGSQKcPSpg5QRAexI8td77jb7ekJ4M7+n0OMAQBUzDejXFb+N34LDbRA1uJWZxkY7qJoqEkxG4is9wQEOTlw/wMvY4LcFKFaJDOI6JLmhPAVA5LmM/BbGCB6mbzwSNo0USTfIMpTOoCtboqJC7h4p0Hfu1o8/SR+h2bFdFez1GIjTLs9uDfp7RoVBKqSfPW+BFcNJpDceDxTpBGz/fDDKdf1NqiytCMAbhdI5SpS6hbvanQp/Z8vZGUlUThZp9BHWeRMuDfO4+0ue5Bb0A/mL1OIp6IiBL0il+CYojG9InAQmKK+vSHh8zrIqg+KVZNqRNmkSJI5viiCN+icmmtNjntVpYwJGAtMm6sH3UWHGjBCQgrbIsTYLSID1yVW6XW+QWuSSfkh/I9+QH8rj8ofW0+E/5M/mMfN/ycf9M2qRQWqRCpmRE0iRfsmVYJqRRSBpkUfbbeSpZkAN2LCAr0ipBCQjKqgxLoyg79tTKNqXbziQsG9IhfnFE2d7Bp1bRasaeJDn92E+f+9KmQBM8AAI/hlfF8VT4DQe9dRB4NYzDX8HHAOCN8AYogu/CRyAFPgV/AQXwcvgxbMIc/Dv8NnjhGzb/+3nQI/iGVWixmRr8E0y/gJYVz7WWlxC8HIagBqrAgUt730sb3K9aSXOItCoxXVePewK7sY+H+IB2WNN19Brcplp2aVkr16Vt6qBinOJBVUdDuIZTJclOBY7RNF2iENbzCp3hYzTt7MmEbG/Aex9wHV7Bu3hdT1GHruXj9BY1gsu00g7BUn6QrgvkcSldpBt4hphm+R30I3ofjWMHHaUrdAInaYsn+Rhto4ur/KDuVaATdR/diycch0/Sq3Q/zvBRHO4DrlLd3Ekn9Tg6fIHewJdUA5fSEYoQEPN1NEIduo1cVLRGy9TChQDhvWbbTKFgnW7lRj1FxoiyH2d5mUJK6TDGaBTrdDa1u3vbIceT+XMTNF+8AP80/nMeVEG51wXMp26d6e6lHlVWAwFQ1XyW9tcn1xjP3lYnHIKGFHTY+JFV6FrVRg0LHh2ihnao9+Z5K3wdPjrEc5SioSpB52ITutSFB91cjuktQl1GzC10RB9UJdxF3dTCGtMogl5Vo4PhVF6nSTdH1XA3bevGGkAIJuJBXlWuk+9U8SndUptG7ZyCRU4T5mAPt/CIDlIjbetJ7bJx6xigDZWPDo1jRGm3HDO6TONJHZ3hhgjU+nxwN2AydeiihmRsIa2ruIojqpnK/RDMpj6qCUIXcBmfpOn6XQycwi5F9/rIj5FgQhOgp+7nb9lnuY4votnC9On5LCNjMt6n55Ml8duyf0bc4jvBdrMV27E8a5lojkzVbEdGqkBWZV/c7HtFvPb5+bIoaXbML0uSaPv0SmQq3kNXJ/fJm+R1liH7lWtAxp/Ht7LflT8SsRrHfyeHpUdmZViOyaD4rI/ufqumnGbtHtttB6Cx845YSMPU9CrsWILM2+qezzIyCu0qvHZrbuaeFV9PgmVpZNkxA70UxT0ynkVaaicQZEABBGAVfgv+HQT+EJZsaPjNhryd8HQM/ho+Av8HPgil4IMzsAYj8HFoBA8o+CT0gg8egD+Dr8FboRC88CiMXgt6Piuk/SoIxQPgHnirzdwSnod29nQuSCOchxvhBrgRZpr20X61TO3oUpNT4HbxaerhTprFPIJItmk2cau4BjtokOYphtWkcZF+hz9Ax6gVa93dhkOLycE0XOPhpmwaog08TLPcidt4oM/bmNgAWExHcYFP6hNsPFdPu32h3XwGl3AK+61/7ozZ4PIpepmeo2aaorfz5/hdeold3Uv3ONP6MN8YTeBZug/ncJnu42iHt8WLAXpIn+FlXe66dLOOUD+9nG7Qq2S0Sq43nWVc15vEIzRhTMyNuopqp2O6S4/xOk3ROCkCzqIZ3OAhrkbmFvZTF57QLY6pFU45wzjJG9SMTENcRRnYhgWjUOJNswpgz3UzXeNVPga3gHoCmSqdOnUTJVMTRzUyqXoMkb/GV+Ir8UbhgFF8WeMjOkzpAJhC/YFCF5oSAgkU4mo3H9uwWgWpzW1UhdjqlPdC4y46gEOqSgEXY7+uxFqK4H10KwawlHppElsnQFU6DcFc3Yxaa9rk1fpk5cVavI73U1C1kD+8h1yd6ua5ozROYeOHwq+nLV2nqqkRB5shnMSaD7lOFUQTmNGhAjeMzVxJRK6zl6NU3AgN3gtAjBwETg4X4Dgdo0nKZwhApQ88bi6HMIhN7JKDMZWr06iNA46xWY/ppAoPexDqXpJOCOt7m/R4qvieSJRZKbcW38lxs+8ki3GWik92WbPvajtWKBtSbqWl0uMet4lSbOWmkuJARpKkSoIUyqpk2zFj9p1qFfUq5XDcsbZR7pVH5RF5ndwnX5SfyY/lZ/Ln8qfyM/mJ/Ez+Tr4sP5F/lyfkr2VMtOy3zmeDFpbwyJg1BsqyAa7bjiXLYTu2x46RFZNPkSUJWYAi1YZur+yyNuYBu4o8WZMy6637FJCRJEWyIWWSKN4n98nJX8z0vBZCeAjeAx+Br4PAD+ETcNWyHny/8ZC3k+ldgrfDHsh9GhM2Pd5pZx7fbWeRY2uLZk7Jv8DVNWLvP19R8ouURNj5gq2ABthtmhyacnBUj7BWDo3yTCjPdXmJWzmAndRDo9jXZFoNsnkFOZJItU4M52gDL9FFinETb/EQjdFVWsABGmSTQbXQVJh1DOf1DdzKENiF23QTdXKXu6RmnRo8QPM0pM9wLw/wp/C3sY0W6Sba5E0jUIrTfD1dVUV0J92p23CGb6W7+FY6SbfxDTSLRNO0TmectFCyUVfRy7xfaRqgs9zK3XQTfZCv4yjP6HLq5YlmaPCEMmibO3UhbeG76bxqpsORgkbQdbRmW3dJOdzP3VQR2Eu9+pzT5k/naVrEFj6IszTprvBRGnXLY7t0u1sSgn2+TEh7gRe50hcCVaj6MNNJoRgdoWipxwVEOkcHWxIJyhPvhK5kbnJcqqRcbqBWdHGfm09RyvCDrsMwZekSnKVTFAimF3mxRdWXQYWvCIJF1I8xp5V6XdNBmUkRCvAARbEGO+lNNIqa1rVf7wnscsvQ5f18D0WagE7S9RzDgM5pS9E5bMh8dXQj3Y412Mh97LJ2/WYT4JTRCIa5l5s5td6b74mlYExVBIDy1QCd121uni6m9qb0VnBLTeikeopRWBU7eU6AQ1Q6CAXefT425kXHeZV3E2AGztAClQcMfa49mJJmCwD40nyWCkxFoXjf4/sk/4m9MiMByZU82SsrEpFsyZNyWRa/5Ei+DRJ+yZMcqZU1aZQcKZB8y8I1G856WZM6yZW9ErCSnPmSK42yLGWSJ9kStpzWvbJXGuSw5EiRZArLrXK/3Cv3yY3X0Ns/l2/IT60Q6N/JV0Xk/9nmlUPSKhPSLZsyIln2dcakV7KkWPbIlPRKjuyVfJmRLsmUIsmRGWHZK3nWqLzV2nkbOMaszJy7JtqeUWWbV3Ls/A0f2Kyizq4sW/KfrPjllpUkK9keb3KBn8KnYSbeMpwA8P9L0LsSR293iGieayyMp1ozn8rNnhKa8vyCop73GcSyF2tF/vPQnlDu9YPKxj5qxRGa4x48SQMELbvwEC2jyYf6MOZm6GYawHU6EmqgdmxtgRnAAzysZ1D7c3CYlvQRN0DL/AgN8yz3c4BasB9P02t1A43z22gWO13iKZ7g69UpXKeHLc/3DG1YXeSTPB2spev0lN7m2+lWDAcBY3gbLdFxPs/zuE2X6RHc5jm8nYwI0mWe4h66m3ppHofwLN1r+u9olAqphi/ypuH30hT1YRA8rPAwL6k2nqazvM0ux7gznE3d3IH7eZkPOtkadA5u8Vl0MoE76BxGCWlOD9E4TtE8n6ODbjK1YS1Dia/6ebO8Z2R8viBgKfb7M1jRFoXaE3QZdbiVXK07ucr0rHEnu5g9BEZNhbOoFiPMupciwWw9xO0UdhnzHcOE2KU7NMWg2lvkKfP2AoZULc/h4Q5jF95DhQo4XUd5N7Jqcfv4AA1qv45pzX4OUTvdTHerYXoTLqhml3WQIhSlIM7qXuxXLapIlaNSMAKauKMtGffRGYpoR5c6UOIp8VwFTsN+XUE52KXKqJybmXEMqSWb92NYR5ipxEkJQReU+bgMO5m+ZtzcQjpCJYTcSsmUiwd5mTOoWvWqNIJib/nzqU+/8NuSF2CxeOvxo7L6hGFLHLFQxKIt9y/F4Yv1ONPhXLzcv2L5GgYCMEJNG/Zxc66BMVYtuLEUBz/O2Vdbkk3L5jCAwjE5F4c5VuVl8g55i/yWPCJvl8flc/K4fPAakPFheaN8XD4oH5d3yWk5Yv+dleMWqjCghTnakjk5Jdv2lZfklByVOdmURTkTBzLM0VNAxjkLZGxYDskzgYyNOJCxZud/zq5s7cltufLYl72/tLnNhyU4D3fBu+FfQeCf4GMWDoD/H8Kexyojk83WfM+AVJ7eke55hqKe51nEr57t+MWIFsRfPeANQyAL5/RxPUnjys9tvKYPqPxwipNMe4noCr2VTlMT5mMzn9IhTqKEDqPku4bHeVKPB/JbjEPDovHZUOcp5OY6dezSIG3h2+hv8I/oHjpMXUyYRwt0BOd5ngp0lK+nG3ReLJGP4wzeQI+yix18lt7Ex0cTyxKDyWoeX0MXaZjv4te5p7iEWvmYmlEhVrhGX+TH6Sy3UAmu0pwu5EN4M3YRBABb6dW0Rcas0OXL9AidpyZVR8c49ipwg9zhVuBxeoc+xqWBNJ3K+dzPm2rUKXaLqJvWdI+u5wPOIew0RDZ1UB3BEe7h0yqwBVW+Ik+d/Z564bd9vhCESvk897jJuoJWaSyU3QQEOttpw00cw71Nvv1Q6vN7cz33GJn1VJVLim/hN9GkKqSsFl8tHACFfB1jxFPqrfGUQIEHPSoV17gTC3mbD9IegeJEDbqQLupgFHAAx4M+J0Vn6Bws0HUUw3X+JH8XH1L7SXM55wUynTTyupl8hIvCXsNVbkqq82V4Q16qoeM4yIW0jm0BX22CA3lQ62HAVJylbb0nAGHAXToHG/l6epuax1LO6vAYoW/XU+VN8DaDSnMbeIVmdKPeVQ3sozpcpiG1K5SG2zzr7AIoNhSKl+6zlOcFyC8ueLxQip4okGlBKZB9Uibr0maPTFbH9sjYPQbtUdACFAVSaAUHCqVQCgRlXRybU6HdIpojs6mtsUetVrZgn+yTetkUlIhoUfIJ+ZH8P/lv+a58Sv7d+lwYw55/l+/L9+XP5S3yefmEPCYfll7Jt1mlsRgqsK+3XwalQIqlQGZlwI6Vy+y1sTlx7FiFrEiPnWeRLMRXVmpNxM1Ro835CqRAimTdskXMjI0cQYEUPVkqpx77F++v3OrtAYRj8EkQ+Hd4JRT+xmGMXw01vPBHPc+Qf/f8Wtp8Nj80JzZ6HAjuw4N8iiewk/p0J/dRL9c4Sa27dL1u5VN8O29ZP6sBnuJwwy6/9yoEs9UaX6Be6qbqKggV4UHb2HGG+zCAzC728Aa9nT9DH6NX0CFsUy45fIzP8gpOm84uOso3Bfc1pvNR3qILfBcN0jBu4hv5TCxtr4dAjfBv0Sla5Cv0Cn3eqTN+HLSf1rCFV/mj9FG6gFF0eRsXOMBDzjDNUWkT0AA/QHPcops4xif4PB3TIeqgTWyPJRwEnqRJtcx36k1UoRx/sq7lbupX3ejXjdxBPdhN3dRLXTyrR2iSl6iHXNrmC9hA3nJPlgcsb+qF3EohDTyebI9jGA2ruhtTqRHHaIiKHoUgYJE2NLABrHITAPZ6E7yVHkME8qdwJbbyWbpVTToB3idgiLPUTGs6Uuut9uZ7UiDTg55QBs5xJ9fzJI+6+2JQneBAqAqPkBsG1Y8jJd7eBM7Spa5i5mba5I/S1/E1OKpcYmpw8zm9BKJ7cZnLmrw0g5MqvdpT4gPQZDr73DpzBY0jco4HINVTBI2ZPMHzbqnp+OOUUBVF6TjfgfPsYMGrIQRejwOJ3lxvC+BuDvEQ9lM4nJZhPDWQRrlPZwdzaYkOhnIKoM6TC9V2XS/NLc7I8FogY6fcn2QZGQELAZjuvMJrggPWP0L2yrodA9unl3yNpZFnQYsKWbX1MbCAx24Lc/hl1TYsJ9lNZY31paixjIyfPYOR8deWfWFu/yTvlT+VP5Svy+dshc4IHIzKcHwmoxa0yLDsi874jKevgRsHLJskycoMsIUqDDcj344ZRkaj5Zxk2oD9lLxCwbVV2KMnc+TEszUnP1PTLh0Owz+DwJdegN/ES/O38r6kwdL7651nZJKC4C+kEdWK7TzHB2mRewNQn6zH+TwuqlrqCHEogRX30RIvKeQuGjjgVbt5nnqpl9swn4bpKp2jIG7ha6jbiE66FdRCI3SBH9AZFKM38wp2o0Njbh+d5uN8TD/Kc2xsG2/gm3QPrvIMVfNFPc4X9fV0K3c7hmh1iu7ji3yMl/EYX6L30A3s0kG1odbpMvWQQ3dbmnyMT/KrdAvV8hwvYStdT6u0Smvufup1Kvs9XEPz+hAibdD1ej8Rn9Yjzcm6xZgl6gs8qjJDEM7HNT6tnfoU7qBVbOcWGuBDNEMx7eg12sYWHnXq/FDp3WUyrRdSz4NS+zMAqsnp8ieQn65HDHgpjzrJr5hjkexawFSOcKc/JwIHQZnNrsudqtHISQVTuJdccnV7qJybnaDjozDFHNjlyfTWeRh0m66gRZ7tATcHu53qIGChjlKqcvSk7tcHeV5FqMMNYCEFqJvu4sscwEdpA6NY6ZZRmDqojY9yF0/QsJOtSjDECQM+jLkue1UmXaSwdrjWgYg3wzNqmpOGw3tDadyFAWrEHrcRBwJNzUk0wH5XU6eq5xSERQh5uJ4GdFXI43i5Fjt0A7Vo7k4IJRlrd52o8nBYZweh2lsC+6yh7UsEZCQWJzyeLJ4nkmXB6qjsiC2hhTRyZF1KxSvplpFRE3eS2JRSi8YaHRXDvTAQwKYUSbL4pEbWJVHSxSuFsi45FnhwZN0KUWVKQDYkKFpYAvKJax4ZP2dk/Gl87Dvybvm6fEm+Jp8VLR4bbsdk1IY6rxy0oEW2RW974zOetWOZdixsx5Jl2TIydlm6XFGca7ImQbuyPNmwK0u17h/ldmVFlmtiGBnFv5qRsZMlPbWxLIX3gMA/QMv/L2Hv56En2bbJ/OpsLiVOGvt5ePPakZ3H0yxh54UrMe+8bgqUQS3kmBaLxiKadgfJUUS9oXEq1Myn9X6uVmVItMSDr/RoCGfzEa3dRC6mCM/S7fxquojtjLxKEziGG4aXqtvcfNbUjhvUSS24SJddv4YsH87xLdThDvNxtcYlOE4T2KDPUzv10UfpHdSL63wXXaJNXOY1PY7n8EEqoVN8g56gm+guvBdvo+N4hI6rBl1Jx+nVfLrDh0k8zpfpKM5TJTrYGarlNno9/rk+g6iGQ6U0wlNRH0E4i7e5T9dgH5+gU9xDR3maU7iez3NY79N+7sI5PUZ7KJn69VXVqjN4muaw17TsUpmewRPUoo3VzmigLAQ13mooMPYOz3mrgEqoh71eB1Sd09Xoc3fpLpx0wnVGBD/Il2iMEhn2e09BxMv51EYBXUxh3Y6NnOSU6pawCWvl1EYZuJuX6Awp3o0+ZuIQVPiiwNVOL3U6AWz15xjxAoxgJx40gQqH9Zv1qKrlaSqjhJYM9HMrjtMdyg/AS3jF7dDNqtifRAncpodC5fb6knJwgAbYWAR5TbszthDhALeF9rTCGWjZxd06vwNC+2iYLqsYJupqagumhID3cnsoIZBl6obYyCUYI+LkWltxbgRVhCd5NZTJEMpRwzyGgQioIurVe5qhxlMMTS/o6+N5bynWGCj18VRJfyJVJqXaoqyZsiKuPSqwfhip1q9iJf6o2TaasTSLihoPjFSpkVWrRJdqwYBMe1QlS5JnUVQty7JHkmxwnLPo7S7JkY/L/8qP5X/lH+Xz8oT8SJ6Qb8qfyI/t/e/lnfI1+bx8VT4pbXG3jHEZs6+7y5r8pEqGpFoeRqqly01LR3zMsC/MWLYsSIudZ4bMSo0d22NxaXNUYkWmUq1zh8lmzVi1rEqtGbOZ3o+8zxsKvHaz+0YQ+K4l5yf8RsOdLx5uvVZu4M3XIA1vvJ7nvaadB5bu5HuayHwCPBSnpaXB7fAd+Dt46Hk5JD8PoeY3RuB2uB/uhQdgq67WncZ57FAtThPnhFr5eu4L1eIoFzsQKOAxHVPIrMawmZdpTDVql9fpt+jNdEzHsFgl68N0UINKwU094ZZZu8aDahb7cJt7HKhKQKOhtoibfJ431RAt0Qk9xJV4ArdoFk1b8a1k7MKX+Cy/ilYxROP8Hv5T/i2a4yif54fUMI3jTQ0pHDQGknSQ36TXHSNnFNSv1Kd42g24ObxEvTSGd+ANdB1FqVO/jKcxpsPRHDxMA7jIk80pCNzMp3WItulRd061crTWw3k0QtO6kxT2sOvswi6+jsOk6Bh1BjLVAT7qOCqs2qhbD+GYU0BQ7i0BFf+WedrX5tO+cBAqoB5KvBqokjocn87iPl1GgA3YRy2kwxna0VGVaDiGDR6Vwk28Tmc0UYKGwB4aCWS6UJyQBBhwArpGU3CXatDdTFyErdSI4M+gGTWqisini/kA1pIRBHiQb8egk4lt1KablRfzlMsF1EFBdnibZo27fLCELvBBrlUxTeEi3eyALjLeaU6Asng/v5GOcpOudUI4ohMCqRigeYxoqPNhGzdat7PWwF6nEENo2tWzBPZ4A4B+7qgBBU6WGqfz7pibhwkCISMzUMidzj5VyIah0xve5QJFKKJ9XEqd/jSGck/XM4Oe59cs0+wwMo48fkzWLJBx1EIRy3Fuxo5/xKYdW42X+1dlzcIXK7JxDchYtaDFzmNmbOf5m/YMY9Z9VK6Ts3LWCkXdLi+T++Xlcput2n1WPicfkjfJH1ib7vfIu+zY5+V35dXy2/JOeZ+8WY7JkuVdnJKTFiJZlVNyQpZly0IVxy1YsmwhjUULV5yVbTsjA1UctWes2fWsxuGYLcsT+fkq1p6xCnPeugUyPvFCMredwPIoCPyxyYF+45BGQvzPPQIL8a22Lz6ecC2nMyNvh7fEMzuP7X59LYjV+gN4DfwvrMAS/Ac8akllP9eqeOY9KY4O76C+/fAIaLvgDDiR82l1xO1Vrewn5kiwMJyvu6ggmq6H9QItYp0iuoVfSxsU5GqaoDCH9BbVnwHcjyMu4Swu4UHOQ0XdOEIXkKmGVg0/Qo81pwIkepQ3BE4JXqV76IiedSlcoM/QBw3iawx+VCk9yFd1oa6ii3SZjGrIKr2R/hTfh4eojW6kh/EyztAGL1E/rZDm43gnXaGSWi9P0O24TS4v8BnuxiU8xpGolw/RQYrxFI8rTTfS+/kSNjqZSit/GDjMZ3FC1fMwLRPpbbrAA5zZCJE8WuBNauYYtrp73Sk+45RxBh2mJe2EWGvsxG7q5QM8TvlRKPXGg57nF0oUO19ggFALld52cMupHZOCZbrXzWbAlEAtnaD9hR4GBehgl9rDGUiqi5Ay1B7dbjSoOeaU1MA+T66nzNdonD/WWg2fBVpBlZN2O2ha1fIYr3Edmbpaq7tK01iAPeRwA5EqonAQAqUUCWXyJh5uSOY6GuYjVF4EBeAmUj9tcBvnOEV8HTUH9nHHWfAXMIVKVDNVcLcKcD2e5FHdqphKqBVPcEC1q3EVUU4wywXXhLlKvEK1fqjyaSj2UIJ23UaVQ13cNJgUKnRbqB2rKA0rsd/J6zOyoYV8Asd19rAnBBjgbkpVxdwW2aWh2lvwdDndX7qOL/BWE5eWqpaKJ8pkQUJSKhVSLGvSKoVSboEMlBKptEJNJGVSLE2Wh1FsfSiMCEGlFNttq1+KpVS07eKrtHJTR6RVWqRZeuRmG+oekJutzMCTtmr3h/Jf8gP5b/kb+ZB8R/5cviuflcflSflv2533cfme/LX8s/wfabONMIUyJQcl377yQQta1EmezMiQlcAqlTnpk31SZ3PJFimTCimRZemQfKm2/m06vrJ1iUqxlFnjRyMtVSnlVvmlIr6yoBRJ5ZNNL0xw4Clhz0R4Fwg8AolWfOk3Uc0zrjD7YQteB6dsD0QHdEIh3AJNpu8IbrTiih3wOngtTNtM703wOvvTa3VVPgD/BN+D0zYv/XA8+B2HbzwnsJgDQ/Y3eWzv7IO2IzExjt6eKn19Swu2hl23EgucUqrmAb7k9ulhvg/XuZFiqrd+LzVSVBVwkz6NS+zkesK+SAoRH+ROrsUJfh3eotuqk1uBB/CIGuNz9DpUzbDHC1DiKwUqppvpNl7gWezTYVqis7zGyzyPpXqAbqMpOoK340m6R29xD12ms04JPUhXaY3P80W+iefpEH2Yz+AhuoU28ACeoJtohi7qA3SEj4T26T08jBfxcmdqhcefg2f1MdWAYzyD66bOR/0UMGICfIy2qJsOBPJdUEEc42G6Gad1LQ3TREuaAhymde7gUd1GOaqJx/S0drWjg26bilE39/EAH6YJzAkCeVJ+DnZ5IQN2X6NoJIAXodpDwGW6VadyEPudFAWqAFvZjSRzAAOu0SJO5S46oUewIpgagRkQKEukBj7r9vp9ISj3aa/26hpup76WbLLKy24q5lAdH6IP8vv0kCascfap5EAaIWnC8C5luA9XOBiCuiSc4GMYUSF0yKVDeijm8UCJ1wGnkBao3yHTtKK76TpsNJayNEeLocRxwFLSjsu1AKFMt1gHHeYz/Bjdh61OCWaopBYPwxg4jaqXIpQVgaAPDDkuR23hTChToBmGIQahbG0cPbZ0DSexMRBv1bnBfOrUCjOUkSYYpD26nJt16mGo8sDTr2P6067jCxf7MML9vuKExxPF+4RPDkuZBSGSZcWqrCRYP4wy28zrtRtYj206Xpdyy3hIkWVJsQyOEis3lSCeeHOyeX6BbIkjTVInEbnRisDfKVfkY/IT+aH8RP5GvmY3tz+V78rvWxeM/5AvWWkp05z8D/JJawf0PfkTiYjP6h7vl1E7O6+MSYut2hlXjy4LUKTIjB1Ls83JjlVETpVF25ycYI+K7blJFqLxxF15y+3KPHGj8gQpsg3LPvFYaakX7HtrLvc++Bv4H6tt95vI9ZKsZp7AX8Pb4EfwdvDA6+ETkAnfh8/BPngf/CdUQgf8G3wE3gv/aMVD3wKPXgt6uTALDfBeuNnWAktht53je+EPIAUSIQf2Qf4v3fdBAdxsg6nJFcetNl9SPLP0+tJ3vwWHXWLFhAGqoxrKCxfoBZ7SoPJ4nfvAWw0hcMvwFC7xHJ6PZM15IinNPvTjumrHUpzEW+kkRrGWh6hVES7QBTpFE7Q7AHm+BI8/mcZog8/wUR7kST6NvdFkuox9qoveQ+/iEVzBE7TM27qPT9J1uEVVpvWE76EH6UY8y3M0roapkU7zmuFtaEWL9Mf857SOYXUAR6hPK93Op+gc+hsAA3SSVmiFNvkKVmvAUm7nEl2KW/xevsGpxzqeUy65dExXaaAxXsS5YIeO8GHNrYBtdIiaQxXKoRXu1LXURGHWaAr/PTjE+2mdp/SeKKQk2C+QBhiCVTgG23AE5iG2s18rTKgEt8Rt4UxEaq2B0G6N2IGlDpQbdmqYo6oSYxjUDrWpwlrI8+b5WhL8oBtVv3a5mXK7TetNGUXCPn8WjXIll6Nj/GXZ4S2+rJZoOtSg8ijV8GHRz1dobxukAJdTF7UojYQtur05mw/gYX8jznNxAMDjeCo8PV7qwP1OE53T5dxobCfR4RC1YbOTVpZAoHvpQhtE4F7ALC7kdr3E63wj9aPCmArpRm3UVdoIqBCbKZmgMVFVUwtFVZ+zW6DBV5SgwElWAWyhOopopBruo30IDVCXiMjtVB0FzKO+YL6q1JFQch8k+q5dxzXYhm04CvPQajsoXmgPxU7Q8z2eJPCEV6YsYJBsyVo76G1GHL1NuSYX77VtyiZIGIbDsuVeeK2MVL5Fao1cvAEFDMp7RKLiCkuH3CKvkAflZXLbNUGpf4gHPeOR8VH5F/kb+Vf5vPxJXHnlH+Qz1gv3+/JNCYnPYqr7ZShOYRuySO0ei9R2xJHaaQtfZFggo86OGcyW49junH2FFBvgGuzKnlIKTLYEu712ZTstOF6BJzPk+Isx+zYXuxd+CN+EqqfRt15aEtoKfNc6t4/AT6AMrocPW+mBb8Pvw7etufEfwsftcx+Bv4NEeDW82Z71VNKfCh+FK0/rz7sZxCrq5cAK3ALXwfW/cL8BLsASfBv+1DZfr8Do093X0j0Jb2qYjioK6mpdpgqwkLO4klb4MDW4jbqX2nVlk88p1WFV4DbyBk3wgXBCCEihaUKexm0a2+PTeXjIZHI0QFNqjZaxg4/oWZ0cSB7wcjvdzP3uiNG/07U4Rpt8Xp/EMVqiV+BN1K2O0bwb5LM0jcf4ddQzDtrX7aPL+A4+QUN0E93B/aEUXKAb8Dgdd1rpOG/TdXwLx1QrTdEt9Ao2tLJRvspneIuG6QCVcx9fxKgxqNHER/UBOoCVFKIubuANer3ewAaaoYgzQZMIwTya517VSpu6z03M8nAEz2IbF5FfOTrAropyu1EadqdpgU7hZE1yqgFmj8ONcBJmoQfaYQQ24SLcAtOwZx80lHEzl3KY/Q5QleF9hJIUhKExlco08TGactP9Xj8E91AvY4u3xnc96FLseAhaIVxB0WC1cnCMGlWjQtqPJ0hjo5MVTONW3tA5UdDdoTZEimEDl4ZIt7i1rg/TybBJwnxFD7kQTqBNHOdRXuRIkW9Ht6LCewhwLw/yGsX0ttuOENrLx3FL5WKdclq8OsPYkLuNbhFpjjgOD+tGNg5pC7oqnISlugFH6Dg2O6irdIx6qRIVuk4mA5Xrdt5VmUCA2dxDOAR7jVBVLZ2mCVXt5B0HBUFwC42CNGY5yaoNa6kR3dqkRHMdT8DNcArmoBc6YBjW4YK9jlkvUM+y3AtQWlz5eKVUPVEuhyUk5VIuVbIq7VJm9YVXJGw3i1VWNKBCygWtwnKZVEm5rEuFVEiZFSYge4a2XW/lUiZa1qRBaqVCtFyU6+WSXJKT8nvy3/Jv8kP5lvyR/FB+JP8rfy8flx/IP8r/kz+Ur8n/yH/L/8i35cPyt/IN+bZ82eogl0q+TMqE/Q3lsl9GrBKz2dQO2pEamZUhO1Zue/Iq7Niy9MbnOS9h+zyTh7bYo4CsXlvZutRJpZQJy/rOyp6sfLEeGaa+9nIQuPuXrBpfqqB3At4JWZAMmfDn0A/Xw0fsbzkPArdamdC/gr+B98P74c/gryAfXvG0oGfCVSZ8BG6w2VoipMJrQGzuZshqAYhBBKK/cG8BDdfBW2DBbtgP2xw2Kb6p8GX60t4SOBAiJt2oaomRsI8vYZceoNfTaVVOIT5Hl3lLs27gwxwlwnXeoklc436srk6hZZyNpqtc2tKdbYDN6gDOYoybaZLuoIMMXMov4wu6lwgP0ijfghf0Ip8yvXN0B9UG08lIRt1I71BBHcXT/DCNNCW6CbjL6uldp2eYcYBX6V66iHfgZTrCZ3i2M8ndQ1dpJlzJ52mSkS5TgDr4Yfp9fR3VUgzvVGamlyimmjDESCdRKwgl8gTPUSkHeD8yHedHuI9G+RjuD6R/DriLI7oRw9hMM+xXudyEAVJEWqGrWrkdB40eCa7gheb2lEPwABz+hR5bHzTD9Z5b8qk1GIxiCxapDB3GTtxnLr/KxHoVwShV6GwKYVUPtCXNevwZupVcBE6mDpXemMYFThFquogP4wxWYhWXhtIdRkWAuRTCUW5qSWBfaLduUQV6r3L4NI+HCrkHdys/DnFbqMHNQb8O6CY9gEO4xidwn5EdBWiAAIS9fT5qMWo1er8bxTodUmVOvg5Tux7kNAqSVhX6DE+rSs5QDgbqEijJ2aV7uYeCuwC8qlMV0R5VjZXKoSv0EB3GaizivOs9uo4cNCGvjxsJWhM7E8KpGFY1KguDqkVrKqlOdqENyI9dui6QyqwiTktfReJ+eBnMPSXKde3zF4ULcJftaXn+sLfDyDj6+LYFMs7Hy/1LVoppxYIGxhJ7RbbirAYDVqxa7wnz6FYcqlixUMGqhQc2LathywIDV+VOuU1uk1vkIXm3vFPeJY/K22wryp/Ip+RReb98QD4o75bb5Hb77yZ5uzwmn5LPWRDjK/IZ+bJ8UE7LUTkvx6xN+LKFVQwjY1GOWHPubTuTZTlppaW2rNn4KTu2ZHkcSxZ+OWdXsGlhjs04zHHGAiA7jx61812z0lKrsv7kKbny4nxvTaCrg+/At63IU+JvIOgdh/dBFiRALvw9tMH18FHr/fRO68yRC7vg7+F1cAjmYBrWIRUeiW9vn6qBZMDv2UzPBxnwTvg3q6z33C0r6bBmefBg64n3We+BZEi2oW8k/9Gw8WdV1IQN4XSdgl1YFsqmA9jGw+Syy9N8mKd0DJepI1SKSIf5vfqjfJGjXKeWeJpG6E46gVGe4fPYToN6QAc5ygN0mt6sZ+gueiua2p9LJbzNG3qOJhzACN3EN1JWS6Le4pN4BI/TDC/RKTrK50mFgPvpDrqVzuMoHsQ5OkUvx9voKo/RGr3aGEtSIjEd4xXcxMM4xqdxnKa5jeppQ5n2i5M0xshX8AN8wQliD2+ZPkTFFKFxrGagBtymgG7Ug3qC78TD3MVnuE2lBIAycIK72M+I9VyDdehnV4cwzG04gCN0AJejK1XvTbjLdnNC3D3Yd82+xufZn/5I40Sbv6HCqVDdpkIWNjkOYgsrLgokxuAQ6AzsD9SFIeZV0Ggo+N2G/kcONWNENWArzzCrkMOpwNDmrfOh4j6OoMIIpnVAmS8GvJf6/dlOsepyqpi4h7d4W4Xc/G5vIVwFnKRzOl31GAXDYP7vgTHVboBSCHuzPRijbbqoDM/mRq5uhT4P7VJlvJ9P4xxG0K/rsSecoh2KOUnDnlpvE+gyjJEySi5c0Groh4B7qZWD1IbT2MhKx9hVCqeN5RDmk7Uv2+flLqZqj5Ehpz1UQyGK6ga9C4EzdUhHnX3o72osvDnxHlvH3vkqf/p19MAB2LnGz7fTyr/GyCh+Yp9Mi4ozMlalxbIVaqyc6FOMjEZ7ZHIkln1SJPvs5rcwzr4I2jOCtuK3zwINr5W/kT+Vv5HPyxflCXlSfiL/Jp+R/5R/l/+Sv5W3yfvlQ/Ih+YAckiTRtovv96x68rfkkzYP/E/5oXxDrsh5uVGuk5tlKM7IGLJHhn1xWPriM56x3IwdRkajFFqWxpJ0WcaFYW5QnJGxJmF7ZHJYjjMyjOCAOcOxDS2GkVEoxx/7jxcT9HZERW8FgVviIfCl397+B0wAwG3wQ8iAW+CDAHAP/COMwT/AWwDgo/Bl+9wb4V0Wo33jtaDntZngh23QM+cIzEEqBKDUvj2MJeQv6umZkT0Wxki0Nb1E2IA7rpFIezM+0XA+3E6tTE49VqCmE9TjNuEBKmIIZ+pTNEiJ9UBFfMrS1htVN2/oVg7xUbeDBjAWydPjPINGeXicL+ltfVBVcRW53Ken+Y34JH6bbucF7kRXB3CdztMSGZPGPp7XZ2gCt/QYHaFpNsJLg3o/R+lGvqSL6eV8q97Pl3ETO+g43hjJUtP0Cr4Jj9CNeqwzyfVyBp+hc04t3U4f5BY6rYanDaG/ns7olVAB76dFKqUYndVjdJD9tIgP4XkKKce0LlM/jbCb5KUpPe5PUKZNGrGJQtjGy9zWnEpZWIDVWhEHHQqGFEZ0m+7hQWcmeqDy0fT7rXtD4i+JQCR4vV7w9aW/tjoc9mNY7T5gKqGtFON6zG7xMkSgziMGmEjCfjcY3MN+ZmS8ju7RIZXr7sVU3seDwQw0hLQm3cm1TeAAEt1AQXS4gixYWeYlY86+ygdKvUFwvRyhd9K92h/YXQZBE9C7qVEtcDdP6EWt6xPMN5sfir2jpqLWq49Ti1rEHgxQD+/REEpw99II/w5dCebVg2tkoba5M5RS5rE7Ry/7nBCV8xSfbEiPQUM6uhxzi5uMBVETtV/06izOpwI+TA/jIRVExnKdi92IDgSg3dPg6TEOuKlOISK1a3Z2x4BLg+29xbnbSfcn5jz7dbT/3QP3QuXzGgOZml5CcUK8pnfYVu1Sr9X0EmxNr8COGS2SUju2w8jwiMc2/e4yhf84I8N3zQIyy7YEv1a+KY/Lt+Qz8gX5Sdzk0TQi/8Qevc/mdJ+TT8q87JVWKRVXPin/In8r/yxfttW9J61e8gU5LpfktNxoQQtTXRyx9bvMa4wMU6vbqentsTU9vx3zxWt6idcYGalPq+llxRkZKbaml2fH8iwjw9T0sp6dkfF8db0AfBe+aVNv30se9ObhZ/Cv8A34X7sxfTW8G6JxzeQNW58rg7+F78E34adW5fjd8FZIeFrQ2wOfhTuNkxn8Fwj8I3wf/gu+AEXPM1PvtXwwFRbhbjgHp+BGuH1fLDxAh7FVMylVT71OHUZomwddP47T/pDLPW5hCLiJx3mDV6hB9ZLbCBHgal6mLexVXVxcDsFdtM7NTiaeRb9bgBEK6SE8we+iu+kufr2epE5q0P10gLbpKC7z/XSeRmmMP0Xv5x6c4at8E53AK1pzG6/jm+gxei8tYbOeohnHwQE+QW1kOvuW+BQP0s3shoHa8Dgeo+M8QYN4ls9in0o7Dk15fJIXcQ2P8NDtniA4/XSVejiMTVhMXRpVmV6le/gYVvMWP4QT6hBN8gKNujAPnMrd3ELV3ExhRqrnUi7mphBRmKLUTO04HOrxn9/1fsg3FpC//FXoAY83KbEBfAvZD/cWVKWoBmyniFOq0hvAgA4KSiCW4O51Gy2v5RJNc1WoANtURBVQj1vAoPbSkLvPhdrENqgAvU+HKGK784ppDdu0t9FX6fFAosfvaUnlZZpuSHXSOErj2EV91EYxJt1CA5Fk3kXTepN6KISHsawOwNPkKfV0JWCrGkXGaTqC7S5QhR4jxCgZWa42OoA9qomBavgIxpbBbyvGe0FDIFkbTZo8A6boMPpVmguF3mpfyMeu6qyAEcAwa1XAg1gTLEbUp2gDtSasCKVPQjP4QUEL1CVgFtXrNjdKBXW7GgZT3wOlicZTzvOs79VEa551xQZAz/MEPW+x1+rpGZ+JHT29HWkpg2fmWptsj1Ws22FkeK0AU4Ud22PpZSbolVrHCa94pFbWJVlyZI9ky2vlW/I1+XP5rHzB5nkm1H0+DmR8T94lH5VPyafkozIn2TazNAbg35G/kL+Xz8sfi1iLoG/LJTkl18t5ucmyLwxocUBi8XA1IT3isUjtYTuWatFbbVdhWqfDNuily5IVj/JZaSnHHuXbeqTHIs6rFqH2WoEsg+h6nyx64S0rT8/1vPAwCGy+5LleorUFMsY+s3FPrRqoh1LoglSb4rfalD8PZmE53vzf9DSr751NVdAG43QrzzEKwzAMLU/jaMBzcnV3GB3VMAzmHZmVAWoPjfAYGuPGaZ6lHtXm7HYzaJLnVQ+5usuqzy1iVJXoGJ/lcJUnmDjqpSRep3M0pw5QxSBwI/Wa4IUbfIxdqqI2PEj30m29Xi6lO+mM20oDdISOqlqapBHKx0tqkCb0vJ6i83pZ9+IknaVlZB3SB+k99EN8Hx80Uu18hB+iMzzBX1WXaZxfRtvs0Aa+h2/jo9xLI3SRDnAnXqGAnqHhYB6PqEk1q2u5zDiwMWC/MfumQ03JCG3Ao7jORbSL2mnU7eQJHsRh9QptFPs2dBNN46CzS6dyipum87lWM0ddRX5S5KLpQOtt7d37Tu8g7KCOz3qRvT4AX3bCTftmOjhIjZnBRA0IAz7KxjJsMsZLFHGDXK32BPepYSdHZ+nucJoGdy+3KlQdWBiEEg9Akwe87eDfhSt8nCsi6TyvW8lbCeWeNM8QjPu4hzM5l05hn66lbmd3NBvbVJoK8yXqwxpqd/fpmHuQ6nEAD1KSF4rMF0A1LRIpxQtUyA7rQC1t8BHM5nKMhMH1UzPW0TqNR5LIJT9Cta8E8jwuhLJpFlvBR718nWp2QKDLWwHZplLpMzqEOsxcm8gQqqWWjwG5bjOluQVUb0TjqUMz1QULOD0IBFFwU7A42NYRTL3ddxDA53vOtCMDboLo82xxs70AucV5jxdI1hM5Vjo0Uwok3Rb006zw0qZUym4pklTZkCbrn1EqR6RK9lh4wbiHGXpZuRyRMuuNYXrd0qRSimSvPCJ/YnO2T8hn5ceWc/FP8jn5qfxIfir/JO+RT8ofyB/Ix2VJKqVLGqVNPib/KH8p/yBfkD+Sn8h/yU/kL23F7byckOtlSJIl33IuYpIolZIokzJoxzJkUdokWcokVaalxSosZ8iqNMsuybWqgBWyRwolTTaE7coKZcuuzIwZIGO3ZEmZHJFKyZTMJ2vl9GNPvtiOO3OhW+B/4P2Q/hKT0kxwughfjmvlPXug8j2L7vFzjbz4TsGnfVV2g0ozbEy9whO6lWexG7tpWJcCHAbHUJluwY/hGQpirurEQzoczjSdzRylCVxmclN5v7qdr2iNc3SdUtyEh6iFWnmZb9LVLoRAOXyJD9EqGu29VdzCcR6nNTqlpw54dDG9km51ihn5Es3zom7hbX4DDuB9dKPqolqapzXdQRt4lU7gYVziY3QAl+ht9GkDXuAq3sI300O0hYNuB7+BPknXkUNDPBMuYZev1xd5Q09yjGu5q343NehuHKAGDY6ii65fAc3gdCBRx/RebMVLPI5MzboZoxwmv1PJRaoAKxUqjS5HsDsaqttMfpUnO3VHp+FZw14lJCdkQMLU7pt6M5yEQALnqSaOqhjGVJQaKF+lYAJ7iyEGCP402k/jlAnQmqihPpsv6cF66INMzyjke4dB5dCA6XejGJ5RVVSjon7Y6y33BoEiqpIyDCeY+lCpOu1ZBaeB+qiZMsIpfJiO4TBHQ0nsch9vEvvBAU6jGT7MncHC4B7eT0N8hRyVGKqmHu4I59wMOoNdN0gT3KsC1SkqrMq7oTSBwE2nXmcPj/FRXRxNo3ZHax9ChacKsr0acDed4omQZ9wbS9gCJ4hzREYrzxSQ2acToxlUSkgt2KJi6GJV/e7sBEosdFMe9uYDJHk8z/0JHIczz+hb+OXbYS/AfPHG41uy9MSihS8WZUUWLQ9jUZZl2XpaLMqqLFnewpIsWUhjzT5vVS5Y14xFy9cwz1mUdTlvhZ3Mf90vvyPvkt+Rt8qb5TPyafkD+Yi8Rj4g75MPyDvlFrlebpQb5GY5Y89bki25T14jD8ur5V55pzxmVVZ+W+6Rl8sr5BVyvxyVBVmVBTkp2zIvazIvp63I1ErcGcOMLcgZOWrnvmilshZk2c59Pb6y89dWdu7a2AXrqPHUypZk6cktuf6xD77YsLUj4vlJ+IFVO3wpN7jmj7kf7rUCoglPy8O88RKu75q2nvfamPdZhaU8zzD1hl8jl/WApxRyvAqaUnGR13AJNyiPWoyTmVMV2KOKXEeP0ATX60E2qilHw426hQ+HijhMN1MX+ekkHVbjuKI7eI46Qgk4iEdpGg9hjz7mxgJG49EDHlfzRb6FNmks6I/sxtP0URzieZwL+NwY34HjdIRfif00Rcd5mW/ndQ2qHe/EfjWEZ/GIMf1xUngRb6Ion+YrOBnKVDG6ykN4kM7xISTsp0WaIUNCO0OtTjEN8zQi3sZfwOs4wkf0OM3ia/g0OWxymVtpSgdpUS/rYT6MjVzJ/aqTzulM18fJmETplKfKsQGRWiis/BRk1lGnPRYqvjflGCTUPfcXjvlLNKZcrW6NEfZSMzY5pTqzMjHiSYZGQBD796v03uMJ+fCAWnEz6uBx8O/SbaFyxdwRTBQY9NYBF1KPKq01m8MA7acIOdxF5WaziI3cSUHqpko2ZLxzob0hGPU05vLlsGkyydHNtA+n6ZARoietF/l8NIMMDewKD1M91agwbXE4WIaRegj49IKebvG2JdaD7uDT5FUem9c6utPNRqj36AiZ3r9uGnJyNNQkqRCHdLKGRF+J0cQeCJYTY7DJk+er9WATnTRCBf0JO+9ZBX4IwiFo9URSMZ+rXdLt2DNYm73hO+JJaQN4vqDXCNdD2XMmHT9XTvY8YeTVy22Db4K1gDQ9bFk2l/Papl+jnGwafPOtUaJpTjaCA+m2I86IEBRIonhsa0uqlEqeZMib5J/kr+Sf5HH5ovzUKqr8h7xHvihfkC/K52VeagSlTkZk0jrigii5Q26TW+UOOSd/Ft/e/oW8Tx6z1LQP2W3rjo5KxDrXwtN8bw9bC8gsW9PTdqObKMv2KMVaQBbYdmaftYA0m+Rcq/Xssa9nqpVmZfusbEKCeF6oBeQvBoUEm5GZSttvonHlxUlLeX7tR5877Hm8kAp53hEIVfAIbqoxDPMl7u2GaDJN4jlaIIfb3EICyuXzuksbInwoNKXfQh+l4yrq1lE6LeGMgkCqMp4SS9arYYLP0FnaX21kFDwVXj8EsuhW/RDN8SEc5iE1jc14Ws2Tqc49qg/QUTxHLaqdB+kcvoxuDpWtQXOK5Wmcwj46wnfTeZ7kbXWBFmmRXs7kmCaPUb6Zj9EZmtd5OEE38nWq1AHqozldziYzWaUZpx63qIWLeREHMcoTqpn9NMMnaCGk+Ri9nEeVpjPUS6foVTymT+4oCFPAraFKt4yLwgW61KknB11s5pa2SO6DSR0AhZ7nzaNTUm/LH/yub4eH2ggOtEAk3ktk/t8EP0PLUk16t24P7Q57dQxLEcLgNDmtyvihlXNb/S4/hCCaQ60MZT7lpz4+gHsok2aoW/snIQgnPNpPXcppSAilY4SqdDOnYCRYrPM5QKCLyUWXO/lWmsa9dCttYojDWjkpZz0c1YkYdYtxL4bZT8EO4AIMY7vKQ+OnkWn+itTRDQ7jBMWwJASUp1s6PQgOONXcFkojg+v26pwGiBoNmKpG4HrFwWTqNsGy2a44em3FLdAICppBQ71vIj3z1uQBD1R4PM93HVPhIvBzBr3EeNBLkYQndsmilFsB9V1Way7BKqOsS6XlXiTZrjvjdltit7yJkix7ZVV2Wbn4Mqu8kiSJlt61s73NkUflH+Rb8vfyh9bk8Qn5qfyblQn9knxFPm81+/qlU2ZlyoIICcLW7eweeUCulz+Jb4O/Je+QT8on5NPyfomKz8rTH5RWK3vlk0npszNOlzk7tkd8MmE5HLtsJS9qj/ZYXkmClUYwtDqzHiN6XyWJllFiwrmZe6lsSoURwn+yTE49mzHQC6m9tcMP4ONGVP0lJqR5foFt6Huej5HvWXgjT4XmhGtc3RezwY0Llnp8pd5GwCIep2bVSHM8rwooQjM0HGrgAqrmTRxp2EV7OIYH9KLu1TVojIGMSMAyD+pK6qYjPOIUURf3ctTp0+3ufpqns/Qal4OQ46uGOq/2sOaLZDK9IRqlk+oAl9J56tGD/Lv0Wh2jeVrifGcC53GJ3ktHAQ56o4BV/ABfx4scpWN4gd6JV3GE2miTzunxuoReYD+9lo5xDZ2jV5tsjq8P7EGfk8ntZAr1a3zFKQuCqsYlWuHzGA5AUwrup01nLwP5+SjWgYc6qdAPNKsHKEiK/TiMe8IFoSJdRjXcQEGtOUzNHNGswhyNxTJfm+gAJD/3e8FjrFi9N6SNtmYGCoIFwYJwgS4IFDj7gtfubkE0k10+6BboHEbeT5Poco4uCO4LZ7NL+7XxrqjQueF9qoBmuEnlBvcFc7GRVukyXtSHVUNTtpsfzWFyx8M5HKEJPMgB3kMtxrQpmI8T5OdsnavyqBHbeYPeqd9LD/EoRbjCzcY8ncX9bpubj0s0TxWURz04rsapRDXQITc/VBDO5X3cjEctH3rALcacQD7l6n7d5WaGCimbI3oah2jEqeDscBHlULE7wBN6gEvcHO3QIV0YzA0WmRVfW7W9Cv4Cp6Apvysz4TYr6eF9AZ+Ri9D23M+0QAbEjYGmLEch0VrlNFntvDRZkn3xsZUd0xxbIdvRn0uSRfsI2PCXa48Mb9fwHUzofHOcSvbH1vrH3H4gvyNfla/IV+XLsihBaRaUcRmP465+uUfulbvkfrlkLYJ+ZjX23idfkMfki/KROKIMMiihOPtivzUGMmOH7NgumwfW2jGPzAtapgXInMVnd1ZWZ+e5J45L7xgDZcZXsWZRXngy7dmMgV5Yt14GfByeBP9vVFjU86Kf7/sFyQJ4kfPzxYO6ZTqOgJPLB3lINxOqOuyhBe7gQRpVueOg6qjLIZqn2+kiOiFXL3M7NtMRKmGgWt2uBvEwBtQovZXv5yinNqdxF03zBF2gi3oSd/uh0BcylKpTeFhN0grNYpBG+AS9nBd5mm/BzmA+buIa3sD36EZup+vodXRjZF+jlxIwQrfpy9TDN9BDdIqaVR9f4PuxE4fpHqzvBz3PN+AxXuBK7sITeJBWeL+CYh/30RrX8BifpZ5iT6hAb3MvRXmBKrkQW7FLN+pyFaXDRmadC3nEqPTxDBdTn27Gdu5UhVRMpYFyVeGWUwWXhyqpXqEb1ZGWWOZrE/wAqc/zYd3tA0i4MW+ro15FKGSyLdLmzvF/5Oog9dMpQ9XSFDaubTeHdMgwZUPa0Q6d4lfwJNdr11DueIqCFNJu2OEmdRB/j97D/dREymUdwS3udeuomW6hsyZoUye+mkYM18UNcJg1BzjoNoem6BP6+3QP9+qQOdO43mFEn9BhfYGv6iby6x66l1a1H4M8x4e1o0MUDPn5JH2e76NmbnSJw6woylu6Tys293N0vx5z612zOpcb3IP0AB3kBtfVARrjY8YyiNydFds123Wzi2EV6mzc9YgpGiV4X8D7/BJ0PGfQq/ICVBXXPV4n9U/Uypw0S63USKNsSLc9Mp1rrfaoXrZE2yNjnhiTGqmTGtmUWvuzWdYlLDVSKyHZlAaplCpx5BH5pnxV/kw+K5+Qf5Tvyffkr+Rd8iUbwv5AtqRbRqRXFmRJaqVeaqXfOtveJffJ9fIl+Rf5J/lX+UN5VN4n75PfkbdJp/39NXJAxuNnLMiIHWmUeRmzs6yx4gLmeUa6dDA+tiCx+Mo2pd0eGfZFq52xyU0b7CqisiHN5owna+XUY9978UFvBza/FwQWX/JMz2urcEnxoDUCy7ZZeEdUKvGaYl5ivFY3Cn3XQuNOs7ShPj0lXfAKuAXqn1dYyveMkLcHJuAEnIZ1wKEMPqwXdBu3uIrrMYCD1FOXqNJxhM7ReV1DLp2lWerAUGM61fFJXuWqUnCTGdxaa/ZdxFP6HK/pGHXyCWolRau4qbqNK5pKa/KFUvAI3uWOcEjN4hjdSZf1QR6hqD7Dt3DWRY9a5hMUpjF9nBbwAp3Bq3otaGCS69UhOsZnaQYP0fU6nQhP0AR16Wa6la/yCN2gDtCsHtKNThQvkZ9G6XU0ha3Ui200gwdUhG/im/QMD5mPMW3Sb9FZRKcGt/khtcLlegK3mXmUHqVJ7uKz2EubepKWcNy0JAerqSrUgAFl/M9ZaY5iNBrb+6oUFyDzOb+mPB7wpHkSbkpoMY3IfuiEam/MpxMiCUPeiO+gp9nb4XUSsS9YVAKVCc0ebsU6Y63dktLobYOaNGzjapVFnYoZ3CLVFUrc7yv1ImAWRXgDkcK45urQbgS3npr7IZxGnVTM9SoMHreN6rmLBt3sGDRByOuWsNKddIVvxTF8Nc5TiBpVNkIAXOP8O8lB1m6V3qM63TxN6ERB78b+puQQ6GLejwtUwZN6CuuiiWFQiePApdTVBSqFB7ixJYNbKFAJgcQAhKt1s9qrY7qSQSX4PRxGjEIosd+rvV3ebp9OiCYEvKUePxD0QA0kXUloBch4/qKOFy5Y/Nb7PIyMrbjZ9znLYFi3kk0GtFizDIafe2TsmH0vW2PvJeuRcS7ukWH4DSv2pwEytuWEHJcteZl8Un5PPi7vk3fJ/5E/kj+WL8h9crc8IPfKAxa+MI4UR+W0zFk3i025SW6Wq3KzXJLflW/IV+TP5MPyTvmsfFw+K79tWRObln1hQAvjkXHSCk+ZGZ+0HhlblqVxIu6RcVo2ZT5u9r1pRaZ2VrZsf++OsfeGdcbYirt/nNkx/X7yhFz/2N/+OkEr0dLz/wde8xtg4Hqe9juug0euwRO+eGB6yjvD1MXeA2+NY1g7Z3XDd6wVuAem4Z/hD+DL8A3Q8Srkr/5dvmt9fiVwM5yAQeiHSbir+OHQJh/AdkTy61rOdHbhMJ3DFhqlm009h7q53Ni4YC1u6iVaoZPh/DRPzOdmcYx6cJO39dQuT2MaLtMU1lEvr1h1uwgO04280g/cze+gde4lxjo8RYtqlg5EgFrVJbpMrEfoMB3ggGY6SeN4gffTDL0Vb6Z7edsJ8xTfgRdomlb5lbyKxpF2jsI0TX/M36J1dlQfHeTr6eU0z8O6nx6kT/HNbpNq4Qd5Cklv0EP6euXXrTivhugCXSFUfhylHjzITmwXNulZHlY1up1Ni0WrP8t1sYbaVInKoWpucBqwlmvcIKJLFAm2xqL59ydPmi655yxGeWsB8tJvrR6P1qugUxrNbE2cAIYwdEIXlPrQW5GILW5lEALeSi9GSQUTWoBrVdsxD+ZTX7C8xnhY70LCELeq3EafC63JFFRRGuBwtyfTq3q4m02S2Omk6t3cSTUOBHxoSIIOgxrDSQSdxY0cIQfRHaXbOBgAXqQLGHODIU0ulQ14VSKdwcLyRByj4eDey+CmqGYMIDjGLSRAET6A9UYpjwaxlSOhsn7o8uhkbuBmilC1AWScVA5TrNCLRdTl7nHM7+zSZVGo8tYmUHOoEqEiwVR0Q6ChC+726FTO4+oADtbsvZo4Bb7y5+nAM9QOuM42cP3qT29evGUlT/Y9kStTErSeZYWyLBF7VCFL4liXM+MJ2yB5kmu5DEHJlX3WNS3PjpmsqtE+r1aOygE5IGMyKI/Kd+XPbU3vC5ZR+2P5N7lXTstVuSi3yLTsk1zJlajMSa4USK60yU1yRS7LjbItfyr/K/8t/yvfsBvdJ60IQaGdU76MSl/8jBnpsWNFMi29dmyvzFrRqb1SLAvSHvdAOyyOfZ7x59X2qFqWRVnvt30WyDD+bU3WIDJX8p/Me/HNyT+v6jXC38Hjlr/gfQnD3V7YDcUwbJEpD9SDH3KA415sfiixz2mHHsiwZzwKr7vWhZcCF+CHILBlH3kvfAxSIB++Dq+xqisJkPRL9xTwQSHUxXNID+yGG2H12myqU99bcUM4hm3kqiAGdMgJ+Wu04jk8WOGlPXichthLEMrULdTo+mmJRngOs5sAJ2hUl6lUPqRGVTpW8gr3h2o4ysZhw7hwDdEJehRfQR/kR3CSOylM1bjEN/ASztNNPItTeorfTR/gQVWLt/PDdJpfjlPcjOP0FvoPfh+PY9jt07fRVVp1+/lldKv2G4IZT6hj/Ci+i69wTFXSGi3qJu7Tp3FEF3M/38QDPKurcT/PhvP8qbboH6VTSncCt/MSLTZnsOlMZLUvCnyA5sO5oVKaN/U8XuVRPsKzaolUuILKsAIbtRNyjGSxjjg9MVVxY8qtsKvxOT+sCQm7PUndKZerCpoLOYDa+PBqxfXhktjuSWN/DehoHfGQL5zALdzclnATtCcAUA3OYj+VxMDvdRMSPRp4nrfKExioDDupya3iDmdXrsfxUoZu5320xAuRPG7BQNDDCd8yijjXKXYSsYMP6gEOMVMu1nILr+F0kdf1UhGd5AMYcvK4jJspxIf0INa3JfMaTbVAVQJ4guncpmpCFXSJXK5DDCfUJUYhUI3tXGgMKtVugnAd34BNDA2+Yl8rRJM5oCZw2MkCKxcbyqbBcNkBiHo4mzpVdgwCUJvAe7mKDAe6RYcY/Y2dWek9SVeTMg1r7zm7HDzQDpet9IDnBaK3hy16azgWJqyZGtgea3/tjWOcFXYsz8pI+STROmg8hd6uyz6L3pbIURmWERmQHnlU/ln+2qK3X44zMv6fPCjXy11ys9wjhy3IABKx6G22RW9vlStyvVyVbflWvIn5L67huH8vu62Gsqnaha/JxXdZpNbMPXLNC9cfR2+XLCPDAC0Ltn6XZt0/Gu0qsmVNiq1SzFMeGYmyz2LVBr3NfnGCA8+s6u2CT8L/WkLhS1XVM6H0EHwJvg7fgL+11pM3wYOwD/4errMEte+BA7vh4/Cv8HfwVdue/La4np7P6u29Aa6DT9lMzwe1kGfUjODLcO9z0rN9cBa648ftcJPNKM322YTSpr2/FerRIXZULRY7u3UKQaWPJniUGnWrclHTIHXqYR3BIjWuDA9zhV7GD6vT2M5+OkQLapTu11eJaINeh9O0ZHBEct1uWuS30Y/oT+lOnKUubsR+MhvWIzSl1vEkt7qH6Fa85A5TLNhNg3yKb6DFcJCv0EWO0sv5gm7nLb6ZhmnIHY2k8BiNYDNt8014UVc4Cl+l+6gDL9NsYy5P0BXs1pAJdJAu0jgb8GLA3VULgWw6Sks0RQfOecihG7GXW3UNpesm3KB79QR30nkcohbaUiHdyq1OLXdxO7Y7xeQgOQ26gRtJUYiaqdPt4ImMN/tqDGTo+VXfZ54kL3g9W9mXu6qr00PQ7AtmUr5boQPapTC2ojEsGgulTII20vEtLUlVnkKf49sDWEXrOFgL2pvg2eNJ9nAla7fCyLhTxNnnJGPULayBUm+hlyC6lw9Siy6mSzQfhiao87Wk6gjloabTdFB36HUuiwDVckx30RLnAezx1nqpRS9gmCIq3fVhOy25ETpOC5F9uoHq66DRh4DFfBX3c5Ge1C3BXTWeEm+Dt85ncvT6JGpwYzSqQ1zFoVB6g6cXCrwhCGbRph4JZzwMBb5iXxhUFvVSNhn/XLN9dlhTC4eRVb2/mPdyeiP0AhZyLPk10LAXfN7n7i2AYzD9PEQ0zzVGhvcJj0xZopnhLSxbTTqvZFvvWsNg8MaDnvG+WIuzNBJkyXplmFC3ZoMjSIkci2d6A/Im+Rf5thUC/bI8YWGJH8j9ckFukytyh0xbdgVISA7FuRQkt8gN8aD3zThd7S9t+PuJzfRS7e/0yn7rh7HDvuiwM06WqaeNNdmxFCuKuvPonIVoTKBesSHRa7PUcsvIAOvKC5ZrsmpXa4Ler5np7dTPHogLN3lfwqC3AgK3QQO8Bf4v7Ib74NPghZfDv8EZ+Bd4NSTCI/BN816GD8FHAOAN8KZrLZrJsAcS4f1w9VqQezX8K/yj3QTshmFYgwVY/IX7ChyGs/AYvN5mfUsw+dS5HvuGSn5Lw2QECVWQHXSVxha+iAd4hF5H11EAo3yJHsKjFMBNZ79bzErN8mv16/msVhzWY6qchmlY92E/dmI/n+Bafw4RtdAQHsf34wQeoNfzHLZSO2/SpmpQh3kw1YvneJsO4T7MwhU+pWswRHfhfTSPU3SM6kKA/XSVj/BZGqc76QLtd0o06xt4Xh/iR3mVIZCOS3yGFiiAZ+lhjLDmDV2ngVr4EVzjADbpUZzI9zkVvI79TonapodohefokDrIZ2lK19IcnsRRJ5f20ZCTTakcdfO5ncb0BBtopdPNUUXYwMhuCJkMDc0Zam0tf3nSbeBL9PyqoJeU4IEkN+OR8tq2IjTQSFE9mBAQ9VEy7+EsZtzEXmzmIE/iQv3uJfMY1AAxhd1UF3XXMJT5PmJo+p1qD2byIh0NlASA23UDQq1Xw5sBPfVAW3rQcZwWU1BQJQgY0G26VA3z62mIErkCXTZYgl8fdiMAhuVRArwHx7HPrdERDnIUd/EefZnvVHVcp7tpdxQoxDGu053kp6Pc4oDyldoOek7QXapCge6hs9TlABGqcs+2JwLuXhp1cnkv9oaKXBgDhGpQAT5ObcSqhadpxinmTJUeSPR4wsDQmowN3EmxkbScteR7IPE5ygQJtl59z/O6E6IXwF+Mj5MEnwjIirRLkzjSIBvSIw0SFJINaZEGQWmSLWmVgDRKSLYkYsdQtkTZ54dlS8LSKH5pkW0ZkCEZkF55RP5cHpdvWlH4/5X/kSfk+/IyuSr3yG1yryxLowSlUYZkWWrFlVrpk6t2e3uDnJA/kh/J9+VH8jX5qvxI/l1+JN+0szBnTFuE1pUqWZD9dp5NsigjUi1a6mVJesUvQWmQNRmQGlESlDVpkyZR0iBb0iUNEhCWTWm2qwja9ZhVhOSIXZnzZFTO/npBbyc0LMNP4N6XsE/PvOY2fNLmaAXwfWiG62xoS4a3wpPwbkgDH3wbvgCHYRo+BP8G2fAQvOVa0PPY4Pb7VnBgp4Y3BDfAP8IDFp44CNuwDhu/cN+CZViH/wO/Z4PeMhx4Ou6bBElvapyKOtgULFcFtNtJ4R52GrKojxsME0GHXYeyuJY3nNYGr66nAVqlSs7S+42cObdSm1NOQMm0Qn3UQKf1gkvsxxb3IN5JJyLgJuI8XeYunsOjaphWaYEO0508iYt4KAi1CbhN03hOP4TLfJDO6+upWkEogX04y4/o6/kQt6ohXKJX0nEeczWt4Sv5iJPcDuToB/Q2zVEtDeOg6/AWbut9vEQ30CZhIAeRbqc303GK4SqbFpBX4WWlcAgLeTdFaRWdUg+VcDMlqBxcx2Ee5NPUg6PUjUhRQ27T5Pq5RjfpsIqqFu7S/XwgMr/nXZ5RS/l8lneEx3w89ybclbfV1xTM4xQsxWbuVPUqVcMYBKEhkbu5yEnCVOzFBUQOU5cm1UhTujWayNDpNTllGPK8CrXSYW7ndEylEE0i3QBV3gaothrIbgM5tMrzYeNGkatcmuJj2KXqsUfVYzPWdSbSeeqLpGEfjzani62Q5HnqQNfqaXKCGXyRukOAbbqOIqrFaAvipu7lep2qgbL4OupylLMXoMK7D9I9BOFkGsERXU2pwQrq0w0Y4/wGcLLc/tC+ELQA76NJ7sRaasUOVNRFa6pOJXOyDmMjQb9hnxhlGM1d7FCWkxhoiOldD/mmfmWXaYKlBtwBI8+rs2IYGXPFa49vyPITS3LGlvuXrbTUxjXews7RkmUwLFnw4Wycy7Bs2ReG02CkpQyXYUWW5BZ5pbxCHpL75BH5nHzaYrcGuHiZvFxeJhet8NSqnJAzlgVhfC3OxJkWW3KbbU++Q26Q98qX5LPyJflteZ89+qJ8QLZkS45a6/Bte4ZhZByLz+6UBTdWLSPD8ErMa5+5xsg4G+dhLMbXs2QdNDbsKpYsm2Q5vgqzsuUnN+X6xz796wU9c8Gb4d/g919Cgakdaak3Q4ZtifkmDMDluJ7eJRC7Tc2Ev4evw7vhg/A+eC3kwquelul57VkfsUEv0cpTgc0c/8oKDiQ8g6Phi8v1GAOhW2AmvoZ+uBSHSnagj5Lst3EvhQ1pnEjX0BB3uFm6PVRI5o16gccajT11AU7yJh/Wiga5KWqUQnbjUdrgNT0XKuZE3UrttE5vwXYd5T7S2KHX6WaV/20oBZ1Fk7jOV+gkTWAtperT9HZac+d5jvp5gQ7ytl6mFr6BZvg0X6XSFqhLZOBRfjufo3FsxmU+hCE8gNt0B63RCt2BPS1A/fQKPuK2Y319Gg/oAPfwW/lzdJR68Yi1wGnGZTrH5zDg5KtjFEMfjvIYd2JXCFQDTZtmDyymMb7EB7WmFUUqE5t1qR7lGV7RW3RAFWMjhhUbIx9sxU49weOhOtW7+63QE5f58jzjbuX8fVfzbhsodQqpywnUJ7BH5XKIupVyshwvsm4KQBBC1dTa6C3wNKVgMjXiOs/rZh0iVhVOFnVQvZvHc9iNZeGEIXPta+iCy00egFzPPg+AyqAO1UIRFVVFmEC52EF30Sm3PLKLW+4GnUj7acVtwj7qog5VWwDN9k1c7mmEYAY16xiNouYWOuo0aaASUpRIrXwXneT6+gxKcB0DVahuCvphl6fMAx6G5l10mJe0LwwDhngWoEkcUMncgfXhbApg2HXJyHeNB3JUUn3iCKgC6sLdDPW7sJPylFeV6WbqxvqmVPKqTG0Ud/Zgx67Xw9CzXkeP/QK/AVbtO9Tz/JzKYnjcI74nTK2s1HbnJVv4whxl2YZlsJvZJbtF9FiYo9xuBz2yYDe3ZlO7ain9pqp3q3xKPiIfl3fL71sd5J/JE3K/ze3ulpfbraxRK3ZlVtLsuWTHkuzRfVZh+SG58dqm9i/lL65tb0mi0my91aLxM0ybsplTikxawYEkK0KwM+NUmYtvb42u8s7KkmTJ1vSMrvNSfLvulUXJsqoxxfHNvPfJVNl+McrJvxj0cuGv4Z9sT5vnJQt6R+FxKyLQBv8N9XADfNQ2rvwDfBj+FQ4BwLfgfvvcEJyx0lJveIa0lNHTu9H+/ChcsM87BX9hxcoTn8UUyKwhH/xxrzUDotwZf7OZW0bSayseam6lZifgVAZzeIBnsIPP6CkK0AjOst9Y1wSzaVoPYgDb+DhFNJQnpINbQHN8geqb02kY76NbqYOGyc+Ew7SBE9RJpzmmoMDT6A2Ck4838216gaZoRC/QfreQT2EbddF7+bfcVl6ibZ7Ag3pMH+MlnuA9DjgFfIJu4ktW9vMoHgBgl9aMbpyO4gV6K27zSZ7nMzRutF54gWaoj+/lt+NVJ4p9bpXTrw4F0gz5Sk/SIm8Z11jOpTYM0im6rA+gQ4fwtD7o5rrF3Kfy2EdD1IU9fMLITmEXDdEaznET1WnSzRTVbTisOrnIaY4FkvPgXjgKmb/0fkiCgBXFBMPfCCdhgHvdgphHA+2iJorgAg47qTFwy6ijMgVg3hsGla9a1d5OCKRgHtUowhA14yV+I007ezG5ydcKoVzVHkk19UA38StQndAIqGhCO70eVaS3aVA5NOrWcRoxnqCmZnAyaZimOF8fpKPoctxc1EjT1Xm6TCtKH5/DWuXoeST0Osk0wfOhEkxxu3UburygD1Eip5FRxNmrodQ3AlhIw1yAxdQc8rZ4OQHTsBZvwtfyIXIxTEG3LJQZ8bUbqf6QSmaY9FVZJziVehp0pVqmIa1V6QXjApwUDHI/5Tq5aiiW59kF98AJyHqW6+iHB63U7fMzoUyneHJxyuPplpGxZDVGjCyU0UFOkt3WHbZckiRLEmRd6iVJ0qRItqRcUiXZisRnS7I1VDwiJZa+nym3yUesUt7b5UPyM/mxPCk/lAfkbnlQ7pdXypR4pUp8EpFlSZdMSZB2O2YknUjuj3ul3Sh/Ij+TH8nPrC3kztG3pVU6pFNaZV2axSP7xCMHZUASJMsGuJh4rOH4QWmJr2JFIpIguy0cU2IrlKmyLkqSJMNSzsrtGr1W6zlZdkmJbEmZ4Zg8WSGnf92g57PfNH8EP7OqJi9d0JsFgY/ACnwHPgYAr4Lfs9ndBwDgHfAzKIcj8CTcA0fg3+F37di7f0FP7zG43b7WK6341GUQGyR/1bfi0wUKvBaRfghmoBIqgOGe9Dvcft7vtlBIEfbhpFNNLU17Qol4iGc5Zqp8tE1vpfO6kfY4zTiDzVxK4KTRuh5BRSd4iA7iokK9RIOYTwM4r4fpFJ/BsebERE+Sp84bAq6gy3S7XscR6uctnOYWYySO8+Q6tbyi5vBOeie30Di1YQyv6P4WoE2+mw7SWd7CWp3BS3iUBniJb6ejDuMMf4G/jSe4U6/RqjLKd524yZfI4Ww6r3qxh2+lBe7jDIL6PWxoZjV4iqe5gCZpktbp3byFJa2G5h+mRrVbF9IKzThRXNKxxjxu4y5apxUa07M4yKQojLqTBrXfn04RdrI96eBNgcvwIExCFeyD3ZABWVACDCfhNVbQ1XscmHVbOFVnUjdrN6MYNOhKmlfdjsJWHupKdOAK1HqxAfsxRxslTI9AEByIJbkOXaRbeVwTNSvmOj1LDW4qeFS1jmAGAefwMrU15bKiFhpTbYE8FaIMDXofzXKMOqnXTa5NxqPcrZZVJ9luuOS4ol4zBFPomNuKR1WHBrcGRzDC+7kn7HNAV7ByCuiQaqdWt4qKaBa7GFrBKaM23B1JoN3YxwO6mppR6ygexXtw3imoAIJOwyf2ZHsdE44HaI+CJY8CVYUjjiaiAzzhJjrgJOhC7FaU5MFyPYj5k2ZWiXAZXgaTUAP5sBvSIQuKgeAUvAaGdmyWXph6RjE8DnFGhuUjWIU5v/2ZJsuWkbEzVhxnZKzGxxJk0eZqYDX28uJAgsn0Piwfi2d6YpkVD8pdNug9bJFaw6VAmYtniVoOxm1+/PKAPCQPyivlRpvfiZWWeuroO0ISkahwnFObbBkZbfHZ7TAyEuxYY3xsh5Fh8ro5y+312FXUP4ORAdc8Mp7OyNjz6wIZEM+T3gJiqwvelyzorcJfwG/DH8FbYB94YB2OQxt8CALggzL4AEzbDfBX4Y/gNTZ/OwdH4o3LT+nhXbX5oJndFfg6PA7X2X4/7wuivfmscNVxuAvugRuhLwtCadTFY0oh6UkaxaPcyTXUw1VG9BIzKcZn8Dgf0KaedpSqOKLnuZsvqMvUxgEs5xUaQ4ik8QQu4WndrJt4gc7gazDMsNdX5AWPk0pzfBQ36Siv6yiN4El62NR9eKYRBPRRPkkzepguUAcGKYbH8AE6y2+hUxzFXlowrAM9Rh/i83iQjugjvEgnuZu2+S6O0BjNq34q1ON0lc7XJ3IiIy3rId42NSaaoTrVjZM4TZr76T66TE18jg5gNs3pZq50MzmLx+gMjVM19XG4NZU6eIrG9HSohbtpijboCLuMuova3CI3jVuxOgbKk7BTWA/CabgLboITcBzOw922gGC8Ib0+T51Xg6rkTtrrGuPDPreUc3U0lE8mLBzV/bopmBNKUXXUoXcbUdAsKPetA3i4WEdokmL5wJoaIulcqhd5ksI6SkFVZHTvOA+naV0H0VWNlE6gg/qEm9cAbiKHOYfCfNZp1zlURlGcpClqVrtdj4Jk0OBAxNPscyuoD5ewi1BnRQpxiTaCeeTn6qC3HVQHHtOJAcACYnKwnc6RClXyEFe5lWwIee20gT2BrFAWtWJ+ZwLOUjcp3N1tjYfAU+5TpmrYzlk6WZcR4RzNhdMJ3KAOOHtQY4/OrQMdwHad1gr7vJ6duqgfTsOdcDOchG04B3fBLTBrW7VeWLdEpWVk1D9eLw1PGH5Ds9RJrfhlS/rskQEyWu2RgQCi9ihqIY1ay3TYlDo71mJNgKqlVqrlJnm3vE3eIa+X98g/yj/Id+Rv5X65U+6Te+RlsirVUifVMmyp/1VSLX12C22cLHriNb075ZJ83p77j/JF+Yr8X/me/F/5uvTLmIzJkByRMamzLIol2W+5FAFZtkdmbFlidsxoOI/Y+ZnOwpidZ5MckR575MqWtNlH6+WIUHwVW5a5UfdkUM4+9u1fL2DtVL0uw8/g1EsW9EybyFn4zLMWaD2/RC97oQzeFyOJ8BQNzYhmQbrvKDhpyqUeXKRZHqYCauVLPIqFVItBTTikWtqACmiRWoKgazCiZ/nD/GE6wS1Uxo20QhNYz1N6iEqCydzDR/UIn6XrcZr3NkF1woqHO/B2nMIuXqR+vp2v4qjO081kDHIKOcLTfIGXsYvP6GqqVB18iN5FP6X38QFu1S5PUEhPuCNcRifpFDOt8V0mAwnl0U102A3qw3g33e220Qafo5BjtmIXcUNV037spav0u3SRAthB43m+wG6cwGk6ylNdyVRPh2iKN3CAKjVTty7RKTisT1And2mXHZ7jKfcAT9MmHzM9bY7RruvRpc3Q5KnwJMA1E4Fd0Ait0AlhKL7GfLGP1/is8WMfVgVA5XAbneCgC04ht1BqUzIaUfglHm9IZ+iBSl+VNwKh3Q5RS6SGY05e0BfZzS1OqVPFDkJbMu7jegpigCfxt+jd7gFsbMrQ0AuNoBt4kavbjSZLO8W0+yUI7qNJ2lJ7sZWGOIwhv8/vSYZ0qPQgcL7uYBdnnAIM6dM6jMmUQzGKqbA/SadQOx120yJmj+5xion4Mv0+38YxbtQBrHCzgxDcozTtZebGTo/fw/VumOq4VVXVeDuBEsDjQgC4hldpnLUuqwO3kkPa2wo0jSuqhnxOCkfcaDhBoMqbbRt84u/01F+4jvD8tbz4bc4LMFO8+vi6LDwxb10j5mRZpuS0rMq0LMqc5U3MyrIclrOyLPMyK3NyVublcBwMWLaPz8k52ZajclLW5QH5iHxQPizvkbfK4/IV+SP5otwuN1uvjNvkomzJCdmSk5b/cUyOynG5Re6Qu+Quuen/Y+8/oCQ7rvtg/L7unpzz7OScOry699brNN09Oeec885smtmMsAgEQRKZAAkSIEgiMIkmlSmJEpUtiQqUbPxp2ZKVbMmyLZOybOmTPtujPzDL+k7VDJZLkAgk4HN8jtV9DvahXuhXb2Zu37r3F9RL6mfVT6kvqx9SP6H+tfHS+LJ6Rn1OfVr9kPq4OqtWTetjX51V82pHzZitRbWuFtRFtatmzV1fUmfVihnTs5gzd31ZbZlZLBjmyJJaNbNYU0tq02y9NourakUtqbVXd9WNr77segchag5egY++a0g9/edyHn4JqsEDKeaax02FpJOqW7Ip5R67LySdGH67v6vW6L5FlXMbSLLr+8xg3bdshqwqVxnYLl7kPR6nEVqi3gqIZvASHdASdlN3MCUIWKfV2ERcNogwnaVVu4q6eBBjdEbGcAi/SB+joF1CnRyRAdyUZ7mH13jTziOQZfQk34+DGBJteMALcg5nuIYGSNAIPUMv8gyP04P0QR6nDYxgkHfoBbpET+EBx5wGwbRGmzQazJQb/H5axT16DGUR+JJEF56nLr6GczTAV7GDp/ghGsBhXsN13OIztCcnaRQ1+KIc4xzyAzXS/Rjhy/Ju7uAtGRJBu4tqd7UY0w5f5SAK7uBmOcvbFKcRXqR12pHXad4Hsp6G+VQQSt0FVvVr30ie1/1UXK8tx46H690MXECDju1o57gZ9GOcekN56BLQnkE91EuIYemnYk3OwlruwAAAIbYEoM6dbdmpNI+bwST2OECw4KJT1Man8Vm5yxNok9ZzbsagGLCLKWag45PYXGd1uEK6M9xNGzgQTecgTVFFOmRbbqixMAnDNIm1gXy8IPvkGPu9kLAwi4O8iOXslb5gDU3LeiYK2V5OyDm8Dz/IPbLBzgkDAbvzgJroDhkog0ZXieVN4vZQYaiQ4xwK5jB0eGSN5ttKB8dEYAGEq8Jlt4g+4YgILbZlYIYYYG6yABpclZD/WlRzv+4r3vX2lrUnr1wXQFZF1svZKvuVTLWgmlSmylRZalOxAQKXGl5susoykpyNKlOlqxqzlaZyVLbaUNkq24ydUcMqoUZVQL2g/h/1TfW36k/Vb5wYOr6iHlPvMTncI+qcSqghFVfzak91qx7VrcbVY+oj6kPqGfV+9ZvqFfV36h/VHxrlZM3D+DP1nPqs+pz6IfWi6lTZqkLlqlnVodJMNXFWdRs9lRw1rzpUqspX6WpO+c0sctSaCqsUlaNyDUsjw8xsS9kqXWWoCrWlGlW6uX9tbpl1MrMGPbNXT/3gy9vjENUF/wN+7B2IOH13NlcJBKm3MjXr1sL1dqmobzu9W28iUvB6f/jvU1pKX6jFAu2fOiQncJ2mKObEeUDGAs1YLWppk/qdFhzjTWnLTjyDPdxH6yJDQjhZIp1jDuXRCl3kaeyiedqT07xNp2lMhHmI7sbLsoj2+cc0d5eiopHW6RHeEpv4Es0HynAOPyU/yGdo347IFhmlGa3QS/fT6ThQL76fdc0Q6QE6hyP4HD1MsyKKi1pDRRT5XbKADugsT9AkD9ENRIzTM/RbdFWGedZpoQF8yKlDoBYconoK0woN0DhtyUUUfIHPYyd12ODPohU+oDFZy+hEZSt18QXSXIZ1nMUZWuXzPIkJ0cMdoigIje58yDckmu/48vCcfEF910+pzRWGUIYUNEkJCXYVXeYJLEOgYh7FWgmfACqTbSwwjiMctQsQZC31tnhaXPWuViuYJ/vliCjSTmrSS3EDpLlITS0a0xelAqpmG8/RsPRxlO/iB0UgCgK6QTpOaauHZ2hAeqkGe3C2KT1kzbkAuIVWbYG17NCsjEqgIJYRbIIvWc7Th3CNbCLc4DmuCZSKauoR5QQ8I9ekj6J2GOsarT5gm+fRDngaXFVWJWAJD7WkATgNso8GMSgD2BjOkdo5LYZxhmRXwI+nxZIfZLqcx15RPw7ZVotVCZXf/SX8hs/xzZMSF0BqRerLGcrzSopaVbXKrTJVqpGL1/DeAnVaVakklWXk4pvMWNlJCyDFeMdmm5ZGueFhdKoxheqT6hvqL9RfqX+jflUdGWfb/2WC3gdOgl5cDap2Nav2VJfqUV1qTD2sPqieUB9SD6hfUX+r/kr9N/Wy+rr6ljpU31J/ol5QP6p+RP24+qzqUXmqXhWpRQNELjSd2j6jBZOqlo3Zd77p6DqmGqlV9LRnbprKUFuGQ5Jl5OIDZhbHLRotJW8ZSXw9poXwq1WKchu5+Js/aNDzGLn2v4PfM9Xg/z2qem8VtlzfQ0TU9QZyAt9PtdIDbpfVoUW8q3lGtHOAB2mSAk6CV3mWS4OAQeqmAN1Fj2i5eM2/1a0FqrgMiaSWJBGQ03wWd3A85m530z6PBF1ENIZjGsaA/bTFn6Gv8R/yo7TIvdTidOlOrDhvmiF9NEa70uZ6foTucvyijOZxj3bwgK859Z2WSOUlreHM604zddFV/BBu8Dp+EBMcpcdoLVX/6V/hGxTiR+lHaYzWaFIQD/EjFOIE3SGmcJEHe3QO5ZXtWIW7/HN8v/DTEJauWtRvO3iNrjo2t3CIO7mBc7mP7uSuRBrN47qWyOdV3qAeR9I5ei9VELR5FGRB/vfxiAugwB0EKqLz2B6s5nauohJy9MJbFPshltzoJmgB6eAyznB7sFKUyk4nrcuq8HRYIhN7ZAml0AL1s5RkFwVKaJEGAinlri6PsLFjPIkaWYQzOJei+BLfTz7DnZ3gsY4kklhRbWGriHCEt7gzAINukccbNIVBJyhLGESIqvyltE1hEUTCTvoU3c3lIpfzKOHL4DLukcWPWgMurORVbvemYQ0H2eFFjo0Dh6Rv0Kpx1buTwa4SwUABermflnmaTpHWD0yacrOHW3iC+rjZySchfVjKyzTRAugqswpeH/Le4R/PCWRFNzKmjUeGS7nV+kkjI1Otm/aFy5T7y8xY8a2Whj7OY9oDJUYzJawGVJN6Xv2d+iv1N+qP1VdPWhCvqifVQ+px9Zj6oNpX/WpS9alldU4Nq1E1rGbU4+pj6qPqOfWw+qr6R/V36n+pP1S/fyvT+6T6gvph9SPqMyp2EpKnDOUs1RDSjiErHjVrxlLUa7PQ8JkVQ0PTrI8FI4ul4SmvSUvlGd+M45npfFWPlb4mn/WqR53/Qbu3x7WyEvhz+EsDTne9az8pz/cpLWW9oWyo9QOIU92ah8ujIFjMszxI3YyiFHWtrYfAm8pDfAOviAbuwHEqFrlUz5u8R5t4RgsQdLoYaRIRi3GN5tuymGja5EZDvM79wWYKyhHe4y/gH9CP4lO0yDGK4mnacny8ShMETpRvyKlGjUF7gnfkEu1LFB10Fz/LfSF3tQchksun8ToNy0W8W95wisjBfZ7HMJE8Tb+Mz/AqjuIGXqQ53sFVvIMGYsDA47RKvXyD5pnwKRqlKgxqcVPZL4mXRS8HaZULqJl2eZTeR7uBbAKnkM7wdVtguuyifYqjttpZplnhI/00DniWup0stppc1Ubu+u28tFx6ulVhcQaNUA624iPseGEYmGkDR7CyE3atMcBSTgibMqSbitimA5wJZP6OORORhagmSUPinN0cBiyUQzTBlT5ocn8RHLdooCWairvAEtW0YofRRyFRwFE+TcSjdIHC3BzMDeQJwZP0ALX0atXAuzhOdXZWoJR8cgwvCeZB3gpWUC3FuJqmqUdqdm0h6bJBwQDYri5XCWBETnAoBsEUHpE72g5SVHCPKOqHdlixsI4v8ixVRzNj7kgpx4kxVTewZapEXuAFymeIuPgMXWpLlT6MILRZyZb4znz5nbyiLoBwReLlDhV7RctDDauoajdtiXEVVjHVoc6oIRVRcRVT51W/iqmo6lVn1YAZi6vzKqbiKqL61IFaU3NqQ42oj6t/p/5Q/an6F+rL6q/Uf1L/Wf1H9YA6b/xo7zTd06CqV/0GMWcrr+pS96sb6h51r7qmvqT+RP1r9cfqV9Rvqb9X31R/r15Wn1Q/rL6ofkS9pOZU3EBWNtWiCqsOFVQ7al5FVLuKqS3jh9Zh5KGGTmaxq6ZVWCVUVO2amcVUuzqnRs3eLnXWzCxmZtZ1MotzxzN7tVNd+8GXt8fLx9+CI/N7/L9HVS/PBNQ3hpsU35ZgHGd1aYaGDbeoaSXfRxZ6fIVMiEMvtKTAbBqt0jJ3oiNDGBGlnIG9tMcRmuUropNHeCiQRrqiE8AwI21hP82y19aW1CN2BYV5UU7wh/gxB+WGfJovYJgLyYcxqU17flgGsIkepbOkdYsPcJq3cYb3+BHsYy1g2UwHvMmng21UQEt4Fi/SJ2gIwPGMWE4ynsF7aYMDuED3kOAe3uNp2pY9tEY38GfpPkaa5Q/hCPr4Bi/zRLBQWlxC9/CZcIUY4kHax5/ia+yVFXRFtiM41TJuN9A+P0PjNMqtTi4N4wSd5yku0o0K2qQO4aVxnKJRjosajNMB78oE9mhwdLG73jplFUHz23jElVAPHisDtoHiXFNsiR7sECGsQklhmWrnUkyyyOZm7uYab9IAgEXAzTTAdZxAiTmBAM7LhJRcRUlUSN2yzU5g3LGFu8mSkO8yqjfLNEyn2Msd1IP5eRaHCSkq0yldaqh2ORGHRTsHRZTuo4d4iT5GiyRlhKPssE8UU48U7W5ZRw6HsMEGDHAPJ6jKaaAtdBgCboB8Kwv8uax91iJsU7uTGsrGNhHRpRBRSJXYwUg+6o+kewFcYeBMQpGgYi6jTvJzMpVTP1YLr4jRoOMPWZzAeoQ6tw5671K2N+8CmK/YfHlbrbyybAr/y6ZZcVntmK3XWgDHLQ1d9F9Wa+qSaWysqXXTDFhTy8ZYe93sW1XvVc+op9VH1RPqRfX76vfU76tfV19UX1NfU7+nflX9kNHS+x31s+rH1G+q31S/o35efUG9rH5LfV19WX1JfV39C/V19Uvqg+ol9Qn1onrWNC3W1Ly6oM6rJXMnumWyqDbUorqozpzcsZay0q2XJXVJ7ZmxJdNWWVRrauVkZmvqtTmuqNVbs1i51aJZV5fUhj731V11z1f/5AfP0XRO9iVQQO9i0LNuuVzo96PwoyfA4m9nYa7bNP2ehSduWUAeB6wfgeu3dbg+Al942/2u47xwDJ6CG3AdPuB5r/eCsy+muYOiogmLnRZsl1HswWWaCbsoH/fEoMjvd3Gcgq0ZOKJ5m7TBX6Kv4j76KSFPc0CO8YB0aIHauQavcxe2CYejPMNP0nYzkC7On8M5vkteomVqkQXOlNZW5nHs5p/kr1C/IwwwOMxa+e0i30GE4M2gcTlLe2KIhmic1ugrdAf6cM454+wikwfb6YMYo3m+m95PH6Z9EriiM0gO0wGfpl0+oHlKwyC9h7ppl8/geKCy0IPz4kyglnvFrojismgRs3SWJcWlwDbswH7qkY4YxGnhC5TiMJ+nRQpyD3bzMK2Sl+CUq9CyzTfMm70qoBIQbCsATlD4hUV9wou6v3oHz6AHtB1kEib4Pp6RKQlQUOEutoJ53ENJXpCp7KMb+CItYkHQIyHo8gL7+CEOoKAyhDqXgHKwQUaomvLoATlFtRRw3G0QKKBH0MdAbcR+iIPPhSlOtlNPcdrAX5f/L38YR0nKUpke9ExAGOo91C0yzwJu41qjFbCCuY7DtXyPnA6kUFzWSGh2advubUAhGmie7yBPjcHTi1TZivfjC3IeS6UnCNxkB9e0T5uLgSysllf5nKypgHErqGd9jWYAWi3sZy+nYJeoCINwVUPNu/OX5DnxvU1Sya941JSpbSWpdKNq7DEuGCtGLj7JiBCUmbEK417mMQLra0bDxKOq1aaqNDLsHnWP+qLptj6rfkbdPBGJ/7pZqir1/9zSUP4rIxmljG/G104aHn+m/lh9y3A4vqGeUz9rIM4/poKGIwIGrOI2lpM9KmEUWtxq2ix5tRD8jNlKNxLy5WYsUy2bml6K8qg5U61MMraQrWZviVpT9WZmSWrduGx4VJWBZ3tU0qtJ6txXj37woKfDzsdBwdC7GvRe6wzr7RgMnSx43SeZmOvEuPv4yM/Bp0+kpfS7Gn4CFOzf6h/OgTJtFs93kXleI0e5TgTl3Schbw6egkpIglRIgaX837YvOP2oxT9RRoLNgdw2F7lxDOcCDs0iol+c46d5X0rax2WqZYl7Yp8n+azTQ9OSBFErg0jBRVrCbd7iHdFhaxObM3xd5mkqKoEI0Pv4UdzGJZqjDX+uKMS7cBBX6P00TUOyle+i53hK7tIe9coDeoz8uEJ3YTt20wV6lPa5S87xLtk6p6N9J01AOINWxXt4XV6gJe7mRd2o4I/wC3yG+nkWhXTkbKDYBhrn92NnqITO8nN8LuDlTq6TwI7sotP4cbnC3ZQj8nmTr0jEVI7TVRHHZOHT7RpcCLaJIHbSkBjmFV7WlTi0Zt8i6GXCKaiEBldIi3x2iGROsN8Byucoai06Ep6aZBHEuChHFjEuYqtFe9wmguXodmodSQO4Jlq5kTulLQuEK5DqxJhpjxJhaHMXwSlXGLDRCfkyuIO93KORdgw2kI1xh4PZFPNlBdNEpWhBxIiIUDtdxKflnfwRnJRhimKIA1TnKxZuuwntQD53cIxKGQTIGJ8lr4yIVsrnDpEpocYqAII9oNNiRAYFohVL5SoMU5TKsIfWRJQRC9l4ZASg3WIPNYtObsAm6pM1URcVcpdoJZYCLZFE/VhLJTzg5BDUuvxGMf4dv1JdAOkVGS9nKc8raWpN1RmfiVS1o0h5VIYqNI2MZJVjGBnNJiCWGd5CivHI2FG5ppFRoc6oCpWp8lSBekB9Xn1afU49q76klDpUSv21+pphZnxL/bX66kmD4i/U19UrZuy/qN9S31L/U31L/bH6fcPh+Jb6S/Ux9WX14+qn1I8pUqnKpyw1pcaVy9zJtGlkFJtGRv/JHS+bsSIzpoWnsk0jI2RksbJOGhm5KkXtKNsESW1vVG0YGZYxiNSOIJprUqVSVdKrleryD768Pc70HgIFW+9S0NPXiMFpeC/8AjxhFq4TMAM18BmjEdsIn4IwAMzAz8HPwwUT7D59m7RUIfwy/Dn8e2MCnmLSir+Af4Afeot7OwWbt2qSTfCU4ekanwwPwHr5J2MJ0Y6M9XZusMCuomY+h4s4Ij5DB6FGnSnIKe6UkxTEJKeORmmOsgVgM5/n03iGtmQR5/A0ddEaPxS0uYn3aY56+A4K+6DEqna3Q6iY76UP4hnu4U6B2Il34C6v8z3UQoCMB9yCgq/SJI9Jh8bp8/yf6J/RjIjJarlJMzTI846G697B52QnLzrd6cBArfRRPkvrYtGfL6b4otQi9Z/jG+jnMRwJ5dMUL5RZIs4f4i0aEk0U4dMYR4dOizZBeJV9olVO8Ip4GKecTALup/uxRyRTDcaReJFH7FopJWOEe3nKnsdtHqesMNRZpUZe8Y1/vKnQYNlAxdiBaRiSdhtwBQ1oif1FS0Z5Tgxyc69b8xionvud1nY3N4pOuwU7ZdipkO1cIyECLWkU4JiI0RLVYBquYI83dQpK3QOAKaKT2qiTalgLUq2hj5PYSxFKdSS9F6coyAmKsOBTnI9tckjez5JcdBovyTBXt+RqcSiMchzDfJEPQrlcLjtlHudQP84nrA5LSpIYwkCbVesqcnm1fvMSRtAlenA6GOaYrNqx2kEAaqPMGuphIkEdTiZlczt1tGRFoRoCOTLoTMjZQIWWG5Uh7OLkYIrso7JADUZsVxgqrXcl6H0nI2PpNvbFcSMj68RHDIwAU7X5t1DtnLQ0UtXmyb4StWuCkM6r3qO+qD6rPq+eU1++lcu9bISldKb3tZOx/2zEo/Trv5ns71uGffFHJ2PfVM+pr6ifVF9WP2FYwJpNO6aGTz5tzIQ1t2lkdJ5wLhZuGwucjK0pOmGOrJm7O55Fq/lXd57Lbs229BYjw8z21cJ3AlmB21zR3p1GRrJhZCj4OjwOfw0/B274BPwSJMEfwm9DJfw8fBPyYQr+X3gJnoa/Nrp5n4WXbmV9BdALhfBjJ9JSyfDP4Tm4G37VYPqSoBRqoOq73jVQCVfhSZBmUT0HOyeKzcdiIelZn7JHmWwv2RjhMNbTGA9EtA1MvazHAY44OQ44p/gMruIEx7k7UFZtdblEJm3RNdHsy+VJfpIeomHq/AXAQbzIQ3iAl3kikAJWjqva6rVEH13i87RJWxgU5XSZ3oNRukgPyvwGoCCtYAeN0j10hX0cwQO6n67hJ3CXotgrNfPigCbECI3SDlaSl0bpWqDKARzFx+lABPhufoKH+TrfsHM4TctFBcpwXSyyoAfxftqkbdqgAZFHICqwK9AqN+njtIZB6qQ0HqFV2uM1ROpzQrKQEGMiDwXtO+3hCoygLr0nsJOHaRG1O1tPqivPKrHeOOh5DUlAgszkbipkRBGEYJMcdUpsnY3lMOOaGBQZNpxKKnYhlLqJ5Axdx37yYlFYI/ocgnKXx2KLoD0V52kOGZfsZlHG7e1JFe5+S4ZohGMtOQzhHI5789nP5/gSh4h4gp/AfjsjmNEH/xmcKgqJMK2SpnRp/vO2GLZDgjjHgXlXNMMp5Yt8L7ZzgMb5Oi/KPKeVOAbtEGjkPh4hLesEoVI7FkjnYdFPQdphx4EWqLRcrkJw0mQf53aDbHBsWqcLOIxVAgJQ75lw1wHX8CpNBWrsNBsQBFE/Zoo06g6XBH1SxK3cdyfoBVwAWOG8HFbiFaH2VI8KqKBqU+fVgGpTqEjtq6jyq4hqUedVp2pTQoXUgRmTKqLOq7CSKqDC6pKRZ4qqoHpQfVa9qD6tnlVfUN9Q/0F9Q/2h+nn1l+ovDYzlZ9Q31J+rb6h/qX5V/Sf1n9Q31O+rr5jjvql+W/2e+nv1/6i/V39oFsc/oX5KfVENKzReF7r61qyChnMxphpUXDUYCHKzksbVY9xwKlrUlhpTXiUN+2JEtSpStjqvIsqvwmZm/WZmfDKzkBlLKL+yzcwiKqACr3ao61/9y3cW9NbhJjzxLkFWdPg6Df/RVMQ74X9BM9yAn9WyZfAH8Efw743P7u/Dl6EA8uHD8F8gBZ79LmmprxiVFYA74F8aytrPHQM14QJ8CB6GR1/3fhzeD+fgL+HPjDbzNozd3j2+H5I+3bIqA2hTnV0SSeMm2Y45GMEyBdSAp2nCl+EHjGMP9YgB3pUhggbXCFCnmMM+XMaEnKEppxY3aE1OcYR0ze8KP0thglpPh8sLoTq6W2cqvCV7aYuv0pADdgLv4yu8JhZpiOvwQX6EdvhAtju9fJ6bEWiU349DYpWmxSyu4ZwxB5rnBa7DMN3gG3IWdYf2Ep91mnkRp+kcXae8Zk/AS/Oy0ZvDI9zDd9Ov8b2ckJMU4V6Z257Ck3hOVFITLtohusIP4gp1T7ppnM7RNsaprNKFubRFZ6mKajgoWiShJl91YA9N4QKu0Hn0xqHx20HPdZuajXWs81Vu5VtOCrVTkxRsV2vntU7ODIIvTTZTT6BJAFZSP5do9gLmBcqR+W66RCKagYDV3Bvy+K1c8FvTQGnU7lQTMOMFO2K3yphWuZNlvCt7ZI6Tx6U8RBuaMMZ38xVhA8gQlwvkMgS7gELUjnUYpUXMl1BgJSwkXBTN1Mqd1NKc1AtCcB167UaRjOP0XtokQQk8I9qwOJyF1XKVRx0I5cuhkBdtHMVzzRk7Lg6J5r+DKleDBVYLYIUYlh7UGjyD+D5ctRtQ25lDI0ibEyNuv4ejmrIGlg1Yjz1OQXuGTDiVTkzWVkDIgjd8jm/7NeQCGK2YeXlOjb4yqi6qJTWiptSYuqRW1aiaUFPqippXo2pKjaoralGNqQk1q66oOTWmxtW0uqKm1IQaM2MzalyNqAVjp33GeE88bfRWfln9uPqC+hfqX6iX1T9XXzCSol9Xv2gccH9b/Y76RfVR9SPqh0x+uG0ESCfVvrqghtWQGlLrRp9vwpDPzqgRNa1G1Fm1pYbUnBpSF9TuyR3vm7EZM7ahhtWkmcW6GjGCppfV/Mlx2o9Dz2zajOmZjZzM59szG3t1Ud391d9wvaPl6Ci8Cp96F4PeAXwWiiAZ8uCPoR/uNSorWitFmWCWDX8KfwlfgV+A34ffglPwEfj0raCn63066L1Xf3nD/4CPwQD8BPwhdEImeKAUqqDyu97VUA3X4MMwbOp7c2ahnnqLkeFJf9EeJimDzLKVu3ifh+k0zQkfL9IZbKMgT9EeX8awk8SSFjAmvbUubOXLPCBaKc67NBUFLKQpmuQR7uUVnsCrfA/N26U+iCWJZD5HD9OI47DkDacOp3iNB2lVzPM8fQQ/L/pEN0nHy9d5Tou1O7V74Pe0p4pJvM7v4XWbxALOBDO5h5mGaZSDtMK/K/+Ez1ME53iKGtmhB2gYL/IMguOSUdq2t+g0XaaQqKWLHJcDcp7X+b20jEyDQkuU+uU6dcoDGscZuov3qI9BVpJWzRvnXqphRJ+oF7qeGZaSItglh2mRlmkPL1KFA7W32CyvZxKsQdgKu9mrgb7SF0rFEIUAImBXalaIzKrW+oLAhTyAguqoPSBEP2MUpF/GiKjTm9LsyrN8lgJOozi2NbpECkUwPegWdRikZVrAO3nJbmOSIerB01Tv5Io+UeLkEHOX5DhwNg9IxCh6ZbpNYtpuQMixOqwqC5MpgWOy3J/FUSFEtx3yQyAfu2Sc2jpdHCSMZjoJ2kQZjLAXtSHULq/TiOPl4gRQjR0AENmUoMZ6qHKVQqW7F0Sl7JJ+6mrLiybRCDsiLATVc7cM+l31rm7PHARrqJPQl41a0L4PqwJZHOEWjGBBtxGB/N7P8Qde3hbfWvAdk/bT1NYJGf/bggO5aufkOC1Bdbwv3+it6K1ThrerxeI71EsnFpC6I/uaBeTv3lrA/it1pI7Ut9Q31WfVb6pfVr+ufkXFVIYqUOlqSI2fLFYdY+et3zoIHm+NGsEBzy0LSDBIPOdkbNxYRer3mlkaH2/l35pF0wkCcfu22RafYPd2jo0sX819Z8tbHfRC8Ap8+UTN7t3R0/tpw3wthv8M7XAXfAVccAp+Fv4GfgMqIQ3+EzwLHTAKQ7AHKfCxk5ret6Wlftosb3vgV+CX4afhP5qQfOpNcbJbpo5nmRXYU6a+lwJJWvTSvVH2qWgCw+QVdVhDvVIHMpb5uIjTdrNdLW15B32RLkkdBHexHpnn8Qr9MN+QUWqiUlrBCeM2NrLsukc7yQ7zOh84Whr+gl0lgcL4Bb5GfTJqN2Mr3ycu8C5/lM/TBHVzPTu0gVtOhE7LOWeG78OpMfC6SzwuS9TgR+kaD+G62MYpf17cQ2M0z8vUwRfxLr6XHhQhjNMifoCf5gsc5Un+EIWogsZ4BQnn6ANOowMclBMU5D0ap3k8ECHUDm5z2EHrsj4EOMmrdI3WcBsHHM8CUK9cddq5QRRzA9nCZyPbHMQOSsh+nOc1XsNrvNGelvUa9zYJyqEVvNBwDCpKcmUkHQDVYdR2hFfmYq9AAl+GIIzJegAF/0Zbf6c65bJLVz5Dyf4MjIjMqMcH/nK6wcNU0AKtbq9bpHKUvAgEdis6Ig3LqY7beJZ+Fr/Iw+TDQrawRbb4gBwUXk8YZAnfK6kVKA+n+XI4uy2Johqe4kuWVorVDWWWBF+5iFGMWmyQ7Xwnc6FHeniTltug2iVyqI9LJgETIiucKuqQ+BL9Bj+lc1audoqcXNHhz0Jw0jhO9QABjwJ2O7XyLC9NQI8rTTsV210gWugcbgq/U1wHzTDr6gCZ6SAlsK5Oa/ENcqudRxoQHY2ml7pOnqPn5Dk2noCzrLdtxZXuAsisyHw5R6W8kqU2jMRSnspUp1VQpapsdUrtqXqVqnKMKJNXpaoMVa3OqHpD/jqldszRxzS0GrPVrPbVjJoxWdUL6i/VH6n/oH5PfVUdqv+/elV9Q/26OlL/Ux2pP1dfU3+v/l79g/pz9Wn1a+oX1D9XP6s2DZUtodbVvEpRbSrPAJiTVIFKNv64yUYyalbFjVdHksn29B1nq1WVUEmqSCUZZb0klWvoZVFDQ8s3Avf6uAx1WrFKVVmqQu0dU85UimnRpJ3MrE5zOV6tV1e++qrrHVVKa+EfzULy3Qp6m/APsA9l8BL8V8iGh83y9FPwF9AL/x5+EQA+D1+HZsiCj8FPGNnbz70u6P2iCXppUAXNUA8fha9BFaSZvq/ne4iIuo36x3EdT/86LcAHTfFJjyy5PuvbDo5RgoLo41la4U2nC0uZqTSkoRFVNMuLVCkCtIk9ThbpIvgufRGv0xrHsY3Ocrfopx+lj6FwJF+gATFA+zQvQ84Q30v3cw+9gJ8j3ebQTmNIO3hBTMkSukYXxKkuKAc+R9t0D7+fHTnJq7xAbXvQ6HnWom66D++ldVHbkcan6THs5xDN0Bm8TNv+9HAh3eBJp47O0AYO0zQtYw99iH4Z91m7c0zRFC7x3L1WJJvP43m6JIJhEA0UY5sW+GHatlt4nWc0KFsBR1nQKs3iDva2WpyisxxucxqoWQhi0t4WCeolzfHY4DN8L0+egPGW4A54AO6GO+A+uB8uQPc0pENzAXZRt93mnOJu0SQ1Ab8DBWaFoBciENBA5agTEuWcL9vIT1FZ44eop9stw9zkVFM3NifAC8SOvytFlJGPzlCMwhQMNNuIl3FCEi0xiWZqo658oHqK26kxK64JYrVaDJUSWM06+42yl9qdIk0z1CorzeC4fEnSr9vtFGF2KmUTTeOcprMFS8GSgKXUO+a2i0QvN0gvD+A0CT7AWWqiAIVJ+wMvUR3ly2yOYQlDIJvDIiKrZIRqKqHPE/JgWEohuMqfw61OVEq7NtcdgqC2nKwQ7dQuMrdcnKCALOUg9zpOHRiHl0W4bp7jdfMc908kWj0/QKY3datpsXZS7k9Tq7fGNk5yvoLbmhtrJ/8Wq40Ts+8Ctaf61YCBlbyovqn+nfor9XX1uwa68i3139XvGFHRb6n/qL6u/tFIyP+V+qz6DfVLxuhxSJUpnypUE2riJNMLGXqZZSy+B04+rcc0LZJNphc9GZu+JS01eWJKbqklJU72fls0a101mH+z1fqtRsaagcToRsbmibSUpc6900wvH/4R/vhdDHpr8D/hz+EP4K+NjNRT8BI48D9Mg2HKOHJUwG/BN+GP4W9g04TD527h9F4TEb3ntrbK3SYLfXOc3u083ySYhAfhLvPHei+09KZzuxwWQouGimEZ5V68Q6yKWukT3YjUyU0MfIq3cJRC2EoJvEbdcbBLRTufFkhFtIXbWpyKVqiTDMIPSTrcJxbpRfo7/Av5IK1QN0pu5QnBcgUXaJj2uBc7OE14eZnP41owHad5wSFnmndlmR8k0900RCu8QBtyGNtoh+7BZrR5j5+wsQ6kB0O0xfO0j1PtaTiO9+EoVdNF/GCgFeP4PK5wEz3Kj9EQLWEPEp2T+W2A03w2UCDzsdtJ0Bo9JUd5gaZIYJtsoasUFH5qZ+ZSO49qJTLbAdvHRGGKUw+N0jjO8zbeLR93OmEBHoEz0AF+qIVKaASGcbgH3pMa7mrDMRKyWca4wJtKEWp3TgWMv1OwhIliLKgskkRG1pMW+FIwzbYUEElbgAQni0PYo+eN0rCAT8uELKYi9NiFOIIzmOoDkqJLlONpXqIwDgVcCOQRJRjDMmrnNRxOc4VceDeNUFPA2+IqsVpMm78Jml31EMzCiL+S7uY+AruW1sSM0xBslU44TXgIZA2PEuJ1u4PqaUScIhBeWkZKJNkZdjFX8rI9SUhSJnALJ6iLmrWuciiL41TS4Y4CI7/HbtQNijpwsmU9hrCdW8LpOvDZadRC3aIlDNLHYW7ADqevvQoW4GE4Cx0QuPUcx+AGPGhQsUlv46+twwXQUdH/8oDqe6VX7akp1aN6VJ+6oOZUj+pVQ+q8mjZbmnMxqnpVjxpTF9SkOapXHag+1ad61KS6oMbNcSNGq+W08Z39hPoT9a/Un6jfUL+g/rv6W/V36s/VL6p/UH+j/kH9gfpV9Q31TfVf1R+oF4w/7i+pnzTtCF053DNNlX7VYwDS+rO61Y7aUt3mDrTce7fqV91qT62YO+5Xu2rtZEyzSXrN2Dm1ZMZ61Jlbs9B5qD5jRJ03sz2eWb+ZxcRrM3t1UF3/6p++s0wvD/4O/r3xoH13gp5WWemCgRNPz3KohFOAxp/MBX7D/SiAPhg1WwDVUP66qkedAYu5TsTgy6HxLcKx9R0SBfpVBVHohYDOAfeAU4zTxBru8ooTkh1YIzLELJ3DOTHPExXg5PI89cop3JZdNCWm2GO7IyCaaZU3cZNnkiHmoovU157NHTiFA9jmhGkEd+hn6DN0mZ+lBep0WriTVvEM9dFl/Oc8YzfgGD1Oz8su2qN7eIqj/gLRKiO8T2ewgd9PD8p2TPAWxnhUVESBInSB9miP7xHDNS5hiWy6jJdkK91Hj1ECN3mCAfP5gC/giqjnfq0Yg0/QgxjiHeyls/wRmmHEkAYZ+714JzdjJQ049biEk3wdH6U9WwNosqmCmcLoE9WBCvZJR5KQ1O5oTZkhnMdduSsfLfsa3ICm77IQKICelE/VvbdXK0yHw6ncQL2iTSRrw0TRyO3czg0yd8wVhl2odEdcoojj7KWYk2yX2N1tWbJKIvqCQb4fH6cJLLdzqImjYRdBAJxW0Y4DTh1Zfk8wiQg7KIy1tC+04kohAsVxXHRgca9ll3G3Dni0QOM+N1jFVou5Oa2CW+pGEKfEOWKWYgyDgXR/ErfJHpz1l2hOCDt0jqdlOfbZcbuqAgJJTS6MUxdHuQh13n8KY1hAueSjA/qIXLc1+MfHOVhLCQXYICJkU2TOlXCnWL3gBSdFlkgbOxwZKu4EHwQLnTB1BLLpFPY4wuku+gK8B5q/6znmQTd8wji5vLVJw7QLYKpi8eVlNfvKjKGSTal5NaUO1KqaUnNq1jQ3ptSCmlGX1JJZts6pi2rBHLeoLql5c/y8uqjmzbJ2WV0yLY4xtaAuKL9qVfWqV51XLapa1Sg08N96VauG1a5qVlWqSg2oPSVVv2I1bYLOjJpQ2+qcGldLalLtqrNqUi2cBMIJ82ln1Y7ZO6bOq23z6ZPqnOnaLpkmyKaaVnNqSl1Q62rc3NdFtWJmMWW2ptXMrZnNq1l1WS2r2ZNZ6GNmX11Td331v7+ToGdBGvwJ/I1xZnrnoJVkk5u9fAL2cn1P2LL7+2Tm/sDcW+2hV+0i8CfTFN5FoxzFPepzmmUQfZQrS3GeQjSNT9Al6e/0UBPdoPN2ySY0gCzlARxAok2axCLRS324So/zaVykZm6mGI3QQ/R5WRpL5Q06oE7qxR3tL+srxQs4iiF/o5zn9+JpPk1zfJkfp7D0EYoYrdMP8b+nL9pzFBeNHJEdXIaDoooTzmkkmsU+vsYOA2mJq7twj320KadlmPecNuHibnyU53hc7NFMKCmQLs5xF9XSMs3Sk/wICtvLF+kBHLHjPIIpWEHeWovnaQs3cYTO4ZhoxWJ/WluOXcXkRIOt1Ig2hTDMCaePRsUyLcn90p9LWYGMk+fovk2YX/+VNqQ9VnHPYENLOYVkjHLCYKfr/q0IiQpKq4EuAKvJqoJPAHooyKUREG20xTewj4IY5LbgKe4UHSKXm6kzeIqDnO9AsRvjHAy2SA55qqxy1yA4SXRJDjnN1BTIoCYhUVtlttoprQbfRLNiX56SPTwj0i6CY4JeHdRBilXrYpBNvMW15Igb3IKwZAHIDJ6iD9CIExClmE1IjbzP/aMQcJe7msCbTzGuw2HZEII4kFc0cTN2YAEV0BS2UQUSh9mhdbyBo1Qoda+5Ngi21WQlub4KMQi7RRa1cFy2i8plGHVxLXX7W2R5uD3npaTNY01HU4Y5fobuk9/NBvgATL0NnlGSCyCpIunlJJX6SpKaOmFfZKh1A+FNUoVq9YS3kGI4F5q/UKk2zFiK4TKkGGZGrdo0aixJqkZtqXTD0qhS60YjWSsibxhiP6gytXCypBTG9xaMcvKMcZ3VS9kJ41frUd1q+oTfoTm0x1sap+cxe3tVwgCMPWrGbGmtlBkVPxmbUxXmTrLUigqd3Of8yczS1abymr0lZqGbZNRiNlSemYXmldTpub6arC68k+Wty7jf/hn8tWkVvPOg5zYtiOuQf0vV7pg58dq2+2QZ++0G/ndLCrheJzng+r7D3jERzlz5i+B3mYJ/DHc0XwJDdAWXwnkA2IXtGJVXqEs0INE8nhdLtMW+IPizcZnnA8XUQKs8yR+jR5x2vTyms3YDVWMMY2KJP05Tfvh3EM3kCVriVdrlZTlPV3HYD9TD12iWSystPo13yyoswLgvT7ZhDJfos/zD9DxucLvjkzbu0gpP0GfwNM/RQxwXkg/ws3QXncEhGsd+rKGiYL+06Tyfc4B7+KO0i93YL2e5AYEqeRm36E4mTOLTcoibxAifpTUO4CKdJ6IF3KB1HMR01Ev3QVltKnjSaZSlwSJukyFkh5wQdXAvD4uJ8ETpzybtTn4v2VYTAlMBapI+VrLS67drHY+vgIOyR9rhXNstQfMmuuB3IQJBK5FKfbxDJKPcyRd53yEn1e9uBGwWHQWWhIhFObzDu5yEILsRRQ51y4IQNFi5lh+cQu7AS7ymOdFhN/XR+3CCJTf7krtcHBboZMk7uJ9KRKdIjxjpMD/UgXCR9q6Ih/O0Ox2m0QBVxUEWMnKQDuguWRPTqjTZeINmOCCTbavCqrDiQD7BlCkHuBWBWvFejGCK1C2WU3LAn4kWJ1ERDvEdtIRhDGGHPE/1xS7H0uq7A9pCCqaBkkMVIsbd2ILJlBrgXm/6h62Dn3rD5wgANfAM9L5lbU9LS6VVpL2cpdxGWqpOuVS2SlLbShi7nTy1qyqUR+UY3kKjcqlU4y5RqZKNet32CSNDy02VqVTlVg3qtPGlOLbOLlQZKkmh2lHpxg+j1dTP8pRbBdWmylC5yqUSxhioxAS9ReUxgXLABMICBSpuerY5pis7bmpxmpsROTljWvUZCLVWVImcMDKmTW830xDnHGWpdMPNKDthc2wrvzENKlS7JohnGxvzajMz3bapMNJSZerSD66ychxgkuBr8A/Q8q5KDlhvWyfFelNFvR80HzQhz4I8qxG4nmapS8SEjxN0BXsoKZJDw/w43SVbZB95hf7VbaFRjslt2YmrtERX+V6hc5nzFNGac1jP604v1+El3CeJfjHA+3xNZlZDoVuCTOFFfpR2scsJO/N8mXa5hzdo0QFuwA0ax0F/Ky7QGQ5QB93LZ2wXj/ED1CeltzCYymO4LHw0xHu4xTEk3MAv0e/RgRQaTEPncFWuUSd30fP4Ip2Wp+W+aHayaJh3Q9nBUr4oBqiXFxp1nnof7bdls2YDo99NRBNyFB/jGVqkbTlDk9zDyMmY7i9ymklizPZhPXtZypDTLrtpJB6vfzz1SV0ieyPH1mQPgKcr+xOtlaF8u4M7uNGXLEBX8NCVSGrPck5RswiJBE3yHrZgUUcKx0INtiU7iQHsRurxemwo9zgQzqIO2y+GaY3rbBeFsbkDGl0AISsDnBDHqAM7udGuxl6ewaZ2wCJi6sR1GiQXFWGX6KAWkrbPa2k3NAUNFoIvjyKiiYLchRGvZutuyUkZtVvbUoWLemkEo7IAg7ID45igqiCQlQx1wBYn/OUtLtGh4SzY7vhsSLPKXCHd5hqKpIpsHOaGqCW6/DUtaVhGXXQBO0VCCqzxF7WlBT2DFmvJCgjlEWG3oOGk0qWU53S2bLneBB3bAY9AwVskGh5j9u1+2a08r7jUrPnj18py2g1NbxWodVVrtpKMObbLWGJvmbEkIy2VZOy3qwzRS++tU1sm+LlUpVpX+cYzzVYbKt3sLVOzJrxYKmTc0PSYVHMmwFoqoqbMuZbqUdOGcesy2igulawsNaZGTizGB1X85IxplTDXSFOzqt2MudSMajF3rJswQSM7laqWTmaWYrgm+owS44bmMpxbDVnRd1xxMkfPq7lq/51kesch56fgH6H9XQt61uv08L4fYalvyxW8pqzn+r4bLLeOT/YsgFPKK2KYuoREH4ZC9dyBAyhwTp6XEV6ikW1NnW/AvkC27Jch9tEK/yT9DO5L4gFk2YYtqG0JJ3iXnuceahZ7OEFDfC+TF4qtaqvS3eKW0/wobTsL1I2ntbeGHKQzOE8dtE/Ltg+n+YCFM0AzPCoPuKIBmlPELC2wX4RpkvZwPA8E8znqx1U5TitcTl30uEZ9UQ81U0ybGNEgfph/m29gD5+lq3a/8NH76Au0S4M4J318hfZxSG5jJ8VlZpNbxEQg4qZ5sRADGeEi6nR65DSdwV3uFzZ5QxWyOFCIzRiUjESSotjpJMJjOV90+fWa6g3TD1emBR7XxaIriYC3hOCX9FI0HQu5kZij1M4xtKmiLR17ZLmEHqBGGYq5C6AuiWycxi63pcWAm12OWwapqiUbJ2mSfYgyjFDtKrXqrHRtATROnQ6IYrqXxwKnMCqywZhNcJCWZZATcgkrAtqbwuHuYFUYCqxKqw7akrXbBobsYtDqLwuENCQX8ZSAOndC/4TRKafrOI9JdilNyYg3iaHeyndFIZJO/YF6juKqiKBHM28TFlu5WmBAO94OU4VuZnMx9nKGhFYXhjlQlYzN7HCcoxx2/FQZzBGp6HGg3k0t4fbUZ3WrwuWy3uw31IKrprL3Zn9zwy6Avoqxl8fV4CuD6ryaVf1qRHWpC2pW9RjL7gumLTBqmhZTxsJ7SO2rEdOyGFMHakQNq141rA7UkOna6pqa3tevxtW+sf3uNrLuPWb/rLqg+tSYcUA7p7rVkOpTS+qM6jSIu2W1Z87tVOvGm2PcNC12TPMkbnx2O9SI6lM7as2cEVe7ps0xrHrUnlpSCTVuGhlL5i671DmjpzxiZqFzQj2zAzWjetWgGlT7aszMbEAdqEk1dDILPbOhV2fUnV/9m3ca9L4M/2g4se7/DRW2txOirNcJiLre4QJbl92LIT0TFty4hOvcJbXsUcDJkWWyR2zTDk9JEMU4TwkK0Yg8TTau8RY2YzvdQRMyjwbEKm3TGVq1C+mU3ORhnsEEhWmB5vmy3Kfp1lSXBVZC84SCvE2zco86+QN0gGmYQz3kF9388/Ql7uc6AT6gKTpDl/kqcqlrwgUg83CQeuUgj5LkebyDl3GQ57Vrhb/AAUynNd51WPbyMOXJWbpBd7CNAXovDWI3R3CMtG33Ht1NfhygBWeOfwwfwBlcl0vyLIX8Dbwn7+FxWqYw19EklVE0UCFtidwpSkS19CNT0PFhPbUIG4McCXS3c8PVlA9AVgyMD8YbFZk8ACnDqfdW50WzRK30S014i2FA1mORP1kbX7eARIkhGAeqwS4nvdjq9DRoF5It7NH2lw3uJuAK6aAPhyK5DBTiewgpDQEs4QbgHloSxdSCHbIVIziKFS1Q4w5b7NMsGJ+LJ2kZg9zIGbKBBnkB88JQ7damRLxMEX8+5WmzIz7HXgKngLqxgMDv/m8aUTmAfttHnaECtmmbqvT4ALQA6kbWAeYiEFKCvKitHi3NAQtU0AoPUcqyy/H0AVfLLicVwEmjTlFEEIUVaMkMlFOLlNyB7cjU4q3sSMtMpD6aWgCQbFlvzoTqgxum6vfGh/WYoDf68pgafmXIiDhpCLDmZiwbPsSEaVAMqUE1oi4avsOgmlYHat6Es0F1SQ2Zf+dMMBlUQ2pWXVKj5rhZdaDGzVWW1YEaM3un1XlzxpDaUBdOxpbVhZOxTcO50OfqRsZrYxvmqCHTyBgyo6fV9snnnlMbZmzUsDSO70mHbn0NzdJYOznjwm2zWDRjulmzcLL3klFwGTTNjTl9lVfH1V1f/Z13GvQ+Ba+c2NK9WyKiHsOW1VdfgAOwIPVEY+U1Xwy99xibvgzTt4Lccb1jBgbNsSkwDefgLFzUFfI3dUNz35YbagGCRbgTbsD5jEikX17Ece6U7dInmuwgO1pKUk7RCiV4iVuloDvwCV7mUe76PY0LG+Xh9vQm4HQ6S5dtxCoaxyf4LjnO3aKY4zRsWAPPMAuo8iRcEaBS3uNtU+95kJecXJznB3mJa2iX9sUczrGXgjzktPMg38/vccoDwO4KdxCwEa/QlkRZLGfpJ+l9VGLX4y5tclkEmiyqxFWOyHq6Hx/EhLiK92OKSKdFWuAxvpPO0NQpsLVl+CgJvoRxfzFty3a7L1AlSc6KiLPMD9K8FHxA43KKz9I4XsAF2uIVbJeFogLLguWyCbUXhcMsIyKRCJY9lbbqsoJvXo5w5wFUZD7YNBULUET4qCyQVgDaY8IHJVCb5AdZgr3hND/IfGfAKY1Ac1IcZAV1iyS7moadMgFezSsZwpDI3IWoG1kGkKhdlrRYNtjldJa7KMLSyQ7rNshluyIBVYAt1J5IllagRkRsvXQNakYHS7nGUwmPgGAV7dCo0yqI4ujtdgWzZbcGwGAFdWBuIQSSuIfOT7q8etEa194kOE5uAXaqbMEO9sqgqG2EXW0VGeNJUemATJIkuv3JTi3FRIqGK0tgdNoVDFuyUSaCyQ0er+sUtIGAMrjfCuZgHZOI9rSV3JO0Cp7GN//CdxuMwQ1TVHK9TZze5C2OwvoJTi9Vrd2GcCu+pTlccstkEU5ECDZOOA9lt1gaBWr1BP/WcgvPV2hqdceNjMUT+0jbWEDqNxt0nn533NpiU6uD78Dp9RlMHpg633fi9MBg96pPtpZvw+kV3ZpF4y1N6NJbOL3MWwjE4hPl5AvvfHn7OBwZ++GkdznP092qK/Ch1+V9375bDZP5cfjCibTU8WsW/qehq1lQC/8Z/hX8LPyuUV1xv2ku6bplI9kEj8F583c4nPp09c/JbRzlBKL0Si8VcIYs4nk5wyP0LJ0TLRSj9kgyF9MOz+AQ9Tgddl6jK1s7XS2hXlT65aKYoDzjNnFFm9LgGl3ju3gyWOaDSCp7cJseoWFOYB2v8HtwkE7zFerCPloRpw5AxGiMF2mRuuUK7/NpGrEzu93lEMyXCblBE3KLL+IwN8te3uUzMkwjtB5M1r0gisprco0EbdCW3OFzHHVA1MpLvECXtZkQeSUEcumMPM1rGG8BDvAoDVF/CALVdD5UYQO264UZdfpzsEU67MUhjOI4z1EEm8hGP+rubZ1olgLDoj0WLfxwShgg13oriFOSO+W9GTGEXtAdzwFYhS1YgQlQmsyfhN2h3ASgxw5zeQTYFQF/McVjqXkQAVGIvVQkm3mL/BHog6gWF5WO3lOGndRqp9MqXxROoDgIHUAZJEUDMRZjFUU+AgNAmdgRyAGYBAfsZGxioi66ToNUxge8zQ7ZdlkDhOBOaAVuQwZoByqjSCST/LJFeoPNfRDXYaoeB/Ee8osciohQfXI7hNKooy2zA4LQnkqjYl5mM3E0DgBCc7SdSFIPBK0AyLCo64IeEAEMtEE33AUrcBYuwRQMQBSi0A8FkH5fcidAofWW6xs33GHWV2/815thGBlZL+ep1FdyjC1OsipWWWpXOSpd5RtSmWZfFKtUtat8ph1Rpc6pepWlMlSlOq1KVIbKVjXqnKpRuSpT+dSeylTFKt3wG8qMwbZUuypHFalkFVCbKs3wKyKmCVKkUlS3WlDJpuPartZUlvmsETWvktUplaw61Yy5p2Q1bSp+JSpdLaiESjZtiFk1bPwustSaYWSUqWQ1qzrNGdlqW0WNz4cWyNKuHiUqU+0qNjMrV2fNzPS97KpWlaFyVI06q+pUjsp4tfmdMTKO629PwpH2rn8Xgp5lvprqQcKu+YFa4AUfFMMo5EMKpEKfQeflwQpsGnAVwCfhORP0jsEzD8E/wN/DGbNnDn77xLsj01xX6668/p1iyFLhW/p7OSdggBNsWdrz9Q9HOuyYcETAadR4WJqSq8EWmsY6Ucmb1Au6CI00hTM0ymdEqAw6wZtO6zxDrXIcL+JECJwqniaWVdRJW7TKl3gIJ3kXGyVQnD7H52hABkQPz0o/nscpB2SM7qOZcqgDYj6gSgk4yis8xwm6l5baIFhJ23KYUc45bXIWl23AMF2SlViLHXyZZgaSnWrsx3Ue5TLZyPcy0gS9z/E6LXwnnaZGHqEpPMtBGeBt7uVauptGG9NxiHvoGk5hOw/wOLc65XKdQ041zlAN94moE+Me0cPz2G1XiGpqlG1sk+QgB+0wRaKdeS8k+QEy3qLtlO0CcN+XvxavCQg7YPttn/Aev21/oJ6meRFbRJNYFPNcjzY1iAjuUbtoJL8IcJPtp3PyBVq2qymALULSWWTRJgLUaNs0Qo/Sj9NsoEk0UUA04Sgve7W+3Z14gbx2q2iiFTEpaoU/oK/VSg3YJtpxhX6SfoeewH6hWTGN6BMB24ettg93qSvQGGiSnXw/blC9JNojEm3ktxulj95LP4nnKBFopFbbL5pwjFYDjRTA1kArPkxP06ho5DY7INqwkWZwMdDCbaSNjnYpEagWETqNYdEoAidz99o+O2CLgL+jLvVpXdFzu96Gwved0Pl9ZHrTt+VD3yvTK32TTG/T9Fp1prd5i4+7fivTW/+uTM9Wi7e2pk62SE2+rUyv/3tkejOGe3uc6dXdyvTsW8zcwlu8ktcyvY1bmd666Q7fnuklvxuZ3hPvWtBLMgvWl+HfwO/Af4XzAPAIfBwK4a/gISM68A/ghUr4XfhL+CP4U0iABZ+D581ZxwvTD8Eu/CLcd8LF+DN4Cj4DM2/ZAb5s7MpNFcSwOZIMFFqH0tqizwd70aFWp4lrZT4WUTzhYduubQLHy/3ci41Uz6ex5zfBCeC0iFGUdevjA9QvG0NZvIkzFMTL2F+Xgl5sF5L3aAWD2E+X+CG8wD9NH6Np7mbEHaZABa/TFi2IQbkqV+UcrmFPkHGJTnMHz3MCHVykT/PnxENik9rRy0Q3eEeO4wfEaV7FaWpDh8/zz8sPyz3ZhZM8x3fwY5oMR338Wf5FPIMjvM37dIFG6F7+Gb5Du1LQIPXxU7RKgzTFB/TzvCnKcVBewC5kvsTj1EtXeAD3nFlaow2a59PYz/XB+lCDbLMFMwUxSpFoPOfjuo2R/BZ/rFkm6OUuxirsJmyUTdzEjXaDXS8aRQV14Zqsp3IewWWulo1cxSHeEiQr7CZqFI1c4SDfT+/hMdkq66kZNylsV1ML1VENtfI2fZ7O8RCLQAXXksR1bKEy6sA93ELEChqiBVGNjTq0iQautqtJUJx26TP0eX5SjlGYWrCS6oS+o0ZZjYI3WdhVNEQXcIlbsVJ0ySVZR3VYi51iHD/IH8NuqqMq0cyNsoanaFhWUzWGeY2e5DVRw7XcGGjEBlmBw3LJqeN6Wc3Ie0hYLmO0hi2ixm4U9aKBG/VzEI3++o6K5A8Cv2U1+zjo3fUWQa/TBdBdMfzyiBp6pV+dVTNqQA2Ygv6y2dLNiDmzNaQuqWk1qAZMTW/OjPSri6YlMGCqYdNqwNTFLqlhc8aMqeTprWXD5jhuc5wzZw4Y9ZTjMV3TOx7bMEaS+owtde7kyutqzVx30Ci3DJj3jto8OeO82lADql8Nq3O3jc2asVFT0zs+93hMz0zX9AbMnVw0sxg0Mxszn6XvWB83aGp6v/lOM72n4AiW3pWg95qe3gHUwofgb6EQHoNfMRpPfw1PwH+D9xnu7e9BDZyCz8MvA8Dz8Klb3NsUc/5Pwf3mWj8KCr4Evw7KBMECWIUbcBWuve59B1yGu+Bl+HFIBzdswvQts2oLXJNW8qd9iyFBEgX6yYc7GiKCq+yldd4Wftbo+5+mq9ggpvgMtZLAOfw0/QodsIMtuEuT3E8/Tk+yH8fpPM7yOdzhMEo5zHvyh/m/0+/RI7xKYRyRM9KmC9xFG/xBukADcoLuFPfSsFPF5/gG73A71aMGJz+EL9HneAUTgQb201nWQvCncUW00JDsxAROOIP0DD7ghLCGlnmLemQXb4sJCtM1etSO4pQM8hy+DxMUo7t0SZ8GZT57tTsuXaYZEaID8gE4tTTYWiBzuS+Y7T9FCcrHEDY6QRmlcZohL7aRIB+3YhsSR6g9Fin5SFoC4NRbLm+tpNQHc7uzoA8YAuADH/RCF3SCP4kiWByEcB7GI8kaZedLoy4uldAIDtRoGloRT/BQYxL5qWsGsFoIrWlsgwTZwFG6KuPTlmzkDqcKtW1nC2pf4a7WVFGEMS6geCDVhlqtX6f5D7kccBh78R4RESm8zWfJQaL6lyAIbRCGFi0E2iR9WEsR9HAdxaNQa8l4MHsJHIkxX05LEl/gZaJgYVCrO4Odze0NlijhIc4L5dCmdAbdfkhAKxA0AaFEggZo1cqFIf0oCEVDEPogAe3QAl6wIQgroKzs96T0ATS9NVArGe6A4JsGPd297a8YfXlCDb5yHC50j7PDdG+7TAh5rcepu7cTasB0Pi+afunwbd3bIdO97TVOZwfm+D4TdHRI0QvUC6pLDat+NWe6t1pS4Du7twk1oRJqSe2edG/X1GkVM73YDbWtetWYsf45liPoVTtq1eSCMXXakM+GVZc6o5ZUXE0Ywx/dvR1Wneq8mjNnDBjKWZ+58r4hpA2Ynu2IoaP1m5kNncxsSPeZX51Wd371G++023kH3ISDWxLv75yG9vOQbcLUf4EE3AVfNmHoGVDwKXBBOvw5/Gu4D+6BX4O/h2L48Ov09PJO9PQs6IYZSIM0+Bj8RyiHVOiFOZiEqde9Z2AE1uF34FOQDB7YMEHvtoZM8ou+2SChsOs4D7vtDhqkXruY5kQ/FooCisqrtI4JOSanqcgu5yBeoA9TECPcyePCsXNpS65jgDZolAvRliPc7Xg5zEN8ln5MLmOIHpdrHOfzwSD2MmEd+5xyvovOCF8g284mSZexTtbQDQqQj4d4g5pbk2me7qEO2c67oTY5RnM2iALs5F7e5zBmBEBU0GXZ54TpHhp7wqJpvp97HKBs3McB0UWnaZquYrMDwsEJlEILOYGQdElexAkJenmLTT4I5uOEqLdP0Tr75RCu6YyHNugsreMOTVOFXeW0YoCJHBmmjk6n7NGULXD3vzFMz/y2ZAHUpz/YMBh1ZAcK2cSl0dR67ZoB5LC/28ICGgnkhyBkRXJ5mOoi0ObOd7dbvYDIXdzL5W3guANVNCVHQ6lhi0GWUycGxChuUnYY/BbmEotpGm8GrKIxWah/JWQl3kutDtS7glDlwXpKUETUSZuWaLDF1aYZNJs8SPXYhp3SCRRr9CC6hIdWaD2SuuiKuISgHqGJeBvUzU0yZcjlA5TaRQSjHAwkL2vfjTr9ZcQ5OhBTkPqpiyuaoM59yl0HLR5MyJCENqsHhI1RsJrSqEcW+EBACQjNcmlzHLu3x1t42b0DyYk3gemdtAwb4AY0vGnQ0zg9t8HpuV9xqTmDZnMZjoKtLOUyS9SaE3TcMYbNMji9GoN/O7aA1CaQxzg9y+D0tk9wehWmufG9cXpwG07PuQ2nN22QdpbqNcvgFDOWMDg9MDg9MHcypGLmDL2o7TCfmqrmVMwsxzV2r+UEu7d6IkKgxeSPZ5ZsGBmWweltqlozC4+RGdCfWmHUoS3leTXvneH0jh//6ZNs6t0JevvwacgFC3LgT6AX7jnR03sfKHgG3JAF/wF+FR6H5+AJuBdy4LnblJN1XS8Lfs7cSwrknFwzAn9rqnZv9MqHR6Afks0VOs25bhPK9cxai78gezBEyK08xIvUJ+K1bpJOgwMxrd2xwp0Evnw664xRi43OAN9AL4LtkTafxxkcl7pP6qYtGsFuXNYZm9BuEBP4fjqIggQO0AqfwzkcwEVax91QMXfzgZzmWtImOUQLcoLv4iVe1/aLWKq5C74knpIztIBjtMPaepu8pTyGOpPkKGh6lAzQRd6xHbxBT7CWBFizS6ot8vM2jtD7cIMm6Gyey+fhqGxAQRewGSWe1/keb7CgM3Se9lF7ZdxJUxSRZ1jLhXaSHzs5TF00JHawj20OsGBbsgyLzohsupz6lH7m1hsGPRckeZLAM5F5fzgjlO4vtOslc4SilOA2DFEfpkmwY1iF4INAJg1zSwUkrEyDm6SYiMgGGWRXsxusIOA4rdpFi8CEfVREFbhJogqkC1wIfjcu0biM4wgW+aAuqQVIywd01ni6kqRfdFDEKatPI5v7qd9J1ZCWauA6GsNurMAMp4USGAtUEjinaAGHvOntVq672pI2jaKDWxgKwirUuX0uXxLN0kggw/Zhv12GgEKep0aGU26ywjkY52oaELVdUO0qcaFp0nBI96kDHg4GGxyQTXIYWyiEGq8XIp9THsjtTi4Kpj3pLtSQlbcIesNw7S38plO+JyMj2TAydNjIfwNGRpWhbx0zMtKN2fdrjIzG72Bk5Kk05Va2CYRZylLNasXs1Tp5GyrNdE1jhpGha2nB78nIGH4bjIzkE0ZG4S2z70wDRD5mZKSrLVVmvDSSDCPDdcLIqDq5l9sZGZUaEv1OGRnHj3/vXQ165+CPTCt+GP4HNML98PMAsADfhOfhb0yL4g/gE0ZMoBseB4Dn4MXXSUt92Sxvc+A34WFzzQ/AnxoJAs/3NAbSmsrlt5ooufB+k+sd/yJlwidq3xPppXjAz9pPYZo3aYIv87JdSTYPoaQo5zNwFAdwhXcwwUvYV2+xhdprbBRHcZ8mZSnOUBet07N8wF4swajTjdt0txZJ704SQI10jbZohzW39xRt8ydkL9k0K09Rm1wgprv4DidAY3wtWOpAhbvCZYOTwqfFe2mL6mWmnKeP00WnTqQh0pLwS7C1NvAVuoFTJHkbxyXSGV4g7SR7P5/HRtlPXfIjuIjJFJEbsgW3+ct02Z7iHerCx2ibxthh5qlQbihTDgaLZQqFA4UUdwblBG/yFu7iOq6KxmATCnQ4xGHqoIHoSM6nrNgx4fONol4rWJmuG0VnOmxvS45bMyjYI3JkAfrwPE9Lm1dwlooDKSIVE9zogA/ACuvZxmWAU52eaGEYaj0AJO0WO5nXcE/6hAdzcYT6ZE4xtFp5Vqemg/koj6/yvJ3lsyJABdRBaRzjK9wtfVhALjudI7Kd+7FYQrZVanpXZMsOmeB6AE6SlShpkc6E8rCa5XnogLBFzXwdJzmTOuyCRg0sd5HWx5vkYBZ4s6gXrwjH8XCCigDSXADkx0AgHbudJgFKXx+aXRreghZlko93cRCJz8q5YJlTINPC7hZtLZ+DTtxJ/aClacgu15v1J9LhBvS8BUzs2A1Nc29TjBta7QlD9Zh7q93QVk9YqylGRPT1bmjrJ25oNSduaMdbr3FvVw31zKNsw8I9PnfOWPC4VVgtGvqYR6GaO/Exa1cT2pZHeQwjw22CaPSEe+t+Hff2NTe0+AlbWHNvv+2GdszHfY17q/m4x7NIM/KoHuOGtm4YxMkqWW2YcKjveNM8geRXk9T5d57pvbtBbxkUfA0egf9hzBufg5+BQvhb+KzZVtAIs3AIX4SH4VX4YdDk2C98R9DLga/CB8z/Pww34aPwcXjVLL2T3sQ797WGzHGz6ym4Ai1QDb3wPGz3p2E7dxHJVTojhqhcxDFg59IsXaYh2hGzopTX6QaGWtyygR+gfconCIII8ya3yVNynOb4Y3SD+rjT9uMdcsWRRDRI1zFmwynL72IIVtCIPOPs8WmOii7e4ipvuu3DMfoEf5K6OCYlJtOC3Jc9QnJSJ1S4JYQyaIfukgM0geOy2WnldexDR7byIJ8XufvA7XSOz/BMoMKfT33USuP0Al+jcbGCZ+UZvkpTNE1fwmvSb3fTGRylVXGNAsG4LPFm0SZOUk8URCn1cKFdJPZoVA7xFeqTSzyCYdJKyfN4QKvBgPRxQGrCXR+NDJ86NZH0ovYcfoMUxUpOAkgez32BT4kMZOpzOJzHrhAgsF+0hS0ZknMywCzjdAkXAmVUGEgNuihXJqhGH0N2HBo8JUCnOGLn2z7uw1GnWWRiN3ZRG8GMlW+FQORQl11IXXTKzpGDbHOyTGAXhUWQhmW/dBHYBaLTruYQ+rQPgQuKodGaAcqihKxjYhJuBi6Vs7KdwujQKFVjpuhjDnrIISGrKUhWj1ViBcFJE3HqlMipsptHqcMu4UYRFMkBqw2cVOr05va5RMQOYFK9y5cVKGQfXdYeJE6A2nEGi6WFnZzF0AEahyg6uIsanKSaibTPvNlzNL/vw/AgpL0FEH/KBTBRsfjykpp5RWuRrBp9kkmjsjJpVFZ0S+M1lRWtRTJjgMjHKisLRnJ93uy/XWVlWs2raeM7O2eutmrYHLNqWq2ZrUU1YcDJWrFl2mxNqCU1biDJx5opemtMLapJdVqdNdcfV2fUnpo0Vz6rTpszXlNZ0Yoq59S2kaX6tsqK3lo3Ci26QbFi7mrqZI6zZmavqazomc2Z/VplZVrNvbqm7v7q4f9ZQW8Xfh9egF+CRw3efAm2IAYvQaNxO3seZrVkDnwFfhnuNwvYPVi5hbFzGezecS/WbXLGX4KfN6p7b0ZF+05Gh87vFuBReAruBBs0LsviWp7gszxJU3wnDWO+NoTu1HT9QfbjHfyoHJde6sENXOANbOd0asED7OcmPMPjPCEpUMQbNCtmaZ1G5YTskvNirtxzCYpd7wVO4wj38DqdpxjN0lWaxnTM5zZa4gPSnd497qcZJlmIETlL8irkaPLWvD0vp3mXJnAaa7WcqYxSrvBRgs7jDVyhy9SJ4zRMu7RAKzTJffgo/wrfwyGedeI0RnMhi4P0BAWdAN5BYQkUkcOym5ZD6dxGI3Kfl0U5D+G9YoEErQsK5XF7oBqH5AydprNylVZoFxMU4DC2Y4dsc7ICtZ0i6w64btCTrxc1t05KBkHrieJ4ezDglckBD7dxF4f8hVSHnSNARdgrsggCbuqWOud1ZKfj4BAfYDulciH1gJUHCE0ujnOYEk5gDiQQi7OCmSOFEWh21bhiFhH7RULWaz5rOJmZ7+F7UMqiVQtBBETQLqeecAHXcVB62k+CXgM0uZY07yMeSyfksF1GnaIwDJTJVTRFD9O6XR4GhE6XjFBQOBrB2OIqtKqBmjggRnjLV+iAnUvdLKnPqdOliQhgFSc4A0twhXY4yhHsEC1ONY1gixYvoFZMBIGKuUdm282UkO32qa+AyPHHO9qStuEeK/1NnqOEJ3Qa/BZ0AN297awYeHlQ9b+iVeemVK9pR+ieba9pB2g9Pb3Vb/gVfSd6elNGr06r0+k9vSd6evq4CXWgBozW3qRhX+iteXXeCMjrvWdVr5EYXVZnzb9671nTWuhRa2rHXE1vHevp9Rr78F6jiaf19I5V/DbU+skZZ8ze3lt6errRoqWoes2naD2946ucvTWLfUND672lp3c8Nmg+4TU9vf5Xh9UdX/2z/7OC3nX4tVv1uO/Fwn0rgYHvpZL39tm31ushFiMQyMIp1mbcw04zBukO2qBsLKFFDmE/ztjpDNzKS9SHm6T7q4/zl+iGCOCEaCcf2qzL5Fqa6cMkJWmmBm/6StqtDFefrlVV8hSvUzf10VXRwqN0jnZ52AlzVzAzYImzdIaXeJxDJOwm2cf7LK4DzfJ7uJ9s1gvXAp6T8UgRT9IY16HDu/Rb9DKdY8GS1knILhzRPedQXrBNvo8TNEp9ooxW0StBLNIFDZHBCSqNesQAMV3kG9RNO3JMPsVnImlUTN1U1gQ8LDplN+7TBE2LXtmBs7SH++I8SRli25shMyVRdygjG+Aa3GUE9+E2aanXGC9h+JgVq4TaLApRJ5b2QQ9wLXbjNclOEcbtIgkimSLsc2DakhAGDIgFDKGXwnSZxmRd8BRmcjufRulLkQBwxZJ+nMTTwUQQHFeN1QDBYuqXnVwdBkzDcm6jAT4nRxyfzK4GDwyAPY3X7XSnXPZQegZoupjL9AR0w4EAa7G7D2SY7uO6EEQtxxMopyCv0ZaQ1Ix5de46cJiGKDTl8UGpOwwLQJs45wwG8iX06RrtKRrhbarAdKpkn9bOoQC38gBOihxhPoeTqVPUS2gAEsLH2bTs7JE/UEjAaaKFe6nBEPmuwr0nJsLf/RyD8BGIvx20xOuUk8veVDm5+BYm79vHWa9TTj51C6dXdIuRobVVjmWkStWsAiMzRWrxZCxgGBnJRmRq/Dtwem5T54ueKCcP36acHH4D5WQtUDV1opzs+g5GRunbVE4ufTeUk//3ZHo/DRXgOWktHEtIJZ1kc9+moXlO1MTc3/Vt57mlg+w5eX+/ggO35OSTYcyy3dyJMxTiKZrnUepqycJ8HKWH+Ipk0ScLbRC5HAnlcC/F2Idr+AK9B9edfpqlHdrxaTr9OZrlfpnBvXRRe2vxpWCeAyVuYWEyD8pLcpF7qEU00hPa7ZYDPCA3uYpAluMWXuZGhKYkrmIporxGT9DT9ILWDMY2p43P0pwQtE37hHKSBzmG56kLx/F92I/1GEa2U2mB7qPeYSuYKodplRtwh/ppGC/byUGHn0S2y+gKv1/GaIQ3HMIr4hz1cau/EJfI5mK7krc0K5U2ZCfW6OU2zfMKrdMKnabrtBhN9oPTIHuouR1CkO42ba0nIH7ra+u1VwOswRMgLUj1pFkMohJ7BHGuDYGAnZCtzhWaxsJQBtnsX4Rg0g0rkoQBCkU9rBs69dgrK7nNDuEuPU2zXC1LqIiSnEYn+G+1xvKALEwAJXnd1EPjsowzuA4jFOE27LdLGNDLfbJOpDkNGMcgO9RNJZnWKZe8dXtNkApVrojurHYTUZTDlMeZ5HCXU8wgwhhixAQiljalCMQ5rO2w6t2RZPTSis0yGfvsbJFGp+xTdoDuoCdxWLJdgz7qtdMSgICnuAPLu6HbE/aEcjCMZeFM2YwXcY4bnGFOR5A1FOcIJjtQ5vHo57gFj0GHXuZ+x6sO1uAp4wX+1gAx7ZGRUZ75L7K/lXyYeXP9qP4o+SjnKPNo58g5SjnKPDp1dPqo7ij1KPso9ej0kfco7SjjqOpo76j+KO0o/aj0aOco5yjjKO2o5ujMUc1RxlHqkfdo9yjDHF91tHt06ijzKOVIHu0cZR9lHSUdNR2tHqUe5R4lH0WONo9yjrKPko86j+aPko6KjpKOokfLR5lHOUcpR8NHc0dJRwVHnqPY0fiR5yj3KOlo8mjyKPko9yjtaPYofnLG7NHgUcpRzlHW0cpR/MhzVHjkOZo5aj/ymM/bOooeJR9lHeUfbR3VmJllHO0c0VHKUcZR+dHuUb2ZWfLRzlHTUepRxlH10d5R3VH6zdR/rPvW5V87sh54Z0FvF5RpHrzzoGeZRWzd2/iB/u8QEP2u1ymrF6iNF7Cf20Wd1I5bXZKcRlzg7WAjb4pRX44oF2Mcojk+Y7eITjogrwOymvfoKg5Sgxilp8UFmrCncRATwsebfI4H5QjWxjXXrY4f5bt5WEalV4Z5njuxyptMvTRNTCG6U8wg8p4c5CbRSq2ynVfoC/R1/izNcTsxl1EmJ7hMAjaRwzHapHVKkM4lFnHZ1sDfD9DDGOV22uHGkPZ5mHF8ooRmnTg/xo/JFT7Hl3mG6nCDHiCHu6mcgEdkD6+LAHXxWbwgZmQd9RCfAtnBEzxF69Qle2henGMNfenBWtJ81dwgBLVM0zFodhDeD3fBLETACy1gQy/swoNw1QjNJrkg12pwByHuZpujwRjFIvoZ91CrZNzAKV9KM/gA0znBYU6u0z3SDOoOZsYgkGuCuqBSGaAoMXfiOW7FDuF1MmUnVrEOjucwRM1OTAaxOgSiBimU0uphvfSM8xkeZEizeJ8GQlDr1t66344lAHXuYZDpfF3GEYLFvM1L1DzpPqd78QXBGLkxk1sohkGux1laQHC0GbtTl0L9shX78TQhRjCIjb5SmqAdqnfSBJAPRcgVSZJ68TzIrWEoh26La3iXx6iFAjgs0oNpYhSRE1jRpsOvK/u159hjjAvmIQpeaAUbemAH3gfXoPLtYmJdxq7k63AEr8DNlZtlN8G8d276zL8ZN0/fLL4JN62bcPP0zWozlnfzzM1Ss5V+c/umy2wV3jxzs9Bs1dzcPblG/s3dmxlmy3vz9MlYxc3lm3Az6SbcpJsbJ2Phm7M34WbqTbjJNxdOxvpuztyEm8k34Wbo5sBNuOm5CTfHbo6e7J24GTw5Y/Jm98nY8s3QTbiZchNuzty0T8Y2b6L513Vz09zd8SxazVjWzd2bJSdjOyfzKbh5xozBqwVHF39HvdOgdxYU3HhXgt73wgG6v8/93x6xDK/C/QN8pqaoedyuYq3EtknjFKEgxfwVM27qp0tyT046QNU0yIRb9BjtUC+NxZNlG81gT5tHJgXzeBPPSIeacE30hbJxmc5rxD5t4WkaEEgzdFXEyIMH9Hle406KOI1yhqJUQev0ME1hFc3SF/kZ7udaDsnTMmEXIWE7HfBFWUrzdCd2UJuwsQl9PBoqDqfwNK3jRbwcSBVJ05YspgHul30cpz2nA1tph+4O5ve7uJP3eJHWeZou8s/j/TxMC9QuciKA3dgnHbnN1djGi3iGHudtHhReissav4uG6Qp204ATJuQVucFbYgQd7qLLfBd6GzxxaHP74FZ+rSurPXAarhgw+BW4BIvQ8tpvy4n4rwssH3Ap34GdZFMY0zoApRiiAMZFEzVQO7atWHWuyiQBgrjZSdVqdTzKPoJ/BpNQ7KZiXkAHw3RgMmyJ49xBd/MqebEpnD8NEvxloh81MNDTAcE86qQBctjHQW6WEgMA1S48+eqshDqocscAcyiBjcyI7KUOHkV/oavMVeWRWjGxEwB1qK6UWjr+bl6mbhyUrcg4hTtUh8PYWeQml4QxaAC9JsAE1rWlUYyLJTQmRSGU42jJ+EpiCrKDI6IIwTklY9xAO7jcDGGoc5VYhcdJ8rH7cjJ0wg5cgSu3nqP3Ni2gt3qNugAGy8e/PqWG/2HkH68cLh4OHU4e9h9eO1w+7D8cPRw9vH44dTh4OHXYe3j9cP5w4HDkcOLwzsOpw6HD0cOpw2uHU4djh0NmbOJw+HDgcO7wjsP+w0kzdsfh6OHI4cDh8uH1w8HDicOhw+XDK4fD5mqrh1cPBw4nDnsPtw4PDrsP5w67D9cPLx32H44f9h7uHe4fdh9OH/Yfnj48b67Xc3ju8Nxhr9m7f7h5csb5w10zNnB4+XDjsOdw5rD38OBw47D/cOJw4PDa4eph3+Ho4dCtWfQfXjczGzkcO7zDjE2asbnDwcNhc8dTh8P/OPg/Z9Xdv/kfXA9Y7yAo6WaDMvCRpHcl/7rNbPttXs963Zfba20Nz22Unbefa946Otldn0FzuC17KSb8ss7xyy5qqHNJ7Qi7QJewmcN8mhPSr6Es1C97qN3OkG7yUA8tUTtt8mUcZ3BacS6c7aSLdjGAQ8KHQePK+mH6Yf5D8RjNUB+2YFyuS+I2XuY97qJm3uA5rqV2CtmQBbyA49hGU7iHlRI4g6ZoQYSoBqtkCy7TY7xlV2CAtnGNo1kQSgoAh/kKL/mL25J4wvHTED6Pn+Ru6qUl7sAlekggVuMdNCiXeYJjYe3AO8hBOodP4zQvigB3yA2aDFZRHu/yHRQkSV2iiqd4m8ZwSFsr4iBf4iu8Jb1hqHcf50q3hT0w8KEKqIKSk5+P5zt/DhUa1sF2je3F95EzBejDcDNkABdQJ13mKVHq87RDo0X5FMNWTjgtgVoKO2lBd7Un7kq4KUG1CCS5jbNEpd1KC/Qr/JM8QQE65cvpSupMIjtQztCaHNYA5iFqCEEojaf5uixvA4qynQRkJYzlWCU0uYLgZGM31hTpL4D7hI+Bkqgdo5RSYQnPHgim8ruAMymf66XD1+l36RnUluGFmE/xUFEvcEx/RoOrxCMsLBVhfzFGbHKQA3aygi4IZAgv7tEONvu1WGs+dwVzmzxygy6IXOHYFWVWs6vk226l1q3CTCaUm+foeltpwLdfD1sATyU/i093fjL88eiD0aejH48+E30x+kD0yejz0eeiz0Xvi34s+onoR6MvRt8b/VD0hejHoh+L3h/9WPTj0eeiH40+GP2o2T4eey76yeiHow9GX4w+E/149OPRB6LPRT8e/WT0Q9H3RJ+PPhv9ZPSp6IPR56LPRl+IPhl9T/SF6LPRT0UfjT4SfTH6dPRFc64+7sXow9EPRD8V/Uj0+ejj0YejnzSf/1D0oeiLZu/7oh+Ofir6dPRTt8ZeiL43+sHoi9GPRF+IPhR93Fz5hZNZ6Dt5T/TjJ7N4T/RD0efNPd9/28yeNrO9NYvwU53v9Z2FB+AdBb1BUPDi29Ds/0GU9Gqh7Xs25l9jYLRA3W2fmmT8cmtvNS9C0A9Z38di+PisWliCbejKhnAn3ccT1E0RJsncIDNqtUz8As3gU7iq9YO5jLUA0SKv0SwdyChYBFTN99Mc19ak4jRPUC/fQ11Co/UXxDp3ijYRkcNilX6Y/pRfoidohWIsaY9tHxBxnR9EDK/hlEyXYKc4TbzOixjDeVrnJfTXgt8TB8rAMU6Qj0/JCurBBbkkJ/ACdckOuiQbWPt0DdKK6KYd2sRFXqR6rMPr/CQ7PEI91IPXNZ6PB2hKBnEO9/k6IQ3wabtaDNA57sHOXi2mdIAf5Tl5ymnliKimLrokY+RFG5tEjObxutzgITHH86GSCbBdTWb1etsXl+s71gPfIXxeAJmWBKrhjk7AGLbIerlHE+0eoWHHdZygKnmKw7JTthS6ZExOUZBPRUB2YRlDmavZZYDAjtfNhRQW4C8VAYF4gOfZ4QnbS15OMPOcXJalMkuAUyFDosiGiIvLRIyrWeftmeSgdwiEpYNelSsd7CyK2zVYQl2y1W7BSCilBLpd3MzBQEqDFo738nmOiXaKOnXUxf3YhffjGAeCLYEkXx61j1hUSL3B/E2odOVaNqAj2/webJIdcj5czNkclN0ap+m0yRhmB10SRCXv0QSXU5xq7FwccDL8Vq2r6PX15Td5jm/x0tCt34Sn4WPwErwAj8Jz8AJ8Aj4FD8NHzMjz8AH4JLxoxh6BZ+DT8Dx8Ej4An4AX4AX4ODwKn4DnzTkfMFsvwTPwKHza7H8eHoFPwgtm7GF4CT5pth6DF+CT8Cn4yMnYZ+ApeNI4Fn7KnKvHPg0fhCfgM/BxeAk+DE/CS/AJ+DQ8AU/Ap825j8Gz8Bl4Dj5jjjseewSehk/Dx+FT8EH4sBl7CR65NYuH4QUzi0/Dw/AMvATPw/PwEHziZOxReBY+Bc/DJ8yYnsVH4L3w0DsNekOg4IV3Mei5b9mguOAx+DHDr3DfYvoeayO7zCIU4OPw9C0LSLehof0qXDPbKfAk/A18E752oqLy5kI9rwVSD2zCY7BtrcHl9Gd8zzhbclR2OEHZzOWBGiFoHM+R7QyLAiyiizzWBJSKi9wb9sg2GqJooJf66eP4oAySHzd4CUfoJ/j9LGiex+UwO06B9IuwGBLvoS9ilz+f1umciNIsTXIT7tBpbMVRrZwsNpo8ArBMhrGXe6gXZ/BuMbsPJa5c65SLoD1LREQc93GLSlrBceQFrg5UUJjO8I/Q+2kfEyx4k4LUS900gKcQ7Cy+IEdtic/RDvXw9Y7McAaepbN4icZoH98jhOwxhpYR7OADupcWcBhHaZOb/ZnUzzdokPIppP1nnTju8AXqxYQY5jGtyyxTIlaDVWpYUa9jZrtfDxfSSPACqwWi2dTHaSzZFoAtzhL12P5qi9vEgEauxcBJc4qCzc4ZepzCQRcDMmMfVLkqXQEQzSIeTraBY5zAICfsGuym86JE6qJDZ6AomE4NYkkIEeAQrdMZ9Adz6lIwgxKcHQRKJ+3J1iq6qM6r9excVRpVF8UQ29SBZZ8AB0ItQXEvULZTTEN8kUeMuFiXnApkUFpQ+9JlMIge3HGa2YcdJGmQqjuAKqmTMgAarSvgZMheKrUBc2mTnsAhLg/mRj0OtGhBrEE7O5DDMTlM0wMex8M9gWJRg5EsaLDKrLrvxXB3/wAWq/sG23rVdcGt31fcF93nT7YOXrd13n3VvW/+3b9t71Xz3+Oxffd5s3XtZOzg1t6L7ivu4084cF8xx9w+dtF91X3Ove8+575s9uozLt3aunzb1uXvGNNXuf2OL9029p3z+c7jLp7c5+2z+M6Z6dH7XF95p0FvGBQ8/y5neq+9bIi+4VJXf/YPwadPwMnHmd2vgTI/bC28o2AAmuHPDKcj6Q1hnK95rB0vibfhQSiGZLcHMj39Ob/qu+b0yqiGrFIo4JOnqMebRxJr20DGkAhpGO8RDyLhEO2TQORN/jJ9ktZEWESoD0/xHs3ZZXze6fBlYqcTYEYpYzyHj9A+aZp6Ojo8x5ekw53caZfSMs7iLK3JRb4TV6mfKnshxy3HcFNcpEUuj8KUe9wSMOfmHj6gaqeJ4v567pXncRS93E679AH6At+BEdkcjDA1W1QtBrlfpsbArqQ7aUfYspfD/CR9jLpwQ6yTpsZ57B7qlcRnSIOnD7CHzsszcjhUrBexdEWSzCFm8qbJIE2ITZq1GbUQZx/38yzvSD9BgXXKst+6oaiNHaw2lwCK2dXcjJ1zQK1iEDNId2sv0VQgRUKvx7IYwqncTVepix1kDFFvrnUPFLlDx7Dp3HqXSPBVGZSnQsnURNvkhF3VnoR2IR6kOpZU2Q+cRj08znXs1caTfB5n8VQwX0OS7TwpKCHmqBphFFo8HOdJEeN6SkHAZLtYttJFmhUOtVOtFDhPDbYrYAnhNEmi9lCy26pxcSbN0aQ3G9Odepym/XCtANOQ8hRAgYuAC2kE/TIqbVrlPdmcAAca3IPuMHAVnqeFUGGXJepwjJOcXO73FXAY6wJgu0ohAf/0+j/59e4GPX21fngQnod/DT8MNQCwCXvQAL9uAMcSftn8PpyH34d/Aw9pX1qTbCednFkMvwy/A1+HO00J+DfhDi2kCNUQftNeVxXcccvA0gdPmDqy+VYtBpgu/UQohmEZwDouCSRRggZoEFcc4ot8jh20+T7+HC1RVCwEKv1FHKVrfJaSI9kYx33qowmaJ6B0MUVL9AGa40qukJJGaJvPcmsLVHl0zd9ewnXq533Zi5OymlIwYoe4T57ju3lMCBrmHXTEKPVgD+34q1Crk1RgF/ukoFlsokl8kfZlG81yl9PNju3GSjqgiUCrEHyB5px80YI7otMGUUN34A4N8B4tsZ8e4A9wP09xBLeoOO4SA0ILTb2AK9jl2DIdu2mXH6ErsgdzRCf60Y01NIgDuKNNdygqIxjHXhqjWbnBy1zcaZaK4i1/xH1Qp/M2L4lQIfX7Xf5qMejNkVptOkxhp12G4mle8Hpsm+I8LLwI7OEGukoT2IBZYYimchRtDGACz2AzufK0J+0odzgFUnubuRwQmXSOFnzgz6CY4+21CIIeO8mJyR5RTSRj3M1Brpclok1O4J4oGwKKyV0Rx+pQGXkxJrtEhNqomcdENXp0a4IzKSGbQ+Dk4N3UEXDnuNKtOlcroBeHaABzGTCNR2lFBrmBuux6DYUJFiHiGZqXWaOWLw37HK2BU86QBaFK7kCHO2UjQFT7qQ3lgqyRcczHuMiXUG8loPmfIsv/NUEv2eCTFPwybMOfw++CC56BXwQLfh3+f1AKvw3/FtJgF/4H3Avn4ZtGU/nTt3Fvc8EPSfCT8F4TAL8GPwa/CN+AF418QTLkQCEUfNe7CIpgB56HYRPoFmHjuCFzglpNyviMPSm1cb0QAZzUFTK56NTQAnVLEJk4zFvRHH8ZX+R4sNLwbQ9EmSaVyxac4028yhNYS5uyR67wFWbZIsOOQ9O0JvuaUqqgydWnSVVIvbwvwzhLU9yCw7iJaJe2W1zIMY7iMApeomVso3bcp4fFKA7yGeyRAUYcxi2aZC2jSSTxIiHDJY1ra5NrIuzNlum8KSecNpzjR2kLl3GRtnFRLOCE7RapfIX7aBTn+BpdF/U0yQeUJ6ppUbTzae7AOVqSE7RFe1xVAOylLttL07SB5VhHLAQlsJ26aYLn5Ayew+FwUiPUWG8e9PTyt8aSYOdTXDuD+VK4EIf8+RJkCQ1xkx/YxU2ym4MyIf3+Aoo4uazloKT0UzqhjArENdxExy4LNIpQq9Wmn3QckdoCYFuFkKlF43NoiCW1y05ZawNYeW4Eu1V0IWQDWuzyZlAF+clhIWJ0jR5BrTq4SEzMLJq40ElGK+BqBlEo+igLIcfdrfm4QerkMHZQdNpqdOVb2VYhNCdreXnqD+QFgEu4HUtFs+jiA+omKdvtan82xsSpOEjAVrJDhTLOQRnHdipuBl8adnM4kmSDDMiekMtuRZtbkGPaO+Wfgt7/RUFPh68z8G9NK5Dh7yEAN4zKih++Bofwh1APLvhD+Emoggr4MPwVJMNHby1vj8NUNnzlRHDg9+B/wS5Mwd/Dj4MbiuAueAE+Ah/9jvcz8Cw8DXfDX8K/g0zwwA6M39LTO47CL7UuhW1EquJy2SFtDAUyyZECNcczLudlCwF5cYy0MXcnLXM4CpUgq5wlpz1cguO0QM/QgRyhTsdDXXyVejguhmhQNFdAoWsMGt1IUq8cx/m8vz6Syfv8LA1SwSSUaEhrG12n6lAhxUQOtlKU5vkj9Ev8eTkvI9IXLhDpvEKrk0AuGscDjmPcTgdodXEKhbFDhLisNRV7pJ878cP4W3yH9MoR2RQswQ0OSc1mXcIgLvIKfQ4fE80spe1ozNwYLdFHeE12+4pJiEG+zE2Yy9103QnZyRqmSy16+c69nHB6eYQnaZ0usteGEpcwTt9v9GqCAqvOkh6MYR112eWcQwNcEAFRhQNcFYRRlw9I81mvyjHKEH5uCYC2wuR2AvaIDPTRffg4jvOpUBrGuMQG2chxLqH2aCZCvVUKC9qavSuQxSV0XUwFUl+Eco8NwUIaiGYFjXNiHBIukULpXOC0Yjuv8Zf4X9KTOERBqhZZlOZPej8QdBjiA/k4hh62XK5q8FfyVZyRHhngQKvV6iIoshpB1kmJ5TwQTrfBIafRTrcDco+f42VRKtODIIoobqeHrGa9Ssi1q+gsbXO97a6APlerJUIcpzQCEjLW4qGQ8ElJdYMQs/4p6P3fFfQO4LNQAB7IgT+CQbgXfs5c9cIJ6yMX/h18A74KvwX/Bv45lH9H0HMbmMTPmhJlPvxrk/Fp14w/heo3aGVYJsSdh/cDmv+bgT2Tb7pO7IJSs35IDEuHGb00SxpYPIkbtBUslRJnuA87fBnURHvUm5tETXg/XeIShhQXz8pFruV1nqdl5lim3NSioxzDet7lA3JkyMkotKq0TWA59nI/D0okL5+nPZp0irFKdnGrr4gcGuFW2uOnZQ95yZH9OIttIou36SL2SJKI53CbpvE0TqPXSWM/LtHoVVgHP1CeiImgXOd5nMdtHhW2DPDd1INBvsLtFKX7RLXIxbN0Ud5JNlfRvdSHrXiJFmQCzzk19ikxqTvGMqarWGKfr1APubkVo1SG+ksggDGRoH7ZjQParpz28YxdYIOw3jjoMbRCm6vDktpDTUOIc2QfF++DXhKKPM2D9XtIsz58LeCU0QJu2jkEXUmiSxRTIQWpnfq5p98liiXLJV7BXFkmosFkltQSB+HqhyrXw7qv6wtWcx/l2q32YKAAQSRzgrJDEE6mLFEkqsmP7RRlZqYeviy7ZBHt8iYHiVnXKXXTqozz7YwOT0QDaVolHIDjxcFAjmjGmCyy20WpHyqsAlNf4S5RSuWY4FzppTPYi/6gm0t51mmnBLVSJgv2BqET2KYDEW1N96ZhJwcpbwDCYOsMsANzNYeYWGRRhAMYFrk1xoT8n17/9wS9ffgFky5UwN+AA3fCzxn06Ffhz+Flk/X/FTwOhdAEEjbBBc+e1PS+LS31U0ZENAt+H95vrjkMf2Bahkm3fHC//daBrQq2IfdkJvXwIai4rZ97UPaRSCdFsAHDOM/jTgN20CiW4xzvUJ8WnuRx+jCfQR8JXMAVuc49XC+W+QEK4hD1U7PW7zUI/h5q5z7eMJ5iZzBkQ7qbXMEkzXSlcYqycAKRUl6jJcqzs6kR5/FhepImBfIqL2OESkkgR7McyLICaTTOM6KNRjBEeTjFD+M1lOQXXozgZV4SuU6xrKM+PKsRgdxPV7BXQDBJdvMy51M1zYo4vo9+mDdw0e6XUZ41NkBLhDRJj/OGEDzNmdQgm2QXrfJ53KazspGRIlToP4VRauBmcjAowhTjPuol7eCxSXfSiPQE3zDoNQBDg0uCUywjHJRemcPdTknUjZLjlOGDci0B5WiivwTbCiRRDw0JPxU5cephohjW28WcoNxWN0HMzePcLsbpvF3B1TLSAMKqcVW7fBAqcjqRKWpnaNK/XS4jfIo7OMKn0Ce1e1s7yUCzLA6lyDIK0DTGdQlXFuKM7JaNwVwnnasDXoxwVDOlZZ1dRYPU4jRxOJaMWj+nBmMcpaCd3OwqddW7JsCXgR2Uzd10AUM0xgFtNBkAakLZkikdjqBDI1QvakjSHDZo17cWkG3UYzcHUhAC4NTiIFX4QDrkC+UTyxCihij/0+v/pqC3Dv8I90I7fAn+ArLhg/ALkAxfgT+DMHwdfgsy4Tn4D9raCn4cfh0APgv/7HXL218zovIAH4S/hVHogD+ALxl8k/t76OlZt7q3SSfQgEl4AiJGtKcMduGZWl9QYIITtI5ncIZmZXdbivSxkwOygnsxRNe4nwpR8LYYocUg8zJ/nr5MlzhMOlNawmJEuiFGYp5gJknqpAWpFY6nZVOz7mDW8gN4BYdQigAV2z65jkt0gQa1mYyco4gI02nZTEDLdEG2KgCryl3qTracbCdB27TGHdRpt3CyLkeJPG6ldtrlF+gJLTVFDdgZaG1PplU6wxMiF0CTtWgCI7hI01L3O+/DKK5iF12ieUa6QbuhLEoToxTEGdqRUiY4U47zAT5M5zAGIKqpXfixiPyEFCApUISow+lHbWy5hefl/dKfMD5e36vRvgZs1VjBFBngTo5QCXfgqWAKx6m9JYWgOQVbqFO2fhV6AF1BN9dzmx9EgK7RB0XcKWp3R1yY0ALrlUkhQD/Vt+ViLxFLvshBzimDHmhLDnpokEexOQElQClYgmXM+ADfzygD6MMazE24tCwAZmk9BurmUIWr3PX/sfcf4JZkWXkouCLOOdd77/09/kTs9a+94/hzrnd509/03rvKyszyVV2ubbWFbrqbpmloGhAgGJCEf3pIjxEgIQ08iUHCSjwEsh+ab2SY0Qi90cv5dmR2VlZ1GRpqppuejPN9eW/eEycizo6IFWuv9ZvVyF5rDr6CPAI1Z/VRdhM36gGOa8VJ3o1Py1l/Uo9KZy1aJW43BRzxky/RbNTQaEQNwGIo53iZlW7VRrq7aNIdj6DGCSHdgXF9QT6FI7nOdTJVbs1GhiMlkk4UucjDNXs0o3pT5s6S5E3Kn1ZVLOnRBUf//4pr+Wj5Jgh6Z+j/Rv+U/q/0u7QWAiw/QwH9WzpERCv0r2k/9dFP0b+m36LfDmWmPkufeIDTuycM9cN0OzyuAfoB+pf02/QrlHoX4k7kAY/DCVGHL9Mz9DS9QE/SWIraXH9Y9sqTvItXeBfX+apc4F6elDNS4DUxiirNmjMdWORlUfoWXkERFX1KrvNJMG/zd+CsSvASHrP22cbIAX1Y75YnZF3N8kv4Eg5jAXkVV4of05AeZmzp/TqepzwhJyf0cX2ey6y077Um3En3Ok1HDJmk3MZ+OSQH9FTSTTXBdncTnDc5SeAxeVlVVBJJeUY+wCWd0CdxpBY1jVjjC3KML+JQPqZITvGqn5XDchE/Li/Icd7N9R8hr09Kcw3YkoM4gZfkutSDMV7HFdkfjOabZUYXJcWz4jOYucSLsoYtdUCdwyX9HG5Ij3LuC8ZHQ1mIe+IQrg167NQcNcsryqhpVcewatWL4i2TZ3mpZTbcU6aRyFx01vplrAGSxmJI8dOWRyvKKKF4xHF0m2hOc9V0MmmRXTqry5zR3Z4Fd19VJR7EHDQKnIfHqzjEuzgfJ6YZqhPT58mkseTPSEJ0sWncabZaN+4xCzEPcmPQvOAPCOXoqHWjI+5VK7ybD7F9ruQlzz4mMCEH+Mx8MygYY+0XGHLA707ZGimMIM4Ru03VhqWgZyEiSgI5giMcqBQvCAvNRpOxy3aqMoOa8rhVk+nSNUk3OqLZR5Irsow27+FxjN0fTfdRwPnWDHo36OepYpENYRgbpTEaCbuysRBSMhdCleu0FsJMHJqkkTfsNUIzoSSPG9bm6rRCfe8itfjmGp/t/NZolULQWX/0zwj92OGDOCdHOM4FgR7COj4jN7Go14NIlbCoVuSAXNLzel1f5mFY3ZUreNZXZoxPqy0d4yk+rGZlkevw5JSUsIIr8t34bf49/lAoM2AzjA3Foeox6aocUTOa1CB2c14KuqTyKosKgkxT2pmPpUiP6i29jlPeXKoVR2zvVAuf9CtTDUUKKEGyD0clHeTMJm5yBbOygc/hO+SQLGCvmvMG+SiqitQwTuMk7rCRCj8ju3EU13DajKLi+0Jhe+KqPo6zZlNqXk42jXBJzZg+JFjgqzSM1Ni2Mzaxh49Ze3L5JI4M0JjjRCNvesg40cZoExU6ZZUXVVzVvGEzIMuYTJM0WottPb3h7qeZ6Bb5lGzFXpz10zIldZ4BYZgDOSrrGcpGeiKjJLN6VRZlKOvmulDNUo5Ul9JYlNPyRTmiEspWHGcwxq3o1kuLzeToQApoXnJL5PdJFQV06yHUuPMS9YfXzoyTc+6SiUtQaeQZVdde0h10djs8hmU1HRBSyE9EpQ/jKs4wWcnxy/IJ2ZQFnrWirqYP+YmIaZSMXjF1tLxE4xFFqkNO6A3JzsdAqq4yMqvKck3nUrRO5AxFC6Q7lMKCmVZUbtAB502TYrDksMXcTv2OE/2ah3X0L8Alf7R800NWnqffoJ7723beEJDuhS73oQvgnRb3DcdIf+6w9/rnnEh0lEYj2MAh5JnNqjwjq2gvTMl5HPAtFGVNmB/DHS7zfukxSk7rcguJ66fluF6XC3Ibe6pUbkG+HgnGZV314yAfZC3rch5/S76Io/ggn+U64lzAJamhIDYj3OaU2sZ+PC0nMG3sBKgVU8LYw2teC8gf47OybTIqL7e0DcSst2H8NoVgzKOZ2Anyu9QyDssV03uG5DBXdF1q/D55VadhiWqGy/wyl7JTuCzbcghringdJ2S3jstufZKzuCbXcVhWzjmShy8ncREXZUvP+91QKHJSjemUCYwWRhmLsq439X45hxt4H15j7w/unZp52qTDdIQOUjk0eqKRBlWSvVrLIo/LtN7Ug4b8SVkRDx3l0KCkTGaYmffzeQwRmTEpeLFFy50d0pexisxEdMjxmnkL+02P2DysxsabYF/D+HyevyinsS46aAN5xGSapCrTSw47ZQt8DqRVx7GIZK/DI1hDj9Cse6/aaHXuptxfstDiWoLQxQa1XG9uCFWMLFM6Kg1clZStEuZphoJRXsamvCSf4RXxBSotE7zmTWratBn4GSRnnR3KdrPgMPYt0c9RyZVeWyCwBuT6sbDB0VoKIaktDgalpit+c4JEZFl1Cozt6e6o6ftX/yxt3B/HSlh7pq+LivZo+aYPevdUYU9SZzgtuhe63AfUa+d+gu+GKnmRB++/9WT1jet9PctXFfWcefJIRJ/Uawx4Eoh1W3geV/ReIeSwBA9P83OyhHPY1EtY5aKJZR108kW5KJ504hgOSpGPoSoreAYVrshhZP0i9vEL/LLpSlGQwmHZ0BW5phP5JkzAGkKOYBqH+If4O9h6OpSlhkBloFDBZZzhkjzLz5i6Vjymh2UdE6BKTM2hpkt6E4Ofoq1IQGpRXYFSR/mo2ebDQUfKwmcPynEMSEoO6Ly8gJ/hW7ILh3Uaj4sftPCqPoLlCGmNTbMH7+cDsoNjwgx/XBkrmiVXgWyr6ZaELklOzRlBXkpSk1WsYw8f5+tyGx83Ly100rL7Gr1Cd+gSnacb9Ax9lO7Q6N4B7JO6rKh5pNSi6rzmSIWrauiYZV9QNopZXZEiz+iNYAyU60Td9Gdo28l3yaLuUK2WKJZ3fR+3eDYzIGnsxg0xEJlTfQj4cVYpJ99tPK5KkO0pEgPZuDPrdkUOWEHSIl7AirQVSI1jk/sVpZ3gQZNljlIOnHlHe7z4DMUjPMyX5Vq+F5R0e91N4kaucv8e4lldQR6z3CiNchIngwkzpHIMvQvXpWjm0p28KldXY2bUZrRoUmklf4dGIiPW5Ak5WiNVUiWZl0UR1bubrO+aalZJXlNzIEnouhnWRtf9XWbpWoyW6cP0Kt2hy3SOrtPT9Bo9Gc6AHoW9b6Gg93q+9U2wxCxtvI8vqIPIo8g56bFgE3TzPj4sx+WW5GQBK9yoR3FYrsk5dRPVTAtIluTDWJMprPERvR+flVso6j2IZx21gB0dmAV9CtelpGksmrTdzCou8h72sCYnzDCo1CIFOa/y2X5ZD1L5NjWAEW8CcZT4GP8wfhc/xgeQZ4+T/hDP6CMCQzVCaz7BB3Cy0haQDrCNA3KNA0uMl4pRAXnkj6t9XJEEn8QJ3cM1eUVp3taH5ah8G2rYzdvypEpKHI8jmevEan4C++SoXOQdvc2B+LIk21xQBUyh30uoInzj6YLU9LKs8X6cwiV52ryqfmLoJ+g5t0C91BqapjdSO03Q4cjnx787WDd1T2lm5cWCSV6TDDeA8sStkrVtBYxIgz8lBSLdYDUGszTkTjqyIBPaOtzGfF8eww+oswLJI8UnMaUbgmguyikc5rpVpqhQPpprs91WfUaOzDtlGqMacZPWqsgKa15/pge7zbBQyp2n3EO95TnStEHakYCrREp4iXNY0NMFMpSwmMkJfhzrSgcjaB6gi44QD/AhLBf6s44fy1uXjC2J67LW+Lh8J+/jsSKBUi7yJl6jLheuWspNeVa+qpxpCdp0QupcwmTdAS2Ef5WqbkEvVzjh1wqFzNWeH6b3OeU3jOMYHaLP0sU3zUgeLX/lg95f9nQ6b1Op+7o/n6FSBMf0dVnnFZVTSV7AZDHCSRzFMXyUt7HES3FrS72CHXQizmui9TqelF/QL/o5ruKETmOtMOB1yA1sq4iFNSClfD6MQ3pbd3o05I5HfFKzfEUZneNjsoSa3tErEqjSXFTI69KLMpVw8m2SQsAl3ODnVYUv4jFeQMokFGuFBbmDE6rMBa10oK/Lq7is78iymuBFnTtMus/U1WmZgXXkyuOCviwneBc3alIrOAFPV3NNelle1NvYkSf5p3FcKT7uDepREbg6MJarsaOu4JyclFUMcrdSuiI5PWGynFdGF3hRVuUgH5VzwbnU9/X9UnQXNUReH8v74+n2Nn5y8PtMQRdVyrSgpCupdo/ukh6UwDrXBh0mUqLJRqx4nUJqGnki42YdFHgJdtK7yHldkNfkeVnS44UIMpKxk1huRlEMV609ZsJtdP659Z8gNaKP6IrUMK+iwSDqAolqSjVir1zSg0xT7jzN3rfBu7fYtkWnQ06CdFluq5yxBuR9egGcbq61c8BV3lS7/EiW7EjWHXYLJDAFlCWbsBDqTgTSYxph1RI/x5clpxekghmel/0YDfm+nViqNkyTygGKtKtjuVEU1BKnVauiwMlPYoPngla/XvLnz3f+bORQaPH4pnGkXrJZdOzrqFQ/Wv5KZHqvB6Dou2jEvlEO3r2vlOLcD3XOOzhrvNM2u6k32kakA3kWR/U6SrokSnVxl1jiUl42ym3Sa27oPekuaHlC+zByk0WEb+Nv8XkpYAmHJDBVGQF5A7zBx/Cs3ETan+JVXkIdWaEuZ9YpUrqJy363X5YnZYYH9CEckb1ymqclqmNWmshClnXVouawpc8FY0zSIpuylwNMoTlw81To5v0Mv01NSaDP4Yflp/lJlDjLjKt6txmTpOzIkxAkZI1PZcdkhE/JClOuTW+ijP3KgLALW3yDD8kZue3P80F5yg/4uOxVWV72e9hwWnbpffopOe4lckO5XsxzgdlkGda31ta4+KDspD7U8XOUnqKvsWJyyLX6oZHrXd9bnNNTWMH0uMsNmNYlLMp8rmmEDtMeN0tK6ZSQ7tRr/lBukOO8T65gQWkdz3ajibdx4rAVdl2QMq/NxzQFg9jQM+xx1qN0uMc+B5Tu0CtBF1O2jct8Q25KHLEKKZIWtSkHTDqIlmjCSVDnvWIjEU3SZMgb1sTdqOijgiQtWvhMq2zIUzjJs79AsGS8YNoxzhylqN0hysRkAWP26tAxsWaeK1wRs+HwJD8uSdUgY+yxln1yjfNqRndoD+VxJ9OqSug3tO0Yyjjcq0WWoLiPo+lmZbi22D13oPHHCcP0NYHtXkIQpcfppRB3+miS+y0S9NzQ9yIS1u8cukyvkvNAWir6QB703stCmS88VMOj0APtaAhOvk6v0QfoVXqeLoeNkXfwY31DaJyhy/QR64bWf8K8KNf8vVjQRaTVFJdheD8mTVZPoBs7EDWHO/K35KYxOGPmMayK8qLsY1tiz8oFvomjeho+HudN9Obn8QJucNHXesbU481E7c6qU3aU0p6ZZCCBG7jity1Yxb4tXrPBT23CN+OWR6qyqMtuW78rRdlJRBDovPKxiBQ3BlRskr28Ihms4SSGZRyXsa7i+T6M6VO8irhe1h/Gz+JlZl3HBU6zkQ9gy29mVgX2cdkfQQ4v4pZe/0+EEyafszfwPpmR07AM3AvYkT2ooqaKeg9XVBZFk/atxrKt6uWDkizxut5rTvb+rFtxKPbWVdTIgBVZ+UDXKxvz8Q7VrjK8rAr+6ByBKlSj36KcY4b1XhnGOJ/GCW1lHlb4VHoAVCQLVoGR43p+P8E1xKfVJfSYYV73RzEoi8XGaZpy+qibMsRRWC868hvUOCqiMIciyt4Q+vSCHjGEEpZ0q6a4M0gdIatiiCYp5SiyAvMWfK5JAhbdwSlZEF/PSRFAV4J2O7LAfoHikSFL5Xb2kozzgmpAXhelx3jyPvYVGecYYYsPqXF73Ptt5hnwaWZtzCKu83K2ywJjCg1WnqFqGy5UaOQUFriCcdXsDZty4w/QsmNxPm93x7XQB+nMQ3Ktj5ZvmUzPPteu3udVvJ6rvX4pWLPBH3sDOLmNLt6Xru+lb6efox+ln6C79M+o737A/Fpo8le3Hbm/DZ8+Q+doLNJLpv2zE7+kL2ADFSh4mtOtuWkpo8pnrOgnDuusVPE09klWLkoeAxzwfrmgejxHd2AFKzyY65RD+IJcY6BL9sspZeWNCjCYIupzPWfcwZAuiZYFURB/WM+jggN6PydR4y3swpKeCzpUvxzDVbXNMwHNh42cfmcyIobns1HOmHVZlBLX5DT26iVv5Av0MZJZ2c81Hdet7VbqfUUXeEQruSlr3C8VOcdpWcd34LKU5KKUcRXfxacs5QxPoyxJnGSTiwTjOl0gFNL9qMsyDuOKXOALuKQ3ZVD3c5I1POSs3TeXsKi2q/WJL8duzFHUebvOUTRK1Jho/tSgX55Vy6L8joCEPkloki4e9KY5jcuyV3zsyMF8e7szHeNirjdL81FyJMaaF6ScbR5yA8KUUrkufUxuecPSyMs8dIzm3WbqoTEn4UDbvI8HLXS62FmmKhWiPKbrfBtr0lmMaPKzWDS9Hs07o9RCdRoKaV/sIsUruovJtGAYl+WcymZ7jtCy9TCLyyrSunU1ikV/GDTgNtpnr5WMhSiP9JI8A/AAa9VkGb5qVFZNzUynaTw6E1EkShI+ZRswK5dRhZHLso1pPab7uK0ULRFoiHhMimpxs6vtRuMTTa7jOG8/EyGaog+HEvyPACx/5YOeE1LOPKrRLVoOO7MZylEPHaABilIb7Q57V9N0hW7cw9HRl+gLD+obLfSd9Kf0H+jaQxfDCv1H2n2fhBb5mpfNJgcpH65tt9BPn6CKPQ5btzlMsU9Nf6pQl5JoZDCmmC/JBVxUWX0U5YC4Ww7prVlruHMCj+GibOA4vKKbj7CtnTEnuaiPS67TxShu4dNc5m1VxBZu+t1LtsIWzUS5Kkdky1jJzxGMcxx35DtkF0aqlpdpxZEg13A9EGzwOZnIurORekTcqYhnc4QSVnU8WJZzckrPIsNPscnSVKwUSbo6LopzclQO45CcTrcYyhB8HNfI9MLPWyzhGJ5HkE/gPO+SD+AlvYajshefxkk5hnPYkVmc5jXM4QDGTRHjoi0QWPbqi3qX2CbKNFICaBWgzEv5Ih9t/6HoRMSJuW97Hzpt0RaKXeh+f32kxdkk02r6Me1nACmhgnlek11oyTZzqdaoKd8gBZ1M0FAk4tQjEpis+PnUFKUjplkXeQzzXFSe1nxIskKpyIhjnTesn6zScCTJqzy7RftoKjIcrZJpQEEBca4ZFUxoJ+iXCo/Vacrtduo0714l3aA8NikHnRKXguRNXFVldopUZDgy6QZUaLFBlIfmO7gqnc/TpEs0667SPOndWNdZaCkHfRpqVrse1aIo6DldlIkkDUcTkVKTLPjjQhmSKauR7VtzKcUKVc7D56SM53pSDcco25YuN3+Zphwn4jrvVPSxrnMX3wK78Gj5Kxf07jEy/jf6bfpF+s8hh/Yz9CM0Qv85VGb+IP2Zxa7Sb9E/p39Cf0Tb5NAP0JceBL0h+gAdpJ+hl++DOC0r43fp+9/FOypG76PjoYqeQ+v0VIgWjDouxeZdGu75IV4VLWkkVBzr2mZUbZjnaeuRqlZ4O2j3GvgIr2BcUvIk7qhJQzzGz6ltVnpSgZEmxARyxozzkhxVcT6DHd4WlWkE+TN4Wq6oTRZOKQ9Zz8eqP8BxBnf4VCHdwT4HMq2Oyjn4sgleDhHXBeIOmdaenMW1Qn+Bkg3Yi8ewgE01o6gYzdNcI+/FSS7LLjYocnkxoqNolbKpI5CS3s39GZKUPsxH+AXFAeGUOsC7g0EVyLP6gJSwKaeQ5Ss4KHtwDfv4Og7ps7IX+3AY+2UaM77S9mbNcSAFf6FqJl9seJKaJt6xaeTGYm6sHHtxJp2fDeEugYbOYEK6SpF8g5Slk4iXvfkJJxNRmkvnnZnoXGQ0wga5TKdeWWgcc/8V6TkpSUWXklEhzXhcB3osSX9A8eg65XotnJgryJsOTXORGTfpdjmlFqlzwqc6ZdslqUtc5Ek9gQU1k6RcpBC7S14zaxY9gCyqbDBeidYpY9F5yY+ScXvcyQjZLvCU1JFmxUU05CLzUVC5gedlNy4n29jqJi+LRs1vY2fS4TEpZFrUgj9aoolog5Pt4l16YMjRDVLTaUWS9eK3KNXE/WoOvmgucNGTymjH/ugzzR3v4rJlH+FFep+VfHwU9v6qBz17pi/Qn9I5itIL9F+pjz5EvxDKTf07+hL9B7pORD9Ffz9c9wfoV4lCBf2vTm/vhbafDtVY7lX8nqb/ROOhakoHnaDn6DY98abXk/QY3aB/Rr9AzRSlc7TvAUKQyNFOw5dThzVQ4CTysiPHZZX3yAWe5V1yQe9gPT8lt/CSgpqRfXLJWn6r/fgueRElnlXzfEiPqLTsk9N6TddkN5p4iU9BsIVrOIU9+BI+xQd5UbROqf5CM+rerNcsHSxYxFyQwLrOFUnS2DBjoXfrZWygC13MpiZFjB8iTuq69AVJJeiVWb3Fl/UsSE+rogIOqoRQvo+Zj6FUsNWjTvjZNhnRO9gEJTrkBu9Xi9hBo+r2l1HH/jRJhQ9hURF8Hp+1DhZdEkfAnmzBAm6O4xwewx6ex7zEFUSz5iJXKsWhTzfvbaNpx3nnei1RZ/uHZg4F02pKBnItGWuQTdb6WnxRZdckWMjJkB7jutcKZy5iiH1ImWBkKkUzLpqwwbt0vIU+TqV2XTLdeoKr4nMjU92+t6wNT06RoSnnKao75CAWFCRRoKw76XhWNCCKcd8KehVxEJkyZUi1Yp234WsjaeldCquMU+4seS2qxFNMcfcVImfRgpNbxFqP70VGU41kCCXWqjeYZn+TmKQD4MOSiZPvaJeLMpjrVAu6t0ATkSypUV5eiGXJ6+OadOtu1IOetO0/U0BZN+jUw95saXrow437yRl0Gt5tHLvpGfIeBb1vjUzvBv1UaObTTX9Iy/Qs/WwoAfoRukufCxsUf0C/S99On6J/TH9KA/Rp+v6HanoO9dLPhxliLPzUr9N3399qM5VoN23Q5hteG7RFa3SN/i59NAyNp+gQua8HPXKav5LZ0VBZTmGPnFYrZp1P8bw+xKdNUXakJk/L84hzCpf5kD4gPk7wz8gXcNYvqhwusdX+vYhNHMJNXLLWfzhjUSZ6jS/Jj/Bvyt/mj/ExswBBVnx+DOckQI1LSOAIPqlfw16e5WN4QldVxlpf4wx/Ht/HH8EJXdUp5Nh6gR3Et8s19iSjcorlIn6YP65PYomTysNN7MeU8mWv+hiucUqNY4vPIg3Nr8oHbb9VH0ISz+BZ2CrgmjzPJ5Xi83hJDqlhXNRLMoNDZprXuchlLMuqbIa2kafhcZIVlLBiVZBitdLzuRgTtb7jLeg45HQ77otUKBO5vivRoDFoCporLgaxnG1Uvdj22y85esisoiuIphvJgdY1RRjVyy3RRBNIb8gVfySgTGMyggX2kxRzdDtKKPlzfFBOq0yiNUKqMd9YaCg0xV3dxHXAJzTlGwoNQWO+yTR8yBYwhiTDS+oC15GRw3wCRs0H7Qs0ESk2Bk35xmKDNK26aJVlmb9LqqHcmG8ImhJRIn8AC3xZgiApi5xcc6fdXJOsqOnfoVTDcoQLuCPjk5Rq9EawmomiH+syTOQ3a9JZlHMNZBUYF5dIklyURmnMN+ebgoZchN1bJBR5X6TkUZMTe3dY1zNUfhT0vjWC3mP0/dQXwkb+OS3TC/Q/heHr43SXvp8aqYX+Jf0tepY+TM/TY9Qeeiq9rqfnhHp6L4b8XOuY8X+n2rvWPdrpfRTc30I51OCzMJl7+R4P/vX8uhiksI2restKHP0MmXEJMg08jw1s4nipq0xc5NlQSj4v7+NzugMTqoYrwlYcUw1KtzrNJdVWtAJOu9hDSTbkJn+ad2RGTuqzelECGVcFrqq2fJfuTXZ41s1MCWORl2SVB6UZAzqLVbXGIot4lq9xzWTNKPeaSTmod3BA59CjZ2UJ+3kbL+B5LiHpD8iMnFFrGDZjXkae5pe5qsawmw9yUS7g0/wSZ7CNE8EcP4vnsSxHUcCHcEPt58PyCTmEhDwuB7Agj/OGvoSDOCuncBLncQ7XcTA3p+Yxq1Ngr4BCpdr5pUiGqPmdx9rpiBDFXhy8uZBDTVdM2ZRM2RSkgKtymAXX+aDWUsEdOShaylrLSTzGVSNyXQ7AaObT8h3YI0pqYhWor+uCLumaBOLJIXw/flgf0FnkpRpuuYIC8nIRF1GQoik9eJVR1SUR9nWJz+HH8Yvyad6EZk/npSrV19fUFdGyKrexW4tU7n+2Yq1R8Bx+Wn8IVZOTktVDxi48FtRQtNuV2/pTUjeCsr6oD0mG98stWdFGygjkmpzRrMu4JjsAbum9OtBf3VcNlSXV8iWLnYm9yziG992ztPgo6H1rBL1L9K9C28fj9Gc0Ti/Sz4Z/+w/0Mv1x6H7xv9IPheseoi8T0efpe96kp/dT9ML9oHeT/nmISHAeQGG+tpERoY4Qo3ovNDbTi3ThwdFM0Q91LZZnpR5a6Oxgv76CJX1cLqLDTMnjMKjJtCKVkgKv4ion9H5clU5YclFCjuCGvqgtQ2Nb9mZbgnG9gRuiZVaqfAhXsM9SkApN2sMeyem6XDdFnrNIMZ1DoDstxJYzfEOl81E/qcpiMKKaPfIo36SWZVsJ++JjRc+nrBPuoqoYK6repinfKFs4CI1kiYIGqWYH4xY20a724oDMp5psPlRoVy3+YezW01xEt98kp2VRL5sxPagek0NGSRa30a9asZTtVcOomx4p8LwYLtqJIB/la1zR1jg70MYrolgrdn1nVDnU6L4jiiLUNHHe17RRb8t16g5jX52mHZ6sSbsUZVHaTQtWVF7avB5p0yXsVv2Wr6HXuEO3SpVfZHAzd0uXGsFBGQza0KU70CU5vizHgpzl3up2dJgO3Wk6vQ5ek2Xp1G3SaTpef0mHbkcfZ7GAWzjOZX1HTuiAZ1SHtD+8nu5El7TyGNtCwb13OnW7DPCKVDjPj+k9+TG027XQjrws6Vb0cHvQLsf5cRlDm8xhEwPcqjJyUEa4U7WbAWyrHFpkWvbJqB7Hbum5Nw66QzqS3fX2yMuUd8l1G98903s6dIx5FPS+BYLecfo/6LfpJ+i/0ufJoS/ST9Es/Xf6Ijn0MfofFNAS/R/0K/Qj9Geh1+6P04++Ieh10j+gD98Pet9J//Ofk4/xurLeIL1Kr9Ai5ekUfTft+wCJw+04JC/gFO9K90tRVnITvIbPyXXe1nsWI5KQE1jFaavdhrMmk6aiw4PYK2ucsqosfBgflQXOs+Z9OmFGuKS29Zas86hHw9EnKeuYTlnhOxI33ZLlw3yLt1XPEiniHl2Hlgt4QnSqDTFLk+pxBiNLlHENdF48vqqPYs4f0bO8wtdEB7RIPRFjQbhLYlSSV/05rwtVv7+XDKlOU8IyHpPjajPbBfLGZbfO6b3Y/QuECb2MdTlzl3SGd3BGpbGKqzqhR+SUr7AhR7GOq3IWj8slucqXcAMnOa5S2tfCJRTL5aEvtGwQ9buRd6tFtbV+aGzPWk+i0wb4gDRlG1SBe3QPatwqxGktVXqJAuI5LKNFaJFQ4U7rJSEHpSC0TMskhIKZZFomQ9zJWjaxK9+krFhAUefzVq7JjiC4XKI6VUjIkKEV+0ghQ8sNOo0yILu5CPtej2yhDuGCjHr311kjE9YbK/aTvVbC39z7ywTXkdiMCOl5Poi6STfbFgetRnTgjxg6T4aqjfoAVvPDASmfQ4U+M4W1YoMKtfxQRY8mzEshS2DM3NtfhdCQ69sc6PtQ0+579Zh3Gcd2eibU+34U9L4Fgt5V+jV6ib5E18OtrdE2gV4Os7Fmep42yFpIWbPf0+Ha+2jjDdDiBjpG1fvHtYv2/bmBMq//1kyL9Dx9kC7YfTa7ectZPYAVOcE7uIAFP4ZRXMVyoRenUZIL+LJclQNS00XZhUKSQAtR2cIZmdN9SOAQ/gaeMYIoD8kKqvCNNdQJWEo06BANuxGHSRf1Ls7zCOLW8AdpFJXhijyBI8igR82YBR736L9Rn2t9zAdd6xyhVvE0jwZdegfP8GU9jyZdFc9qlUxHLhA6eJlnVIyDkCC/kW8ztEmygidkTsb4AI7qhiVSSlQwxrd4f7GV96lFfopf4CVc4JvyMXNazuIpOS5FXNFFvRh2sRdEpCbr2OGz8owVs9eQPBd5vVoYeiF2kxqm3vERE0L4OPbiDFdY1UMN4gx6WCudc7ikxzXpKdmYixH1kZ5Vm16nor1k5hncqBcQcE13XaPpWEAqhWo+WrSdceaazOlFGQ9oKPIS+REVl00kTIQzvJxvIJp2M45xyFGUI44E/TCyzGndZ0oquWoRchb5Z7kbGW9AFWQpSOkW41oEYZcjTtaZdj2ScWxnOlYauSKLpidN5My53cQF3yClVtVowvFJjWBJd5ZoIpKw0gFVrkmWu1XZ7xikOUJGbyYaM3SQgmlZM01CFoxsIthlRtQ4CyqoqMW1qY6j7i1qcd+ZQ2TTaab33Z+jPFr+yge9J+nvha14etMJdd/ib86bgha9J0jBB0uzc5Ckifeoo1znHIoI9CLfxnnezDtSQknl+YZkzTDOmztyCVelKr25Dj6uXzBlm9vJnHoMu8gRTxblSRxBp86Ykjes6pnWX6aIk6bATThsNBrIm8ZtuRB0Zhxu1BPqOH+GH5el/HyxixvirVyTnB/bR2NONvz+PMdlX3DeHMbMbIs/oPNSNh72iQrI0KdJUarF6tWlHO6UHA7oU5zAorXnxhbGIHhRXrWS77gpe9U6Pi+Po67PYg639NNqk6GX5TaWpAcVGSJSxZx18lrmLRyVC/K4XMElvsyXhEXZUVGZasNwpunz7ghR9B3OQEOMqOFk96sH270GonSbmpAEVuUpLmI/dtCmemQl1y4UWImpVa87TfHIdEQXJYE1zCLNXpYSEU2qF4toyTuhFabmiPhIGRp1y+Q4d2ma5lpY5JzaM+danHnauUCGkg6aMYUyFsx8Jaa6sazmyvdUTmjYzZPXxDUAUa+bQ1qY6ucGQ0LksEOOkEzpq3qfmuqlD4UWR53ORYrHpMZ9hW5eVpJrK5CkWCvnKHVSqQGV3AgXlYUyzuWdOdeQzvKStb8sEWekgCbrriIFHJHH2NMJHpyNkcNN89L6RXeUnIZ3C3rHQjyq84iK9q0Q9M7R/4mGHqjl3fOyeLO0VOSBgFTkHaSlIn9BvPr96p/rFOh9JHl9Ri9LWapmxvTJAntyBMflGp6THC9jvkha8TGeUmneUsLH+DvxI7iMhdwYt0lVjj/rbDheN+7o97HoVV0uEFdkOk7kbFHchSU+1YJ2jkuNe3gcOzikahzgCM+JtUoEqlznFPehiCW/F7TfmtFkcEA0PM7b3qJyi7RK0mEyvCS3eDcPotX0ej0qzZd4l55HinfjC/LTeJqBNE5aJWc9g/PyIfg8p5e2ItyLy1jSi/7sFumDajdW/E5elud1XfXLVezGptzmDZyXHb0uu3iB9/E5ucPP83F/0rQHZFq9xFq66zX3lCXYvu1VYOPhWOTjo7sXRFX9UWnR4RQU8zIq56zzBJ7gA5L0B3hWtk3fNrU4TP6EbOtlNSTtej3TPOZMuSbKRTXOLYZlRSaseLwpM/U6Q869vtTeSGB1kI9gRaWk1SpQ52LcxRle4IIZHbKqLhPY1FNCNsumUDV2wtmycJgSV7ItQktNKsV1LnsT0rbsKFqzBo8B9utNv2mNeiL39tPlEJku2URLK2nhRUySI0U9eZTa3byVkahWI8hhl14oxpgabJ7JvC59MsGCazipUrwHB0YbpK57hFQEnUiq5eVU0/O2ruy8/d1k74xhei2E5z8iov2VD3oUksvavxlSdocijk+5Qb4ih7DACyqlPVksuboPR3FCXpUV7Kjtv0ncL7dkASk8ZsXC5SqelEGvi5O6LBfkCdmvc3pZ7ee1M44U5SKn/IqVmPedOXfcmbD09jzGdBYljGBKC1blsGxgW88KzUUD28ywNas4NHJ6RR+WuOlAUa5hnf3cmHTwGI5hj5/w45zxkxzobbzMH8UFWeUiz/sceu7G9baXVwW5iXWMDbmcxpCd1qkV2Z/PyALKQnpG1jkvj8m4muUdeVxu+dt8Qb5TLiAlp0Rn+6WGSd+S447zBXlMLuEYDvO2tOhe+HqBC9VGGqTPhi2o2FteB1GKuESP08VRGmjgCS6jGloMFXcIBYzMklSkwP08hVV5Aismoz01iF45x/tUxCMUecyjuZhyMc+BHpea5iccITVmVrk57QyFU3+Hpt0F8iaxvBjrcgEU/JlgUGWlDuV1W55rzrE5r99dptkHRzlE49TnTDir5Ce5Lr2Wv2JlA1RRSmZKjXJOqjIpJNNqmVs8GnWtb1UnRawR+JRsSqOhfJ9eEF9N6wraS27SCRwYnhYbYB+XKtr0HHz25bRc04pHMY51PaFIgmC03CxrakhE18VP99yxc/vPhKpXbzeO0ZBhfvVRnveNDHqbdDdkTLxX3NuHT2XkXZ5lX/v+67KhEWqghq8723O+KmcwGEFEDsjjvFtWVAnQCd0ic3IbG7xPuaoTJ7jONXxUnofgghZ/UjZxzuu+S3l33qrwgg/hNC5iRx3DQbMjGysR7eFZFFQP0xOUiOUiXJY6KmqJ4/AZejxHQlKT8+xxb5wmI+jUVtul2xsST4pyTD6NH8T3+GdVGUrlpKC1ZLEPFzmvZzluhqRVGqQqF3Rdz/MIqJvkGJ9WPb6VNkpa3zU2rGS/GhFKtaDA8wy5jppp401eksvyCRziE7KK5/FCUFIGp3lqkbCLy7LIj+GIOo5NXuSaLugq9spVXIGVLGhL3bsSCvR5ij/QvnEenM2vYh/P04edrs5oLAKrYDIgLHfYBt2KIhM3BdUgFLRJ2Rv2GhE3nsmp5/FhMTzKeV7f41gtE2nkTesqEgxbviD3Yjnf00szzj2ZqElXyB/DcrZDE9NCE8p8Tc5DHSfQknuIggYAlaC5Qgk7F3+wjFMXRZ1cxKfAasCML1LV7Q0fOLKJx3BCTQaRlG1DJLnut1ZpzJ2mAXJozglIpzhfiK3TtMs5ZfQeKEMzZKL+KPZLnMf5kHwWO4hzLhidb0RWPM8R0sN6UTWVYtinkjjPJ/VUvsVOpzvtSBn67tDZ5a3G0QlZSx+m7r/wTObR8h4EvW26S9/1TaKnF/maGuDXKxf/YO0E+UW8qM/ILq6IRgKztj/LwAymZIRPA5LCR+RTeklOcjU3oPKyh+f6qdDgu/AMVI3P6Dmvcb6FT+CM3tbWTOcEr3AZe0ye2z1Cgq+yZXkY+Hqk2C59elhv6m0/ITtyQe+RvM7pQIqWQq99lPmifBhP4CmcUxWdk/FKLEv5e9O1Cg+BCpbf6niEMezVGineJUd5g7dzE0TcoGPIcJJ7MS+ruKQnCzEITikPR/FZnLUeE7lBvR93sMJ+tkl2yUVVVnv4ljqCAl/CLvb1ImaRFaXyWMIpfQcv4imZADU6WbfvHiN0nb49ZC/fG8mv8psp7KtfpU+EBpuRWQqcjKtIT2mrX/KsKOSxVYkx6R6sqNEs7XWZVqyn7E3M5Ic5wC0sidFJM6sv4yqm7cPhZ8iPYNWfvEDj0TJ93grkuMqK6dcLzUQYhWfKkpIxTnNez0lDnKRNFrioYncp7k7SyBtO/D0l9hnLABnGBlIlUmR6RYnkZ/U4iy4iLt0+8ZwqcmuDM+8MU5r63YWoQygia+gggXzr7/aCWg7GwErjuJyW+XwX1uQqj/qUp6Ou74iIKUbyhFnsNnHez9fNFBakcc6JR0aciXvX6yp9NgSk3BvH6EPj2E4X6KM0/khs4Bsb9JboLv3gexj0nPsi8fZ3Dk995P7/3Ac/3ftPwID8B3ATJ6Sx3RPEvdfUP03nwqvZ/XPmlffWM3SOrtB2PBk8ged4R68gMAyjEpjVASt1Wkp4XK3JMLZwqdjBAziNK7iEo1rnyMQUqSTvQw0XZNbqiPACH1N9JSqT0tjHSQC75Coex7PyI/wadmQBXjAHTxeRxyl9Umf8OT1hcrJbH5JU0FJtSjbIpORkA6dlCqTaZEFvW1NDGMmq4VJTjjAkC8hkaMIdjlhVEjWka7KCXbKPBVCHzSRonNCAKqp6TFdwG5/EiQDY5H1sbXVu6aJeYE+RFLHMV63qH9/Cx/CsrKllVLMRVkiquBQ5LStyQq7KY3IeO3xEVvJN8cic84AIn6eP0i1Sb8jAe2gvfYhuhiZNUaIUtTrjrmqTldkm0Wqcp/C47JY45lDjAZ8ysR7yejmPAyqRs53qFHxu5X6IPIOXUdNZVkigF2XtWdjLEUpR3J2PVQn9XMp1+5PIc0mldX8vlSyoZYjLwmqWA8lMu0cp7c6E/u9vtSTcAqEHAaf1nCppFTQt2HZHg55goKx9rxvzGuXGbCQV1U5Ac1YgKsorKo4BUeyHIrHfhiOYUx1+Pxe8jhJ5LpZ5gz3lLkbrsXlHcjCYhcIlOaI7tRRGCmMoa8o4MXtc98bR0IfpCcIbQlsn7aYP0p2vjuOj5RuzuKEc03+nvxM2ENz3JOjdS+qj4RZfox8NUXeR+zp69/61e2oIQ9z33VdZcR4UeH8jhDA7NEu/QH9Ef0h/j3LvoDzm3G9c0AOllsfpFTpMB+l814+kfjg4IVtY5rxKyni+H/vkrNXE08dQCEhmcFxEE1dlB3Gd44tSM9OwZjfXZVHt4aruK/TJCn8ayzrJOb2Ea1JBmvNYlrP4QfwMPor3y1musOGsGVwnf47L+UaPEGEqUI7Qq5VOqynF7KPA2xhRlGnwaciVlCzKmPQhyyWUNfMgmmFtwCLanYnupmKb7MbjGGI7XUzKIXwKx33FSmtc5MMypvtVhe+gyuOc5zlDJoUVncYtKSHNF3AOn8B1qeiKXObTjRHr6qq6RFmIij6Nazgvu7CsF3kDJ3AJqTQlXHo97I3SYXo/vZ8u0mHaoWN0h16jO1T86kNyn62HOWlCXk37WZWfITGIm65Ay20cUCOZmCEZkyXJIm+FunhQljOxYkzmZQuHsh3cYEaRQIIP8zWtrQcuBrKNVrcu6MA2lzmQvDfpt2oqU6uTc4cjRXqcJI+nse5RjpLhI3TkbXoEPW7CTpF79DV9MTdkrAWfO+fukNBZB73I+BbftwHY+uAC5Tr0KCeRwQbflLKex6zpe95RCTkLrcaTpGalUmpaJCQhHEjtI9bvrkuncRUn9Bi6uazHK01YlyEYjJco49bowTgO0SF6NRzHQ7RDR+k2vUZPUOW+kOij5Rsa9LL03+gX7wep9yLoUehfe+/3tKUjPiSX3XDf3LHpfpb5g/R9YfC7F7z20W/RXboRrvlp+nehQuPv0Rfuf+5rX3bLzQ/Ulh1qCm1s7t0PsSbd+lPJ95k1rmit8pyTPbIfu/yR/KiZFcKcXsfqjO0+viIF9Mh+VGD0MbwPP4QnpaxP8SJbsYFvxyJP6Vk9IevwuEcpKVpuh1zGaKZRx3k3bwN+htM4yJeDSWlejmSoQkmHadU6316RO2AzhFK236eE22chFNThqAGuqVTGOqUNcUoVpQAte7BohcmRwCZPewk+jf3GU0byWJPn+Fm1YIa5SQIzY50pkFX7kMQSn9EjNeId3sOH5XNyEVtIiyfn5SRnJYOzuNTn+lOoFcZxFBdkL5YFrLEkG/5+dUjO8yG/PedMu8WHiwljFNBuOklnyArSZe4zY9x7p3bIPUm5Ya55Q3rRi1mP2qyjm6UuKW+AA52Xbd6Tb1XT7OtIIYJCfpRH1RIUli1e0XU9O/Ucx6YalAFOsijDIuB1vCDH/SR373UN+TTtTka6XNediohVlFnQ4yYpK/6woTlnwBkhoeaQ5G1P/lDoGxpxJhyhuyRiajyiM1iU7sM0GWlyBt35SINjQcReiz+EQO7Yaqa1g+O8+DKDbni8NBPNWJE7t0ooSYELphC0iZjpi8TNqlpv0Cl9kOtS0BkMoqyTaeuPtp7t5WEUc6NSLTcaJ+40PTyOo+E4nqIzdJRWKUetXwPberR8Q4Jejv6M/peHYCR/ucnybvoi/Qz9Ef1SiDe/QU/SNP02nQin0b8ZTnY/RP+G/jV9H/US0Vfoi2GmFwnZFD9Hf5P+QZjpWa7Gr4c/f47+xjuKSw3RC2Hx3R670MfCcGpDoNtKtDb4vYUFv2DSetAfU6u8YYntOK1nsUfO83G1rQ/gs3zCKDwu+2VEMy7LK7LGNdzU2xLTg7iMcibM3HiMd6lwQsqrWOBNnUYoT64aTUqWdUIrOSJZCJa4IqowiX5/VgrK4w7dKzvymIwYmnPtgd6luGM/6XeqIsrSZIcpFzPtegRFXMXzckfOsOWj5hRwUtdVix/TpNv1luxi0VonsMWTGWtMCOPxuDyGz/NJlPhovpvT+gLWeIfb2NO79CXskgQfwR4ZwLo8KWXRypOUgRhZUms2OMlxfQ3ap0ln0HlwTTgPEqfYQwAi595zrC1ckxcwLEum2xvldS+Wb5U1ldJUIBOROi6xza63VKeQTGCZC6iqTolrnXML7kik4gSdvJrrYRvgKef67cjweXySz+ll5FVOEsEwNxRCvoedJyrF67pDqOJ6o1LXJmgo05CLsAJCtJeitEJ3wwenIX+EF0VMe5EKhDhvoLcWztkD2qJiJ6Y4o3xU9ZY8Jx/CmoxnoxbUUqIUsYK2cPMhd9lRLVgMOvWcXjAlKenmAnFObcHHYX0a01XHEKJY5gxIj2HrLok1WUqbJNO4O/PVIXt95nSPDf6GcXy0fKsEvXt6enfpR6lMv0q/E+rp/c8Uo5+jPyShf0x/l5roefrP4VPv90OlvO97SHCgjWaolf5GqKdnA9i/p1+jf0R/QsshEGaCEjRH8294xSlBs3Se/jpdDvO+Y3T83lFEiJxOJ+40f8Xba7Qqa60O8E0+JwfkOkN2cFDnZBsLeF4HmYj44nMMKbOLj2Z72Tqc7dM1OYgLaneeWqkagzUu3FTDegx1TugklwIXTtHpdJZo1UVjiIrLpqzsUUO2Rc1jP27gMdkviVIbYOEiKEsisGQTx4a9KmkLOonoKb0niOsOzGrmAgo4i1fxGp7hGma81hpxVItkmEadDvJbrKUk+pCVdevlluvmPG7LHh6WFZubqrIsGispVcQeXERa4hB1FuelxnfkaV42fVLQo5JWohWMrmNJr2KfneDyOX/AUNw9Sk2vXxcPi/A/+L2dipRzFHHKeFBIzrdixW8pxWRV1JQzSJNRLrJwg2rBfr6gPIzjqOzHNGK5VrVSasnRiFugdIzrZtJCiy2XQnLWKVYflzk/YqKmx8xopfO6JjVhb9i0mRLYazA0R39IRSo2BRm9aiaHrcFPiNPbS5Nkp7FVUs0QWdKjcDSR02ddNfq4jvnAsmjzsoCS0Srjj/mt+YhuxCIOWN3o/ORyLGEpdW5QxnyFBpyY45GOqxIo3wnmCyqvp/QSbuqMiko3lv05pjnKNPOGTmaJUzqfb9IFleBA9VykOUcevr+cN7T4HgW8b8mgd51+PdRHztCfEtML9POhb8X/Qv+dfo2sV8rv0E/SOA3Sd9O/pyb6HH3lDdzb1vvSUlb4+E/pF+kX6U/pdIg/fZK+SN9On3nT67P0bfQ8/SH9LrVRlC7QHnIekpai6FdSx0o+z6sE9mBNzetSvt0bFoYVAN+SA7rOhDGuSQIVbbDhTxao6CCLeeSwbutnXERJKjjP4IhMyoY34rVjMdVcpphTpRkai+TJtEsNc0qkboYkaoZVScB9uSZ0qazc5psmjwT7vKor+a6CE6fAzcS4V2ZFieJVPI4bvl1/Sq+aolg5pBWzKeCyX/Zn0CZFyKaFW9jJ1JJKoYfzfBXfKU/7WW+QK+j3iQ2vC3ALi34LKqV2bMp5OaAtX+JF/g65LOMq4Fy6FWWkkAF7QBVr2JLDfJhP8FNY2efOUdyZe+tixf2ln2Zp0vJQOqSMjK5Kk6zlRp5yUPd0C3mkW3mVRVl7xU4uSlRN4MPyUa11tORIHWNC45EJVywE2POJo2aADVZVWg/wqrJ+b877SGic2DGuaTYDmNBLeAqnASTNmNeCmDVSCijXpaoooeUS3aUBt+z0O4fJc/U4llQuF8lQljjqx4JunuO0WsATcinI+qO5rmJD0RmlihXlcb7NZpB1Qa7f1LCokrqdnUKrrAQj4zTqZh2JcKDSyuEeOYwv8UndqEZF27aL6uINk2XXGhjJbjMdkM5LRvWjDIZXcxzHsjbettn2aPkWDHpWWqqLItROv0Wb9Dz9XHjCr9NdeiVU2fvf6N/RP6B/RL9Fv0RD9NmHgl4kTCV+Nsz02ug36WPhNl+m36X+dyCoRUMb5cHw931hPTAWfhNbKu7s+CHs1kYUn+Dn5CxfwaIs4VjQCg9P6gKX/Q4T4/2ym0V1SVGycYJT7EBZbShfz/AhvQ/n5Lje0TW0QEstaMrHsK1HcmRpRmM06WryOtSSHrGtC4zLcdzU+/K9eTt9JRXTBfE2KOjQsyojVTwmL+uzsowVWdSByvFcMJZvXo4GtuSf5bKeqdBd8mnGZQ9a2jEsmisecEjt4i50mjGu4Fk5xtOzzWZEn+RVtrDdg9KTIBR4ONcpt7FftCqhkRflEj6KJ2VR1XGbD5kGnVVFrx9lVtrTrApqAWtqF+/l47ihH+eJDJWdzDue3hZKE7vzDsNal+c6pGRvchR1/rgl5fdhxXrELtG0a3WkMcD7cUyGlQ2Ph7GuogOONdPBDBdUK09yFVWei0e4iatIC0263U7hQYDYa20Z+7CoEn6jnoBnDNdRE6Vm1YC06BjmsKhmFh0/LDL4LSy6It1eQ7FLj5kk53mBy8w6levRraaslR8V2qa9YQiyj6shZ4M2onpFJRIk3aywAKM6/XGpB81M5ylwpF9OyjrKaliLnEZRelHx+ubpCJlGG+CURR12YZc3MhfxV2SKZ5RGYGl/4pQeRZa/AkHvF9+zoHeD/m7oXjZH/4UUPRdKS2XpH9Mf0O+HxJt/RR8I95umk6GSyne/SVrqJ8NMr59+K3RFs4in3wlRTW/VyrBQz2k6fr+OZzGq30aZh47mhfYblbjK6zVc0ZvY4gIWcUqY9+OLOI5DshMk5RaeYo/buWIqBXfb6uemcYVXRclVbJh2n3JRPolLuCbr+VZ2TSDpuDPjWFzNgLuPcq28gNEMcZfKcMW2NMTAz/WnSDWgzlAdXq+M6zkWVVKVULz9/XyRy5LmUXT7bSknoGwTNvEk+5XIPhqLzkTm3JskOV1Dp6GZRi/Oe/BR/jhfkCV/JNeMmozN0SIF/ajnJlQGp3GOh/NtsqY7/A4c1Qu4iWNyUA7wGs7irOSlhDNymNvUlFpUE77WDIbhKpb1iuzmU3JWnpaD9YYEjb9DRmJPwrgrxCMQqfvTnNSGreB70VbN1KRa9If30HBEk+mwZDxRsqQnhXwKRvmCqquCGS818AhsTlpEzQyTlcxqlJrkNKXdBueryiRph9ws8Tiv2o5oj2OVUo5RLep3ywwbXZGyFHhOUnpbil67bsyNYhcW/En22QKlyzqHkXLLJx2fSlSiu6QcaFWWFtCM23M/fHdTq0PkNepVk7C23qYRaSwZXxZ0wW80LSati7Jf73/NYWpxUTKBDmQ3Fos0EJl3PkyiuMTtQtLPm9LlNUsdQ8K6wl6yQVPpUa/irwRkxX2Pgt5JukufohX6Jfodagxreh30D+k3aZR+kX6P+unj9Kd0iBbpN+jXiOiH3iQt1UF/L2SEO/Sj9O9pg9bp9+ln7ge8t+8Vvw70XKVPU4mGqJ/m6RZ9mpprNN+CY/IE3wg7byUi1cpnpMoDfACBvILnwcjxVb7MGZNRs1LAp+VlMbJP1yYdRYvEBWwoHxnJAba/6jqKep2CG0S6nKCZK95Uvg1pv8pK2m0FEI3IYlv24Ro2keAaV8CcURNe592wmc0dpsq7FHQWNcuHkGUc15lkk9ImL81MB+kAEXlRyeCkWlA5YzhlRrAg51FTCvNmBvslwRY3OC0Vr3FPRHbJdVaqIpuVBszIkRDicoE39Aiy2JDHcFQq2JYFnpGhIECcfaNEUOAV2cB+nMJpvi4v6Zx1naV36BiNu92uNID9Rcly3AYATqNyxfFd4/FKsvPT1BaB9SI7itPS5/cj0K1wcs1Y4L40+SNSMDvyQT7Hs9bC8a41jYxJQXJM026j81Ucx5RznF52TAIL+S5D05GY0+8MuXF3zKWQ1qdtgOqVuPJRwQ3+iLyCD/BBNvD0eKmDQhkq0Iwz7k67Y26n0+hOukyclEX0lmjI7XIGQwZHSyj1WW7mZTWdJI4UKE0YFCMvyR2si19pNiSCjHFrjj/u66mYEtwUnaFVGo8sEtKyJgNMGMQGOtGn62ZaNFb9UeMUnUdB75s76M3Qf6Z/GGLp3ougd5b+Lf0a/VP6RyGy6wX6MOXpN0JJqTL9Ou2nFvp++pf0z+iXqU5EH6NXH9g33qvpfTFkJbo0S3+D/gX9Nv1smLtF3hEX6DxUOSnRy/QcPUMv0nXqyDpw/XneL4soyx6cwZIcwUXe7o/yFpdtFzZoCIhTIrsiPIUSLuGv4RmjUJELWFKZYJLX8MlQyLI5ICTlApeRVANTJPQfKGE1l8tmVhfZeEPcpcc4rsFGJ7CfX5BrvC2J56lCdavRRgUadGYimagtUaoZKVpJAjUgh+S4VEWzcFyvyh7MS0fQi1lWKsclPicbxRiFk14ZkmWZQ1o0L/BNVE17ifQkSmjetOzXFU7ihn7WymJhqtZq9shBOSeLklVQJ9k2VWaUgjaDSpQYTyvJS0W2sCPH5IRcxsu46nUU3jbozdAApZzPWa7qIspmWq/kmmUetfkIN7CWxVTrXucC/TUSq+18pdCainBVT1RtIAEyinQfjyott80JLqkcRgotC5S3CD/up2l36EGDfsZdJBNjgwW0LtN8ZNZJusZtdJ6irTCcqah08jBPYBpZVcdp3MZj+jHehwAJnvTHpZ9bRkLfjsN0l4yTdrPuqJNwmWQam2qcqdOddcZpKpwmdDvfTbkOXvJGQDkHPTwthhdwh495s5hAs9fIVQws0SxxVc0zcQ63waZLaMwFyYysYKxEPIpltElCWy+WBZS95syjTO+beHFCnPgf0x9Tz8MUrr9E0LtJ/xPFKROaz1tDny7qoeH72x6kkfBqSJAKZUId6qbON0lL9YY4BDf8PUvZ+4DmP++3iYZHoalKU/YPHZGgDTt8AgumwEnVoTZkWw7zEXlCnvPyWA06hPwpXgiGkZasKuIs7/yylaEsSw39akJO60/pDfhSsNU1nOMy0npJbaIQDLOlLJ2XZVlHXsdVjotSEE/m9BBKaivdmiM9iwLnVF+KbtB0bDhidT36adrpdw2ZHiNylPeacasC4rWgT8eljOv4KL/I53mJs6pPWfaoJ5Jr7nQKTXHCgC6prrvEPchYeKxK8wQWuJq0lK+9ss8vy5NyVRSfzA3kp/QsqjjPV00NGmU8JaelU8ZR9pOcFqUFBVPjOu9RB3FULslNvCa1Olnnwrca7iwlnDlCs5TNWjCPKrrVNNdXItwiBZEg1m5bLT0cSJEPytB5krQUvKgm1S1VGYWnyz5jnT2mcpOf4pLkMY2ytqAPdyrS73SHe9FOgbLNusLFbEMrccTqC1pLpAKpVumXCWS0lgAlpZQlFW4KrKq01yerekmn/HnOS9FKfUlcj5juYoM1ErJ2nAnHRIR4WJZ5ft5egM5UeBnOOslIivwWvw5Px1FhwYTtvWJTFbTRJUzonJJ5lyP5LqwX2jSpErbZSPY2WflS9MuCihdIxtWCakNWmD1s+fGn3lGi69HyjQ96XfSv6F9R73sU9J6hXw+7tO4baG3uA1bFVyUGHs7Q3hrz597/5Nd3VA/WdqJuZI6koM9hFatKyzQq/ni6Re3gkn5SPJzm3f6ABHJeVTTznPZkiddkdon0iC7kSA2w4ByyvjUY7Ar6sEsqMmxzOWzIk3hNflB+Dq/Jca6KIKsGXnUW7k2tpiBe+xgpd8qWyD2r86a7CnSVEm7McWjAmYnUCd1i9G6pcUp15ptlltOAGC8lPm/yOV7mFCsIMjIkQMnrYDJRRWaI1xEXm8m0Yh/28ryv+AqucFlV5ZhqHyJZZfAiHpMqb5oun1GWy7iktnRejsgRq9Os0qw5ayB1WZRlWcFe7OA8HueX9fsKA4ffstPYQWnK26x5Tm0LZDE3lZ2WWjoifbIsyRvWNDsqKSxwXEa5mHRNjyyZDiFpwxnsDoCUdPpjXONGFbOouWQjD+IELiLnj+yz4BOC0+TMRgJSA3pREiNkw1VAF1zpxjRnmLnABa04qaf0QDUy6MKTvAwI9bvZ2CLlGmTelDCStB3kUZmVjIgUYcSDLQ20rN2jsxHapag1x4jm3T4n66yTongDprHIj6OMzn4KKBn5CuUHpK6a9IT4bPgSylZz2U9yQSycKY+eUDR0KJxqd+gq558kfwrlfDc0iryADa/d+rg1PYov/3+Q6bkhVGUXtT0IbQ/r6dEDPb3oA/q1+w56eg+v9/UdRQgGtYKUakiu66NYRZ41KujVnbjGO7KrGuVBrEPJTfmC3FSmGuE+yfMMl01zoVkXMIsEqlKDroV9WCIEvJmbZM9oGL1LTqsPy1OyiVM4p1aQ1nHRpqh9JPRePuAN5lrSTZZOYsG3usMCYpBDk6GUOxkdd3zSM1zyxoiCEXUI12VH+zyNwaBVQjKyDGIF8Lt5glnAgiO4igKasw1MfisWJfslWqagSWvxOKEO8gvqGaVZZMfrUs0IMk2o8A728lldEaXmsIWL1ppH16AkQNzMAQg4kIqpyyq2ZJ+c5Gt4Fp/lnV+3fWnna4PekLtCplP2oo4SsjzHC2iQMWwFM0IeYcAKS6GvRKjLWMLljMxmY5Ll83xERoJWkNchy9xdpQl3wE1EE6TTLNzLCZS5pGc5Zg2/PbL96aBPETr8EZkXkTLnISrrT3If2kvRAhkr0DAti8hIe4nG3CHXpZR7jg7belwJxVy7zcDmCE3SLYOBFYTSFpKuc3qaB8ejvbYOWZCmtDPsJCjfw55UodWQGpeS6lml+WgDDbgu5TMolKka9TrZw2NYxcRKlEvSJzEuYLp0T69F1WKagmZUUDvp8qwUeRJlbbBb8gFF6VHQ++YNet30r+mPqfs9CHrfPN/KsbJmja4clCdwEAtSEe0NYBYXsSpJPZ0bwx0OTFWfknRmACkcw9PwFCRVIO7DkqkgLR1Y4riJIwBjH26igBkZC1K8IoGui2XvUtCsxrksy5zN9Oo+TMtJ7ChrFVlWeR1IIKzj3kCyOWURe3VOblGBMo1SNOvIW78t5HnGn+Wa1NPNQgXbJ4zMR7YILexxaS6yTtLKXegWkctympnzJokJbPopUJR8Vk/zjmpXbaioBW8C+3DL+ChgKUfs+/O8iON8RW+hbLK8G1fkSZ3V7VDI8xzDLwoHNb0k69gThtU7/DJ/BxJEDa7jhI+OyFcfPB3OgFOIaK3384J4QVIWuNmf1iv+oE9zEfiyZKZ1DKTnUY6TGcARUxbGOvZyi1CedDNWMezTuNvuTDslC6GupWJlGiPd5o9rhQDzRP4075ciPF2w/VnJyqTu53aJ7bXTW/rrdNfyczu5xiUeyFKdUs5gqGA/QvMOWZZEk8zLimQ3yZLRahb8Q2Un24xuPaTmbcaMEozy9AaWc425NvY5r9KmTzWctF37EazkezQNuTbIn3egfcU0bx9cSRxFHoGsyQaIB7jut+etWwawIGOavAgypi5NmNXlYNb6sPABM1impnviGw+N4yO83jdL0IvQb9O/DxEJ7wUN2v1Lhs6HeQD0Jkz7nzfbJIf+JjH5WX5FLmAf15FCQpc0c8UqqJiaPKEMBniZR2FZASlez06gwDc5XRiXM3JNV3UGl/S5gOHJBCf1QTWyTKaPA1WSPluNqkaJxqKakiSN/gjySmNeL/BMOpqJ6la/TXXrETWNJHwEXFYlk4e14T4lx/mmXDeLSOb70eo1Ji2bwJEpLIm67Rwgclqdzshd4gYksBxM2n5l2eaLbSjpLZlVKVZck6fxpD6ktD9g7SuZyhFVwaREpYpLGnKF9+pZU9dNYpDlE7gi52VFqrwjV7jsDXoTOtDglKmippfMqt7Nh3AOd/AKvlduj0Q63iK9jlNuEId5yy9p6HquVaelZpoD0kOyqCCtL9E+Srtc0oM8Jtf1jgypPi7LYDrM4LiuvDwNRMZoxNYzPV5KNVs2hc3K6uR3Sk7tk5fwKRwJ5syEGsi2BU0mAvKJ72HTnRHXPsYkLat6mhuWiJy089WLbZTaaZhG3T00S6aNA6xwzwJNOP0uOXet8AMJ/TghhmbTpUbNBIs8iW9T16WOqdFYqNxHvhU0ncSa13WAJty0s0CmRVZ4ro2yUc8Cc1LSqTK4ge18i/GD2QwtUdX1h7Eg2m/SxBOyWuz2Z01ZKVnEjl4buU8L/5rr81Hg+6ZY/iH9B5p/R4brXyRs/cWmxw9vw3nHqt/b77/V6XZi5xpxR57jk7KtDQLk0SyCo3xTNvmwJMdcDvSUNWr0fV30GiqN5oAc1ofl+/CjfJutafeibilFPFsCV3pUOlDnKib9mBpUq15rifrcGBmn3bF+Xzqq4vKEPq1zhQ4/9ONSZHH5Fco5OiKNaNczUsJ5+TZ8kj+Kk5I3Ilo8mefxTE/QuOmoFuXritd7gAKL53cukGddvFaU+G6NopF12keSNUXdgm6umb24jFu6wJ7U+ZL1BMvHUPKHfdLQkmvi4ziEQ3zKGDEyoTWv4iau4bg+KIGA894kUlyC5gB1vSi75ZicwlX9PF6TrwTFSxQZpj2hO/FH6EN0hQoUORTVazgGawe0xAO6KGUVJUdbk56hrKtpxiESj89J3kKpTSxP7PnwnFQkTyorhYQTnk0r2hnnuteSp2yj14+klLimDAd8kreRMeWgbAbrlKcV60Pk5BzfiTuOE1CR8j1qlY1uT9E6sTNBndT54IK5JzyQCPO9bERGeYUx7uZtwdrNOcqBY8OfPS+JqLIiDQBwRu3WSpdQY9FT6JToVZIptei3WBJbrztv2xRLQW+JRl1pUmuZdiLVJxe5jg057HdazVVjRatysm4mV8kM6125CZXEIldlm0+Z+NPkDtFueoY+Qh+hD9NVKlDjm67zR8s3LNv7NfoTmn6PMj3nvlbePfbmk/SZ+xyJhyWg7imk2L29RE/e79R+NbS9L3Sute9fot+mX6HDb+CBvu1k9kFwTNBz9O3O5+jl8U/KF+WaPsCrKCFhhrCASzgnGT0lvh/RRWPKjTKOHTmjrQjTNk5wgHNyHsN+l9TwBFdUd84p2Kf8Logsyng85lEwJNteb57a7+8z7kw5HgWDehkjKzGT1Usqrwa0aw1+ZimIFboxq4XLMGZJH9VzfiTdI1W9KRke0pPIKSM1WVZ1rXVKlnEOa7lBieYifkxFyjThIMV11RPQXtpHXoSL/CQf4PGnqWyRbIvZwewgAmtJZFIifJpnTERrmYo38pKMyzpOyAV9WO+BEcg6n+en+BT6gxEpasUpGFNCTZawC8dwRi7zE/yS+Z7c9zY9S59zb9Mq5UNvw0P0EfrY4A19wayqOtf9SS5pxVEZlQ3l5S1cmSQmVj/vCZhcryz6bZpkUurZhoMRY6XsF4zLlLTs1ggncFyyJsFlLHOZs95UotXrwqLOVKhAu10e1RUsq2SuXbl5ukL9ri0Ts2U/L6vJrLOHyMnRbFiK/tplkjqdXyVDiZiCZeF67l3qdCxH1x4jrADUqniZjirlyWtRiyo31yB9Mm9YFqQOI5O8og6q9gmn4sD2o0dRSzV/j3OGvAlesB5riMMU29VJPoM5bpWIDaTost8l3oguXtBx9rHM1fzezPWGp+k76DatUYGsTtZB+hB9hg6Epb5HYe8bvvws/aeQsx19z8PpSXriDVncw8p4Nq/8EfrBB9JSDnXSy3T3/ideof9Bn6CP03+ly/f9Bu4F04df7hu09NxQ8PyLtPuehU3zh0b/Ac6bNamKLd8rXpa6EiRxADN8HDet+SDfxAEzUuzMWJDKdpBDheOguhMW+uc5jwqOmA+qFe6zUy2Q6eHdMmoo4lg68Cz1uo3OVeJJs2z6lq2UlPU/HZOCVDjB40jrkrWVxkiuG3ld0S2W9RkKkw7rEiu/O+/anHA8kmjDEGYRB8wRuYHDqKpAMafURKpLZ7El8+jkPlXQvk5wPRir0ixlSFKo+S3W2Id3Y11msIJnsCm+nEWcx1GccRh6Gnv1Eb7K5/kAFrDBV/iweHrcT+g8Q2tdxSK2sF8O6fN8K/9K4heH/3bkeKTpTXflXNOHh34qe6GMnKcLPO41c0kvZbqFfomkWaalrq2/hxQJrDhlNY4XZQyUsl3mZdMpjblOMyqzeo/ckWW2Npn9C9HQNZekRxYlqanZiUUKoRRDsYsZC8IY4AamEukRXlQ612gnohFnNeQAv/2iyXF826sdlCXWybBWilZM64qp6flKzJ4jcmKRKnEjKqIkanP1G2RaeMJn5eMU3/aNnvQHvLZClLO+KYTVROS1VyTVhgXdHbTLLtRMWQz3BQ0528pJqE01nYxqsA+plaY+0fuTzgmn5U0HN0sv0cfCw3+ktvINrup9hf6fIXz4Lxv03LD4U6Q99AE6FD7RLIajny6HQrdddJ4SlmVE76NXaCHc85fvS0vdo6D9Nfov9B/p8RCk/Bv0kfvB7+9T49vkevZvvVQNnZWdUAXu20L8Q9RxohYw8OLE50tVlCH+hKTlBK7qw3hCluUYn1DtPChbnDA0brXp0nJL2PRzzbSIw7O6VIlyixnDcfmoHDJa5r3hXKNpRQ1joFF31mmmbjudopLrp3mh2K6pSBnKxqTDdCMhu+SCXJG93nTZGkz3qyXJFKJHadIZogaHQ0K6zMsCtAxkI0w+/UcqhlT4gIIeWOxfMjvCaYtJE9Yb8io+hBsWciNdMszbKsi3lilNepJXuVfZrKWOSZ8wI2fFlxKe4yU+oHYA2fT62XCO9+KoPC7n+Qz2+DPMilVKM/KqiJqsyS6zo88Flyb/dutXqNdq1Dj3GDqR8OZ0rZ2we7jrx+cPllR2XI+rFU5WSEWDXsmiIgUZQKOUgjZ0quV2q3/nIdFguS89cgAryKCg6gxewDE9CjpBeSqRZeImrTTTspXdmnHbKUJ1anI0HbBQkCZJacu1tYbrZR5gCpxBN/fnvBALNBmZoU87OuEvWpVmVeSKjDxuBflJwmdilKLOXfuIUlKRNkMTLoXm4MfoujUxOgmFMmqadU6OiqhWaX7KkbL0gtQ0V1IuMmo+G9VxqUuBZ7gjIL+BK1zgLs+r8uBrzV8JpfW/+mB2vzqOofnjl0IDpkdCot/QoPdD9P8IBZz+sqchFprH/L/oj+jn6c/oU0T0XfQzNEh/Rj9NrfQF+t8pQx79Ef2v9Cv0b+kIEX0/fc+DoDdAT1CdfoLeH/7+T2gt3OZ++m2aDMVC3+rVQr30QbpOE2Hmtx0GzMZ72rQtkUhf1w9iQ/JQonAcV1HSy8FAvpcDtmXqgpmPh20EnsVteIpUHvNlQqMq+KN6nGu6jGPSB1LDEASqgnMo6kbrlfCblIskol7Eb4TSVXGbXGnnQT0nkIouwpchcf0OTioFw2tmmTsVZSNDD9KnQSdDefKts1eVleofp21KRIaiY27V3W3fmUKZZxT5pJuUJ6uoYNMa/nAagQR+FRf0KQFPmEEUcVhmVyLcjDWdEPL7US47mUHskSk+ysdwBOd5h3ehIlVdxQG+gCf1uhlTVlWPGVKQOhZlk49X9sx8MfK91PTz9onx5keM22KvjaXmH4sXaglVqTQgxiOipcZsgR5LxDnxiiQlNZKJYE6OmHmkkMc1HEYa8/7AAhU6TMXvzlMmMumMhKSyNUeyvKJ7ApqNkNPzoKTc44xFUg7oDEmNb+CSznC3BRcfIO1MO+3vchGOOHF3xrH1VK9FD8BWM8/4UzZP99wBt+U+DNpOL1qctKNIsrKGviL1RwbdEbfszFquRRI6S7pJJlQCGjdkP3ye5YIckA5p0NqMSRPXpDtPQ66aVgWuIqP7jlIwwiv7BwafcL4cyoV+rQGDe9+J5EuhRMajsPcNDHqfpP89VKJ7L4LeWfoT2hf63/6/aYheop8jogP0b+gH6I/oIBH9n+mXwnW/TL9DLn0Xfd8buLcx+ll6KQxcf59+jRKUo/8L/W7I0jhDz9EdevJNr2foJp2h36d/RE0UpXO052F/tQ4n+uX0AeOrDKw41O7Q+ULhGA9who8qjQ6/m+f9JT4iG5mozPNakZZcLvA+aA20IR1M6DD7EtsDXMIKp8F+nAcQC6hAZWKWmnQFQ5Kz+D2o/Ax6jJuxE9ho2vIpsnIWpyXAlN9ToOOk3FRk3J11Zpy4OxWZdUuUbkQGNWHpK1h6vNPtTrvzsRwVGzmQXbImRZPRvQHlqWD7t2lyZmK5DrSjoi9hI/DE43Vcs6p80HxVFrkbmvdyczCsPSaRoF9qsqoP4xLO46I6hR2c1qcBlTRp9pVlHZS5jl1mOXuz/QdjQyuO89bddycWJXLOdXwmP+y3Is5VVQni8UZFIW+kmev+IPs4blJcxE0ss68npSorK9ECrdjpX58sm2Gm+XBa57sLVI9pzQu6tU4Zl97Qss+5Ry0ab5ADiHRxs+RURSDj5SZNNRp1593C21yAQw67REVKEXrUPBd0RcYLUZ603iBoKtK8O3U/6N2LQI2OFZfHDFbNaIH6XM+ZppibsixfRsGLKNoiJm8UB9S8JFnhmJzBPKpyhPuZdS5jMQKUtA0OpRfY+GOLDRPrDV9xJu/S241jeH2epaeo9T3zH3y0/AWC3vP3Rdrfi6B3k36cuqiRuulf0Op9aSmXXqK79IlwCvsv6Pfoe+l76DfpT2iAPkPf/5C0VIR66OfphfD/Zfp9+i/0G/R79Os0Ss1Up720RdtveO2iPbROT9NP0tOhKMFJOnb/IX6vFeK0/rXcSQF8nJILOIxDsgdXoLGJa2xbCSU+xRfEWjCuQOOSlKDkNH8Mp2WZZ/QKn+OsznFGJXQCe7Fq+vUUNC9gha1HqsKOnAwUirpsUnpQYlVaI9Bd6ouUiSnTDGbJNxrCIGfZ56lCo6IC7aNjVKclKtCq9SEL4cu+LzXkpLNAUxHjbpFEzRiUFQNQK14rKBedaSJSzVpQx5CiVds3HNYVGZskFcOMHFArapBzuIrTksVhPispnMTBfJIPeOOqIBNi+9d7+AAu4jpu8aKklIhv1VakgAW1Xlke+PHIHqIm9+1q7FG3x23rbXx5aP9SxtNqpES2O+q3yoBMYj8Ocd76j8Byb4NBYlI9XMg0kjPdcJdyPbyoRuy3CwtbdgLcKkXh0cgemnZTD12Mw45xS/Y7ZVDVycXIISIH5FkZUEvzS6gOQyXKOLNuv/PViso9b4JeB64NUXsdDGtlTT8x9oyjqSEk/fkByhjTtESpsFTSEe6tmVoc2GZVn1R1fIDmaM7toAZn2CViKJmOjEfjsZz1q9MWbM7t2Cd5meATfFTycklpGfG6paFmrT+bZJ5LazMtH4wd+CS5Eefti0CWnvl+WnjkiPaNDHq36C49+bb2xF9f0HuMfph6qYF66A9oMRQRdamTvkB36cephVrpj+iH6TLdoet0jdrou+h7v0ZP78Uw/HZTmp6iHTpFv0o977DPFrpB3v0tGPpI6JTbcN92aLHxNT2FHA7IUzjDuziLUq4JvbwYjIDyfVjAAg/KHJb9LhhsSxHH5bYU1LD0oYALnFVzkkHSS+kzfFSlOMsJngoY+0Izx++Vz8qLuCxrYD8X2iAWEdjeAGdMXK/Iednnp2VOEjypxwXYxUewprOmr9SmuoJev8tvk2Zu4kbLMM01S0YX1UTBosoGwUZkbJkUeRO6iLm8BTU7ln4mE1KSJNOU45N0oyB+IcJUbBTInCLVyZtiTCMv8yGexRkcwR5cxw6u64NyQjZlP+/HYb6IC5LKTcMTYSNFLBXyqQstn3P7Yo7zDvogjdFWajje/pFQPr0DM5yGRhW+ruIURq3G3Jo1YCwcoF7yu3lVDc3QeHQ3SadaVkMezYabnosYUv2yzPE47aJZ5yGclDPsbpCx/hkVGNNpkXyz7oCbdyxSUTVgFL4qM8twMgy4027v/aMddabdSQLNNfIcF3SB46qnYv0KnIIz6Fq7npoNXDWNbEuepiI9TsdDl+yUu0iqTZcRJCLWe7eZJpxhB64Cc4r63XiUSGsd7KMq5bpRlCg6ZEMmpMwntS95KSqFJI90NC5Qv2n+LnfIciDf4VayycUhepwaHmV635jFXjVH6C59/D0Kehfp34dOGDfov1E/vUw/FfJx/4Su0x/TR4noV+hnwnUv0w8Q0efpS1+jp/d8+P6P0efCn78arhd7y1eDtb8KC8axsNXRQHfo6QdHE9Bfp5RQrkMO6Ys4oU/oW1i31atER55kwhgZu02FCEpee7nb4q/MBArIeHba2iRF9FkPhyplSGegv2Inn108xyWpa9tbPC6ejHGOF7GMgj+X79e9MsCjPBH0c1KO4iBEpmVecvDgQ0kuBBXvVif5Cu/oglU/QUHl2dboCrqoNPtS5+vyDG7hKlbER5wTJq7HkJMD2Itsqk336IGpJvSpVV6Qzrs0Fc3FuIjFXJumQiOKzIZGXBTNFJNK5Sb2E5fQg3nkbcjFGk7jDC7xZbmOp/UezaxtLioFv14Lxl9rvOK+G04z2uBQtvnV5FoFqOhApzEpg0GbBuYyLaia5mKrWTcDZUc1qjqnCzQR63eCTqxgIqDRSJvb5Y5G8iRTvImZMvW7Q26f0+P0OL1Ot9PizkQ0ZVuM8CImAvcUjUYH3D5n0OlzhiNzEQple1QfJ3UFJcxuRoth4BuITLuLtESZTvioqUAmgrYyVajLnY30uz3OoNPrjEV6XUNo10ovy8weijnjkY5wz+He3aHoXdJNKOv6UmO3MxTpcUbcRicX44Kov+Mk3YFoOabXJJ4kiTIkLyRxQZ919h003RjmWWEUVaWeG7gRuRJ5N/6ZndZm6IWwvfcIvPINCnrLdJe+9z0KesfoLv1b+mW6S68S0ZfoJ4npbhjunqO7FldK/4V+n/5eON116Cfor78h6HXRr97v2l6gu/Rr9G/oX1DiXQlyzgOcXyfdpo/QGTpGt+g7rHhVyvU9HJeqFllGAuv6vC+8INfkAmOuCdbwp66TcoO3uMPvR4UbPDeIooZMzYFrPc2Qkk2ekJyUUTa+HlctmMZqplvTLBUoiKgumdO2+pQotVm2ba5HVznhNdj600LEuCm3HMnGgkaOttBSJNeVm+CybIjO9+sWv0O6C32ZfvRyNya4hiN6vxy01t08zVMqbTzkkNY+b+ESLnBNBAtSxoI6KbfkECCaC3xMrkjdxKFxRc5yAuCb2FZTOKc3eNa2OfSGClDUC7Kkl7Gp9mvrinY+mMMkp5RwSZWqhcHPNC/bFsI7j7NLTmPr+wc28l1e20K0M2Q7oIPzKRfAXI78gKezlvmahPcEBbY/2qCrwZhHM7RwT1iA9LhUpB+UpGXSodm5/XeTrpJQdkDqQdpv8UnRC7REFm5SsBJU1mibtihjLRip0CxDUKooyVqjsTkw6X7FXJA53cXRbCg5v0K773/u3uf30LDNmynfx3nBVtRWBev392+obKVGadmVhBTWY3naJkWbdm9RMWZekQU9B026yt0ZQkwCPe5HdaXYxUPWTNKyZrYd05jprHR3vty42UttzrvOrhrpGZJHQe8bF/SydJd+MqyG/eWD3jX6VTpLz4UmVRYFUKQ4naSuMA87Es5KkvQsvUSr4dqV0PDq9UshRksPzL5r9BLdCSWi3hma7L7huzSSojN0lbZCrRfr53Acx1Djsj+llA6KMT3Au1DTCWRgZBdeldOyJitJF8R1HrMXsGTEJJyA0FBrlUV5UpYNI4N+1Ro0WFgIb5jeLRqPlt0R12JyTMS0Ylh7kudFPqS3g35rNtgZ4grv0h/Qj9F5Oh8e4F0qkqYFh9uRNhVRpsNQjjRNxiQlFT8jLVkaoFw7tFS9EaKy40d1A7uZCNpFyao3YZp0q2nymzEqG6ihz2uXTiT5mNRNvz8qe3DBZoh8WQ7ruFzRR7mqbmKDL+EIX1Cn5BJf5WtySz0pL+qjKuCyBJJXhWK56wsxj6j1nW9BJ+ISOS82bH5PLDGYGcgOyaDfzxsI/BTvzXUp5n3pwWy3KqidTJ8MSx8P4bCqpzuzQ95gbijXj25/Qe3DeLYrN+INeYP3XrkhfwhduRFs8Y5O+d2Z/uzw6+++4TXkDeUGM/3pntwAp3lJbWOFy2oXdqGoJtHr92YG7Dpv9+nMcLZHBqSijiLQ3dybe2i93FB2SHWKqCN+iu8d8XCmV42oQ1zyO3g43W3bX5nJdDt8tZPr55S/LzOEg34m25sdygymB1N9H2iMfpiknSKu+85BLxLOf2qPgt43LujN0V36xfcAMGnraE/Rr4SeFvSmYPVmjWN6iGz2tWu9+Qi/nm/zQL6q0RkmXcUltclLKm2nKibGCmtBZ0CK/C5VsKY8KMt12fYTalOXvmQJZEOqmO3Q4ybP2hyVy/lxHc1Hs87FkAOrMtZ8x6deJ0L7aeAeaYy+ZBV9HZnAUdnRdQR+UrVknONUpbvkOhkn4cSdCSfUb3PKji3N+262RSVQg7GyoKZq0tJm6Vw2TILY9ft1lReyw9NhfkTOfpu19JgaBzPNmrbt0yQiohbRbgWOVAcWOWUFkFQCBZ8SjaqCKY5wzQzqEa6pvlBHr6qqahlWLfk4LutLQVpSxnCFa6XVri9HMraN8c5BrzNCFHtp+Nai79e4ylUU9G6+zkt4DBuoyRNYY6htfoKXuaiLqPETOM0Bl1HhKgLU+TYuocwFrnLl9RfyUuCTfEsfkorkufzGd9/iVUWZjQIv4Y68gpf4FTkleR9csO+962dLOuBVXOTHeZdoLj38nmXO8C48pU6KHZcyqpxHXe7wSWhdQSDH5XFVFMFpXIZSl/gYdvFjYr+PHdvKkrR8DymiyLuMY3gXPEuLj4LeNy7ojdF/oX9CrW8ryv71TW+/Nwx6r0tLvU6yjtyfxroP8jPna/boPCQt5fyFjug+c8NxzxEP4jGc5FWBGDOru2UR/jIZ1+/jMup+UtVVd37ClAsd2vBVrvOCrMhTOMlFwAximuu1JhtUdlOD+0fkR/KKi9mYphanlyJh2kqUc2z5MNQPruW67tJcTI2IwqIuqmnTiqj13bhN5KRCerP1mkg65DxnJ4ZRv5/369v6ArLSpK3JjTPmctg7JGtNM8FLVvBoOrSwJlqkaRKrnTI349ij6ibTz4u5WRVJkBdR0IFu2utwGttBl9/DJyTvD8tpDV7DDtblkhzjy3yZn8BT8hSelVf4sGTY5xRmV4Ya3u8E736zWiqB+76GhXp0IJq2lt2u8fWITGkWVxk1nSHTIFXTV3fGKYhaxZQpyjoZV5wqcatUTC5w4k7O8Rx2lJNyC06Oio7qkLwEuZY4pchzPNd3fMd700s5npN1rQeZpZShgbtZmbKOxxs9F93MqozZYquJWnGBopN1M/c/87Vb8dyMM0vsyKisyJxu1PQ+yrkZhx3fybkp5whJC2oqYSKzBDfn3iXVJqtq3ObdcHVW51KOrfnKaMGRBTSzeAM6JDQNNFRjkWecKpH7bkHP3gdPh8/LR0HvG9S97aE/pH8RTge/NVrojgXX9jmXHdmRp3CYF1URCczyogylI0G/FLCMNIhn2F+MmYrp4ma9qYsaeltekhuyjCWe92d5l9+37JiwKLlFQSOXdb4SuUu9YQgfpT4aomG3ZIXGR3gBSFgD6jAEguoRPWaKuoa8mkZ7EFOUtM4XTtIdck9ZNZBmMypFqeuJFOl268oq6VLreKjAh5CxEE6cCaNcYc/rlFiRdEy1SHPQK6u8pie5I99n+n2PT/MBpVVGQ87JY7LMGd6DO7wqWp6UM5KXK1zDBu9BXW/oOm/xCjZkW+3VR2WvF9HkNWbbq809LzYeIqffedcHZH/Hh+cPL6S8JA9yqxqWQroNZb+BZ1XVa0xHsYp0ndbcoosSgh+xvSmX3BxlengZc2KrhvcrsC0OOQVrzZOWdZ5tsgmS87ZmiU6j0+vcDeeDaFEzqPKCik83FENKWSgQ2s1GlgDTrxuK1lve6XmHrdm/F4lbuKAXVb/nHLHh/oHIRYUkwiUtfsMKtbqdEav/jN1qokIl8pvUgsrMkR7XK/kYz6ic16XrugWdalx5S+mhDzceIXfy3cdxiJ4PjRAeBb1vUNBror9H/zbUyoy+B9tz3nB633mLb/TlcMOe7Fcn2ff+537d+w+zw8YokUnoF3FFDmrL9hSYoAW9XNRLMn/ZupY2oqIHpCC7MYNTckmyPIKCnwZ5DabTgG+pAwzJ6Wn0FWJBp6nprKEkjbnaGXUGnPGQhlaxdtWeLKuRMk25/e6sk3FGXLi+U7DBrxkzxmDBQI8FbeLam1QoiOkxWDHSwXnrIeEMuy/YPCirl3RgptCbaVFt6JdRNelPYVRbYdILOCgVUcxS5iIXcQw35BxqnNNpfw5bfFHKPOh1Kc2HOFG28Ix1PXqApCrjk44uoN34ktVp5DlAXspmAVtyHNewzjOq6K0upgdORJ+nlnepn9pzuRB7ITFaGfeUKnEVF2QJm1yUHl6y9UmV8WWRos6YKwaFqDPgzLkfoxHS01gzI4amwtASoQlnzi3SXcoOoiaBatM07mbvS5C8eRmlpJN3NkhRwboFp1HlIBi2XBqXOh0Lh2tyOp3Pk6ZUo4rrqhS8aWm3GeEvUs2Zebvv47Q6oYreGBbho03Rn5Dv3Pv67U6z1dHTWDDtFZpxpx1NxV7ZUiOG8k7QhQXp9q0moPjNOII8Tugd5Nl4ua2u1kXnxVD05d3GsUrPUfejoPeNC3pR+kH605D2FXuPg97Xs0Qe+s15w/++3pre/UPwb8urclLvlQryuTiGteaqmcmSR35MulCWQ3pBrsHyW/d7DUxmUJbyrbkYObpN6jIxR94Ap3WghFfkirYs1s5UpBJmftOuH7WOW3oMdZH+0H/1Fh2gnfuuDve04DjsHhYcnpKSqrEvM5jXHtZ4XanMCA/rKR1Hws9CIadzUuVT+gpOqx2piy+eFjbIi8IsZ7AiO1iRSa8xaAmaQeOxMACO3dsXd4nOz5smRblOlCSTdtCndvN8ogFbkjQ9vGzGUQwdJrSq8F45Ljf5afmQvAgjQ9MtWct2/hil36Lc8PCZjVID3aIjCboQmh3xJDalhqtG4TIOm2HkZW++5f3OLKk49JPOBiWi804xKlmso7dMqfvXRiLM8XLtUFwvTCVoh2bCYNjyNReDonm33anZimkzj4roCpTqLlKdPGfETTyIIJZ9Y9mzvq27TlqDdp1Gv2VubFHSnXYG3vILdTjsFKjSICw1TGu3SEl3xBmmZup3Ek6eJCer6C+RH0lEyhT0Sj3XAcrFJIH9wbSk+Da29IJcZtGbYxHQgi1CtNDHKfeu4xij66EF6iN1vW9YVc+h1+h/hCeh4T3Y2j1H2ntXbZl2kXM/X3Pui787D6nIWo7966e9l87RU2GpzA0FcS/RJRp5l6fhw5dXJLwHlumcc422M8eDj/FtfdysIG98zrHo0S2b3w0jrZXU5YoW2dR+jSTPgz9J3Cfr3DfhzkZ0u95gv8tFJE6WMcEj6gDKEvcDJX5GJlSnaTCh54I/ZwpB3yIVG3ON3KzbpDPoCfp4gIcwggk1Y+Kcgc+en5Q5lPmCvIIP4YNyjWvaQ44ZinOSwpyZ5mmZ9Ab9Nu7EnK03SjboToVmhnmqhw4PqagFVHBSOmzDG26e1KDUkcdAgrKk28Qqww0JoR0LqNiql94lqWwEK5iUTlW2ThBWCY4v4jHcwGV9lo/rc5Iq0T+iZnveD96HhTvv0KbS9ElnbMhtjxk3FdUFHhJPOjDBG/6oLsltXtDQWd6FA9zLbemINbTkHIqF1iM0HZl2mpxuZzZSs85Qs1yDz011mnMHnJ632NmQMxdSynIWhJ2CzW9nF5pARylwJl3zFgfY5Shn1LHwbu7TFmKkeTLXZK2BKs6c2+K81fN+NhQaMCNc5rx0WwxJ3G2mIWfczURKhEmpoN8KEZQb/VbJ4BSshiFwlC9hilPYlXCQ9CeRlIRHM9GmhtBy/tX7yNG3r3x79Akaf8fQ+Gj5/3or43G6S3feIxnR6P12hf35/hBafO/3yBsmvPcsBH6YvvxAcGCK/g79Hv0y/XFoAjlPv0z/lP4p/UNKvYMas/NQWmB/76On6FnacXboZM/fSPxY/oTaw3VhpM1UqUemhaWiC+KZGZOHn+mVQtyBSL4U3YrKohqzrYQtR1inLB7M1nDKxFOmwI2KVhyvRcYVyyL22QqZ7MJFnJCsGkdCMgDynOciijrPRouw+PB0FhlJwiLigBVeYaPTSGiPywDGJ2IWI5ajNFl9tyLV6DKdpDwp0t0mo+1NO+1ZCK4zH5uLWWSR6WNBLcgWWgKac/dTKoIkVzkbb9RUJ0zxMtI+dbqWKZFtWWpAFYkpVx+UBazLY3wIx/U+2S8ruq5WZR0H5YI+GfTMuiOWAthEr4aWu7G3HO2G0Fjgk7Rkx7vdecpqBed5HhpNvMxtHENFxjIx3a7W1QnlScAlTsKTvahs02aIh9ukdGQuIlYcNc8lPapoNyXD2775TTsbdhLuVtgcwAiYi8IYW3dAzxDcCWf6HS6+bmfWZadkEZRtiLPhAlKqs0o1mnOn3QHnzRdPB404GTdPHEFGqpKxpk0SiThWHSdHYp3W9smSmTfMZfG4jnP/n/beBEqy6ywT/O6NiNz3fV9jy9je/f//vvdiz8jMWrJUi0qWSqV9l2zJlnfZxrItI3kfbzI22GC8QJul2U+3YYYeaMCYpY2bwcD02GZpH3Af6MHDGQ6c7mamJ+fcm6lyaSvZEo2rIO87pVJVRUZk3vfe//7lW6hY6Q26TSQbhKBAlntpmxapQX3basRdqSm8xTPZu551HwfxDq9qdBjyvqNB74YDAHHqBZ+Ifk9pLB30hzYQYNAbP7oLYBLj/vc1ZA/C1Sfx8QM9PY3H8TcoYBgfxZcxhvfhz7GOHL6Cj/lLJfmMjIwEJg5mxS5z7MOr8WrXUfFvXuj9yewbq5vcZGFDZK0EshyP17uzaEGM6TUVGqEhqktqGzYMq7lUMFofpmPmeGWGVjkTZGiNTvEDfIwstbhG1rnROi6vOUoPyav5TocBpLOmFmR5kkYqo2bcjNFwMFjrraeO6l0V+zKXp5xReLDKvbHrAWJFyYgsC3PNWlkLBp14QU4XEnPJicSiLmijt1BGOMxpjqUmuUav4+zm9UrylBtzTFqhTc7bpGviH0cwymKasuwAvWaSYq5V+wh2lY6bQjjHd/HNNpT7+JSNeFs2bBSGYcwdOkbX8Xm+TV7GNWBNJRIpYBY/4EUh4H0d1IVMOukfVKP4EF7m/qR0QaU0tWjFCcdzFOYBbnA+VhbBKoskrkM4TmMs8lJ5kSWuCnOa56Phmsucl6XG+WzXMawmZ/S/f8rlI5jXpF1mm+42aaoFNcnS2IYXhWK9+i0Vg4Q17bqALRRTNC/OFJyi6ea+ML96KgBbY0ylE73OGXfSUZFpUNBMyGSwRBtcZQnr9h652czQBA1sO5ZuVYYqiPukY5clIdu8YJZtTQq22MDWvurjDD7hWeDPvI8D+J/woIdVHZa239Ggt409fOaCX9kLgaycxc/ic/gyvoSjHrX3CBbwFdzv/+XLvvv8KfwlvobPYs1LS33sILtM4NaDG+4kvgyDf31AKLsPX/CmRc+2+vAaPFHr1PB2H0K7VdK/a23yU9EOVd0wwkxH/Zt6LBEMVCZ5hrfNad7kW6QkL6FrOCdn6cUcUmgt3ca3kxgjLEWTkRv4ZrtqJ2meZmmKJoJxM9pMyYxtcJH6ADtCc46CRCGbsBjObKUMHAbQ4e1SKkQtYbK8SQ1OR4M1nIbRuQRrKMdOqCbtOK2SSJ1CXi2lXNC6CWt6Qllk1LhykgRhdzwnYttkzLDFcSwnphIN9CGYsmI2af3Lags5NLQs8ZbYdBc5JZcSX00tk6ddfpVczbPS4VbUFdRsNl6ViJgbXJWOPUYn6Wq6gV7Ct4VjoyrWB9n2e/AyDF00EnrieojwQTywr2y4otswaRZhWQsW7daC0yRpcMIizMiWHXgX5hIMnqI2L2cTPGTneJUDiayhbXJ84OUNrKCJHcdkwKKe1eMOL4NJTCh24BaUhjmwjUCCpXK/69P1q5ye/7ZChMNEVvRd/tKwY5IxNVMz6TMJwVWY013+vXrVpFrwIlcNbKOAImopqdFdcj1HljmyeVm003Gq2i/GWBdMd5MLDpy+FYzEkAnZrQyFA7xb7hNryhJVR0SZ/ZJ1Ge/DKw7EnZ+8j4L34n4nT3iY532ng946/ht+DT0v0BHNBZzbsYcfQIhfwNfQgw/il5HCj+MvcC3+yEsOvAt/hi3U8Hn8OIAfPChv9+EFbpY7iM/hsxjDr+OcvzBO40tYQBfqOIEjOPqU4zi28HL8a7zV56i3eI2+/b6kSuivo+eTxTOx07QLOeYWbe7DT21D7qIte7uU5YQ9S+NS5lvtQjxgBo0NNu2A7eKealcdFJrYdDv9X4JBzYEcsAyu2J14GrgVLnhtuVFFDw2ZedqQkLekSWWzWur1xdEKtSSihaAnxHFMq7Ta259Hqqwi9Qg2nRF1F4+YVWttx9jK4mLKFdQd3Ih+VVBL+kVOUS/Jo6ZAbRPTdIBdPwYwqCbLUw7oQks/5LNJ081luYZbVBCRk/JivrY4aie4IeWyI4U1w0FqWcN5ERvYSDq8Y3fpWrnB3s6v4WYJS2ph/3Ydw0vwAdyKjQsOhpNo4414Pxr7UJMi1lSt2zbNBlUrI3w07HEWS8GAQNJyJOx3fhnHYDKy6eSyHPHM/UQtTT2mJedsjUoUSkdiLtjlwrAjeFU9aYxwtd9hO+ucO8JiNBGkmmijpLJqRj2fCJHEkgqVo5tFKPdVFo1zsSuV+t0nOmDQKcendtKhXTIl6xRwi9pkJLDH+FpJt509E5r4IbSwrWWDt2RwEtOJGsy6m+sWYHLUCUFpjuyENCSgUojFJwiVo7gHH8LtKFzYxwk08Xq8H50LBgmH6zs6vx3BH+J/x9ILBK248PUAPuclAFbwNwjxBvyCv5F+Dn+L/xnjAL6KX/SeAT+Kv8IgPnRBWmo/3A7hZ/BXnpr273C9f08X9OYxgHvwCF6P73rK8TBei/vxZfw2+rye3tVPEqRH1w8Vbw+5siGzwQgPUD/1UrdNmTIX7QaXqwPcDgaKoKZMll3hlaZmQc3A4e3aSdOQclbvYknnlAMMr+oa7AwfI2N7BVBptaCK7smOG/yUFpAu6rfTJuv7fufpLj4Vz9US4spOv89Oo7mIhv/OOkirDfUiXO/a6IhTzQFZlypvhhHNRAn3fnuAyquSeoNz21Dl/mDNtm07XDmmTsMJmAvCpLMM501al3kyXJOjdDvdLCtR0vZS0bQyfSuKQj4GbTJ83IxTXYwUmCTktj1ir+Izco5v5wfpJcHUF5zk0n53NIE1vBhvw1sPjsfwZpzw587h5VB0jhMbItySyahm18yA2XHwXLvOx81w5ApzLVY2qW8TaZVVw8p1IyuzvBUa27WKJVBvNMRzthjGUpcm1yQfT9YSTlOFFrhuGsGa9J5WFneDVUbV/AfvPY/Lcc9j5ddRVErtuAw8xSNhRVpEMuDwkMU+XgoDatqG1APhtBu+SFcBPwIZp02y+b4Ic2pEs9rDHuwKn+S54370QXnaqvTfAkMUUoI2zRplpMWhHbsDhScUgzTWcA8eu7CPj+ItOPnEPh6Gne980OvFT+OvPEL8hQa9l+JTcMrfg/hDnMAbvZ4e8Ers4bEDGPQf49/gV/E5/Cym8T0XREQTnhnym/iPPn6M43dwnX/Pa/AFzEChB91PO3rQg168ES/BoP+UU34Ys9/fcz/HbOJ7ggwXuUabXCOmosnKtJ3lLZ6T0EBiXgnBLmdxAJOMXJXtHcRysozYTUBzon4UgZrcN/tGPkWB3ea5grLoUZkL1UkaBRg1oqAehtNcC3upxKe4QxUrDjVmKrxY7xcdeKsZTzVWjCIY30AWGRcE1XeBsIQoURyK0tzkDgUybVNFZT0nfVZDXYubXJCbcRQuk86lRNd0ZTCY54pcRy+ju42lgQ0n4L7ARznvdIbtEp2srFUSkuOjcZ8syU4wzbXYSCWIbUc2aUd27fV8E93ND8tmBr0q43QvnxgNDWLNW7qVMHOQq2ioJJZVGZt93KCaLXJe4nLSHDGFGGbVngzHjJs3OyPKZuhB3Ea9HSEqXYb5iJ1p6V1Ae9FRZ4SuJFHsro3xIudsRKfpRnsvnzcF011W+6+o+bCVUBUUkfUK69/6mkKIAgroV/twcReMA5fXJWmE2nQX38nX2yMcSLo8a4Y4WUy4MHgcD/gHsMB0mQod4UWjTgOqpIAyaMackDVAVF7ZQDrUcwNkm3PcLx2zSEItyT+ELrXnro1v7uOqgwM+eR8Pg87lEPQUHsMe7niB89v9oPfrPtML8HcoeT09B0z5Cv43fN1zDf8Eb/evLXoO/kcP5OJdyJvG7+K3/FjCxZN/g4/7170f/+sFr4anHkkfKLc8qnUf5PLeg0QKHnL9blyfA1QbiwkzSHOcIStGbufb6D46JUfkfKWHSLajvg8gmjO75W7BES2wU7Ir69cBOq+WVVF90OVVk9QJ4lJP5HEbKxdpM0yBsYtzbmCRdLrFcoQrxV4HMzHYTIZTUpSYWtziCs+VB8KU0TUITmIPt4JV6DRJvPGYY93W0EFGmcGgSE3bkXJpXLqquo7/jA/jl3HC2ejoyhR1+Ca+3p4Wl7llggHWvBxuWtPoz4LR6a7EvB3N5NRGr21xo9IdDNkjZl6muW2WqEpWImrxJh01Z4NzfAPdyQ/JgzwVoKQ2nrgi1NOukYO/MfoUnC4hNSpzsrOZ5ApZBi3SKZpyMTLo4TaXQ7wVE9qiiThhl+1RrtT8s2xA5UHYwjJ6FfSe1zeJ3K6FfJSaEpAhS21qSiGaKwyEXWFiFjUcwxl8AfciVFal1TKiS1yC08hgQ7Fqqxj34QgEa8goSRZ74lFHl6NNrhNJxVqnhC25oCdS4rwSVELPI3bKhihCex+T0rBsUTUYbuIIAqWVRdxPHVMo6Q38SwSR2SqlKt18XIbtMtV5ybaoFowb55D3bPt4GPAuq67eLdjDIy9QacWFr5uxh09jG7+HLwB4HJ/FEH4fv4okPou/wizeiD28BCfwp/glAD98QVoqiU/5buD9eBsexiDuwd/jPtyHv8ODl/iuLvbHVd4R5sPYwTzmsY634J37zF/xoJAq1pzwU580pcI7lRzdwyJn6JWmLUVp0X0OcRYMxt1mmU6YGeOFjX7Ek5ykxxTohCy76V+vurjQGkZWjSvX7zPdNM2h6UiOu+KDyzvyQayDIuIemeQ817htI1MOlmRQ+hp609tQ/zYWkFV5VcWmc1nzxaBFTldGbYm3pGbz5aFqV6wlVRyildCwpaq0wmN0tdTstPQYT13LdXOBd6RcHnIN99IMHzFsBhdgy3SERprdfCwoVMZsldMUSzVoS5u2aZdP0Xm+W+6XR2hnQ6VcVnPxVaGfbL85jXW15qWkaDtc405l0i7bduAYzsedR5y4ActOuBZgXs3rLVRc2HD9wxEnuK/UK/zp2EJWTesHQU4leYDXbJ03KR0nQxwB4WyyOGjmqEh13rSxNZQtzgRD0ltJ7BPznBOBURtewOGbissDKCOjNpRVCfUTOAtG3fkGp0w/jYZLVGTrsI9sZZ0n8r3uMnF7Xx0WNh2hcIZ7KhD0qbJaOfhpN9Cvyi5vzfIxWudul+0v6G1QkuscS3cBAaTGjSBRGedt6nUq1LZIxyq5gnKdwEvt4+G6HFbCTz7/Oz7jR+z6BQW9O/Bn+Dz+CL/syaavwZuwiS+iDoUKfhM3AHgX/hhfwc975uFjeMPB6GQAP4wv4g/xZd+hc7XMo/ga/hjvuAQjE08CJ+//Xx4Pe3Plt3mwtf9KxgzGVL/aTu6BhYrUoGFr7HJN05Ys1zTn5S5uVspS41jO0QPUknmZs+N2uJaAc3eosz2qxH9G01Pl02pJuXHEvHYIu6AvWOTYtDj9Iu06UBNqXzbXYgcDakAbtYeO81xDLkmzpkhWWo43YZZkzPZVdR4Rjjk2gaqpJbWssnpB53xtWYGMishpPidX8SnaknK4Hk8Wk84qsYZglVrSlnUHV3b8j043G+7YooxUMAypyFFZbetoTK4KC0GKhAxNiqWSVLkpW9Kmo3SKb6Q75D77On61TAPpS9yYaxgD62Ud5Oi4GGYJgnE+Vew2o3yMFj2mbp1P2bk6sjqlmm60kpGjlN9EB/Oq+6AV4ML7MUfFS/J4pSSdMKa5LUTYw5Tu16RwwGghrGuakAwHznhdalwyK8FkOFjpqvosrI3zqKlQ5fWqLmhRrg/S8vayjUS1l0Z41maZucUNw7ZklqOBOf+I6eBetDGhBjSrax16sIs3bJvrdsUOnkPHAQdURvX79nIWOR0i7nP5cjAVYBM5vaSqKoxliwZco8LWKcy7QdGmGRY30W/Qth0GFg4D3BWR6S3hj/CHXggk+YKC3ivxSxi+gDZVXrz9mzlZnw9x/Rh5xnT/4nwu4QNh/7dVEjwxe15E7uAr9TdzgUX9MUSjUg1tuGHS0jjmnExLVQRDUq2MCh7CCsKyOUlZXpbQOJhxEMV8jdwhmzxppmSYuo86PRUYZ2+gZlTHTRtHOW+a3AhX8ipGt1rWTxeQPIJBNaUWNKsRP8Opw3bTJLlOVo0iCexKZToaLKgGYnwMv4SOc0RSPMgzdo3zXOa6OconeFcadi0aC7oc1HZIS2LQ4Q1nrQ3rVOSZcsLlWrUhQ9yyBRkuOMn2ttTMZD+scNMM2lVqBGuuvJW6tGVTjtO1dI5u4hfzy+kdfNwqdYmdnkdabaEybDalw8Y0S328Y6ZNH23JikVTS5E7NLaL9eQ7nbXjDNekXh8OEapZ1XVAKdtUm07ys19WhLlB5eKIl/FU8xcYFv1qWE0rUqR2UPdTVjjR0CnJiuWqxGSpKEs8wyOFrqoX9jrpsY9AtU8mZJbS1kgocVi1Aa00RiS1iRpCnEdOsRI1qfovgJsn1Ip2/b63KF4QZ5FUoOmqNrgHotd8iTqOrH4f+sGrtMUlGWAM6LTOuDDXDiermNfckKANCm1JZrgpAe9ycV0dZnVXQlfPAYo/g//i8fbPv6vX5YPer3sZ7K4Dp099YPnzhMqdPgBAJy/8+zeV9hIevrn/OuXBm+rbhkt/8/0uCqFT6IGjnhtneliXKdmq93FRGq9XNGi2OH1CtdVOgg2HuaRTOInQxlmE6/Y6OWMrlJE4aEgYsqkEeVo1czLiyjQeojUyXKF5N20VvZFI67RaVqNq4lm+uWG1qFe1VW9FHYQGij2VOckzUyOMqWTm46Ggp9rNgzxLRY65IcwFs5hNujwui3hGyrbBcWVDpsspxiCMciOYeMyUTdNYWa72xC5LmrBsm1ys9BQcvOKobARJXjOdygIv26bJWysNadmO2eKTfIbOy738oDzKDwcz2896u6462QC1qTknp0PDrfKctGilnqRNSTOaPdaZZHbvYSkZotVny9ySdeAMsok99GHBu445aLYd5ay3+EmH3YQIWb2oi8/4iRXM6VXNeki9HHWfpZ3UZlxWuWCF60Yob1ajOZ6QMTtdWQzSUnKhjiqSDebj/i0P5DkBoK7SeknPqOuf8cIfV2u6RzlpVzsZVmydxCx1ugWbiPW6HlcDmFPzmtHsZ5Y2L47iflSTJdh56tjVIihFzSC3Dq6bHBXcOaNdGjp3OJ+9AoJe4kDO/YEXlOlpTx/roPdCzrVfmuqDnlviwu+JZ9DT2x9XJA5C5BOvU9/mT+Im0Wfx4IF43cEawrKjo086ZFuwTHWzWJmUXTsQ9FOHcsZh97t5k2vFnjxyiXzqDGy3FKRO0yEiBJqSxT4ei+YpzYExQZHInOTzfAu/yAY0EvQ500Zv24MdvAwTqqoyel0v6BmVe0Yoxaxa0YEuJ/pVyfmm4QZdH6AcH+Pr+Ra5iW4wJ6Rkh6vOpwuEvM6kiskFvYUApW6eC8oU25gLZvaojnC1Fz0vDZh1jqJalDcjVad0N2Mtt01xBrbHS+XPlLsrNbbxDFecMYabEfM2bcuuOcd32Qf4NfJ+uhp4Nj+bOQRqFMEg7TqfXJMVG3IRpmVyBON0R9g5lJ3VWfCK3WRTHogwonNqHnMq0L+IhnMKWAyI61ThWdYN3AnSC6r7Oc/vqFp0PriJQjJ24v1ws9w/A02FRCflRrmFb7G38DnZ5qzpz3jxeZeJR4lMKpeY17Nq+TkuF2BKrWvrZQ3iPlqj2DZoQ0ZiNDCnnPnQmIrVDYicMXnT1qLBCuKuLUdQOyKVJeR6TNuslrtop5KWkJt8kngPicOgd9mv5AEr4xM+v9JXdPC+Hf8Z/x0/6z3U1H4DfkRl1KCiIOxEzHnmZoqP0Nh20m6RYc2IBqhjpK47WNW3uvJzQtocy4hBIRFqqMdR96MQV9pmQQt2y5ymFpWDnJQ4dGUXR1Kx63bejkY9Y7px4P1wBlvK6lCJchY4A8pJFibVmGqoqnoU22i7tn4vT/pgGrCQtRUpO6qDNZYoz3PxwB4idPBJbOhSYt7b49Rg+sM5KnGVq2ExmnQQCwfIKHeF88zcJC5POgkrmaMqdcLVOmSGWsT5QVkPqzYtZWm68pK3+Sjvyjm5Q+7jV/Fj/G6Zc7rOz6Q6saC2sKaDkj3LW8aYAsUrCdPkjRpokndMKe9+TtT62fnozp9HE0Yvq3kVOKcxdLqjdalKHOR4rIIaRlReLz1HWDiFETWjWIWqpRg173NhuyqjtMxlEuO4zQXKyDqnZY2zUhJjmdjmwlkeuFUTWmghBVKs5vToJUMfPCQpo5f1GRCqXTRvDNWFZSaAxbBa1QMqp5aVU+AzG9KR3HVYVQXQMLVZqjC93JalcMJR8aTKR/lMPNLxmMbDdbmPMnL4S3weMy9QSlR/B4VI94Oes5v8e3zDD0r89zLiAaMyYZt2S1ZlK91PbZOZc1LyMSVC8KjdpswJ7GFN7+Dfgyq8zUtFfRysBrGCObWkZhN5HWBN2VVpSD1ctMnIY+iCbtNvh2WSFykjJWOdyLiJjJGKZCozPPAyDz52OeAWRhAqVjm95/8MHU3zhpGgyXWp8KqZDHvzHtKVQbVbxuwSFalqWxRxmZfiHjejvQpKFfV84mGEeAWkn2ekZBtck2Iw7vpfFksJGacNboa1eKGABWfJWKd2NF3WkpbtYMVO26o1tkAxkW3QEXvSXsfO/feV9Gb+KN/Iz8KDt+oUykP2tL2KmkLcXOulqpSKiBa4YxdrWMDtoDxvmYLtJUypNTWhppSD7dCwCXhTrFmIe0M0MaByeuKSAS+PcTWqC2oPO06gHw3k+2XBlAybOjVFOEcLwQQPxMnA+9WFeD2Cbhq207JKJY5tiyMykpXJWmLDTWlRx8chakiPqNIlPncIaUXqXhASTqwrK01pmHSsQyxiXo/oknbdVJqS2LaDEeMg193C1Cgnqr22Y+Z40XF1pUPXSlT0di2H63IfZQzip/BffVcvecX+HEkPwv8bb3Q0up/pZTGhtjCsgpLsSils0QxvmNptcCzUQtIgnObt8pzjWDibwHgs3CLmwRAfdq1vb6abUktOSErTmmlTVRal3wEelrQrmW/wU1Y3mW3BJMo95MShpmXVFiyZkOvSto3QSLY8Z4aLqZp3zjJ9sizW5ZLOApzGuL+aMAhwBlqtJkR3q7sgIGwq6rVD4bwtSChNaUqBZ6jPqcnd6gUvj6GFJWX7oxkqcZObkqPhkx71ZwdkRRq0ZdILyCbMjDSpURmVQcPS5GnJ06ZsBG6Msskn+Tq6he6gl9JD/F7+MC/tIalHn7apu2hqJrkp3LJE2+EMR2LSkALv0CihAjvCTa6aMWdEvqR7lZMISCqaMzG1qWBGTaqGq71O3VO17QL/3xAJlVBJxQiR83n1HJrd4QSvGRY3g7Vc5uXyGA9GXVWECHAM/wrjSnRWRwrqBh/yy8hr02uHZCbISCAxtdmNJxYKgxMJQQNtFF2ZiqRK+HPr1m1PnVIrVg72E0H6aI5DalOxMhB5GMqkXlQt2BSvcsdUNnQFHW3zdKw0VO23W7xoy9SiKp+gG2ncUcAHDyPLZV0YJr2T2b5x45WLKdrXsqjjPKafKG4j5HXsJCB3w7YVCaIl6lS0yXLbJAzMihyViU0k9TGwcjexLJM+ghYyat9p1UFsi0nKcsfEPFVJVXAcOZCa9PIx64qUqJq7UdT34Crchw4M1tBScZK7NvrMSDBFi1FenC32rlzHN8kd9nZ7zGbtoOkKdBkGvK+Y4L09lIo94kyUC2ufgEUGO8qmgr7KNBWCurSkJkEwv9l9GrfgGjg8oUFBc09l2rBs2obJ1/rcDW5SPGUi2rKlrSSngplw00Y0JNPcMhVa58jxfXmbjhlnA347vUTewO/kT8m91nl4PC3bKzlxhevlOmlSK1ySasjnYCI6GvYJsomgRDu8Ksl9yXcH46kmaZ3bvMmrUW+kCHdgU+XUyEWhzvgsznpGiuPht+Hcat1IKD/Ay0Jc5YZtW6ZVGbO9Qaqu3eNl2wV8xCpQWbWG/QCa9eeBlVXr+LfYxRGU8F5IQrpKAzzLeapLm+sSmYJMF7tcl7bhFaz3r5gNn107fcRvhqhFkKp4QawwWR4hY7Y4tJPkB1x9XuXPDLLQTmXGgcvNOp2WSTPkRmIUcJWP8a28FWDqMK5cATlSgD/HF7xXhv4nEci9zNCKw3VpIT5lndPWrOzWuuwidRqpHKhIJ+yoAx2fR2GIWlQv9bfwLozpPAbU1xAio+p9tmh2jA1GK3oJ93rKvTzDx60jgzwyqqB6tGNXHPe39DHkVW2QFkyFO/aobbK1hlz3rmHbFFOF0zIfjNneSqKoY2en40cXdp9rqhzMokdBfdyDM9KqkrC9NBtsUGS3bFM2KnP5fkqUFfvAuaYKKTMvzFvkTIl65lBQwVBYlmM25JGoixe4I4bGgg1pcpaqtm6rsm3OmBvlVr7bvoK/iz9qP8lpoC/5lAtAL2lq8D28TUfLRanZMExQHNZKqoTyFHckCgba2MMbsQnS0RCVeYtCO0XJDZ/JEZ4oK2ewjFVsOGdYN033xf+rQPp0MhigGZtlF4rbIsGGmY/7Jcl6f0BkPBd5SBV8kHo2RT0HQM87qyblyNvu6yzKyiRs0jg+Rplj3ooaXOYVGc91USKjQo9wdJg7rQQbWMQTs+STCHANHnM0OhX1huvctq3KcqVr1bM190BalmSbabMrAk3wUbtgR+2WzZsqbcvVdGcwB/QkngEncbguq65eH34Ce/6cXrkGQQ4Es4HWvjySRhMlZR3A+Ax1uC4r3KxMBtP2yGY3axvIjhlyU7ooRRneDVetS3RVTo2p293YIkFDHNgjYqOBbYweZCj8DE+EESwjp0RVcD9OeWgGJ2xPOCJr7OZ5bRvbtdrAWVS9XKgLsp0k9QczlDFEDduwdVMzsZSiVZ4M+qUnShl9F4r+Zj+NPX/DT2nHI93COdyJHDa6ytNhKWxwk2tUMXNmwHbtoeJv4IWELFKVNqlqVoJeq7+OYJ06tiaz3GPS3JaCWaKIxBra5I5cJdfyrXKXfVDeyh+Sn+IHvQhIL0YxhWlMYMiNIutDdI89L8e5ym2yUb+0pEyw3bbCR82yo3FtoQDbxTMS2m02GwOOnLeHIt6Mh9CFKSwhrzZUU7mAccSJLGBVBamwl0dpTZjrti5NIVqqD9yi2atF1/B3PkyEfh8cOGfmW7wIXJAlbxUO/3mCOppwwqC1LjseZ6Vqm7YuNSrJfHWAuiMnbep7pu5cWmXUulrCOEp4Edx8Ofb5aGWeGrTJGzzYSLDX3Z1OsqXtymJRFXtox2bKk7IVRtzhU+Zec8LHt56L9jF5cKcdBr7LJi9y+Ly78f/h3VcwaSbhx35f83NoF/bUSXSrqjIxneWtMJBmeY3GeNcMlJMsprbR7Xpx1WFpmprpraGOCb2pdl2+kqIpZumExbg3xtUHz2h6ysdVECCrampS/dZB052SUV8wFqxSRRrUZgrXZcw5QjRwLYquetUJVfW+MISan/ASblDVfjspyybPxtakQ01rbdlko0WZMANRX9wV6w3vhbHtaFgKugdHsY4Crnet9Dne4Jg6NrIbshiORL11b5SYS0UrHNOOWF4yfYWETDkmhlkuT9gyVTnLga16b9pjcoZfxLfzA/IGfod83P7YxjY29WvwKN6Px/EevAl3qYB34/vktNnklmFakOPhCmDnaEvCSpdFhJOKBsI1boZNuz7nFaH7APWfsKBm1YbaVMNqDyd9yAdMV9BfHguWqEChtLlljaSD6Uy3UxB0s+nTsM7BUyUOKH/8vC+H4YPfBdoBrxV5cHgbMc6p2qBdkA0OeYsabDhLs2aIegtJJwoReAnpCWVVRmXUESSUUgM+dJZGyEgnZJ4yPUUnQoBghrfZ2sFa0rmlREuyyQ0+Jufie9PONuNV+G68D4/j3W4fYf1VeRj2LqsCt4g/xVc9uFhfkYHbBb2PYA//Fd/wVDa9ptZgpvhae8pa18eSabnKjnGPqTI5w0VJspP5zFUcKSURKEeJCnrsgrG2JYW1VIQvYkb3HlykWxfSySmVUXnNasMTzGrIahrgSVolIzWpUmhywYi7XR1Z/Tjm9ITqU/mDrzZQ6IAwpMbVlCY1pV6JjhcoYKxgVxcGeTbMskgokalJTRwLYS2Y4wk7FPa4KXIake833odV7KLhPBy67CwF5GTYq1yUJZqwvTswOJLgDNe4E4iZkb5omMom4jSvsCUjxtaobXbkBF9F5+ReenX4UPTRwpcmfwavSpzyKoZuvBXgLvXu6Z8sPNzYNo6/muVOZYKHSGQ7mHXhtZayk1ykpvPZLbgeKmb1qF5XBW0UlCt5G6hiRYd9Mm7mKctCdapSZCt2fqP37dj0o6AxzOkZParquOkZ2wf/EMtBXyym1KyeUTf5vt5x3KRo1KyzsBvsVE3FrNrpYNh0rXpNnDZeg1gV9IZaUuN6XjvD93Q35bhBMa9Uhl32OAEJ7E64nk9IYCPOVtphLXrR2seGPoOH1Gks+nTC0YPvxLvxVmQPhQcur5Ch8L3Yw8uv0N7DftC7H3+HPfyKG2X066QymupyS7jDdZJgWk7YmcoQ71C54jpKExJyozJSxXpiOuEQZTIQrHM9rJt0pF1WEjrRqIvWoFpSWd1S4+pazxNY1TzE0yZtiCJuEPFaMGmTbT/+iBSrJT35hObGs64eNaam1YI2ilVJZX2+U/fuuUWv9ExLJsOBqTqqO4sxVLRr5Vk7QUPSA1Xzs2PyeeYGKgM0T3mOTUMiS7LKk1F3hK1us2IiaUjRTvN0UBAjG45/4ovvbT4qp+yNfA8/wO9Z/PzYI65llsRTjNdPj/zI/LuOFgMnKu1ypKNUdgHOuKGDtS0q83Do7MgTi8k1fVTBK8USMij12jGapawx4qbZVSmGy9F41OWyrgZ2cZWqK1FTqvCPeqn0qAk170zI1QI2fWfxhNu7GV4nYxsUG6GyrNgpGm6mnDBVEyegVazSiaWkVSFWlSy4XTalaKqTFITD0uGqHYqWKIqKfNXkTw68zbHP1VP38Vo8jnNPMz89XN+x5Z5IMf4Kf4S5KxSi7J6gI3gJ3rU/EHVFlZ1yNpDc4q1olTo8H4/ySdlw2sOSEwfdwIeRT55BHuEQ5x0bNlw5q0JoldHf1PFwzIK0Jr2mXN7Swo1o9Mkc5TiQqo24QjmaMknr3cuco9aqnlOV5/EDOJGpKbXkGJ6eRr+NLS9AX0INlVTg5OmzVAict1vsQqAtS57WeT4YNT0F1fbNe/c9bHTbhbDITHWuM1Oaxqoq7JU1W4mCME85qZiSBGy5Ztp0RM7w+fC8vHziNxL3esHTpE7tT5M97jKVcNfCRtcnph4+ki7NcmwbMlwET5iiVDk066bHfVUutZz4QS/nVHO2l4Myb7NSNtbWQksVyfFM0Bv4ee02/hqkM3pFT3jA9ndy1TCnVnRGt9SWh0C7oUZ1mJao4DSmKWaiAq3LZKVnwT9azmIPhWQ+cRWWIRNUCmtieb2a8hrKW5QJlqgx8GOJV73O31HqSfvo76kivt8bBx16ZFwmIcM9f34Ae3jZFazuqi76XcXaduwdcow7lLdNXqCp8LhdEQTjziuCxo6jkDjvmthjXJF6QDRTQMMTk2YPJMon1aJe1ztqzwFT0UKl385x1lobS2gCXgkno17jp6t7sIrVsp7+B9o5iwk1r6b1uja6rKrqg3BMDyd5cBr1lAzyBM/Jqik6QjGHVLWRDWzWrshcMBymnOZIBZVuMxGuMVM1rIvh5XDSzPEK5+yGmJBZqEpN2rYnzDXVa2c/gxcrzKaQfJpOsU46pO1S6pOL547my+lFyEwYUkvYzhUTBk3kHfULp1DttzO8xmUbS0QhmTAjs+FwM9XwTYCTmFGiMnpVzyq5zC6bPOaV4/paNaCOe0+6NUifjPMiF0gkMtXQcl6W4vGjqch7u+2higJoMFh3TrtUtN0mVbEn14ffidemMJVEKvH0O6zbq4p/n6/gk4ch5/LJ9f4v/DlWr1DrEuVxEftJljqJYJrvtTfZ4yxSlQW7wFt2sgYu0RZngpTFw26SOMWhNLgkE2fdqEIV9axytjHTasmLHe0312td0SyVXHChOCzFyzTJPXVv3HgNApXT63ruf2CJ5mC182pFpXVOO87q67Dj1UWcXt86qNsO04xdDNe4wGRjE0tkQ7a0EczZfjdWiLUdMwuSE2LDAZfDQpjjIrM4WYNNOtnYXn5H13tGkiPJZ7GjUMkUoLd6v29pqTNjNqUeZmms4EHUNZxMVIZ5VZy+ScQxGU7bhXC83H0c7hXn8WY0VV5n9KIaV3yZX0AF98hTGW001FVooux22Sn/zciSLVgJq643zAUz1/DKfK40LiXNfGBsK4j39PCNycd7egYSKnGJe2wT7/AegYcl7mURMpzKyfceeKNdee3WhB+M/gb+GI95myM4v1c+y0dsi1cpSy3Tn+u1TVt1HNAK9lCbowa3TTYcHkETPSpU82rIEajUPI7AaZY0u2jG5iSUtkRcMEsyUu5rKPGiRr2qrnJqXdl/5B9zxIU/lVWsdtRJ5dRMtnyLvoI1FXSF/TwcTMoiZ2xZrGnYTapRRdI8b8YqI3aCpmRJ8mIlFCtWHLilE5+a+LEEfQY9z86U1wOJ/u6uh6Zfe9V6Zc715AInQLDIeSPcoroxlKMFGjH9FT8B7eAk+lVGkVOWUUtX3K2wghm1qjKqqKa0Y7+4LuunEXfbQZmQVXKqiG1bp0qYiaajVIgsokG72qGBj+n4GqT0s++jtzN9Pa45nONePmHDdcW+iP+O26+4sLffh3yvB7b9J2w4oxl5Nd/Fx3iHi0HItaArXJFjkqul2OGulh1TtrLC/S03l1UbTvPDeUCgiquwkogmuOBQdFSlcnVOhqjnGlX1wJE9GJVX62rKK+N/J9c01jGv1lTO+TaofrWH6/EGOKU/N5vs6Nhzg81ksGqLFFJMoUSViMkWJBNmnDNZGAdbdUm/pu+dqQEH0X32E55IdiFxMvVIorvdVUlbJzpfC2Ip0VJlVPpNqu0Fs7ZwOwZUTZWduvHzMvS53NY8Mqqkih5jeB22nem6Q392y1A4ZTKGbZUb1GRTXpxAT5R6pxp1zh6XuHFcWXsMr/UUkMNc77JY7pTsYA//t/ebSF5RQc9lem/1Qe8/YJHBZ+X1dJM9bavcEqFeiWXL9tUxClnnNtXtbLmr4Qx2FVTDs2h/E80kT7LTnOtIy5R4vjxIXQVdwg7OADgBVmm15k19L781jSWkfQhsw1kV7eFOx8T1ZXCoTZK6uY/GZE7WjCvUWrYlNdsMdpqNhQ/03AxVu/QjLpEEFgbelr2pFpfFrEWTQX85VVMVdHAHfhsHDXt90Lr/p3hcJP3+KK6HwS42EpIyQ3be5oN6PZp5a9fN0H3PXY8s4o3IHQa9y6tIfLPPlpr/yCn4M1nSfDtL+47eo/ixxPEWgiV6lF9O18txbpu8rPAxXqfEQjLI0w5VacpqjZfgww66irJe76IxyXgmQ81QsLTRS4k1Jb7EdYyIMgrIYuM7cDoizGEeS1jBGtJOch0Z5A7oXEXk4cA3oe+uNXAEFls4hl0UkEPG8QkOHERczvWQ5yk4SPUmXo0jaKRoVOZpvZ0ZfW93HRjSz9Uv1Tr5pu7NTmI+mVYO57junHmVaKMDHSh3GH8E/ySPJ/1s2mhWDc8bZvQiVrPdnWT3Q6mOG9o+Z9/ZnYzqYdC7vIYBCh/HHv4MrYPs71uXbL90SXxxWHuqbOj+9DjxlFfg2w57B4tup3fSbXKKWlxi5tgOmj5b5KNUlVHjoafkmBe9Mh5kAy+rGZBZMAND2jmL8wH/tYEyKpd04Pp21g52vR/gBtYQIMIKFrCIVZX1Pbq8Kqi8yqoNVVQFVVCijGor626iC04he/givt97OO3hRtyA0549us/tEC+wbrx9ovVqwzWP3ZlUrHOJIBElKSVd1BV0Sw/1SK/pNb1BX7k37u16m0PY6OcIeoMaSL5p4s5TSxXDlcPj4oMCU75mpffDzuQ4+VwPD3dVv865DhwGvctnaX9inDLdX+Ja79epDkyD9AsCLqtvLVwdvO7bvyD2Q2RfcljQXpIP81vkPO1yzKGU4lEq0E5YqfU56lkpFfZXvHARtaluiNZosO2DhuNfdimtg2+54zOBCcyrObWsltSqWlXral0tqKwPZDmv/sHKiVmyavlgZpSoqtpR1/pEeg9vxm24Daewi+M44bkZLWx6rqjjnNYRYsPnbVns4bw6qiQhiThpUmEq7K52U0/QS31xvx0wg+UhMxKPmUkzVZ7heV6wS7Rs1iXDOd4ISlwJA2bX2eOqNKlNHdqitulQvRUOfUSXge7nuFlHNZB60+SdR1cqJSocHhcfplgpHl/ve9yNp1PfStB7CJuHQe9yK3EdpugdXpvuoyhdlIsln5J97edrqYO/r+Eub/adOMgQEwcBM3WQwR3BySdklBDjJlyH63EVjni/23m8Au9G6yBbVB6qds1zXBjqou9Ge774Lh5Qr8S5wnvjD9ADfJ63bLtSlKzUODuLLDyDIuPAGlRnCVZoCMrRjU4gUtN6XA2rwOd4zmNhSS0chLLME4fO66zO6w2d84rIdc8rHb6QhX0YL/MB7P04iWNwTmDsqewO1uqMCcu+GGWP62t4Lu+ayiTKqWoX90if7a8OynAwwmN2QiZ5SqbMFE2Hc3aBl2VV0jZjc1SwJa44PzIrbG0oYRBSFIYOSGtiG0tsqlzlmjhro1iEiIOwxHnOyLosh4vBHM3UJ+JRGsoPhn1xT7pnvgtQr3S3oHqOsmzMAS7eADmK16B+eDzpcLTA444PtPOcTZl9z+bX+vLhMOhddmHPqWR+3ud7H8QZPJfmtvNAuws/cWDYrZ7mg9Hl7b1/ygdDlzM+ii/hV/Bv8df4W6xjGp/Dn+DX8Be48eDTR/G7+OVLFtfqQl66//9zeASvw2m1i5snfnr9Z8Pb+VrelIDY5GSYJ5y3gzSoIYHNmMm8Yn/dFXU2uZJMJyJdV06pzXlxrauq+l4An8V5bOMYjqLjlT+8JosnioW+j+aoVBkYzyN/iTK6kayn4i7qCXvjvnCAhmSER8NxnqApmuZZWuClcIXWgjRlg7xshEVbCkqVCjtxeGZrbRhyZKpcc5oj3JBaENsotIa9AVFZCrQR5MIsZzgt63aNlmkhnKUpmTCj8VDcX+6tda0mnUacQcXLaooPt6Evdd3R8KWvyyl3EOLF+LzzXE9B4Ubc8VytKD+SzOGNev2cGkhNJw6Pi4+pRF/XpsINuAtdR57rzlJYx3chfRj0LsciN+nzr0fx+34i+kV8HB/BYzjyJJvtCcxhFmf8KVRYAWMYMQZ9iMuj4F8Z4Qzm/L+/Ex8/OO0KU8hgFQV8w7lqe2NvR1P9cfy6kzMC8DHs4QcPXp1C19OOHiQx64UF9r3X+vEm3HOhLp7t+5H0W2pN06GINihvLFup8IodWdWBt48RFD24uO67YsaLPjGKPkxkEaOF89omg+5Sr/RHQ3bUjtOUmbFzZpGX7apZC9dkLVgPMpKjDSlw2VbEOB6/2DDmqo2lSpFEHLIV8b+YiYwDB5sKlalsC2Ges2bdrMqyLJpZnokmaYxG7JAMSG/UXemi5GpiXt2Ml2Eazu3VFb2Bl2WKUUUHTr68iRpacF3Ia3Aa/9I/p8qu3e7YBVo0adahZu0MEEWt6SW9pFf1kppTU2pGTatxlUh5zay3YvQ5yIfuajiLV6P7UBfuWZsrOTyG8W9hH0/iVd5A6zDoXYZhb1/oP4ub8VEv2eSOnznI1fZP39X4FfwS/hB/hLsB3Isfwih+Cz/klZe+jFvRhe/Dn+P/wH/ALoD34ZNPmQi/HV/1ueHt+BpKSOJf4Od94nQzvopfwM8+B2wmgZf73gg8LPkR/+oulfIhtzz5w+FWIFSRPK3QeDH1ANYS9R4ejIZ5zEzIVGU6mA3nZcmsyBqtS9bkg6KtCJFw6BgNYegKSBOSy8EshRRaa60JxbJlGzpzmgoVzYbJSZrXZIWWZaGywPPxHM/JjEzxeDjKI8Fg1B/2NrolOaNP4jSKqHgyvvVB1vjwK77o3ef17uAozuJePPAEyk1NqgE1p2qqrRoq0KHO6ozO6uXEgp7Xab2iV/WyWnVOHmpeTSoniR7hwW+n0+qaFu9A50nNgqdfCwkM4k2uhruC9Rb/xw4AXX3yThz7FvbxLTh1uI+X8/PrCfHDHKrYwd04dWGW6P7leuzhnYjwCfyfmMQr8QcYw83Yw2vx7/AbGMXL8ee4Fhv4QXwBfXg7Pn0h6HUjCcbf48X+/cfwOfwlvoT/BmdRWsY3cDXux6/4/uAgzuAluBN3PeW4F7fhdfg1fC96kMBtuO6Cb6+C/rTq+XTxJok5Do1UqEKWHUeybhq2wU6CKaaQhdkSVagkRd4wOcpKOlyjFVqyizxvZ3kmnOIJGrOj4XAwRAONvrCHuqupfPJooqbryvEvHTsj43NHN3pwMqNtbOModv1YYhMtXIWrcTce9t/Y+5FXFVXXpK3PwIw2PgdzGitZva5W1ZpaVStqWS045q2aUbNqTE2qEVV4zv7C815J38T8gDdjT1ziNdfgYQwc0qcuuY9lPI7hS+xjyud5b8HQ4T5e7mVu6llP8k34gj/By/gTnMH1+FUsAngM/w/+GLNI4KfwNbwY572QQYg3+Rxwf7zR7WPAH2DEh8Bz+DrejXvwFXwaI/g5fD+AN+IX/OcMPEvQuwc34zb8Hj7rA+gdOHsghnrw5NUfXaWao+XPyhzPmEk7KqPBiBmxIzIUD3K/7Yt7K91RV5jaSBzRjnacB6PkBw/W98RcP4wOsjIXyq7B1bgGL8UD+O0LeZhWI6pfhSpQLe9twaqoV/WqXtFLOuegzP7Xus/EZlXZS8JflqXZvXj7habGU3OYLh8WP+GbGIf5yaXD3h143wXfmWfaxwA/6FX1Dvfxsk/d9823k096PrnTeid+3J/ARfwObvaDj0Xf+9nDb/lp6r/C1/EJ/DQ+g0+ihO++EPT2u3BfwSMHFt0/jX/h3/MsvojX4xv4VfwAvoy/xfu8SnjyIkzfE4f7u1G8A+cx5N/jOF7nn6SJg+9sHe+BPofiQRkZ+sZ+Ey3chJvxUjyIXZzFKdyGV+B9B6g8Jy2eUaLIA02s910l/6dQpVVa5VXGg1KW1ZpaUW66O4dpjGMKgSewXMHnV6MLb8e7Lszp1YW/3/+bTfyIR20e3qrPvY+P4P0e6PVM+1jDj/mu+KG01BV2Yp+c6f1HjHtN7r9AHbfiNzCLSfwp/hd8HY8B+En8PHrQizwexggexacObhz3tXV89QD+3Iuf80MLoIPfw624G2/Dw/g8/gIPetvuZ6I2uXcZx8ZB3ghM4d0X8cMUPoTTYz64atWjyq4QVaLyPnCtq7Ra9YzVtMoijRWsYwlzfiJ71POD/lme1S48gMdRe9qgYgj34COeQXAY8r6VfUzhfnwIzaeVrwO4Gx/xT8dDqYErOpk/611m78RX8ZsAXo/fxRA+i6+jC6/E/+uHjP8FP4qz+DK+jiG8zw8YEwdl6P34fd+oSviM8e/xAdyGr+EX8YTx6qP4VX8rqgs8kacfT7A8vNAlvg+3YArDCPA4vkurcUxgBfOYRfSsHlqH60kPsxgfxGM4hwLGMYx5NPFyfA9eg/4rWGPxO7GPhMfxdtyAEiYwjDk08FJ8GG/wMgOH+3iFB73r8Nf4UXwJP4p1P9Z4BIxfwDEfrD7pc73r8Dn8AX7S+wC+GK84yNv2A+b7fZa4/0S8G1/A7+LTXrpkHyV4K971HFovT6a1AZN4AO/Dh/Dd3rb88PL6dpf2v2K8GG/BB/ERvBuvwzkPNzrElH27+6gguA9vwQfwEbwHr8f5A1Gew3284oPe7fj9SxbB+hkL40sVzc8/VKmLvq/DkPd8b1f1DOfh0MrmcB8P14XgcjN+xxPPkgdZQsJncfoCX1cdjBz2KWlPHtNfLCjgXp288D5P//dv9VJLHLBBDrtPz788SxzwrPePQxOb57sO9/GfaBK/gOpBiHumTE09rQi99O2m/kFu2sOnKf6B9vFwJw/38XBdoig9XIfrcB2ufxYpfOpwEw7X4Tpch+twHa7DdbgO1+E6XIfrcB2uw3W4DtfhOlyH63D9c17/P3kI07YanRDHAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mnist_2layers.png](attachment:mnist_2layers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 1\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.5281 - acc: 0.5700 - val_loss: 1.0071 - val_acc: 0.7232\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6390 - acc: 0.8680 - val_loss: 0.7937 - val_acc: 0.7583\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4321 - acc: 0.9080 - val_loss: 0.6455 - val_acc: 0.8120\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3221 - acc: 0.9260 - val_loss: 0.6342 - val_acc: 0.7996\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2439 - acc: 0.9660 - val_loss: 0.5821 - val_acc: 0.8249\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1939 - acc: 0.9740 - val_loss: 0.5297 - val_acc: 0.8389\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1575 - acc: 0.9700 - val_loss: 0.5364 - val_acc: 0.8327\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1185 - acc: 0.9900 - val_loss: 0.5054 - val_acc: 0.8399\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0970 - acc: 0.9940 - val_loss: 0.5547 - val_acc: 0.8301\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0838 - acc: 0.9960 - val_loss: 0.5285 - val_acc: 0.8307\n",
      "Trial number: 2\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0623 - acc: 0.9980 - val_loss: 0.4951 - val_acc: 0.8437\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0480 - acc: 1.0000 - val_loss: 0.5498 - val_acc: 0.8300\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0395 - acc: 1.0000 - val_loss: 0.5340 - val_acc: 0.8441\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0338 - acc: 1.0000 - val_loss: 0.5238 - val_acc: 0.8448\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0228 - acc: 1.0000 - val_loss: 0.5200 - val_acc: 0.8437\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0204 - acc: 1.0000 - val_loss: 0.5196 - val_acc: 0.8498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.5278 - val_acc: 0.8523\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0138 - acc: 1.0000 - val_loss: 0.5328 - val_acc: 0.8525\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0103 - acc: 1.0000 - val_loss: 0.5329 - val_acc: 0.8494\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5488 - val_acc: 0.8489\n",
      "Trial number: 3\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5718 - val_acc: 0.8464\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5934 - val_acc: 0.8409\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5771 - val_acc: 0.8470\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.6102 - val_acc: 0.8483\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6125 - val_acc: 0.8485\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6072 - val_acc: 0.8495\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6157 - val_acc: 0.8488\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6254 - val_acc: 0.8531\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.8523\n",
      "Epoch 10/10\n",
      " - 0s - loss: 9.2985e-04 - acc: 1.0000 - val_loss: 0.6487 - val_acc: 0.8509\n",
      "Trial number: 4\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7495e-04 - acc: 1.0000 - val_loss: 0.6537 - val_acc: 0.8523\n",
      "Epoch 2/10\n",
      " - 1s - loss: 6.0082e-04 - acc: 1.0000 - val_loss: 0.6497 - val_acc: 0.8536\n",
      "Epoch 3/10\n",
      " - 1s - loss: 4.9042e-04 - acc: 1.0000 - val_loss: 0.6797 - val_acc: 0.8488\n",
      "Epoch 4/10\n",
      " - 1s - loss: 4.3743e-04 - acc: 1.0000 - val_loss: 0.7354 - val_acc: 0.8443\n",
      "Epoch 5/10\n",
      " - 1s - loss: 9.7605e-04 - acc: 1.0000 - val_loss: 0.6999 - val_acc: 0.8516\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.6071e-04 - acc: 1.0000 - val_loss: 0.7077 - val_acc: 0.8525\n",
      "Epoch 7/10\n",
      " - 1s - loss: 2.1144e-04 - acc: 1.0000 - val_loss: 0.7202 - val_acc: 0.8528\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.6657e-04 - acc: 1.0000 - val_loss: 0.7320 - val_acc: 0.8523\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.3811e-04 - acc: 1.0000 - val_loss: 0.7418 - val_acc: 0.8518\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.2442e-04 - acc: 1.0000 - val_loss: 0.7528 - val_acc: 0.8510\n",
      "Trial number: 5\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 9.5736e-05 - acc: 1.0000 - val_loss: 0.7619 - val_acc: 0.8528\n",
      "Epoch 2/10\n",
      " - 0s - loss: 8.1281e-05 - acc: 1.0000 - val_loss: 0.7734 - val_acc: 0.8532\n",
      "Epoch 3/10\n",
      " - 0s - loss: 6.5039e-05 - acc: 1.0000 - val_loss: 0.7817 - val_acc: 0.8539\n",
      "Epoch 4/10\n",
      " - 0s - loss: 5.4674e-05 - acc: 1.0000 - val_loss: 0.8059 - val_acc: 0.8527\n",
      "Epoch 5/10\n",
      " - 0s - loss: 4.3364e-05 - acc: 1.0000 - val_loss: 0.7929 - val_acc: 0.8542\n",
      "Epoch 6/10\n",
      " - 0s - loss: 3.5049e-05 - acc: 1.0000 - val_loss: 0.8059 - val_acc: 0.8537\n",
      "Epoch 7/10\n",
      " - 0s - loss: 3.1170e-05 - acc: 1.0000 - val_loss: 0.8066 - val_acc: 0.8535\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.4777e-05 - acc: 1.0000 - val_loss: 0.8463 - val_acc: 0.8496\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.0207e-05 - acc: 1.0000 - val_loss: 0.8277 - val_acc: 0.8534\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.5652e-05 - acc: 1.0000 - val_loss: 0.8597 - val_acc: 0.8482\n",
      "Trial number: 6\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.3808e-05 - acc: 1.0000 - val_loss: 0.8487 - val_acc: 0.8541\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.0729e-05 - acc: 1.0000 - val_loss: 0.8763 - val_acc: 0.8527\n",
      "Epoch 3/10\n",
      " - 0s - loss: 8.5160e-06 - acc: 1.0000 - val_loss: 0.8776 - val_acc: 0.8536\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.6106e-06 - acc: 1.0000 - val_loss: 0.8792 - val_acc: 0.8513\n",
      "Epoch 5/10\n",
      " - 0s - loss: 6.1951e-06 - acc: 1.0000 - val_loss: 0.8907 - val_acc: 0.8515\n",
      "Epoch 6/10\n",
      " - 0s - loss: 5.0345e-06 - acc: 1.0000 - val_loss: 0.9130 - val_acc: 0.8509\n",
      "Epoch 7/10\n",
      " - 1s - loss: 4.2764e-06 - acc: 1.0000 - val_loss: 0.9047 - val_acc: 0.8528\n",
      "Epoch 8/10\n",
      " - 1s - loss: 3.5336e-06 - acc: 1.0000 - val_loss: 0.9139 - val_acc: 0.8521\n",
      "Epoch 9/10\n",
      " - 1s - loss: 3.0012e-06 - acc: 1.0000 - val_loss: 0.9138 - val_acc: 0.8537\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.4926e-06 - acc: 1.0000 - val_loss: 0.9290 - val_acc: 0.8511\n",
      "Trial number: 7\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.2196e-06 - acc: 1.0000 - val_loss: 0.9259 - val_acc: 0.8542\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.8302e-06 - acc: 1.0000 - val_loss: 0.9394 - val_acc: 0.8527\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.6096e-06 - acc: 1.0000 - val_loss: 0.9417 - val_acc: 0.8521\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.4194e-06 - acc: 1.0000 - val_loss: 0.9511 - val_acc: 0.8522\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2097e-06 - acc: 1.0000 - val_loss: 0.9535 - val_acc: 0.8529\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.0716e-06 - acc: 1.0000 - val_loss: 0.9633 - val_acc: 0.8520\n",
      "Epoch 7/10\n",
      " - 1s - loss: 9.6154e-07 - acc: 1.0000 - val_loss: 0.9640 - val_acc: 0.8536\n",
      "Epoch 8/10\n",
      " - 1s - loss: 8.6641e-07 - acc: 1.0000 - val_loss: 0.9707 - val_acc: 0.8529\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.6497e-07 - acc: 1.0000 - val_loss: 0.9723 - val_acc: 0.8532\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.1681e-07 - acc: 1.0000 - val_loss: 0.9791 - val_acc: 0.8531\n",
      "Trial number: 8\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 6.4099e-07 - acc: 1.0000 - val_loss: 0.9713 - val_acc: 0.8529\n",
      "Epoch 2/10\n",
      " - 1s - loss: 5.9259e-07 - acc: 1.0000 - val_loss: 0.9819 - val_acc: 0.8528\n",
      "Epoch 3/10\n",
      " - 1s - loss: 5.4658e-07 - acc: 1.0000 - val_loss: 0.9867 - val_acc: 0.8519\n",
      "Epoch 4/10\n",
      " - 1s - loss: 5.0759e-07 - acc: 1.0000 - val_loss: 0.9909 - val_acc: 0.8529\n",
      "Epoch 5/10\n",
      " - 1s - loss: 4.7398e-07 - acc: 1.0000 - val_loss: 0.9886 - val_acc: 0.8536\n",
      "Epoch 6/10\n",
      " - 0s - loss: 4.4334e-07 - acc: 1.0000 - val_loss: 0.9930 - val_acc: 0.8536\n",
      "Epoch 7/10\n",
      " - 0s - loss: 4.1866e-07 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.8537\n",
      "Epoch 8/10\n",
      " - 0s - loss: 3.9649e-07 - acc: 1.0000 - val_loss: 0.9978 - val_acc: 0.8529\n",
      "Epoch 9/10\n",
      " - 1s - loss: 3.7360e-07 - acc: 1.0000 - val_loss: 1.0019 - val_acc: 0.8532\n",
      "Epoch 10/10\n",
      " - 0s - loss: 3.5679e-07 - acc: 1.0000 - val_loss: 1.0015 - val_acc: 0.8531\n",
      "Trial number: 9\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 3.3975e-07 - acc: 1.0000 - val_loss: 1.0065 - val_acc: 0.8534\n",
      "Epoch 2/10\n",
      " - 0s - loss: 3.2258e-07 - acc: 1.0000 - val_loss: 1.0084 - val_acc: 0.8527\n",
      "Epoch 3/10\n",
      " - 0s - loss: 3.0959e-07 - acc: 1.0000 - val_loss: 1.0087 - val_acc: 0.8534\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.9898e-07 - acc: 1.0000 - val_loss: 1.0104 - val_acc: 0.8533\n",
      "Epoch 5/10\n",
      " - 1s - loss: 2.8706e-07 - acc: 1.0000 - val_loss: 1.0132 - val_acc: 0.8528\n",
      "Epoch 6/10\n",
      " - 1s - loss: 2.7978e-07 - acc: 1.0000 - val_loss: 1.0140 - val_acc: 0.8530\n",
      "Epoch 7/10\n",
      " - 1s - loss: 2.6643e-07 - acc: 1.0000 - val_loss: 1.0171 - val_acc: 0.8535\n",
      "Epoch 8/10\n",
      " - 1s - loss: 2.5904e-07 - acc: 1.0000 - val_loss: 1.0187 - val_acc: 0.8534\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.5177e-07 - acc: 1.0000 - val_loss: 1.0208 - val_acc: 0.8534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      " - 0s - loss: 2.4426e-07 - acc: 1.0000 - val_loss: 1.0212 - val_acc: 0.8535\n",
      "Trial number: 10\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 2.3639e-07 - acc: 1.0000 - val_loss: 1.0235 - val_acc: 0.8529\n",
      "Epoch 2/10\n",
      " - 1s - loss: 2.3103e-07 - acc: 1.0000 - val_loss: 1.0239 - val_acc: 0.8531\n",
      "Epoch 3/10\n",
      " - 1s - loss: 2.2602e-07 - acc: 1.0000 - val_loss: 1.0264 - val_acc: 0.8532\n",
      "Epoch 4/10\n",
      " - 1s - loss: 2.2101e-07 - acc: 1.0000 - val_loss: 1.0268 - val_acc: 0.8529\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.1529e-07 - acc: 1.0000 - val_loss: 1.0283 - val_acc: 0.8529\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.0885e-07 - acc: 1.0000 - val_loss: 1.0288 - val_acc: 0.8527\n",
      "Epoch 7/10\n",
      " - 1s - loss: 2.0456e-07 - acc: 1.0000 - val_loss: 1.0301 - val_acc: 0.8529\n",
      "Epoch 8/10\n",
      " - 1s - loss: 2.0170e-07 - acc: 1.0000 - val_loss: 1.0317 - val_acc: 0.8529\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.9813e-07 - acc: 1.0000 - val_loss: 1.0326 - val_acc: 0.8527\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.9491e-07 - acc: 1.0000 - val_loss: 1.0338 - val_acc: 0.8530\n",
      "Trial number: 11\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.8978e-07 - acc: 1.0000 - val_loss: 1.0350 - val_acc: 0.8527\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.8847e-07 - acc: 1.0000 - val_loss: 1.0360 - val_acc: 0.8531\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.8537e-07 - acc: 1.0000 - val_loss: 1.0371 - val_acc: 0.8528\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.8239e-07 - acc: 1.0000 - val_loss: 1.0381 - val_acc: 0.8530\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.7834e-07 - acc: 1.0000 - val_loss: 1.0391 - val_acc: 0.8530\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.7798e-07 - acc: 1.0000 - val_loss: 1.0397 - val_acc: 0.8528\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.7488e-07 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.8528\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.7405e-07 - acc: 1.0000 - val_loss: 1.0414 - val_acc: 0.8529\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.7047e-07 - acc: 1.0000 - val_loss: 1.0423 - val_acc: 0.8531\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.6940e-07 - acc: 1.0000 - val_loss: 1.0426 - val_acc: 0.8531\n",
      "Trial number: 12\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.6594e-07 - acc: 1.0000 - val_loss: 1.0436 - val_acc: 0.8532\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.6546e-07 - acc: 1.0000 - val_loss: 1.0442 - val_acc: 0.8530\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.6379e-07 - acc: 1.0000 - val_loss: 1.0449 - val_acc: 0.8528\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.6189e-07 - acc: 1.0000 - val_loss: 1.0459 - val_acc: 0.8532\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.6022e-07 - acc: 1.0000 - val_loss: 1.0468 - val_acc: 0.8525\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.5962e-07 - acc: 1.0000 - val_loss: 1.0471 - val_acc: 0.8526\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.5712e-07 - acc: 1.0000 - val_loss: 1.0481 - val_acc: 0.8527\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.5569e-07 - acc: 1.0000 - val_loss: 1.0487 - val_acc: 0.8529\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.5450e-07 - acc: 1.0000 - val_loss: 1.0496 - val_acc: 0.8527\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.5318e-07 - acc: 1.0000 - val_loss: 1.0504 - val_acc: 0.8528\n",
      "Trial number: 13\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.5175e-07 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.8526\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.5080e-07 - acc: 1.0000 - val_loss: 1.0520 - val_acc: 0.8528\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.4985e-07 - acc: 1.0000 - val_loss: 1.0524 - val_acc: 0.8529\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.4973e-07 - acc: 1.0000 - val_loss: 1.0529 - val_acc: 0.8526\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.4842e-07 - acc: 1.0000 - val_loss: 1.0534 - val_acc: 0.8527\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.4687e-07 - acc: 1.0000 - val_loss: 1.0543 - val_acc: 0.8523\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.4591e-07 - acc: 1.0000 - val_loss: 1.0550 - val_acc: 0.8528\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.4520e-07 - acc: 1.0000 - val_loss: 1.0555 - val_acc: 0.8525\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.4520e-07 - acc: 1.0000 - val_loss: 1.0559 - val_acc: 0.8527\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.4448e-07 - acc: 1.0000 - val_loss: 1.0570 - val_acc: 0.8527\n",
      "Trial number: 14\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.4353e-07 - acc: 1.0000 - val_loss: 1.0573 - val_acc: 0.8528\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.4329e-07 - acc: 1.0000 - val_loss: 1.0580 - val_acc: 0.8527\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.4186e-07 - acc: 1.0000 - val_loss: 1.0584 - val_acc: 0.8527\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.4138e-07 - acc: 1.0000 - val_loss: 1.0589 - val_acc: 0.8528\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.4055e-07 - acc: 1.0000 - val_loss: 1.0597 - val_acc: 0.8525\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.3971e-07 - acc: 1.0000 - val_loss: 1.0601 - val_acc: 0.8529\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.3936e-07 - acc: 1.0000 - val_loss: 1.0606 - val_acc: 0.8526\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.3864e-07 - acc: 1.0000 - val_loss: 1.0611 - val_acc: 0.8525\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.3781e-07 - acc: 1.0000 - val_loss: 1.0616 - val_acc: 0.8527\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.3697e-07 - acc: 1.0000 - val_loss: 1.0620 - val_acc: 0.8525\n",
      "Trial number: 15\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.3697e-07 - acc: 1.0000 - val_loss: 1.0624 - val_acc: 0.8525\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.3638e-07 - acc: 1.0000 - val_loss: 1.0629 - val_acc: 0.8525\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.3602e-07 - acc: 1.0000 - val_loss: 1.0635 - val_acc: 0.8524\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.3554e-07 - acc: 1.0000 - val_loss: 1.0640 - val_acc: 0.8523\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.3554e-07 - acc: 1.0000 - val_loss: 1.0644 - val_acc: 0.8523\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.3435e-07 - acc: 1.0000 - val_loss: 1.0646 - val_acc: 0.8523\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.3435e-07 - acc: 1.0000 - val_loss: 1.0649 - val_acc: 0.8525\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.3316e-07 - acc: 1.0000 - val_loss: 1.0654 - val_acc: 0.8524\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.3316e-07 - acc: 1.0000 - val_loss: 1.0661 - val_acc: 0.8525\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.3268e-07 - acc: 1.0000 - val_loss: 1.0661 - val_acc: 0.8523\n",
      "Trial number: 16\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.3232e-07 - acc: 1.0000 - val_loss: 1.0666 - val_acc: 0.8523\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3149e-07 - acc: 1.0000 - val_loss: 1.0671 - val_acc: 0.8523\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3137e-07 - acc: 1.0000 - val_loss: 1.0673 - val_acc: 0.8523\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.3065e-07 - acc: 1.0000 - val_loss: 1.0676 - val_acc: 0.8524\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.3077e-07 - acc: 1.0000 - val_loss: 1.0678 - val_acc: 0.8522\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.2970e-07 - acc: 1.0000 - val_loss: 1.0682 - val_acc: 0.8522\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.2970e-07 - acc: 1.0000 - val_loss: 1.0687 - val_acc: 0.8522\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.2898e-07 - acc: 1.0000 - val_loss: 1.0691 - val_acc: 0.8524\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2898e-07 - acc: 1.0000 - val_loss: 1.0695 - val_acc: 0.8523\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2875e-07 - acc: 1.0000 - val_loss: 1.0697 - val_acc: 0.8524\n",
      "Trial number: 17\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.2827e-07 - acc: 1.0000 - val_loss: 1.0701 - val_acc: 0.8524\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.2851e-07 - acc: 1.0000 - val_loss: 1.0706 - val_acc: 0.8524\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.2779e-07 - acc: 1.0000 - val_loss: 1.0710 - val_acc: 0.8524\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2791e-07 - acc: 1.0000 - val_loss: 1.0714 - val_acc: 0.8523\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.2767e-07 - acc: 1.0000 - val_loss: 1.0717 - val_acc: 0.8522\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.2720e-07 - acc: 1.0000 - val_loss: 1.0719 - val_acc: 0.8523\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.2684e-07 - acc: 1.0000 - val_loss: 1.0720 - val_acc: 0.8523\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.2672e-07 - acc: 1.0000 - val_loss: 1.0725 - val_acc: 0.8524\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2660e-07 - acc: 1.0000 - val_loss: 1.0728 - val_acc: 0.8522\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2565e-07 - acc: 1.0000 - val_loss: 1.0730 - val_acc: 0.8522\n",
      "Trial number: 18\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2541e-07 - acc: 1.0000 - val_loss: 1.0734 - val_acc: 0.8523\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2529e-07 - acc: 1.0000 - val_loss: 1.0737 - val_acc: 0.8523\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2541e-07 - acc: 1.0000 - val_loss: 1.0739 - val_acc: 0.8523\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.2505e-07 - acc: 1.0000 - val_loss: 1.0744 - val_acc: 0.8523\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2493e-07 - acc: 1.0000 - val_loss: 1.0746 - val_acc: 0.8523\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2434e-07 - acc: 1.0000 - val_loss: 1.0748 - val_acc: 0.8521\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2445e-07 - acc: 1.0000 - val_loss: 1.0749 - val_acc: 0.8521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      " - 0s - loss: 1.2362e-07 - acc: 1.0000 - val_loss: 1.0751 - val_acc: 0.8523\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2350e-07 - acc: 1.0000 - val_loss: 1.0755 - val_acc: 0.8519\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2326e-07 - acc: 1.0000 - val_loss: 1.0759 - val_acc: 0.8523\n",
      "Trial number: 19\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2338e-07 - acc: 1.0000 - val_loss: 1.0761 - val_acc: 0.8521\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.2326e-07 - acc: 1.0000 - val_loss: 1.0763 - val_acc: 0.8522\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.2290e-07 - acc: 1.0000 - val_loss: 1.0767 - val_acc: 0.8520\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2290e-07 - acc: 1.0000 - val_loss: 1.0773 - val_acc: 0.8521\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.2267e-07 - acc: 1.0000 - val_loss: 1.0773 - val_acc: 0.8520\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2255e-07 - acc: 1.0000 - val_loss: 1.0775 - val_acc: 0.8521\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2243e-07 - acc: 1.0000 - val_loss: 1.0779 - val_acc: 0.8522\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2219e-07 - acc: 1.0000 - val_loss: 1.0781 - val_acc: 0.8520\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2219e-07 - acc: 1.0000 - val_loss: 1.0782 - val_acc: 0.8520\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2207e-07 - acc: 1.0000 - val_loss: 1.0785 - val_acc: 0.8520\n",
      "Trial number: 20\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2159e-07 - acc: 1.0000 - val_loss: 1.0788 - val_acc: 0.8520\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2171e-07 - acc: 1.0000 - val_loss: 1.0791 - val_acc: 0.8519\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2159e-07 - acc: 1.0000 - val_loss: 1.0793 - val_acc: 0.8517\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2147e-07 - acc: 1.0000 - val_loss: 1.0795 - val_acc: 0.8518\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2147e-07 - acc: 1.0000 - val_loss: 1.0797 - val_acc: 0.8520\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2147e-07 - acc: 1.0000 - val_loss: 1.0799 - val_acc: 0.8520\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.0802 - val_acc: 0.8520\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.0805 - val_acc: 0.8519\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.2124e-07 - acc: 1.0000 - val_loss: 1.0806 - val_acc: 0.8520\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.2124e-07 - acc: 1.0000 - val_loss: 1.0808 - val_acc: 0.8520\n",
      "Trial number: 21\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.2124e-07 - acc: 1.0000 - val_loss: 1.0812 - val_acc: 0.8520\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.2112e-07 - acc: 1.0000 - val_loss: 1.0813 - val_acc: 0.8521\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.2100e-07 - acc: 1.0000 - val_loss: 1.0816 - val_acc: 0.8520\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.2100e-07 - acc: 1.0000 - val_loss: 1.0817 - val_acc: 0.8520\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.2088e-07 - acc: 1.0000 - val_loss: 1.0818 - val_acc: 0.8520\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2100e-07 - acc: 1.0000 - val_loss: 1.0822 - val_acc: 0.8520\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2100e-07 - acc: 1.0000 - val_loss: 1.0825 - val_acc: 0.8520\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2076e-07 - acc: 1.0000 - val_loss: 1.0827 - val_acc: 0.8522\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2064e-07 - acc: 1.0000 - val_loss: 1.0829 - val_acc: 0.8520\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2064e-07 - acc: 1.0000 - val_loss: 1.0831 - val_acc: 0.8520\n",
      "Trial number: 22\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2064e-07 - acc: 1.0000 - val_loss: 1.0835 - val_acc: 0.8520\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2076e-07 - acc: 1.0000 - val_loss: 1.0836 - val_acc: 0.8520\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.2064e-07 - acc: 1.0000 - val_loss: 1.0838 - val_acc: 0.8520\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2040e-07 - acc: 1.0000 - val_loss: 1.0840 - val_acc: 0.8521\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2052e-07 - acc: 1.0000 - val_loss: 1.0842 - val_acc: 0.8521\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2028e-07 - acc: 1.0000 - val_loss: 1.0843 - val_acc: 0.8522\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2028e-07 - acc: 1.0000 - val_loss: 1.0846 - val_acc: 0.8520\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2028e-07 - acc: 1.0000 - val_loss: 1.0849 - val_acc: 0.8521\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2028e-07 - acc: 1.0000 - val_loss: 1.0852 - val_acc: 0.8521\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2040e-07 - acc: 1.0000 - val_loss: 1.0854 - val_acc: 0.8520\n",
      "Trial number: 23\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2028e-07 - acc: 1.0000 - val_loss: 1.0855 - val_acc: 0.8521\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2028e-07 - acc: 1.0000 - val_loss: 1.0857 - val_acc: 0.8521\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2040e-07 - acc: 1.0000 - val_loss: 1.0858 - val_acc: 0.8521\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2040e-07 - acc: 1.0000 - val_loss: 1.0861 - val_acc: 0.8521\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2040e-07 - acc: 1.0000 - val_loss: 1.0864 - val_acc: 0.8520\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2040e-07 - acc: 1.0000 - val_loss: 1.0866 - val_acc: 0.8522\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2028e-07 - acc: 1.0000 - val_loss: 1.0869 - val_acc: 0.8521\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2004e-07 - acc: 1.0000 - val_loss: 1.0869 - val_acc: 0.8521\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2004e-07 - acc: 1.0000 - val_loss: 1.0872 - val_acc: 0.8521\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2004e-07 - acc: 1.0000 - val_loss: 1.0874 - val_acc: 0.8520\n",
      "Trial number: 24\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0875 - val_acc: 0.8521\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0877 - val_acc: 0.8519\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2004e-07 - acc: 1.0000 - val_loss: 1.0880 - val_acc: 0.8520\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.0882 - val_acc: 0.8520\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0883 - val_acc: 0.8519\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0884 - val_acc: 0.8518\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0889 - val_acc: 0.8518\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0888 - val_acc: 0.8518\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0893 - val_acc: 0.8519\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0892 - val_acc: 0.8518\n",
      "Trial number: 25\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0893 - val_acc: 0.8518\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0897 - val_acc: 0.8518\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0897 - val_acc: 0.8517\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0898 - val_acc: 0.8516\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0899 - val_acc: 0.8517\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0901 - val_acc: 0.8517\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.0902 - val_acc: 0.8517\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0902 - val_acc: 0.8516\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0905 - val_acc: 0.8516\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0907 - val_acc: 0.8517\n",
      "Trial number: 26\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0908 - val_acc: 0.8516\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0909 - val_acc: 0.8516\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0910 - val_acc: 0.8516\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0912 - val_acc: 0.8516\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0914 - val_acc: 0.8516\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0916 - val_acc: 0.8516\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0916 - val_acc: 0.8515\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0917 - val_acc: 0.8516\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0918 - val_acc: 0.8515\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0920 - val_acc: 0.8515\n",
      "Trial number: 27\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0922 - val_acc: 0.8515\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0924 - val_acc: 0.8515\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0926 - val_acc: 0.8515\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0926 - val_acc: 0.8514\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0927 - val_acc: 0.8515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0930 - val_acc: 0.8515\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0929 - val_acc: 0.8514\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0930 - val_acc: 0.8515\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0931 - val_acc: 0.8514\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0932 - val_acc: 0.8515\n",
      "Trial number: 28\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0932 - val_acc: 0.8515\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0933 - val_acc: 0.8515\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.0934 - val_acc: 0.8515\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0935 - val_acc: 0.8515\n",
      "Epoch 5/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0938 - val_acc: 0.8515\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0938 - val_acc: 0.8516\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0938 - val_acc: 0.8514\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0938 - val_acc: 0.8515\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0941 - val_acc: 0.8515\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0942 - val_acc: 0.8514\n",
      "Trial number: 29\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0943 - val_acc: 0.8514\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0943 - val_acc: 0.8513\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0943 - val_acc: 0.8513\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0944 - val_acc: 0.8513\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0943 - val_acc: 0.8514\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0945 - val_acc: 0.8513\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0945 - val_acc: 0.8513\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0946 - val_acc: 0.8513\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.1957e-07 - acc: 1.0000 - val_loss: 1.0948 - val_acc: 0.8513\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.0948 - val_acc: 0.8513\n",
      "Trial number: 30\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.0948 - val_acc: 0.8514\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0950 - val_acc: 0.8513\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0950 - val_acc: 0.8513\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0949 - val_acc: 0.8514\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0949 - val_acc: 0.8514\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0950 - val_acc: 0.8514\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0951 - val_acc: 0.8514\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0952 - val_acc: 0.8514\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0950 - val_acc: 0.8514\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0952 - val_acc: 0.8514\n",
      "Trial number: 31\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0952 - val_acc: 0.8514\n",
      "Epoch 2/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0951 - val_acc: 0.8514\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0952 - val_acc: 0.8514\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0953 - val_acc: 0.8514\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0953 - val_acc: 0.8514\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0953 - val_acc: 0.8514\n",
      "Epoch 7/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0954 - val_acc: 0.8514\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0955 - val_acc: 0.8514\n",
      "Epoch 9/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0954 - val_acc: 0.8514\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.1933e-07 - acc: 1.0000 - val_loss: 1.0954 - val_acc: 0.8514\n",
      "| 1 | 0.8307 |\n",
      "| 2 | 0.8489 |\n",
      "| 3 | 0.8509 |\n",
      "| 4 | 0.851 |\n",
      "| 5 | 0.8482 |\n",
      "| 6 | 0.8511 |\n",
      "| 7 | 0.8531 |\n",
      "| 8 | 0.8531 |\n",
      "| 9 | 0.8535 |\n",
      "| 10 | 0.853 |\n",
      "| 11 | 0.8531 |\n",
      "| 12 | 0.8528 |\n",
      "| 13 | 0.8527 |\n",
      "| 14 | 0.8525 |\n",
      "| 15 | 0.8523 |\n",
      "| 16 | 0.8524 |\n",
      "| 17 | 0.8522 |\n",
      "| 18 | 0.8523 |\n",
      "| 19 | 0.852 |\n",
      "| 20 | 0.852 |\n",
      "| 21 | 0.852 |\n",
      "| 22 | 0.852 |\n",
      "| 23 | 0.852 |\n",
      "| 24 | 0.8518 |\n",
      "| 25 | 0.8517 |\n",
      "| 26 | 0.8515 |\n",
      "| 27 | 0.8515 |\n",
      "| 28 | 0.8514 |\n",
      "| 29 | 0.8513 |\n",
      "| 30 | 0.8514 |\n",
      "| 31 | 0.8514 |\n",
      "Average: 0.8511548387096777\n",
      "Trial number: 1\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.6495 - acc: 0.9130 - val_loss: 0.9651 - val_acc: 0.8585\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.3358 - acc: 0.9480 - val_loss: 0.8715 - val_acc: 0.8720\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.2429 - acc: 0.9690 - val_loss: 0.9238 - val_acc: 0.8616\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.1919 - acc: 0.9770 - val_loss: 0.8492 - val_acc: 0.8678\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.1598 - acc: 0.9840 - val_loss: 0.8700 - val_acc: 0.8639\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.1370 - acc: 0.9900 - val_loss: 0.8101 - val_acc: 0.8708\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.1235 - acc: 0.9910 - val_loss: 0.8269 - val_acc: 0.8692\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1105 - acc: 0.9920 - val_loss: 0.8056 - val_acc: 0.8677\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.1068 - acc: 0.9910 - val_loss: 0.7868 - val_acc: 0.8732\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1033 - acc: 0.9920 - val_loss: 0.7987 - val_acc: 0.8744\n",
      "Trial number: 2\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0996 - acc: 0.9930 - val_loss: 0.7680 - val_acc: 0.8797\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0975 - acc: 0.9940 - val_loss: 0.7864 - val_acc: 0.8764\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0974 - acc: 0.9940 - val_loss: 0.7752 - val_acc: 0.8788\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0971 - acc: 0.9940 - val_loss: 0.7879 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0970 - acc: 0.9940 - val_loss: 0.7896 - val_acc: 0.8760\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0969 - acc: 0.9940 - val_loss: 0.8071 - val_acc: 0.8763\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0970 - acc: 0.9940 - val_loss: 0.8486 - val_acc: 0.8732\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1037 - acc: 0.9920 - val_loss: 0.8187 - val_acc: 0.8792\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0968 - acc: 0.9940 - val_loss: 0.8060 - val_acc: 0.8799\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0968 - acc: 0.9940 - val_loss: 0.8059 - val_acc: 0.8807\n",
      "Trial number: 3\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0968 - acc: 0.9940 - val_loss: 0.8195 - val_acc: 0.8781\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0968 - acc: 0.9940 - val_loss: 0.8200 - val_acc: 0.8799\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0968 - acc: 0.9940 - val_loss: 0.8273 - val_acc: 0.8781\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8317 - val_acc: 0.8798\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8788 - val_acc: 0.8728\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8334 - val_acc: 0.8806\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8669 - val_acc: 0.8777\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8570 - val_acc: 0.8796\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8641 - val_acc: 0.8805\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0970 - acc: 0.9940 - val_loss: 0.9257 - val_acc: 0.8726\n",
      "Trial number: 4\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0971 - acc: 0.9940 - val_loss: 0.8571 - val_acc: 0.8811\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8532 - val_acc: 0.8822\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8641 - val_acc: 0.8807\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8668 - val_acc: 0.8820\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8755 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8742 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8739 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8855 - val_acc: 0.8834\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8929 - val_acc: 0.8815\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8851 - val_acc: 0.8824\n",
      "Trial number: 5\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.8897 - val_acc: 0.8836\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9078 - val_acc: 0.8810\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9111 - val_acc: 0.8805\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9139 - val_acc: 0.8817\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9083 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9157 - val_acc: 0.8820\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9348 - val_acc: 0.8819\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9193 - val_acc: 0.8829\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9273 - val_acc: 0.8826\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9389 - val_acc: 0.8823\n",
      "Trial number: 6\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9363 - val_acc: 0.8826\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9311 - val_acc: 0.8824\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9382 - val_acc: 0.8835\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9375 - val_acc: 0.8826\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9380 - val_acc: 0.8827\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9478 - val_acc: 0.8827\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9393 - val_acc: 0.8828\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9415 - val_acc: 0.8829\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9480 - val_acc: 0.8827\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9447 - val_acc: 0.8828\n",
      "Trial number: 7\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9496 - val_acc: 0.8831\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9510 - val_acc: 0.8830\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9482 - val_acc: 0.8829\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9515 - val_acc: 0.8831\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9501 - val_acc: 0.8830\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9520 - val_acc: 0.8827\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9562 - val_acc: 0.8828\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9554 - val_acc: 0.8830\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9555 - val_acc: 0.8830\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9569 - val_acc: 0.8827\n",
      "Trial number: 8\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9568 - val_acc: 0.8829\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9595 - val_acc: 0.8831\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9610 - val_acc: 0.8829\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9609 - val_acc: 0.8829\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9622 - val_acc: 0.8829\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9641 - val_acc: 0.8828\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9625 - val_acc: 0.8831\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9640 - val_acc: 0.8833\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9654 - val_acc: 0.8832\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9649 - val_acc: 0.8832\n",
      "Trial number: 9\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9653 - val_acc: 0.8831\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9653 - val_acc: 0.8832\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9671 - val_acc: 0.8834\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9681 - val_acc: 0.8833\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9680 - val_acc: 0.8834\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9686 - val_acc: 0.8833\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9685 - val_acc: 0.8836\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9689 - val_acc: 0.8835\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9694 - val_acc: 0.8835\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9710 - val_acc: 0.8832\n",
      "Trial number: 10\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9714 - val_acc: 0.8833\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9719 - val_acc: 0.8834\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9732 - val_acc: 0.8832\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9726 - val_acc: 0.8834\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9731 - val_acc: 0.8833\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9734 - val_acc: 0.8832\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9741 - val_acc: 0.8835\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9746 - val_acc: 0.8835\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9743 - val_acc: 0.8834\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9753 - val_acc: 0.8834\n",
      "Trial number: 11\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9750 - val_acc: 0.8835\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9762 - val_acc: 0.8836\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9762 - val_acc: 0.8836\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9772 - val_acc: 0.8837\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9769 - val_acc: 0.8838\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9775 - val_acc: 0.8837\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9777 - val_acc: 0.8835\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9783 - val_acc: 0.8837\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9793 - val_acc: 0.8836\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9780 - val_acc: 0.8835\n",
      "Trial number: 12\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9790 - val_acc: 0.8836\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9803 - val_acc: 0.8837\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9806 - val_acc: 0.8836\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9812 - val_acc: 0.8835\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9808 - val_acc: 0.8836\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9804 - val_acc: 0.8834\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9816 - val_acc: 0.8837\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9821 - val_acc: 0.8836\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9825 - val_acc: 0.8834\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9828 - val_acc: 0.8835\n",
      "Trial number: 13\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9829 - val_acc: 0.8834\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9829 - val_acc: 0.8835\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9840 - val_acc: 0.8834\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9842 - val_acc: 0.8833\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9840 - val_acc: 0.8833\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9846 - val_acc: 0.8834\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9848 - val_acc: 0.8833\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9853 - val_acc: 0.8832\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9857 - val_acc: 0.8833\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9855 - val_acc: 0.8834\n",
      "Trial number: 14\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9855 - val_acc: 0.8833\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9859 - val_acc: 0.8833\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9863 - val_acc: 0.8833\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9864 - val_acc: 0.8833\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9867 - val_acc: 0.8834\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9869 - val_acc: 0.8832\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9874 - val_acc: 0.8833\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9871 - val_acc: 0.8833\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9873 - val_acc: 0.8834\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9879 - val_acc: 0.8834\n",
      "Trial number: 15\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9884 - val_acc: 0.8834\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9881 - val_acc: 0.8835\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9889 - val_acc: 0.8832\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9894 - val_acc: 0.8833\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9896 - val_acc: 0.8834\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9897 - val_acc: 0.8834\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9895 - val_acc: 0.8834\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9898 - val_acc: 0.8834\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9905 - val_acc: 0.8833\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9910 - val_acc: 0.8832\n",
      "Trial number: 16\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9911 - val_acc: 0.8834\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9908 - val_acc: 0.8833\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9913 - val_acc: 0.8835\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9915 - val_acc: 0.8832\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9910 - val_acc: 0.8833\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9919 - val_acc: 0.8834\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9924 - val_acc: 0.8833\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9924 - val_acc: 0.8834\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9925 - val_acc: 0.8833\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9926 - val_acc: 0.8832\n",
      "Trial number: 17\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9926 - val_acc: 0.8833\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9927 - val_acc: 0.8833\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9931 - val_acc: 0.8833\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9936 - val_acc: 0.8832\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9936 - val_acc: 0.8831\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9939 - val_acc: 0.8832\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9936 - val_acc: 0.8831\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9941 - val_acc: 0.8831\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9937 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9941 - val_acc: 0.8831\n",
      "Trial number: 18\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9941 - val_acc: 0.8833\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9943 - val_acc: 0.8832\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9943 - val_acc: 0.8831\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9946 - val_acc: 0.8833\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9946 - val_acc: 0.8832\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9944 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9950 - val_acc: 0.8831\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9948 - val_acc: 0.8831\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9953 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9953 - val_acc: 0.8832\n",
      "Trial number: 19\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9951 - val_acc: 0.8831\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9951 - val_acc: 0.8833\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9954 - val_acc: 0.8833\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9953 - val_acc: 0.8831\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9955 - val_acc: 0.8832\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9959 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9958 - val_acc: 0.8832\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9957 - val_acc: 0.8830\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9957 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9959 - val_acc: 0.8831\n",
      "Trial number: 20\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9960 - val_acc: 0.8831\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9962 - val_acc: 0.8833\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9963 - val_acc: 0.8832\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9961 - val_acc: 0.8830\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9964 - val_acc: 0.8831\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9963 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9962 - val_acc: 0.8831\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9963 - val_acc: 0.8831\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9965 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9967 - val_acc: 0.8831\n",
      "Trial number: 21\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9966 - val_acc: 0.8831\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9968 - val_acc: 0.8831\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9966 - val_acc: 0.8831\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9968 - val_acc: 0.8831\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9970 - val_acc: 0.8831\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9969 - val_acc: 0.8832\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9971 - val_acc: 0.8830\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9974 - val_acc: 0.8831\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9971 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9976 - val_acc: 0.8832\n",
      "Trial number: 22\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9976 - val_acc: 0.8830\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9977 - val_acc: 0.8832\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9976 - val_acc: 0.8831\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9979 - val_acc: 0.8832\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9978 - val_acc: 0.8831\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9978 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9979 - val_acc: 0.8831\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9977 - val_acc: 0.8831\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9979 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9984 - val_acc: 0.8831\n",
      "Trial number: 23\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9982 - val_acc: 0.8831\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9983 - val_acc: 0.8831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9984 - val_acc: 0.8831\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9985 - val_acc: 0.8831\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9985 - val_acc: 0.8831\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9987 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9986 - val_acc: 0.8831\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9988 - val_acc: 0.8831\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9987 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9987 - val_acc: 0.8831\n",
      "Trial number: 24\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9990 - val_acc: 0.8831\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9989 - val_acc: 0.8831\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9989 - val_acc: 0.8831\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9990 - val_acc: 0.8831\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9996 - val_acc: 0.8832\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9996 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9997 - val_acc: 0.8832\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9998 - val_acc: 0.8831\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9997 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9999 - val_acc: 0.8831\n",
      "Trial number: 25\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9998 - val_acc: 0.8831\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 0.9999 - val_acc: 0.8831\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0001 - val_acc: 0.8831\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0000 - val_acc: 0.8830\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0003 - val_acc: 0.8831\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0001 - val_acc: 0.8830\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0003 - val_acc: 0.8831\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0003 - val_acc: 0.8830\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0005 - val_acc: 0.8830\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0004 - val_acc: 0.8830\n",
      "Trial number: 26\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0006 - val_acc: 0.8830\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0005 - val_acc: 0.8830\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0008 - val_acc: 0.8830\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0011 - val_acc: 0.8830\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0007 - val_acc: 0.8831\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0008 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0008 - val_acc: 0.8831\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0011 - val_acc: 0.8830\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0011 - val_acc: 0.8830\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0011 - val_acc: 0.8831\n",
      "Trial number: 27\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0011 - val_acc: 0.8830\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0014 - val_acc: 0.8830\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0012 - val_acc: 0.8831\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0012 - val_acc: 0.8831\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0013 - val_acc: 0.8830\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0011 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0012 - val_acc: 0.8830\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0012 - val_acc: 0.8831\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0014 - val_acc: 0.8831\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0014 - val_acc: 0.8831\n",
      "Trial number: 28\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0014 - val_acc: 0.8829\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0014 - val_acc: 0.8830\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0015 - val_acc: 0.8830\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0015 - val_acc: 0.8830\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0016 - val_acc: 0.8830\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0015 - val_acc: 0.8830\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0016 - val_acc: 0.8830\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0019 - val_acc: 0.8830\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0017 - val_acc: 0.8830\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0017 - val_acc: 0.8830\n",
      "Trial number: 29\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0019 - val_acc: 0.8830\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0017 - val_acc: 0.8830\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0019 - val_acc: 0.8829\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0020 - val_acc: 0.8830\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0017 - val_acc: 0.8830\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0021 - val_acc: 0.8831\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0020 - val_acc: 0.8830\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0019 - val_acc: 0.8831\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0022 - val_acc: 0.8832\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0022 - val_acc: 0.8830\n",
      "Trial number: 30\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0021 - val_acc: 0.8831\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0020 - val_acc: 0.8830\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0022 - val_acc: 0.8831\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0022 - val_acc: 0.8831\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0024 - val_acc: 0.8831\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0020 - val_acc: 0.8832\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0023 - val_acc: 0.8832\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0023 - val_acc: 0.8832\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0024 - val_acc: 0.8832\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0024 - val_acc: 0.8832\n",
      "Trial number: 31\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0024 - val_acc: 0.8832\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0022 - val_acc: 0.8832\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0023 - val_acc: 0.8832\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0024 - val_acc: 0.8832\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0024 - val_acc: 0.8832\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0026 - val_acc: 0.8832\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0024 - val_acc: 0.8832\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0025 - val_acc: 0.8832\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0026 - val_acc: 0.8832\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9940 - val_loss: 1.0025 - val_acc: 0.8831\n",
      "| 1 | 0.8307 |\n",
      "| 2 | 0.8489 |\n",
      "| 3 | 0.8509 |\n",
      "| 4 | 0.851 |\n",
      "| 5 | 0.8482 |\n",
      "| 6 | 0.8511 |\n",
      "| 7 | 0.8531 |\n",
      "| 8 | 0.8531 |\n",
      "| 9 | 0.8535 |\n",
      "| 10 | 0.853 |\n",
      "| 11 | 0.8531 |\n",
      "| 12 | 0.8528 |\n",
      "| 13 | 0.8527 |\n",
      "| 14 | 0.8525 |\n",
      "| 15 | 0.8523 |\n",
      "| 16 | 0.8524 |\n",
      "| 17 | 0.8522 |\n",
      "| 18 | 0.8523 |\n",
      "| 19 | 0.852 |\n",
      "| 20 | 0.852 |\n",
      "| 21 | 0.852 |\n",
      "| 22 | 0.852 |\n",
      "| 23 | 0.852 |\n",
      "| 24 | 0.8518 |\n",
      "| 25 | 0.8517 |\n",
      "| 26 | 0.8515 |\n",
      "| 27 | 0.8515 |\n",
      "| 28 | 0.8514 |\n",
      "| 29 | 0.8513 |\n",
      "| 30 | 0.8514 |\n",
      "| 31 | 0.8514 |\n",
      "| 1 | 0.8744 |\n",
      "| 2 | 0.8807 |\n",
      "| 3 | 0.8726 |\n",
      "| 4 | 0.8824 |\n",
      "| 5 | 0.8823 |\n",
      "| 6 | 0.8828 |\n",
      "| 7 | 0.8827 |\n",
      "| 8 | 0.8832 |\n",
      "| 9 | 0.8832 |\n",
      "| 10 | 0.8834 |\n",
      "| 11 | 0.8835 |\n",
      "| 12 | 0.8835 |\n",
      "| 13 | 0.8834 |\n",
      "| 14 | 0.8834 |\n",
      "| 15 | 0.8832 |\n",
      "| 16 | 0.8832 |\n",
      "| 17 | 0.8831 |\n",
      "| 18 | 0.8832 |\n",
      "| 19 | 0.8831 |\n",
      "| 20 | 0.8831 |\n",
      "| 21 | 0.8832 |\n",
      "| 22 | 0.8831 |\n",
      "| 23 | 0.8831 |\n",
      "| 24 | 0.8831 |\n",
      "| 25 | 0.883 |\n",
      "| 26 | 0.8831 |\n",
      "| 27 | 0.8831 |\n",
      "| 28 | 0.883 |\n",
      "| 29 | 0.883 |\n",
      "| 30 | 0.8832 |\n",
      "| 31 | 0.8831 |\n",
      "Average: 0.8823999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 1\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.5779 - acc: 0.9395 - val_loss: 0.9012 - val_acc: 0.8902\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.3844 - acc: 0.9575 - val_loss: 0.8489 - val_acc: 0.8931\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.2878 - acc: 0.9675 - val_loss: 0.8536 - val_acc: 0.8939\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.2436 - acc: 0.9700 - val_loss: 0.7991 - val_acc: 0.8981\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.1894 - acc: 0.9810 - val_loss: 0.7574 - val_acc: 0.8990\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.1721 - acc: 0.9840 - val_loss: 0.8236 - val_acc: 0.8924\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.1534 - acc: 0.9865 - val_loss: 0.7673 - val_acc: 0.8987\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1442 - acc: 0.9865 - val_loss: 0.7336 - val_acc: 0.9006\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.1311 - acc: 0.9885 - val_loss: 0.7335 - val_acc: 0.9033\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1233 - acc: 0.9910 - val_loss: 0.7246 - val_acc: 0.9054\n",
      "Trial number: 2\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.1213 - acc: 0.9895 - val_loss: 0.7074 - val_acc: 0.9064\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1112 - acc: 0.9915 - val_loss: 0.7273 - val_acc: 0.9043\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1000 - acc: 0.9925 - val_loss: 0.6830 - val_acc: 0.9090\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0932 - acc: 0.9935 - val_loss: 0.6829 - val_acc: 0.9088\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0889 - acc: 0.9945 - val_loss: 0.6716 - val_acc: 0.9099\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0889 - acc: 0.9945 - val_loss: 0.7003 - val_acc: 0.9075\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0964 - acc: 0.9920 - val_loss: 0.6916 - val_acc: 0.9090\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0890 - acc: 0.9945 - val_loss: 0.6957 - val_acc: 0.9084\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.6936 - val_acc: 0.9087\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.6963 - val_acc: 0.9090\n",
      "Trial number: 3\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0978 - acc: 0.9920 - val_loss: 0.6985 - val_acc: 0.9095\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0888 - acc: 0.9945 - val_loss: 0.6973 - val_acc: 0.9094\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.6914 - val_acc: 0.9101\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.6983 - val_acc: 0.9090\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.6919 - val_acc: 0.9105\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7127 - val_acc: 0.9107\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0898 - acc: 0.9940 - val_loss: 0.7117 - val_acc: 0.9101\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0892 - acc: 0.9945 - val_loss: 0.7264 - val_acc: 0.9091\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7151 - val_acc: 0.9104\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7161 - val_acc: 0.9106\n",
      "Trial number: 4\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0925 - acc: 0.9940 - val_loss: 0.7569 - val_acc: 0.9067\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7206 - val_acc: 0.9103\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7191 - val_acc: 0.9102\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7198 - val_acc: 0.9112\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7120 - val_acc: 0.9119\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7328 - val_acc: 0.9107\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7222 - val_acc: 0.9114\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7782 - val_acc: 0.9035\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0909 - acc: 0.9940 - val_loss: 0.7294 - val_acc: 0.9110\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7299 - val_acc: 0.9113\n",
      "Trial number: 5\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7303 - val_acc: 0.9116\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7299 - val_acc: 0.9116\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7302 - val_acc: 0.9120\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7299 - val_acc: 0.9119\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7376 - val_acc: 0.9117\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7486 - val_acc: 0.9107\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9945 - val_loss: 0.7434 - val_acc: 0.9115\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7480 - val_acc: 0.9115\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7470 - val_acc: 0.9115\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7452 - val_acc: 0.9122\n",
      "Trial number: 6\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7433 - val_acc: 0.9130\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7465 - val_acc: 0.9125\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7516 - val_acc: 0.9118\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7498 - val_acc: 0.9120\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7551 - val_acc: 0.9122\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7552 - val_acc: 0.9115\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7555 - val_acc: 0.9117\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7562 - val_acc: 0.9115\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7570 - val_acc: 0.9113\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7585 - val_acc: 0.9123\n",
      "Trial number: 7\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7587 - val_acc: 0.9119\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7557 - val_acc: 0.9122\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7592 - val_acc: 0.9115\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7574 - val_acc: 0.9122\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7593 - val_acc: 0.9117\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7606 - val_acc: 0.9120\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7606 - val_acc: 0.9117\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7618 - val_acc: 0.9117\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7616 - val_acc: 0.9116\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7609 - val_acc: 0.9120\n",
      "Trial number: 8\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7633 - val_acc: 0.9117\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7629 - val_acc: 0.9117\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7639 - val_acc: 0.9118\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7645 - val_acc: 0.9115\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7650 - val_acc: 0.9115\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7640 - val_acc: 0.9119\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7642 - val_acc: 0.9119\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7656 - val_acc: 0.9115\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7660 - val_acc: 0.9113\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7647 - val_acc: 0.9120\n",
      "Trial number: 9\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7672 - val_acc: 0.9116\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7668 - val_acc: 0.9116\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7669 - val_acc: 0.9115\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7680 - val_acc: 0.9116\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7671 - val_acc: 0.9117\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7673 - val_acc: 0.9117\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7671 - val_acc: 0.9120\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7685 - val_acc: 0.9117\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7680 - val_acc: 0.9117\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7685 - val_acc: 0.9114\n",
      "Trial number: 10\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7684 - val_acc: 0.9116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7690 - val_acc: 0.9114\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7692 - val_acc: 0.9115\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7690 - val_acc: 0.9116\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7695 - val_acc: 0.9119\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7703 - val_acc: 0.9115\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7693 - val_acc: 0.9116\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7705 - val_acc: 0.9114\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7702 - val_acc: 0.9117\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7699 - val_acc: 0.9116\n",
      "Trial number: 11\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7706 - val_acc: 0.9119\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7703 - val_acc: 0.9115\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7714 - val_acc: 0.9116\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7716 - val_acc: 0.9116\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7715 - val_acc: 0.9116\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7716 - val_acc: 0.9118\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7717 - val_acc: 0.9117\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7720 - val_acc: 0.9115\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7719 - val_acc: 0.9116\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7718 - val_acc: 0.9119\n",
      "Trial number: 12\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7724 - val_acc: 0.9119\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7726 - val_acc: 0.9120\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7729 - val_acc: 0.9118\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7734 - val_acc: 0.9120\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7727 - val_acc: 0.9119\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7733 - val_acc: 0.9119\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7736 - val_acc: 0.9120\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7740 - val_acc: 0.9119\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7737 - val_acc: 0.9120\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7741 - val_acc: 0.9120\n",
      "Trial number: 13\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7740 - val_acc: 0.9120\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7745 - val_acc: 0.9120\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7746 - val_acc: 0.9121\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7744 - val_acc: 0.9119\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7749 - val_acc: 0.9120\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7749 - val_acc: 0.9120\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7749 - val_acc: 0.9121\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7752 - val_acc: 0.9120\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7759 - val_acc: 0.9119\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7758 - val_acc: 0.9119\n",
      "Trial number: 14\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7757 - val_acc: 0.9119\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7762 - val_acc: 0.9118\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7757 - val_acc: 0.9118\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7762 - val_acc: 0.9119\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7766 - val_acc: 0.9118\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7759 - val_acc: 0.9120\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7761 - val_acc: 0.9119\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7765 - val_acc: 0.9119\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7764 - val_acc: 0.9119\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7772 - val_acc: 0.9119\n",
      "Trial number: 15\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7770 - val_acc: 0.9117\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7768 - val_acc: 0.9118\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7771 - val_acc: 0.9120\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7773 - val_acc: 0.9119\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7773 - val_acc: 0.9118\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7778 - val_acc: 0.9119\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7775 - val_acc: 0.9120\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7774 - val_acc: 0.9120\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7780 - val_acc: 0.9118\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7783 - val_acc: 0.9119\n",
      "Trial number: 16\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7784 - val_acc: 0.9118\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7783 - val_acc: 0.9119\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7782 - val_acc: 0.9120\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7787 - val_acc: 0.9119\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7785 - val_acc: 0.9118\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7787 - val_acc: 0.9118\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7784 - val_acc: 0.9118\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7789 - val_acc: 0.9119\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7792 - val_acc: 0.9118\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7792 - val_acc: 0.9119\n",
      "Trial number: 17\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7792 - val_acc: 0.9119\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7791 - val_acc: 0.9120\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7793 - val_acc: 0.9118\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7796 - val_acc: 0.9118\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7792 - val_acc: 0.9118\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7791 - val_acc: 0.9119\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7796 - val_acc: 0.9118\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7796 - val_acc: 0.9120\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7796 - val_acc: 0.9119\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7795 - val_acc: 0.9120\n",
      "Trial number: 18\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7800 - val_acc: 0.9119\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7795 - val_acc: 0.9119\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7801 - val_acc: 0.9120\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7798 - val_acc: 0.9119\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7800 - val_acc: 0.9120\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7799 - val_acc: 0.9120\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7798 - val_acc: 0.9119\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7803 - val_acc: 0.9121\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7801 - val_acc: 0.9120\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7800 - val_acc: 0.9120\n",
      "Trial number: 19\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7804 - val_acc: 0.9121\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7804 - val_acc: 0.9120\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7803 - val_acc: 0.9121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7803 - val_acc: 0.9120\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7803 - val_acc: 0.9120\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7803 - val_acc: 0.9120\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7804 - val_acc: 0.9120\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7806 - val_acc: 0.9120\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7809 - val_acc: 0.9121\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7810 - val_acc: 0.9121\n",
      "Trial number: 20\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7809 - val_acc: 0.9121\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7808 - val_acc: 0.9121\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7805 - val_acc: 0.9120\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7812 - val_acc: 0.9122\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7809 - val_acc: 0.9121\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7810 - val_acc: 0.9121\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7808 - val_acc: 0.9120\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7811 - val_acc: 0.9121\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7809 - val_acc: 0.9121\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7811 - val_acc: 0.9121\n",
      "Trial number: 21\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7811 - val_acc: 0.9122\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7814 - val_acc: 0.9121\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7813 - val_acc: 0.9120\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7813 - val_acc: 0.9122\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7813 - val_acc: 0.9121\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7816 - val_acc: 0.9120\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7815 - val_acc: 0.9121\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7813 - val_acc: 0.9121\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7817 - val_acc: 0.9121\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7815 - val_acc: 0.9120\n",
      "Trial number: 22\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7816 - val_acc: 0.9120\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7817 - val_acc: 0.9120\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7819 - val_acc: 0.9121\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7816 - val_acc: 0.9121\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7816 - val_acc: 0.9121\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7818 - val_acc: 0.9120\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7816 - val_acc: 0.9121\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7818 - val_acc: 0.9121\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7818 - val_acc: 0.9120\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7819 - val_acc: 0.9121\n",
      "Trial number: 23\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7818 - val_acc: 0.9122\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7819 - val_acc: 0.9121\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7817 - val_acc: 0.9119\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7821 - val_acc: 0.9120\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7821 - val_acc: 0.9119\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7820 - val_acc: 0.9119\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7821 - val_acc: 0.9119\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7820 - val_acc: 0.9120\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7822 - val_acc: 0.9121\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7823 - val_acc: 0.9119\n",
      "Trial number: 24\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7822 - val_acc: 0.9121\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7824 - val_acc: 0.9119\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7822 - val_acc: 0.9120\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7822 - val_acc: 0.9119\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7824 - val_acc: 0.9119\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7822 - val_acc: 0.9118\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7823 - val_acc: 0.9120\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7821 - val_acc: 0.9119\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7824 - val_acc: 0.9120\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7824 - val_acc: 0.9119\n",
      "Trial number: 25\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7825 - val_acc: 0.9118\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7824 - val_acc: 0.9120\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7824 - val_acc: 0.9120\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7825 - val_acc: 0.9118\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7825 - val_acc: 0.9119\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7825 - val_acc: 0.9121\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7825 - val_acc: 0.9119\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7827 - val_acc: 0.9120\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7826 - val_acc: 0.9121\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7827 - val_acc: 0.9120\n",
      "Trial number: 26\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7827 - val_acc: 0.9118\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7826 - val_acc: 0.9121\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7825 - val_acc: 0.9121\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7827 - val_acc: 0.9119\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7827 - val_acc: 0.9120\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7825 - val_acc: 0.9121\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7827 - val_acc: 0.9118\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7827 - val_acc: 0.9118\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7828 - val_acc: 0.9119\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7826 - val_acc: 0.9119\n",
      "Trial number: 27\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7828 - val_acc: 0.9119\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7828 - val_acc: 0.9119\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7828 - val_acc: 0.9118\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7828 - val_acc: 0.9117\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7829 - val_acc: 0.9118\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7829 - val_acc: 0.9119\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7828 - val_acc: 0.9117\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7829 - val_acc: 0.9119\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7829 - val_acc: 0.9117\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7829 - val_acc: 0.9119\n",
      "Trial number: 28\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7830 - val_acc: 0.9117\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7830 - val_acc: 0.9117\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7829 - val_acc: 0.9118\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7829 - val_acc: 0.9118\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7830 - val_acc: 0.9118\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7829 - val_acc: 0.9118\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Trial number: 29\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9117\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7832 - val_acc: 0.9117\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7832 - val_acc: 0.9118\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Trial number: 30\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7831 - val_acc: 0.9118\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7833 - val_acc: 0.9117\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7833 - val_acc: 0.9118\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7832 - val_acc: 0.9117\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7833 - val_acc: 0.9118\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7832 - val_acc: 0.9118\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7833 - val_acc: 0.9118\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7832 - val_acc: 0.9118\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7833 - val_acc: 0.9119\n",
      "Trial number: 31\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7832 - val_acc: 0.9120\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7832 - val_acc: 0.9119\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7833 - val_acc: 0.9118\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7833 - val_acc: 0.9118\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7833 - val_acc: 0.9118\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7834 - val_acc: 0.9119\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7834 - val_acc: 0.9118\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7833 - val_acc: 0.9119\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7834 - val_acc: 0.9117\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0886 - acc: 0.9945 - val_loss: 0.7834 - val_acc: 0.9118\n",
      "| 1 | 0.8307 |\n",
      "| 2 | 0.8489 |\n",
      "| 3 | 0.8509 |\n",
      "| 4 | 0.851 |\n",
      "| 5 | 0.8482 |\n",
      "| 6 | 0.8511 |\n",
      "| 7 | 0.8531 |\n",
      "| 8 | 0.8531 |\n",
      "| 9 | 0.8535 |\n",
      "| 10 | 0.853 |\n",
      "| 11 | 0.8531 |\n",
      "| 12 | 0.8528 |\n",
      "| 13 | 0.8527 |\n",
      "| 14 | 0.8525 |\n",
      "| 15 | 0.8523 |\n",
      "| 16 | 0.8524 |\n",
      "| 17 | 0.8522 |\n",
      "| 18 | 0.8523 |\n",
      "| 19 | 0.852 |\n",
      "| 20 | 0.852 |\n",
      "| 21 | 0.852 |\n",
      "| 22 | 0.852 |\n",
      "| 23 | 0.852 |\n",
      "| 24 | 0.8518 |\n",
      "| 25 | 0.8517 |\n",
      "| 26 | 0.8515 |\n",
      "| 27 | 0.8515 |\n",
      "| 28 | 0.8514 |\n",
      "| 29 | 0.8513 |\n",
      "| 30 | 0.8514 |\n",
      "| 31 | 0.8514 |\n",
      "| 1 | 0.8744 |\n",
      "| 2 | 0.8807 |\n",
      "| 3 | 0.8726 |\n",
      "| 4 | 0.8824 |\n",
      "| 5 | 0.8823 |\n",
      "| 6 | 0.8828 |\n",
      "| 7 | 0.8827 |\n",
      "| 8 | 0.8832 |\n",
      "| 9 | 0.8832 |\n",
      "| 10 | 0.8834 |\n",
      "| 11 | 0.8835 |\n",
      "| 12 | 0.8835 |\n",
      "| 13 | 0.8834 |\n",
      "| 14 | 0.8834 |\n",
      "| 15 | 0.8832 |\n",
      "| 16 | 0.8832 |\n",
      "| 17 | 0.8831 |\n",
      "| 18 | 0.8832 |\n",
      "| 19 | 0.8831 |\n",
      "| 20 | 0.8831 |\n",
      "| 21 | 0.8832 |\n",
      "| 22 | 0.8831 |\n",
      "| 23 | 0.8831 |\n",
      "| 24 | 0.8831 |\n",
      "| 25 | 0.883 |\n",
      "| 26 | 0.8831 |\n",
      "| 27 | 0.8831 |\n",
      "| 28 | 0.883 |\n",
      "| 29 | 0.883 |\n",
      "| 30 | 0.8832 |\n",
      "| 31 | 0.8831 |\n",
      "| 1 | 0.9054 |\n",
      "| 2 | 0.909 |\n",
      "| 3 | 0.9106 |\n",
      "| 4 | 0.9113 |\n",
      "| 5 | 0.9122 |\n",
      "| 6 | 0.9123 |\n",
      "| 7 | 0.912 |\n",
      "| 8 | 0.912 |\n",
      "| 9 | 0.9114 |\n",
      "| 10 | 0.9116 |\n",
      "| 11 | 0.9119 |\n",
      "| 12 | 0.912 |\n",
      "| 13 | 0.9119 |\n",
      "| 14 | 0.9119 |\n",
      "| 15 | 0.9119 |\n",
      "| 16 | 0.9119 |\n",
      "| 17 | 0.912 |\n",
      "| 18 | 0.912 |\n",
      "| 19 | 0.9121 |\n",
      "| 20 | 0.9121 |\n",
      "| 21 | 0.912 |\n",
      "| 22 | 0.9121 |\n",
      "| 23 | 0.9119 |\n",
      "| 24 | 0.9119 |\n",
      "| 25 | 0.912 |\n",
      "| 26 | 0.9119 |\n",
      "| 27 | 0.9119 |\n",
      "| 28 | 0.9118 |\n",
      "| 29 | 0.9118 |\n",
      "| 30 | 0.9119 |\n",
      "| 31 | 0.9118 |\n",
      "Average: 0.9115645161290319\n",
      "Trial number: 1\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.4452 - acc: 0.9506 - val_loss: 0.6726 - val_acc: 0.9193\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.2797 - acc: 0.9662 - val_loss: 0.5910 - val_acc: 0.9232\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.2031 - acc: 0.9754 - val_loss: 0.5441 - val_acc: 0.9251\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.1526 - acc: 0.9800 - val_loss: 0.5567 - val_acc: 0.9233\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.1233 - acc: 0.9838 - val_loss: 0.5220 - val_acc: 0.9243\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.1008 - acc: 0.9892 - val_loss: 0.4807 - val_acc: 0.9283\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0930 - acc: 0.9896 - val_loss: 0.4891 - val_acc: 0.9259\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0747 - acc: 0.9930 - val_loss: 0.4669 - val_acc: 0.9304\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0661 - acc: 0.9938 - val_loss: 0.5019 - val_acc: 0.9250\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0626 - acc: 0.9950 - val_loss: 0.4468 - val_acc: 0.9336\n",
      "Trial number: 2\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0613 - acc: 0.9954 - val_loss: 0.4681 - val_acc: 0.9322\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0591 - acc: 0.9962 - val_loss: 0.4783 - val_acc: 0.9307\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0609 - acc: 0.9956 - val_loss: 0.4445 - val_acc: 0.9360\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0586 - acc: 0.9964 - val_loss: 0.4743 - val_acc: 0.9316\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0584 - acc: 0.9964 - val_loss: 0.4528 - val_acc: 0.9334\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0587 - acc: 0.9962 - val_loss: 0.4820 - val_acc: 0.9343\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0585 - acc: 0.9964 - val_loss: 0.4466 - val_acc: 0.9373\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0581 - acc: 0.9964 - val_loss: 0.4478 - val_acc: 0.9385\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0584 - acc: 0.9964 - val_loss: 0.4650 - val_acc: 0.9382\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0582 - acc: 0.9964 - val_loss: 0.4666 - val_acc: 0.9393\n",
      "Trial number: 3\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0588 - acc: 0.9960 - val_loss: 0.4443 - val_acc: 0.9412\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0580 - acc: 0.9964 - val_loss: 0.4433 - val_acc: 0.9418\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0581 - acc: 0.9964 - val_loss: 0.4632 - val_acc: 0.9408\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4522 - val_acc: 0.9423\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4562 - val_acc: 0.9413\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0551 - acc: 0.9964 - val_loss: 0.4628 - val_acc: 0.9415\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4732 - val_acc: 0.9409\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4639 - val_acc: 0.9418\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0555 - acc: 0.9964 - val_loss: 0.4741 - val_acc: 0.9408\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4631 - val_acc: 0.9411\n",
      "Trial number: 4\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4772 - val_acc: 0.9415\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4828 - val_acc: 0.9409\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4818 - val_acc: 0.9413\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4755 - val_acc: 0.9427\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0552 - acc: 0.9964 - val_loss: 0.4871 - val_acc: 0.9401\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4810 - val_acc: 0.9414\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4801 - val_acc: 0.9421\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4798 - val_acc: 0.9418\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4794 - val_acc: 0.9421\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4823 - val_acc: 0.9418\n",
      "Trial number: 5\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4807 - val_acc: 0.9422\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4825 - val_acc: 0.9421\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4825 - val_acc: 0.9429\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4841 - val_acc: 0.9423\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4838 - val_acc: 0.9430\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4840 - val_acc: 0.9429\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4844 - val_acc: 0.9426\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4850 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4862 - val_acc: 0.9427\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4865 - val_acc: 0.9428\n",
      "Trial number: 6\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4870 - val_acc: 0.9429\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4860 - val_acc: 0.9430\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4874 - val_acc: 0.9429\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4871 - val_acc: 0.9428\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4879 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4881 - val_acc: 0.9430\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4888 - val_acc: 0.9433\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4881 - val_acc: 0.9429\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4887 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4886 - val_acc: 0.9430\n",
      "Trial number: 7\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4894 - val_acc: 0.9430\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4891 - val_acc: 0.9432\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4895 - val_acc: 0.9428\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4900 - val_acc: 0.9433\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4901 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4900 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4902 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4904 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4906 - val_acc: 0.9434\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4906 - val_acc: 0.9432\n",
      "Trial number: 8\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4909 - val_acc: 0.9430\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4912 - val_acc: 0.9430\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4915 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4913 - val_acc: 0.9430\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4915 - val_acc: 0.9433\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4918 - val_acc: 0.9432\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4920 - val_acc: 0.9433\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4918 - val_acc: 0.9430\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4923 - val_acc: 0.9433\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4922 - val_acc: 0.9432\n",
      "Trial number: 9\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4923 - val_acc: 0.9432\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4925 - val_acc: 0.9433\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4925 - val_acc: 0.9433\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4927 - val_acc: 0.9432\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4926 - val_acc: 0.9432\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4931 - val_acc: 0.9432\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4931 - val_acc: 0.9433\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4932 - val_acc: 0.9434\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4934 - val_acc: 0.9433\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4936 - val_acc: 0.9434\n",
      "Trial number: 10\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4935 - val_acc: 0.9433\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4934 - val_acc: 0.9432\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4936 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4939 - val_acc: 0.9434\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4940 - val_acc: 0.9434\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4940 - val_acc: 0.9434\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4939 - val_acc: 0.9434\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4941 - val_acc: 0.9433\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4945 - val_acc: 0.9434\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4945 - val_acc: 0.9434\n",
      "Trial number: 11\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4946 - val_acc: 0.9435\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4946 - val_acc: 0.9433\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4949 - val_acc: 0.9432\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4949 - val_acc: 0.9435\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4948 - val_acc: 0.9434\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4950 - val_acc: 0.9434\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4950 - val_acc: 0.9433\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4951 - val_acc: 0.9435\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4954 - val_acc: 0.9433\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4955 - val_acc: 0.9433\n",
      "Trial number: 12\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4955 - val_acc: 0.9433\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4956 - val_acc: 0.9435\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4956 - val_acc: 0.9434\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4956 - val_acc: 0.9435\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4957 - val_acc: 0.9433\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4958 - val_acc: 0.9435\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4960 - val_acc: 0.9435\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4960 - val_acc: 0.9435\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4961 - val_acc: 0.9434\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4961 - val_acc: 0.9435\n",
      "Trial number: 13\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4962 - val_acc: 0.9434\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4964 - val_acc: 0.9433\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4965 - val_acc: 0.9434\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4965 - val_acc: 0.9435\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4966 - val_acc: 0.9435\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4966 - val_acc: 0.9435\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4966 - val_acc: 0.9434\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4967 - val_acc: 0.9434\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4969 - val_acc: 0.9436\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4969 - val_acc: 0.9435\n",
      "Trial number: 14\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4970 - val_acc: 0.9436\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4970 - val_acc: 0.9436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4971 - val_acc: 0.9435\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4972 - val_acc: 0.9436\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4972 - val_acc: 0.9435\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4974 - val_acc: 0.9435\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4974 - val_acc: 0.9435\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4974 - val_acc: 0.9436\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4975 - val_acc: 0.9434\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4975 - val_acc: 0.9434\n",
      "Trial number: 15\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4976 - val_acc: 0.9434\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4976 - val_acc: 0.9434\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4977 - val_acc: 0.9434\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4978 - val_acc: 0.9434\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4978 - val_acc: 0.9433\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4979 - val_acc: 0.9433\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4980 - val_acc: 0.9433\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4980 - val_acc: 0.9434\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4980 - val_acc: 0.9434\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4980 - val_acc: 0.9433\n",
      "Trial number: 16\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4981 - val_acc: 0.9433\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4982 - val_acc: 0.9432\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4982 - val_acc: 0.9432\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4983 - val_acc: 0.9433\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4984 - val_acc: 0.9432\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4984 - val_acc: 0.9430\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4983 - val_acc: 0.9433\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4984 - val_acc: 0.9432\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4984 - val_acc: 0.9432\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4984 - val_acc: 0.9431\n",
      "Trial number: 17\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4985 - val_acc: 0.9433\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4986 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4986 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4987 - val_acc: 0.9431\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4986 - val_acc: 0.9430\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4986 - val_acc: 0.9430\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4987 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4987 - val_acc: 0.9432\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4988 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4988 - val_acc: 0.9430\n",
      "Trial number: 18\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4989 - val_acc: 0.9431\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4989 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4988 - val_acc: 0.9430\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4989 - val_acc: 0.9430\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4990 - val_acc: 0.9430\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4990 - val_acc: 0.9430\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4991 - val_acc: 0.9430\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4990 - val_acc: 0.9430\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4991 - val_acc: 0.9430\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4991 - val_acc: 0.9429\n",
      "Trial number: 19\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4991 - val_acc: 0.9429\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4992 - val_acc: 0.9429\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4991 - val_acc: 0.9430\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4991 - val_acc: 0.9430\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4992 - val_acc: 0.9429\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4992 - val_acc: 0.9429\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4992 - val_acc: 0.9429\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4992 - val_acc: 0.9429\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4993 - val_acc: 0.9429\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4992 - val_acc: 0.9429\n",
      "Trial number: 20\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4993 - val_acc: 0.9429\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4993 - val_acc: 0.9429\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4993 - val_acc: 0.9429\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4994 - val_acc: 0.9429\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4993 - val_acc: 0.9429\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4994 - val_acc: 0.9429\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4993 - val_acc: 0.9429\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4994 - val_acc: 0.9429\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4994 - val_acc: 0.9429\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4993 - val_acc: 0.9429\n",
      "Trial number: 21\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4994 - val_acc: 0.9429\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4994 - val_acc: 0.9429\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4995 - val_acc: 0.9429\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4995 - val_acc: 0.9429\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4995 - val_acc: 0.9429\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4996 - val_acc: 0.9429\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4995 - val_acc: 0.9429\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4996 - val_acc: 0.9430\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4996 - val_acc: 0.9430\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4996 - val_acc: 0.9431\n",
      "Trial number: 22\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4996 - val_acc: 0.9429\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4996 - val_acc: 0.9429\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4996 - val_acc: 0.9430\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4997 - val_acc: 0.9430\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4997 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4997 - val_acc: 0.9430\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4997 - val_acc: 0.9430\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4997 - val_acc: 0.9430\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4997 - val_acc: 0.9429\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4998 - val_acc: 0.9430\n",
      "Trial number: 23\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4998 - val_acc: 0.9430\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4998 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4998 - val_acc: 0.9430\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9430\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9431\n",
      "Trial number: 24\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9430\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.4999 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Trial number: 25\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9430\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9430\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5000 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Trial number: 26\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Trial number: 27\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5001 - val_acc: 0.9431\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Trial number: 28\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5002 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Trial number: 29\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Trial number: 30\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Trial number: 31\n",
      "Train on 5000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5003 - val_acc: 0.9431\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5004 - val_acc: 0.9431\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5004 - val_acc: 0.9431\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5004 - val_acc: 0.9431\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9966 - val_loss: 0.5004 - val_acc: 0.9431\n",
      "| 1 | 0.8307 |\n",
      "| 2 | 0.8489 |\n",
      "| 3 | 0.8509 |\n",
      "| 4 | 0.851 |\n",
      "| 5 | 0.8482 |\n",
      "| 6 | 0.8511 |\n",
      "| 7 | 0.8531 |\n",
      "| 8 | 0.8531 |\n",
      "| 9 | 0.8535 |\n",
      "| 10 | 0.853 |\n",
      "| 11 | 0.8531 |\n",
      "| 12 | 0.8528 |\n",
      "| 13 | 0.8527 |\n",
      "| 14 | 0.8525 |\n",
      "| 15 | 0.8523 |\n",
      "| 16 | 0.8524 |\n",
      "| 17 | 0.8522 |\n",
      "| 18 | 0.8523 |\n",
      "| 19 | 0.852 |\n",
      "| 20 | 0.852 |\n",
      "| 21 | 0.852 |\n",
      "| 22 | 0.852 |\n",
      "| 23 | 0.852 |\n",
      "| 24 | 0.8518 |\n",
      "| 25 | 0.8517 |\n",
      "| 26 | 0.8515 |\n",
      "| 27 | 0.8515 |\n",
      "| 28 | 0.8514 |\n",
      "| 29 | 0.8513 |\n",
      "| 30 | 0.8514 |\n",
      "| 31 | 0.8514 |\n",
      "| 1 | 0.8744 |\n",
      "| 2 | 0.8807 |\n",
      "| 3 | 0.8726 |\n",
      "| 4 | 0.8824 |\n",
      "| 5 | 0.8823 |\n",
      "| 6 | 0.8828 |\n",
      "| 7 | 0.8827 |\n",
      "| 8 | 0.8832 |\n",
      "| 9 | 0.8832 |\n",
      "| 10 | 0.8834 |\n",
      "| 11 | 0.8835 |\n",
      "| 12 | 0.8835 |\n",
      "| 13 | 0.8834 |\n",
      "| 14 | 0.8834 |\n",
      "| 15 | 0.8832 |\n",
      "| 16 | 0.8832 |\n",
      "| 17 | 0.8831 |\n",
      "| 18 | 0.8832 |\n",
      "| 19 | 0.8831 |\n",
      "| 20 | 0.8831 |\n",
      "| 21 | 0.8832 |\n",
      "| 22 | 0.8831 |\n",
      "| 23 | 0.8831 |\n",
      "| 24 | 0.8831 |\n",
      "| 25 | 0.883 |\n",
      "| 26 | 0.8831 |\n",
      "| 27 | 0.8831 |\n",
      "| 28 | 0.883 |\n",
      "| 29 | 0.883 |\n",
      "| 30 | 0.8832 |\n",
      "| 31 | 0.8831 |\n",
      "| 1 | 0.9054 |\n",
      "| 2 | 0.909 |\n",
      "| 3 | 0.9106 |\n",
      "| 4 | 0.9113 |\n",
      "| 5 | 0.9122 |\n",
      "| 6 | 0.9123 |\n",
      "| 7 | 0.912 |\n",
      "| 8 | 0.912 |\n",
      "| 9 | 0.9114 |\n",
      "| 10 | 0.9116 |\n",
      "| 11 | 0.9119 |\n",
      "| 12 | 0.912 |\n",
      "| 13 | 0.9119 |\n",
      "| 14 | 0.9119 |\n",
      "| 15 | 0.9119 |\n",
      "| 16 | 0.9119 |\n",
      "| 17 | 0.912 |\n",
      "| 18 | 0.912 |\n",
      "| 19 | 0.9121 |\n",
      "| 20 | 0.9121 |\n",
      "| 21 | 0.912 |\n",
      "| 22 | 0.9121 |\n",
      "| 23 | 0.9119 |\n",
      "| 24 | 0.9119 |\n",
      "| 25 | 0.912 |\n",
      "| 26 | 0.9119 |\n",
      "| 27 | 0.9119 |\n",
      "| 28 | 0.9118 |\n",
      "| 29 | 0.9118 |\n",
      "| 30 | 0.9119 |\n",
      "| 31 | 0.9118 |\n",
      "| 1 | 0.9336 |\n",
      "| 2 | 0.9393 |\n",
      "| 3 | 0.9411 |\n",
      "| 4 | 0.9418 |\n",
      "| 5 | 0.9428 |\n",
      "| 6 | 0.943 |\n",
      "| 7 | 0.9432 |\n",
      "| 8 | 0.9432 |\n",
      "| 9 | 0.9434 |\n",
      "| 10 | 0.9434 |\n",
      "| 11 | 0.9433 |\n",
      "| 12 | 0.9435 |\n",
      "| 13 | 0.9435 |\n",
      "| 14 | 0.9434 |\n",
      "| 15 | 0.9433 |\n",
      "| 16 | 0.9431 |\n",
      "| 17 | 0.943 |\n",
      "| 18 | 0.9429 |\n",
      "| 19 | 0.9429 |\n",
      "| 20 | 0.9429 |\n",
      "| 21 | 0.9431 |\n",
      "| 22 | 0.943 |\n",
      "| 23 | 0.9431 |\n",
      "| 24 | 0.9431 |\n",
      "| 25 | 0.9431 |\n",
      "| 26 | 0.9431 |\n",
      "| 27 | 0.9431 |\n",
      "| 28 | 0.9431 |\n",
      "| 29 | 0.9431 |\n",
      "| 30 | 0.9431 |\n",
      "| 31 | 0.9431 |\n",
      "Average: 0.9426000000000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 1\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.2874 - acc: 0.9672 - val_loss: 0.5112 - val_acc: 0.9332\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.1782 - acc: 0.9774 - val_loss: 0.4317 - val_acc: 0.9415\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.1252 - acc: 0.9827 - val_loss: 0.4026 - val_acc: 0.9419\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0924 - acc: 0.9861 - val_loss: 0.3537 - val_acc: 0.9485\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0650 - acc: 0.9915 - val_loss: 0.3453 - val_acc: 0.9496\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0561 - acc: 0.9927 - val_loss: 0.3781 - val_acc: 0.9463\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0510 - acc: 0.9941 - val_loss: 0.3614 - val_acc: 0.9483\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0455 - acc: 0.9960 - val_loss: 0.3834 - val_acc: 0.9455\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0432 - acc: 0.9967 - val_loss: 0.3595 - val_acc: 0.9499\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0423 - acc: 0.9968 - val_loss: 0.3540 - val_acc: 0.9526\n",
      "Trial number: 2\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0423 - acc: 0.9971 - val_loss: 0.3719 - val_acc: 0.9483\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0418 - acc: 0.9970 - val_loss: 0.3612 - val_acc: 0.9522\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0409 - acc: 0.9972 - val_loss: 0.3482 - val_acc: 0.9528\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0407 - acc: 0.9972 - val_loss: 0.3388 - val_acc: 0.9560\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0395 - acc: 0.9974 - val_loss: 0.3450 - val_acc: 0.9551\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0390 - acc: 0.9975 - val_loss: 0.3498 - val_acc: 0.9530\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0391 - acc: 0.9975 - val_loss: 0.3473 - val_acc: 0.9564\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0392 - acc: 0.9975 - val_loss: 0.3577 - val_acc: 0.9538\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0390 - acc: 0.9975 - val_loss: 0.3688 - val_acc: 0.9540\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0388 - acc: 0.9976 - val_loss: 0.3472 - val_acc: 0.9569\n",
      "Trial number: 3\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3624 - val_acc: 0.9546\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0389 - acc: 0.9975 - val_loss: 0.3571 - val_acc: 0.9557\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0388 - acc: 0.9975 - val_loss: 0.3586 - val_acc: 0.9551\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0388 - acc: 0.9975 - val_loss: 0.3568 - val_acc: 0.9578\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0391 - acc: 0.9975 - val_loss: 0.3687 - val_acc: 0.9561\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3532 - val_acc: 0.9569\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0389 - acc: 0.9975 - val_loss: 0.3675 - val_acc: 0.9548\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3565 - val_acc: 0.9575\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3719 - val_acc: 0.9554\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3697 - val_acc: 0.9554\n",
      "Trial number: 4\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3727 - val_acc: 0.9567\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3673 - val_acc: 0.9575\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3630 - val_acc: 0.9580\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3635 - val_acc: 0.9579\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3639 - val_acc: 0.9578\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3649 - val_acc: 0.9579\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3647 - val_acc: 0.9580\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3651 - val_acc: 0.9577\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3650 - val_acc: 0.9576\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3654 - val_acc: 0.9576\n",
      "Trial number: 5\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3658 - val_acc: 0.9579\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3652 - val_acc: 0.9583\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3665 - val_acc: 0.9580\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3658 - val_acc: 0.9577\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3664 - val_acc: 0.9578\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3665 - val_acc: 0.9580\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3665 - val_acc: 0.9581\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3672 - val_acc: 0.9578\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3670 - val_acc: 0.9578\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3676 - val_acc: 0.9578\n",
      "Trial number: 6\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3672 - val_acc: 0.9579\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3677 - val_acc: 0.9578\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3680 - val_acc: 0.9578\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3678 - val_acc: 0.9579\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3679 - val_acc: 0.9577\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3680 - val_acc: 0.9579\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3680 - val_acc: 0.9580\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3684 - val_acc: 0.9580\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3687 - val_acc: 0.9579\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3687 - val_acc: 0.9578\n",
      "Trial number: 7\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3691 - val_acc: 0.9577\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3689 - val_acc: 0.9581\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3689 - val_acc: 0.9577\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3689 - val_acc: 0.9579\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3692 - val_acc: 0.9578\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3693 - val_acc: 0.9577\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3692 - val_acc: 0.9578\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3694 - val_acc: 0.9577\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3695 - val_acc: 0.9577\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3695 - val_acc: 0.9578\n",
      "Trial number: 8\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3697 - val_acc: 0.9579\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3697 - val_acc: 0.9579\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3698 - val_acc: 0.9579\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3697 - val_acc: 0.9579\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3700 - val_acc: 0.9580\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3702 - val_acc: 0.9579\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3703 - val_acc: 0.9579\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3704 - val_acc: 0.9581\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3703 - val_acc: 0.9581\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3703 - val_acc: 0.9580\n",
      "Trial number: 9\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3705 - val_acc: 0.9581\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3705 - val_acc: 0.9579\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3707 - val_acc: 0.9581\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3707 - val_acc: 0.9579\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3709 - val_acc: 0.9578\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3707 - val_acc: 0.9581\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3709 - val_acc: 0.9579\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3709 - val_acc: 0.9578\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3709 - val_acc: 0.9579\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3710 - val_acc: 0.9579\n",
      "Trial number: 10\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3712 - val_acc: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3711 - val_acc: 0.9580\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3711 - val_acc: 0.9579\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3713 - val_acc: 0.9578\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3711 - val_acc: 0.9579\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3713 - val_acc: 0.9580\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3714 - val_acc: 0.9580\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3713 - val_acc: 0.9583\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3714 - val_acc: 0.9579\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3714 - val_acc: 0.9579\n",
      "Trial number: 11\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3714 - val_acc: 0.9580\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3716 - val_acc: 0.9581\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3716 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3715 - val_acc: 0.9581\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3717 - val_acc: 0.9580\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3716 - val_acc: 0.9581\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3716 - val_acc: 0.9581\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3716 - val_acc: 0.9581\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3717 - val_acc: 0.9581\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3718 - val_acc: 0.9580\n",
      "Trial number: 12\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3717 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3719 - val_acc: 0.9580\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3718 - val_acc: 0.9581\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3719 - val_acc: 0.9580\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3720 - val_acc: 0.9581\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3719 - val_acc: 0.9580\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3719 - val_acc: 0.9582\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3720 - val_acc: 0.9580\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3720 - val_acc: 0.9580\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3720 - val_acc: 0.9581\n",
      "Trial number: 13\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3720 - val_acc: 0.9581\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3721 - val_acc: 0.9580\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3721 - val_acc: 0.9580\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3722 - val_acc: 0.9580\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3721 - val_acc: 0.9580\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3721 - val_acc: 0.9580\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3722 - val_acc: 0.9580\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3723 - val_acc: 0.9584\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3723 - val_acc: 0.9580\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3723 - val_acc: 0.9580\n",
      "Trial number: 14\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3723 - val_acc: 0.9583\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3724 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3723 - val_acc: 0.9580\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3724 - val_acc: 0.9580\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3724 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3725 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3725 - val_acc: 0.9581\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3725 - val_acc: 0.9581\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3724 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3725 - val_acc: 0.9582\n",
      "Trial number: 15\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3725 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3726 - val_acc: 0.9581\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3725 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3725 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3726 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3727 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3727 - val_acc: 0.9582\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3727 - val_acc: 0.9581\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3727 - val_acc: 0.9584\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3727 - val_acc: 0.9583\n",
      "Trial number: 16\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3728 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3728 - val_acc: 0.9581\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3728 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9581\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3728 - val_acc: 0.9583\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9583\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9584\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3728 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9584\n",
      "Trial number: 17\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9581\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9581\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9581\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9582\n",
      "Trial number: 18\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3731 - val_acc: 0.9581\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9583\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3731 - val_acc: 0.9583\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3731 - val_acc: 0.9581\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3730 - val_acc: 0.9583\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3731 - val_acc: 0.9583\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3731 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3731 - val_acc: 0.9581\n",
      "Trial number: 19\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3731 - val_acc: 0.9583\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3731 - val_acc: 0.9583\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3731 - val_acc: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Trial number: 20\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3732 - val_acc: 0.9583\n",
      "Trial number: 21\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9584\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9584\n",
      "Trial number: 22\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9584\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9584\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9584\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9584\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3733 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Trial number: 23\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9584\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9584\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Trial number: 24\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9583\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Trial number: 25\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Trial number: 26\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Trial number: 27\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Trial number: 28\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Trial number: 29\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Trial number: 30\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Trial number: 31\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9976 - val_loss: 0.3734 - val_acc: 0.9582\n",
      "| 1 | 0.8307 |\n",
      "| 2 | 0.8489 |\n",
      "| 3 | 0.8509 |\n",
      "| 4 | 0.851 |\n",
      "| 5 | 0.8482 |\n",
      "| 6 | 0.8511 |\n",
      "| 7 | 0.8531 |\n",
      "| 8 | 0.8531 |\n",
      "| 9 | 0.8535 |\n",
      "| 10 | 0.853 |\n",
      "| 11 | 0.8531 |\n",
      "| 12 | 0.8528 |\n",
      "| 13 | 0.8527 |\n",
      "| 14 | 0.8525 |\n",
      "| 15 | 0.8523 |\n",
      "| 16 | 0.8524 |\n",
      "| 17 | 0.8522 |\n",
      "| 18 | 0.8523 |\n",
      "| 19 | 0.852 |\n",
      "| 20 | 0.852 |\n",
      "| 21 | 0.852 |\n",
      "| 22 | 0.852 |\n",
      "| 23 | 0.852 |\n",
      "| 24 | 0.8518 |\n",
      "| 25 | 0.8517 |\n",
      "| 26 | 0.8515 |\n",
      "| 27 | 0.8515 |\n",
      "| 28 | 0.8514 |\n",
      "| 29 | 0.8513 |\n",
      "| 30 | 0.8514 |\n",
      "| 31 | 0.8514 |\n",
      "| 1 | 0.8744 |\n",
      "| 2 | 0.8807 |\n",
      "| 3 | 0.8726 |\n",
      "| 4 | 0.8824 |\n",
      "| 5 | 0.8823 |\n",
      "| 6 | 0.8828 |\n",
      "| 7 | 0.8827 |\n",
      "| 8 | 0.8832 |\n",
      "| 9 | 0.8832 |\n",
      "| 10 | 0.8834 |\n",
      "| 11 | 0.8835 |\n",
      "| 12 | 0.8835 |\n",
      "| 13 | 0.8834 |\n",
      "| 14 | 0.8834 |\n",
      "| 15 | 0.8832 |\n",
      "| 16 | 0.8832 |\n",
      "| 17 | 0.8831 |\n",
      "| 18 | 0.8832 |\n",
      "| 19 | 0.8831 |\n",
      "| 20 | 0.8831 |\n",
      "| 21 | 0.8832 |\n",
      "| 22 | 0.8831 |\n",
      "| 23 | 0.8831 |\n",
      "| 24 | 0.8831 |\n",
      "| 25 | 0.883 |\n",
      "| 26 | 0.8831 |\n",
      "| 27 | 0.8831 |\n",
      "| 28 | 0.883 |\n",
      "| 29 | 0.883 |\n",
      "| 30 | 0.8832 |\n",
      "| 31 | 0.8831 |\n",
      "| 1 | 0.9054 |\n",
      "| 2 | 0.909 |\n",
      "| 3 | 0.9106 |\n",
      "| 4 | 0.9113 |\n",
      "| 5 | 0.9122 |\n",
      "| 6 | 0.9123 |\n",
      "| 7 | 0.912 |\n",
      "| 8 | 0.912 |\n",
      "| 9 | 0.9114 |\n",
      "| 10 | 0.9116 |\n",
      "| 11 | 0.9119 |\n",
      "| 12 | 0.912 |\n",
      "| 13 | 0.9119 |\n",
      "| 14 | 0.9119 |\n",
      "| 15 | 0.9119 |\n",
      "| 16 | 0.9119 |\n",
      "| 17 | 0.912 |\n",
      "| 18 | 0.912 |\n",
      "| 19 | 0.9121 |\n",
      "| 20 | 0.9121 |\n",
      "| 21 | 0.912 |\n",
      "| 22 | 0.9121 |\n",
      "| 23 | 0.9119 |\n",
      "| 24 | 0.9119 |\n",
      "| 25 | 0.912 |\n",
      "| 26 | 0.9119 |\n",
      "| 27 | 0.9119 |\n",
      "| 28 | 0.9118 |\n",
      "| 29 | 0.9118 |\n",
      "| 30 | 0.9119 |\n",
      "| 31 | 0.9118 |\n",
      "| 1 | 0.9336 |\n",
      "| 2 | 0.9393 |\n",
      "| 3 | 0.9411 |\n",
      "| 4 | 0.9418 |\n",
      "| 5 | 0.9428 |\n",
      "| 6 | 0.943 |\n",
      "| 7 | 0.9432 |\n",
      "| 8 | 0.9432 |\n",
      "| 9 | 0.9434 |\n",
      "| 10 | 0.9434 |\n",
      "| 11 | 0.9433 |\n",
      "| 12 | 0.9435 |\n",
      "| 13 | 0.9435 |\n",
      "| 14 | 0.9434 |\n",
      "| 15 | 0.9433 |\n",
      "| 16 | 0.9431 |\n",
      "| 17 | 0.943 |\n",
      "| 18 | 0.9429 |\n",
      "| 19 | 0.9429 |\n",
      "| 20 | 0.9429 |\n",
      "| 21 | 0.9431 |\n",
      "| 22 | 0.943 |\n",
      "| 23 | 0.9431 |\n",
      "| 24 | 0.9431 |\n",
      "| 25 | 0.9431 |\n",
      "| 26 | 0.9431 |\n",
      "| 27 | 0.9431 |\n",
      "| 28 | 0.9431 |\n",
      "| 29 | 0.9431 |\n",
      "| 30 | 0.9431 |\n",
      "| 31 | 0.9431 |\n",
      "| 1 | 0.9526 |\n",
      "| 2 | 0.9569 |\n",
      "| 3 | 0.9554 |\n",
      "| 4 | 0.9576 |\n",
      "| 5 | 0.9578 |\n",
      "| 6 | 0.9578 |\n",
      "| 7 | 0.9578 |\n",
      "| 8 | 0.958 |\n",
      "| 9 | 0.9579 |\n",
      "| 10 | 0.9579 |\n",
      "| 11 | 0.958 |\n",
      "| 12 | 0.9581 |\n",
      "| 13 | 0.958 |\n",
      "| 14 | 0.9582 |\n",
      "| 15 | 0.9583 |\n",
      "| 16 | 0.9584 |\n",
      "| 17 | 0.9582 |\n",
      "| 18 | 0.9581 |\n",
      "| 19 | 0.9583 |\n",
      "| 20 | 0.9583 |\n",
      "| 21 | 0.9584 |\n",
      "| 22 | 0.9583 |\n",
      "| 23 | 0.9583 |\n",
      "| 24 | 0.9582 |\n",
      "| 25 | 0.9582 |\n",
      "| 26 | 0.9582 |\n",
      "| 27 | 0.9582 |\n",
      "| 28 | 0.9582 |\n",
      "| 29 | 0.9582 |\n",
      "| 30 | 0.9582 |\n",
      "| 31 | 0.9582 |\n",
      "Average: 0.957812903225807\n",
      "Trial number: 1\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.2215 - acc: 0.9750 - val_loss: 0.3173 - val_acc: 0.9601\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.1320 - acc: 0.9823 - val_loss: 0.2948 - val_acc: 0.9603\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0910 - acc: 0.9877 - val_loss: 0.2657 - val_acc: 0.9619\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0693 - acc: 0.9915 - val_loss: 0.2372 - val_acc: 0.9648\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0563 - acc: 0.9931 - val_loss: 0.2353 - val_acc: 0.9658\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0488 - acc: 0.9949 - val_loss: 0.2520 - val_acc: 0.9642\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0454 - acc: 0.9951 - val_loss: 0.2442 - val_acc: 0.9645\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0396 - acc: 0.9964 - val_loss: 0.2433 - val_acc: 0.9645\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0373 - acc: 0.9967 - val_loss: 0.2424 - val_acc: 0.9651\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0339 - acc: 0.9974 - val_loss: 0.2395 - val_acc: 0.9660\n",
      "Trial number: 2\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0336 - acc: 0.9969 - val_loss: 0.2363 - val_acc: 0.9667\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0319 - acc: 0.9974 - val_loss: 0.2452 - val_acc: 0.9659\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0306 - acc: 0.9979 - val_loss: 0.2513 - val_acc: 0.9665\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0300 - acc: 0.9979 - val_loss: 0.2340 - val_acc: 0.9698\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0292 - acc: 0.9981 - val_loss: 0.2463 - val_acc: 0.9682\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0287 - acc: 0.9981 - val_loss: 0.2581 - val_acc: 0.9662\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0288 - acc: 0.9980 - val_loss: 0.2368 - val_acc: 0.9681\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0286 - acc: 0.9981 - val_loss: 0.2443 - val_acc: 0.9699\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0282 - acc: 0.9982 - val_loss: 0.2480 - val_acc: 0.9698\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0277 - acc: 0.9983 - val_loss: 0.2457 - val_acc: 0.9693\n",
      "Trial number: 3\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0276 - acc: 0.9983 - val_loss: 0.2467 - val_acc: 0.9696\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0278 - acc: 0.9983 - val_loss: 0.2460 - val_acc: 0.9706\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0277 - acc: 0.9983 - val_loss: 0.2650 - val_acc: 0.9680\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0270 - acc: 0.9983 - val_loss: 0.2566 - val_acc: 0.9689\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0269 - acc: 0.9982 - val_loss: 0.2518 - val_acc: 0.9697\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0269 - acc: 0.9983 - val_loss: 0.2468 - val_acc: 0.9698\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0267 - acc: 0.9983 - val_loss: 0.2501 - val_acc: 0.9693\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2493 - val_acc: 0.9690\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0268 - acc: 0.9983 - val_loss: 0.2499 - val_acc: 0.9701\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2666 - val_acc: 0.9694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 4\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2688 - val_acc: 0.9678\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2459 - val_acc: 0.9714\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2615 - val_acc: 0.9686\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0267 - acc: 0.9983 - val_loss: 0.2516 - val_acc: 0.9703\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2479 - val_acc: 0.9706\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2474 - val_acc: 0.9709\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2471 - val_acc: 0.9709\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2483 - val_acc: 0.9708\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2483 - val_acc: 0.9709\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2489 - val_acc: 0.9707\n",
      "Trial number: 5\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2488 - val_acc: 0.9706\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2489 - val_acc: 0.9708\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2492 - val_acc: 0.9709\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2494 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2503 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2496 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2499 - val_acc: 0.9708\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2501 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2503 - val_acc: 0.9709\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2504 - val_acc: 0.9709\n",
      "Trial number: 6\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2507 - val_acc: 0.9709\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2503 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2508 - val_acc: 0.9710\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2506 - val_acc: 0.9708\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2510 - val_acc: 0.9708\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2509 - val_acc: 0.9708\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2508 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2510 - val_acc: 0.9709\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2513 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2511 - val_acc: 0.9707\n",
      "Trial number: 7\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2516 - val_acc: 0.9708\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2512 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2513 - val_acc: 0.9709\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2515 - val_acc: 0.9708\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2515 - val_acc: 0.9708\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2515 - val_acc: 0.9708\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2515 - val_acc: 0.9708\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2517 - val_acc: 0.9708\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2515 - val_acc: 0.9708\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2516 - val_acc: 0.9706\n",
      "Trial number: 8\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2518 - val_acc: 0.9708\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2516 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2517 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2519 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2518 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2520 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2518 - val_acc: 0.9705\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2517 - val_acc: 0.9705\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2521 - val_acc: 0.9706\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2519 - val_acc: 0.9707\n",
      "Trial number: 9\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2521 - val_acc: 0.9706\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2520 - val_acc: 0.9705\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2521 - val_acc: 0.9706\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2520 - val_acc: 0.9705\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2522 - val_acc: 0.9705\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2522 - val_acc: 0.9706\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2524 - val_acc: 0.9705\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2522 - val_acc: 0.9705\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2522 - val_acc: 0.9706\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2522 - val_acc: 0.9706\n",
      "Trial number: 10\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2524 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2524 - val_acc: 0.9705\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2523 - val_acc: 0.9705\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2523 - val_acc: 0.9705\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2523 - val_acc: 0.9705\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2525 - val_acc: 0.9705\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2525 - val_acc: 0.9705\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2525 - val_acc: 0.9705\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2525 - val_acc: 0.9705\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2526 - val_acc: 0.9705\n",
      "Trial number: 11\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2526 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2526 - val_acc: 0.9705\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2526 - val_acc: 0.9705\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2526 - val_acc: 0.9705\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2527 - val_acc: 0.9705\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2527 - val_acc: 0.9705\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2528 - val_acc: 0.9706\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2527 - val_acc: 0.9705\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2528 - val_acc: 0.9706\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2528 - val_acc: 0.9705\n",
      "Trial number: 12\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2528 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2529 - val_acc: 0.9705\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2529 - val_acc: 0.9705\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2529 - val_acc: 0.9705\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2529 - val_acc: 0.9705\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2530 - val_acc: 0.9705\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2531 - val_acc: 0.9705\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2531 - val_acc: 0.9706\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2530 - val_acc: 0.9705\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2531 - val_acc: 0.9705\n",
      "Trial number: 13\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2531 - val_acc: 0.9706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2532 - val_acc: 0.9706\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2532 - val_acc: 0.9705\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2532 - val_acc: 0.9706\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2533 - val_acc: 0.9705\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2532 - val_acc: 0.9706\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2532 - val_acc: 0.9705\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2533 - val_acc: 0.9705\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2534 - val_acc: 0.9706\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2533 - val_acc: 0.9706\n",
      "Trial number: 14\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2533 - val_acc: 0.9706\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2534 - val_acc: 0.9706\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2535 - val_acc: 0.9706\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2535 - val_acc: 0.9706\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2534 - val_acc: 0.9706\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2535 - val_acc: 0.9706\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2535 - val_acc: 0.9705\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2535 - val_acc: 0.9706\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2535 - val_acc: 0.9706\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2536 - val_acc: 0.9705\n",
      "Trial number: 15\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2536 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2535 - val_acc: 0.9706\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2536 - val_acc: 0.9706\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2536 - val_acc: 0.9706\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2536 - val_acc: 0.9706\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9706\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9707\n",
      "Trial number: 16\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9706\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9706\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2537 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Trial number: 17\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2538 - val_acc: 0.9707\n",
      "Trial number: 18\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Trial number: 19\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2539 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9706\n",
      "Trial number: 20\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 21\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9706\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9706\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9706\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 22\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9706\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9706\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 23\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 24\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 25\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 26\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 27\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 28\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 29\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 30\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Trial number: 31\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0266 - acc: 0.9984 - val_loss: 0.2540 - val_acc: 0.9707\n",
      "| 1 | 0.8307 |\n",
      "| 2 | 0.8489 |\n",
      "| 3 | 0.8509 |\n",
      "| 4 | 0.851 |\n",
      "| 5 | 0.8482 |\n",
      "| 6 | 0.8511 |\n",
      "| 7 | 0.8531 |\n",
      "| 8 | 0.8531 |\n",
      "| 9 | 0.8535 |\n",
      "| 10 | 0.853 |\n",
      "| 11 | 0.8531 |\n",
      "| 12 | 0.8528 |\n",
      "| 13 | 0.8527 |\n",
      "| 14 | 0.8525 |\n",
      "| 15 | 0.8523 |\n",
      "| 16 | 0.8524 |\n",
      "| 17 | 0.8522 |\n",
      "| 18 | 0.8523 |\n",
      "| 19 | 0.852 |\n",
      "| 20 | 0.852 |\n",
      "| 21 | 0.852 |\n",
      "| 22 | 0.852 |\n",
      "| 23 | 0.852 |\n",
      "| 24 | 0.8518 |\n",
      "| 25 | 0.8517 |\n",
      "| 26 | 0.8515 |\n",
      "| 27 | 0.8515 |\n",
      "| 28 | 0.8514 |\n",
      "| 29 | 0.8513 |\n",
      "| 30 | 0.8514 |\n",
      "| 31 | 0.8514 |\n",
      "| 1 | 0.8744 |\n",
      "| 2 | 0.8807 |\n",
      "| 3 | 0.8726 |\n",
      "| 4 | 0.8824 |\n",
      "| 5 | 0.8823 |\n",
      "| 6 | 0.8828 |\n",
      "| 7 | 0.8827 |\n",
      "| 8 | 0.8832 |\n",
      "| 9 | 0.8832 |\n",
      "| 10 | 0.8834 |\n",
      "| 11 | 0.8835 |\n",
      "| 12 | 0.8835 |\n",
      "| 13 | 0.8834 |\n",
      "| 14 | 0.8834 |\n",
      "| 15 | 0.8832 |\n",
      "| 16 | 0.8832 |\n",
      "| 17 | 0.8831 |\n",
      "| 18 | 0.8832 |\n",
      "| 19 | 0.8831 |\n",
      "| 20 | 0.8831 |\n",
      "| 21 | 0.8832 |\n",
      "| 22 | 0.8831 |\n",
      "| 23 | 0.8831 |\n",
      "| 24 | 0.8831 |\n",
      "| 25 | 0.883 |\n",
      "| 26 | 0.8831 |\n",
      "| 27 | 0.8831 |\n",
      "| 28 | 0.883 |\n",
      "| 29 | 0.883 |\n",
      "| 30 | 0.8832 |\n",
      "| 31 | 0.8831 |\n",
      "| 1 | 0.9054 |\n",
      "| 2 | 0.909 |\n",
      "| 3 | 0.9106 |\n",
      "| 4 | 0.9113 |\n",
      "| 5 | 0.9122 |\n",
      "| 6 | 0.9123 |\n",
      "| 7 | 0.912 |\n",
      "| 8 | 0.912 |\n",
      "| 9 | 0.9114 |\n",
      "| 10 | 0.9116 |\n",
      "| 11 | 0.9119 |\n",
      "| 12 | 0.912 |\n",
      "| 13 | 0.9119 |\n",
      "| 14 | 0.9119 |\n",
      "| 15 | 0.9119 |\n",
      "| 16 | 0.9119 |\n",
      "| 17 | 0.912 |\n",
      "| 18 | 0.912 |\n",
      "| 19 | 0.9121 |\n",
      "| 20 | 0.9121 |\n",
      "| 21 | 0.912 |\n",
      "| 22 | 0.9121 |\n",
      "| 23 | 0.9119 |\n",
      "| 24 | 0.9119 |\n",
      "| 25 | 0.912 |\n",
      "| 26 | 0.9119 |\n",
      "| 27 | 0.9119 |\n",
      "| 28 | 0.9118 |\n",
      "| 29 | 0.9118 |\n",
      "| 30 | 0.9119 |\n",
      "| 31 | 0.9118 |\n",
      "| 1 | 0.9336 |\n",
      "| 2 | 0.9393 |\n",
      "| 3 | 0.9411 |\n",
      "| 4 | 0.9418 |\n",
      "| 5 | 0.9428 |\n",
      "| 6 | 0.943 |\n",
      "| 7 | 0.9432 |\n",
      "| 8 | 0.9432 |\n",
      "| 9 | 0.9434 |\n",
      "| 10 | 0.9434 |\n",
      "| 11 | 0.9433 |\n",
      "| 12 | 0.9435 |\n",
      "| 13 | 0.9435 |\n",
      "| 14 | 0.9434 |\n",
      "| 15 | 0.9433 |\n",
      "| 16 | 0.9431 |\n",
      "| 17 | 0.943 |\n",
      "| 18 | 0.9429 |\n",
      "| 19 | 0.9429 |\n",
      "| 20 | 0.9429 |\n",
      "| 21 | 0.9431 |\n",
      "| 22 | 0.943 |\n",
      "| 23 | 0.9431 |\n",
      "| 24 | 0.9431 |\n",
      "| 25 | 0.9431 |\n",
      "| 26 | 0.9431 |\n",
      "| 27 | 0.9431 |\n",
      "| 28 | 0.9431 |\n",
      "| 29 | 0.9431 |\n",
      "| 30 | 0.9431 |\n",
      "| 31 | 0.9431 |\n",
      "| 1 | 0.9526 |\n",
      "| 2 | 0.9569 |\n",
      "| 3 | 0.9554 |\n",
      "| 4 | 0.9576 |\n",
      "| 5 | 0.9578 |\n",
      "| 6 | 0.9578 |\n",
      "| 7 | 0.9578 |\n",
      "| 8 | 0.958 |\n",
      "| 9 | 0.9579 |\n",
      "| 10 | 0.9579 |\n",
      "| 11 | 0.958 |\n",
      "| 12 | 0.9581 |\n",
      "| 13 | 0.958 |\n",
      "| 14 | 0.9582 |\n",
      "| 15 | 0.9583 |\n",
      "| 16 | 0.9584 |\n",
      "| 17 | 0.9582 |\n",
      "| 18 | 0.9581 |\n",
      "| 19 | 0.9583 |\n",
      "| 20 | 0.9583 |\n",
      "| 21 | 0.9584 |\n",
      "| 22 | 0.9583 |\n",
      "| 23 | 0.9583 |\n",
      "| 24 | 0.9582 |\n",
      "| 25 | 0.9582 |\n",
      "| 26 | 0.9582 |\n",
      "| 27 | 0.9582 |\n",
      "| 28 | 0.9582 |\n",
      "| 29 | 0.9582 |\n",
      "| 30 | 0.9582 |\n",
      "| 31 | 0.9582 |\n",
      "| 1 | 0.966 |\n",
      "| 2 | 0.9693 |\n",
      "| 3 | 0.9694 |\n",
      "| 4 | 0.9707 |\n",
      "| 5 | 0.9709 |\n",
      "| 6 | 0.9707 |\n",
      "| 7 | 0.9706 |\n",
      "| 8 | 0.9707 |\n",
      "| 9 | 0.9706 |\n",
      "| 10 | 0.9705 |\n",
      "| 11 | 0.9705 |\n",
      "| 12 | 0.9705 |\n",
      "| 13 | 0.9706 |\n",
      "| 14 | 0.9705 |\n",
      "| 15 | 0.9707 |\n",
      "| 16 | 0.9707 |\n",
      "| 17 | 0.9707 |\n",
      "| 18 | 0.9707 |\n",
      "| 19 | 0.9706 |\n",
      "| 20 | 0.9707 |\n",
      "| 21 | 0.9707 |\n",
      "| 22 | 0.9707 |\n",
      "| 23 | 0.9707 |\n",
      "| 24 | 0.9707 |\n",
      "| 25 | 0.9707 |\n",
      "| 26 | 0.9707 |\n",
      "| 27 | 0.9707 |\n",
      "| 28 | 0.9707 |\n",
      "| 29 | 0.9707 |\n",
      "| 30 | 0.9707 |\n",
      "| 31 | 0.9707 |\n",
      "Average: 0.9704290322580648\n",
      "Trial number: 1\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.1570 - acc: 0.9815 - val_loss: 0.2178 - val_acc: 0.9726\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0995 - acc: 0.9861 - val_loss: 0.2011 - val_acc: 0.9710\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0731 - acc: 0.9906 - val_loss: 0.1835 - val_acc: 0.9730\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0593 - acc: 0.9924 - val_loss: 0.1764 - val_acc: 0.9747\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0480 - acc: 0.9942 - val_loss: 0.1796 - val_acc: 0.9742\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0403 - acc: 0.9956 - val_loss: 0.1693 - val_acc: 0.9773\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0363 - acc: 0.9958 - val_loss: 0.1740 - val_acc: 0.9758\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0315 - acc: 0.9970 - val_loss: 0.1770 - val_acc: 0.9765\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0309 - acc: 0.9971 - val_loss: 0.1844 - val_acc: 0.9759\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0297 - acc: 0.9972 - val_loss: 0.1769 - val_acc: 0.9759\n",
      "Trial number: 2\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0277 - acc: 0.9978 - val_loss: 0.1921 - val_acc: 0.9751\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0270 - acc: 0.9979 - val_loss: 0.1837 - val_acc: 0.9766\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0264 - acc: 0.9981 - val_loss: 0.1771 - val_acc: 0.9770\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0259 - acc: 0.9982 - val_loss: 0.1757 - val_acc: 0.9776\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0259 - acc: 0.9982 - val_loss: 0.1746 - val_acc: 0.9778\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0253 - acc: 0.9982 - val_loss: 0.1869 - val_acc: 0.9762\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0251 - acc: 0.9983 - val_loss: 0.1833 - val_acc: 0.9767\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0254 - acc: 0.9983 - val_loss: 0.1967 - val_acc: 0.9755\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0252 - acc: 0.9984 - val_loss: 0.1843 - val_acc: 0.9769\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0250 - acc: 0.9983 - val_loss: 0.1790 - val_acc: 0.9783\n",
      "Trial number: 3\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0248 - acc: 0.9984 - val_loss: 0.1815 - val_acc: 0.9772\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0249 - acc: 0.9984 - val_loss: 0.1976 - val_acc: 0.9763\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0248 - acc: 0.9984 - val_loss: 0.1912 - val_acc: 0.9776\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0249 - acc: 0.9984 - val_loss: 0.1978 - val_acc: 0.9771\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0249 - acc: 0.9984 - val_loss: 0.1913 - val_acc: 0.9757\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0248 - acc: 0.9984 - val_loss: 0.1899 - val_acc: 0.9773\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1978 - val_acc: 0.9760\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0248 - acc: 0.9984 - val_loss: 0.2010 - val_acc: 0.9763\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0247 - acc: 0.9984 - val_loss: 0.1929 - val_acc: 0.9770\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1891 - val_acc: 0.9780\n",
      "Trial number: 4\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0248 - acc: 0.9985 - val_loss: 0.1936 - val_acc: 0.9763\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1994 - val_acc: 0.9773\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0247 - acc: 0.9985 - val_loss: 0.1980 - val_acc: 0.9773\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1900 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0248 - acc: 0.9984 - val_loss: 0.1935 - val_acc: 0.9764\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1974 - val_acc: 0.9773\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1996 - val_acc: 0.9774\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1922 - val_acc: 0.9777\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1981 - val_acc: 0.9778\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1917 - val_acc: 0.9783\n",
      "Trial number: 5\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9777\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9779\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1904 - val_acc: 0.9779\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1907 - val_acc: 0.9782\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1905 - val_acc: 0.9782\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9783\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1905 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1907 - val_acc: 0.9779\n",
      "Trial number: 6\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1905 - val_acc: 0.9782\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9779\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9782\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9781\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9781\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1905 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1905 - val_acc: 0.9781\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1907 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1907 - val_acc: 0.9780\n",
      "Trial number: 7\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1907 - val_acc: 0.9781\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1907 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1908 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9779\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1907 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1907 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1908 - val_acc: 0.9779\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1908 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9780\n",
      "Trial number: 8\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9781\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1908 - val_acc: 0.9781\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1908 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9781\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9781\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9781\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9779\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9781\n",
      "Trial number: 9\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9782\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9781\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9781\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9781\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9781\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9782\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9780\n",
      "Trial number: 10\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9781\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1909 - val_acc: 0.9782\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9781\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9781\n",
      "Trial number: 11\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9781\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1910 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9781\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9781\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9781\n",
      "Trial number: 12\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9781\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9781\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9781\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1911 - val_acc: 0.9781\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9781\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Trial number: 13\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9781\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9781\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Trial number: 14\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1912 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Trial number: 15\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1913 - val_acc: 0.9780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Trial number: 16\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9781\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9781\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Trial number: 17\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9781\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Trial number: 18\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9781\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Trial number: 19\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9781\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9781\n",
      "Trial number: 20\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9781\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9781\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9781\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Trial number: 21\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9779\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Trial number: 22\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Trial number: 23\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Trial number: 24\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Trial number: 25\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 5s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 6s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Trial number: 26\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Trial number: 27\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Trial number: 28\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Trial number: 29\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1915 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Trial number: 30\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9781\n",
      "Trial number: 31\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9781\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.1916 - val_acc: 0.9780\n",
      "| 1 | 0.8307 |\n",
      "| 2 | 0.8489 |\n",
      "| 3 | 0.8509 |\n",
      "| 4 | 0.851 |\n",
      "| 5 | 0.8482 |\n",
      "| 6 | 0.8511 |\n",
      "| 7 | 0.8531 |\n",
      "| 8 | 0.8531 |\n",
      "| 9 | 0.8535 |\n",
      "| 10 | 0.853 |\n",
      "| 11 | 0.8531 |\n",
      "| 12 | 0.8528 |\n",
      "| 13 | 0.8527 |\n",
      "| 14 | 0.8525 |\n",
      "| 15 | 0.8523 |\n",
      "| 16 | 0.8524 |\n",
      "| 17 | 0.8522 |\n",
      "| 18 | 0.8523 |\n",
      "| 19 | 0.852 |\n",
      "| 20 | 0.852 |\n",
      "| 21 | 0.852 |\n",
      "| 22 | 0.852 |\n",
      "| 23 | 0.852 |\n",
      "| 24 | 0.8518 |\n",
      "| 25 | 0.8517 |\n",
      "| 26 | 0.8515 |\n",
      "| 27 | 0.8515 |\n",
      "| 28 | 0.8514 |\n",
      "| 29 | 0.8513 |\n",
      "| 30 | 0.8514 |\n",
      "| 31 | 0.8514 |\n",
      "| 1 | 0.8744 |\n",
      "| 2 | 0.8807 |\n",
      "| 3 | 0.8726 |\n",
      "| 4 | 0.8824 |\n",
      "| 5 | 0.8823 |\n",
      "| 6 | 0.8828 |\n",
      "| 7 | 0.8827 |\n",
      "| 8 | 0.8832 |\n",
      "| 9 | 0.8832 |\n",
      "| 10 | 0.8834 |\n",
      "| 11 | 0.8835 |\n",
      "| 12 | 0.8835 |\n",
      "| 13 | 0.8834 |\n",
      "| 14 | 0.8834 |\n",
      "| 15 | 0.8832 |\n",
      "| 16 | 0.8832 |\n",
      "| 17 | 0.8831 |\n",
      "| 18 | 0.8832 |\n",
      "| 19 | 0.8831 |\n",
      "| 20 | 0.8831 |\n",
      "| 21 | 0.8832 |\n",
      "| 22 | 0.8831 |\n",
      "| 23 | 0.8831 |\n",
      "| 24 | 0.8831 |\n",
      "| 25 | 0.883 |\n",
      "| 26 | 0.8831 |\n",
      "| 27 | 0.8831 |\n",
      "| 28 | 0.883 |\n",
      "| 29 | 0.883 |\n",
      "| 30 | 0.8832 |\n",
      "| 31 | 0.8831 |\n",
      "| 1 | 0.9054 |\n",
      "| 2 | 0.909 |\n",
      "| 3 | 0.9106 |\n",
      "| 4 | 0.9113 |\n",
      "| 5 | 0.9122 |\n",
      "| 6 | 0.9123 |\n",
      "| 7 | 0.912 |\n",
      "| 8 | 0.912 |\n",
      "| 9 | 0.9114 |\n",
      "| 10 | 0.9116 |\n",
      "| 11 | 0.9119 |\n",
      "| 12 | 0.912 |\n",
      "| 13 | 0.9119 |\n",
      "| 14 | 0.9119 |\n",
      "| 15 | 0.9119 |\n",
      "| 16 | 0.9119 |\n",
      "| 17 | 0.912 |\n",
      "| 18 | 0.912 |\n",
      "| 19 | 0.9121 |\n",
      "| 20 | 0.9121 |\n",
      "| 21 | 0.912 |\n",
      "| 22 | 0.9121 |\n",
      "| 23 | 0.9119 |\n",
      "| 24 | 0.9119 |\n",
      "| 25 | 0.912 |\n",
      "| 26 | 0.9119 |\n",
      "| 27 | 0.9119 |\n",
      "| 28 | 0.9118 |\n",
      "| 29 | 0.9118 |\n",
      "| 30 | 0.9119 |\n",
      "| 31 | 0.9118 |\n",
      "| 1 | 0.9336 |\n",
      "| 2 | 0.9393 |\n",
      "| 3 | 0.9411 |\n",
      "| 4 | 0.9418 |\n",
      "| 5 | 0.9428 |\n",
      "| 6 | 0.943 |\n",
      "| 7 | 0.9432 |\n",
      "| 8 | 0.9432 |\n",
      "| 9 | 0.9434 |\n",
      "| 10 | 0.9434 |\n",
      "| 11 | 0.9433 |\n",
      "| 12 | 0.9435 |\n",
      "| 13 | 0.9435 |\n",
      "| 14 | 0.9434 |\n",
      "| 15 | 0.9433 |\n",
      "| 16 | 0.9431 |\n",
      "| 17 | 0.943 |\n",
      "| 18 | 0.9429 |\n",
      "| 19 | 0.9429 |\n",
      "| 20 | 0.9429 |\n",
      "| 21 | 0.9431 |\n",
      "| 22 | 0.943 |\n",
      "| 23 | 0.9431 |\n",
      "| 24 | 0.9431 |\n",
      "| 25 | 0.9431 |\n",
      "| 26 | 0.9431 |\n",
      "| 27 | 0.9431 |\n",
      "| 28 | 0.9431 |\n",
      "| 29 | 0.9431 |\n",
      "| 30 | 0.9431 |\n",
      "| 31 | 0.9431 |\n",
      "| 1 | 0.9526 |\n",
      "| 2 | 0.9569 |\n",
      "| 3 | 0.9554 |\n",
      "| 4 | 0.9576 |\n",
      "| 5 | 0.9578 |\n",
      "| 6 | 0.9578 |\n",
      "| 7 | 0.9578 |\n",
      "| 8 | 0.958 |\n",
      "| 9 | 0.9579 |\n",
      "| 10 | 0.9579 |\n",
      "| 11 | 0.958 |\n",
      "| 12 | 0.9581 |\n",
      "| 13 | 0.958 |\n",
      "| 14 | 0.9582 |\n",
      "| 15 | 0.9583 |\n",
      "| 16 | 0.9584 |\n",
      "| 17 | 0.9582 |\n",
      "| 18 | 0.9581 |\n",
      "| 19 | 0.9583 |\n",
      "| 20 | 0.9583 |\n",
      "| 21 | 0.9584 |\n",
      "| 22 | 0.9583 |\n",
      "| 23 | 0.9583 |\n",
      "| 24 | 0.9582 |\n",
      "| 25 | 0.9582 |\n",
      "| 26 | 0.9582 |\n",
      "| 27 | 0.9582 |\n",
      "| 28 | 0.9582 |\n",
      "| 29 | 0.9582 |\n",
      "| 30 | 0.9582 |\n",
      "| 31 | 0.9582 |\n",
      "| 1 | 0.966 |\n",
      "| 2 | 0.9693 |\n",
      "| 3 | 0.9694 |\n",
      "| 4 | 0.9707 |\n",
      "| 5 | 0.9709 |\n",
      "| 6 | 0.9707 |\n",
      "| 7 | 0.9706 |\n",
      "| 8 | 0.9707 |\n",
      "| 9 | 0.9706 |\n",
      "| 10 | 0.9705 |\n",
      "| 11 | 0.9705 |\n",
      "| 12 | 0.9705 |\n",
      "| 13 | 0.9706 |\n",
      "| 14 | 0.9705 |\n",
      "| 15 | 0.9707 |\n",
      "| 16 | 0.9707 |\n",
      "| 17 | 0.9707 |\n",
      "| 18 | 0.9707 |\n",
      "| 19 | 0.9706 |\n",
      "| 20 | 0.9707 |\n",
      "| 21 | 0.9707 |\n",
      "| 22 | 0.9707 |\n",
      "| 23 | 0.9707 |\n",
      "| 24 | 0.9707 |\n",
      "| 25 | 0.9707 |\n",
      "| 26 | 0.9707 |\n",
      "| 27 | 0.9707 |\n",
      "| 28 | 0.9707 |\n",
      "| 29 | 0.9707 |\n",
      "| 30 | 0.9707 |\n",
      "| 31 | 0.9707 |\n",
      "| 1 | 0.9759 |\n",
      "| 2 | 0.9783 |\n",
      "| 3 | 0.978 |\n",
      "| 4 | 0.9783 |\n",
      "| 5 | 0.9779 |\n",
      "| 6 | 0.978 |\n",
      "| 7 | 0.978 |\n",
      "| 8 | 0.9781 |\n",
      "| 9 | 0.978 |\n",
      "| 10 | 0.9781 |\n",
      "| 11 | 0.9781 |\n",
      "| 12 | 0.978 |\n",
      "| 13 | 0.978 |\n",
      "| 14 | 0.978 |\n",
      "| 15 | 0.978 |\n",
      "| 16 | 0.978 |\n",
      "| 17 | 0.978 |\n",
      "| 18 | 0.978 |\n",
      "| 19 | 0.9781 |\n",
      "| 20 | 0.978 |\n",
      "| 21 | 0.978 |\n",
      "| 22 | 0.978 |\n",
      "| 23 | 0.978 |\n",
      "| 24 | 0.978 |\n",
      "| 25 | 0.978 |\n",
      "| 26 | 0.978 |\n",
      "| 27 | 0.978 |\n",
      "| 28 | 0.978 |\n",
      "| 29 | 0.978 |\n",
      "| 30 | 0.9781 |\n",
      "| 31 | 0.978 |\n",
      "Average: 0.9779645161290328\n"
     ]
    }
   ],
   "source": [
    "trials = []\n",
    "accs = []\n",
    "accuracies = 0\n",
    "examples = 500\n",
    "counts = [1000, 2000, 5000, 10000, 20000, 40000, 60000]\n",
    "k = 0\n",
    "while examples <= 40000:\n",
    "    x_train = (_x_train.reshape(60000, 784).astype(\"float32\") / 255)[:examples,:]\n",
    "    y_train = keras.utils.to_categorical(_y_train, 10)[:examples,:]\n",
    "    for i in range(1,32):\n",
    "        print(f\"Trial number: {i}\")\n",
    "        history = model.fit(x_train, y_train,\n",
    "                       batch_size=100,\n",
    "                       epochs=10,\n",
    "                       verbose=2,\n",
    "                       validation_data=(x_test,y_test))\n",
    "        acc = model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "        trial = \"| {0} | {1} |\".format(i,  acc)\n",
    "        accs.append(acc)\n",
    "        accuracies += acc\n",
    "        trials.append(trial)\n",
    "    average = accuracies / 31\n",
    "    averages.append(average)\n",
    "    accuracies = 0\n",
    "    for t in trials:\n",
    "        print(t)\n",
    "    print(f\"Average: {average}\")\n",
    "    examples = counts[k]\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8511548387096777, 0.8823999999999996, 0.9115645161290319, 0.9426000000000007, 0.957812903225807, 0.9704290322580648, 0.9779645161290328, 0.9815387096774097]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt4XXWd7/H3N/c217ZJ27RpaZFbw0UosYjgFOGgBRw4gM4B1IERxeconplRHg+Mig6OhxkPx6MeGJXRCuiMyBQvPdoClcuIRy5NgdILtJRyaW5t2pKkabOT7OR7/lgr6e5O2mzoTnb2Xp/X8+wna//WWsn3B7uf/PJbN3N3REQkGvIyXYCIiEwchb6ISIQo9EVEIkShLyISIQp9EZEIUeiLiESIQl9EJEIU+iIiEaLQFxGJkIJMF5CsurraFyxYkOkyRESyyrp163a7e81Y20260F+wYAGNjY2ZLkNEJKuY2RupbKfpHRGRCFHoi4hEiEJfRCRCFPoiIhGi0BcRiRCFvohIhCj0RUQiJKXz9M1sGfBdIB/4kbv/Y9L6Y4DlQA2wF/i4uzeF674FXELwC2YN8NeuZzSKSIQMDDr7++J0x+J094avWJz9vXH29QZfu2NxppcV8bGzjhnXWsYMfTPLB+4CLgSagLVmttLdNydsdgdwn7vfa2bnA7cDnzCz9wHnAKeF2/0RWAo8kb4uiIik32AY1Pt7B+ju7ae7dyAM7aHlfvb3DbAvDO/EMO/uPTTQD/QNpPQzz5hflfnQB5YA29x9O4CZ3Q9cBiSGfj3whXD5ceDX4bIDJUARYEAhsPPoyxYRGcndOdA3cPjRdG981JAedRSeYlAX5htlxQWUFhdQVlxAeUkBM8qKOGbGVMrCttKwfWibspKC4XWJ2xQVjP+MeyqhPxfYkfC+CTgraZv1wBUEU0CXA+VmNsPdnzKzx4FWgtC/091fOvqyRSRXuDux/kH29fYHo+pY/OBywgh7tNH00Gt/QngPpjB5nJ9nh4ZuSQFVU4uomzb1YICXFFBWnE9ZcSGlxfmUlxQcXA6/lpUUUFyQP/7/kdIoXffeuQm408yuA/4ANAMDZnYcsAioC7dbY2bvd/cnE3c2sxuAGwDmz5+fppJEZLy4O73xwREBPNZoel/s0JAeWp9KUOcZh4T00Oi5trJkxOh5eGRdlDSqDpeLC/Iws/H/DzUJpRL6zcC8hPd1Ydswd28hGOljZmXAle7eYWafBp529+5w3WrgbODJpP3vBu4GaGho0EFekXHi7nT1xOns6T/saHpfwrRI8mg6MbTjKSS1GZQVHQzpofCdVV4yHMyHHVknjKbLiwspKYxuUKdTKqG/FjjezBYShP1VwDWJG5hZNbDX3QeBWwjO5AF4E/i0md1OML2zFPhOmmoXkQRDgd7a1UNrR4yWzh7aOmO0dMRoC9taO2P09I89V11alD9ihDyjdOqoo+nh5UPCO3hNKcwnL09BPZmMGfruHjezG4GHCU7ZXO7um8zsNqDR3VcC5wG3m5kTTO98Ltx9BXA+sIHgoO5D7v5/098Nkdzm7nTF4kGIh2He2tFDS2fskLbks0TyDGZVlDC7soRFtRV84KSZ1FaWUDW1KGnK4+AIu7SoQEGdw2yynTLf0NDgup++RM2+WD+tnTFaOsLReWeMts4eWjuD0XlrR8+Is0nyDGaWB4E+p6qE2RVTgq+VJdRWBss1ZcUU5OsazCgws3Xu3jDWdpPuISoiuaa7N05rx1CAh18Tpl9aO2N098YP2ccMasqKqa2awnE1Zbz/+GrmVE45GPCVU5hZXkyhAl3eJoW+yFHY3xs/GObhnPlwsIdf98VGBnp1WTFzKks4tqaUc46rprayhNqqKcHXyhJmVZQo0GVcKPRFDuNAX3x4VJ4c5ENtXUmBDkGg11aWsGBGKe97V3U43RJMuQwF+kRchCMyGoW+RFJP3wCtnQfnz1s7emjtiiVMw8To7OkfsV91WRGzK0uYP2MqZx07fTjIaytLmFM1hZkVxVl3sY5Ei0Jfck6sf+CQKZe2ruAA6fBB0c4eOg6MDPTppUXUVpZQN20K71kwndqqkSP0kkIFumQ3hb5klVj/ADu7gnPPE6dcDp6PHmPv/r4R+02bWhic0VJZwpnHVCWM0IOvsysV6BINCn2ZNHrjA+zs7D14UVFCmA8F+55RAr1qaiGzK4LpldPnVzEnIcxrq6Ywu6KEKUUKdBFQ6MsE6YsPsrPr4PRKS0dwHvrQxUWtnT3s7h4Z6JVTCofnzE+rCwJ9djh/PjRCn1qkj7FIqvSvRdJuf2+cVRtaeezlXTR3BAG/u7t3xHblJQXD556fMreC2qHz0MOvtZXB/VlEJH30L0rSYnDQefq1PaxY18RDG9s40DfA3KopvGtmGfW1FYeE+dDFRWUKdJEJp391clTe2LOfB59r5sF1TTR39FBeXMBlp8/hI2fWsXj+NN0VUWSSUejL29bdG2fVi62sWNfEs6/vxQzOPa6aLy07kQ+dPFtnwYhMYgp9ScngoPPU9mD6ZvXGVmL9gxxbU8qXlp3I5WfMpbZySqZLFJEUKPTliF7bvZ8H1zXxy+eaaOmMUV5SwBWL6/jImXWcMa9K0zciWUahLyN0xfqHp28a33iLPIP3H1/DLRcv4sL6WZq+EcliCn0BYGDQ+dOru4fPvumND3LczDL++7KTuPyMucyuLMl0iSKSBgr9iHu1vZsH1zXxq+ebae2MUVFSwEcb6vjImfN4d12lpm9EcoxCP4I6e/r57YstPLiuiefe7CDPYOkJNXzlknouWDRT0zciOUyhHxEDg84ftwXTNw9vaqMvPsgJs8r4u4tP4j+fPpeZFZq+EYkChX6O27ZrHyvWNfOr55vY2dVL1dRCrn7PPK48s45T52r6RiRqFPo5qPNAPyvD6ZsXdnSQn2ecd0INX//zOs5fNFMP+RCJsJRC38yWAd8F8oEfufs/Jq0/BlgO1AB7gY+7e1O4bj7wI2Ae4MDF7v56ujoggfjAIE++spsVzzWxZvNO+uKDnDirnK9csojLTp9LTXlxpksUkUlgzNA3s3zgLuBCoAlYa2Yr3X1zwmZ3APe5+71mdj5wO/CJcN19wDfdfY2ZlQGDae1BxG3duS+4eOr5Ztr39TJtaiHXLJnPR86s4+Q5FZq+EZFDpDLSXwJsc/ftAGZ2P3AZkBj69cAXwuXHgV+H29YDBe6+BsDdu9NUd6R1HOhj5foWVqxr4sWmTgryjA+cNJMrF9dx/kkz9dBtETmsVEJ/LrAj4X0TcFbSNuuBKwimgC4Hys1sBnAC0GFmvwQWAr8Hbnb3gaMtPGriA4P8x9Z2Hnyuid9v3kXfwCCLaiv46ofruez0OVSXafpGRMaWrgO5NwF3mtl1wB+AZmAg/P7vB84A3gR+AVwH/DhxZzO7AbgBYP78+WkqKTe83NYVXjzVwu7uXqaXFvHx9x7DlWfO5eQ5lZkuT0SyTCqh30xwEHZIXdg2zN1bCEb6hPP2V7p7h5k1AS8kTA39GngvSaHv7ncDdwM0NDT4O+tK7ti7v4+VLzSz4rkmNjZ3UZBnXLAomL4570RN34jIO5dK6K8FjjezhQRhfxVwTeIGZlYN7HX3QeAWgjN5hvatMrMad28Hzgca01V8rtm6cx/ffmQrj768k/4B5+Q5FXztz+u59N1zmKHpGxFJgzFD393jZnYj8DDBKZvL3X2Tmd0GNLr7SuA84HYzc4Lpnc+F+w6Y2U3AoxacRrIO+Jfx6Up2e2b7Hj51XyP5eca1Zy/gyjPrWFRbkemyRCTHmPvkmk1paGjwxsZo/THw0MZW/tv9LzBv2hTu/eQS6qZNzXRJIpJlzGyduzeMtZ2uyM2wnz79Brf+ZiOnz6ti+bXvYVppUaZLEpEcptDPEHfnf6/Zyvce28YFJ83kzmsWM6VIt0cQkfGl0M+A+MAgX/3NRn7+7A7+oqGO/3H5qRTk64wcERl/Cv0JFusf4PM/f541m3dy4weO44sfPEG3ShCRCaPQn0AdB/r41L2NrHvzLf7+0pO59n0LMl2SiESMQn+CtHT0cO3yZ3ljzwHuvHoxl5xWm+mSRCSCFPoT4JWd+/jL5c/SHYtzzyffw/veVZ3pkkQkohT646zx9b1cf28jRQV53P+Z9+p+OSKSUQr9cbRm805u/LfnmFM1hfs+uYR503XRlYhklkJ/nNz/7Jv83a82cOrcSpZf9x7dO0dEJgWFfpq5O//nsW18e81Wlp5Qwz9/bDGlxfrPLCKTg9IojQYGna+v3MRPn36DKxbP5Z+uPI1CXXQlIpOIQj9NYv0D/O0vXmD1xjY+s/RYbl52ki66EpFJR6GfBp09/dxwXyPPvLaXr364nuvPXZjpkkRERqXQP0o7u2Jcu/xZXm3v5ntXn8Gl756T6ZJERA5LoX8Utu3q5trlz9JxoI+fXLeEc4/XRVciMrkp9N+h5958i+vvWUt+nnH/DWdzap0uuhKRyU+h/w489vJOPvuvzzGrooT7PrmEY2aUZrokEZGUKPTfpn9v3MHNv9zAotpyfnLdEmrKddGViGQPhX6K3J3v/8erfOuhLZx7XDU/+MSZlOmiKxHJMkqtFP3D717ix398jUvfPYc7Pvpuigp00ZWIZB+Ffgpebuvix398jY+dNZ9vXHYKeXm66EpEslNKw1UzW2ZmW8xsm5ndPMr6Y8zsUTN70cyeMLO6pPUVZtZkZnemq/CJtGpDG2bwN//pBAW+iGS1MUPfzPKBu4CLgHrgajOrT9rsDuA+dz8NuA24PWn9N4A/HH25mbF6QytLFkzXQVsRyXqpjPSXANvcfbu79wH3A5clbVMPPBYuP5643szOBGYBjxx9uRNv2659vLKrm4tOmZ3pUkREjloqoT8X2JHwvilsS7QeuCJcvhwoN7MZZpYH/C/gpiP9ADO7wcwazayxvb09tconyOoNbQAsO0XPtBWR7JeuU1BuApaa2fPAUqAZGAA+C6xy96Yj7ezud7t7g7s31NTUpKmk9Fi9sY3F86uYXVmS6VJERI5aKmfvNAPzEt7XhW3D3L2FcKRvZmXAle7eYWZnA+83s88CZUCRmXW7+4iDwZPRG3v2s7m1i69csijTpYiIpEUqob8WON7MFhKE/VXANYkbmFk1sNfdB4FbgOUA7v6xhG2uAxqyJfAhGOUDfOhkzeeLSG4Yc3rH3ePAjcDDwEvAA+6+ycxuM7NLw83OA7aY2VaCg7bfHKd6J9TqjW2cVlepB5qLSM5I6eIsd18FrEpquzVheQWwYozvcQ9wz9uuMEOaO3pYv6ODLy07MdOliIikje4lcBgPhVM7F+msHRHJIQr9w1i9oZWTZpezsFq3TRaR3KHQH8XOrhjr3nyLi0/VKF9EcotCfxQPb2rDHV2FKyI5R6E/itUb2jhuZhnHzyrPdCkiImml0E+yp7uXZ17bo1G+iOQkhX6SRzbvZNB11o6I5CaFfpJVG1o5ZsZUFtVqakdEco9CP0HHgT6eenUPF51Si5keliIiuUehn2DN5p3EB13z+SKSsxT6CR7a2MbcqimcVleZ6VJERMaFQj+0L9bPk6/sZtkpszW1IyI5S6EfeuzlXfQNDHLxqZraEZHcpdAPrdrQyqyKYs6YNy3TpYiIjBuFPrC/N84TW9pZdvJs8vI0tSMiuUuhDzyxpZ3e+KAefi4iOU+hD6ze2MqM0iKWLJye6VJERMZV5EM/1j/AYy/v4oMnzyZfUzsikuMiH/p/2NrOgb4BXZAlIpEQ+dBfvbGNyimFnP2uGZkuRURk3EU69HvjA/z+pZ1cWD+LwvxI/6cQkYhIKenMbJmZbTGzbWZ28yjrjzGzR83sRTN7wszqwvbTzewpM9sUrvsv6e7A0fjTtj3si8V1QZaIRMaYoW9m+cBdwEVAPXC1mdUnbXYHcJ+7nwbcBtweth8A/tLdTwaWAd8xs6p0FX+0Vm9spby4gHOOq850KSIiEyKVkf4SYJu7b3f3PuB+4LKkbeqBx8Llx4fWu/tWd38lXG4BdgE16Sj8aPUPDPLI5p1csGgmxQX5mS5HRGRCpBL6c4EdCe+bwrZE64ErwuXLgXIzO+TIqJktAYqAV99Zqen1zPa9dBzo1wVZIhIp6Tp6eROw1MyeB5YCzcDA0EozqwV+CvyVuw8m72xmN5hZo5k1tre3p6mkI1u1sZWpRfmcd+Kk+MNDRGRCpBL6zcC8hPd1Ydswd29x9yvc/Qzgy2FbB4CZVQC/A77s7k+P9gPc/W53b3D3hpqa8Q/hgUHnkU1tfODEmZQUampHRKIjldBfCxxvZgvNrAi4CliZuIGZVZvZ0Pe6BVgethcBvyI4yLsifWUfnbWv72V3dx8X6awdEYmYMUPf3ePAjcDDwEvAA+6+ycxuM7NLw83OA7aY2VZgFvDNsP0vgD8DrjOzF8LX6enuxNv10MY2igvy+MCJMzNdiojIhCpIZSN3XwWsSmq7NWF5BTBiJO/uPwN+dpQ1ptXgoPPQxjaWnlBDaXFK3RcRyRmRuwz1+R0dtHXFNLUjIpEUudB/aGMrhfnGBYtmZboUEZEJF6nQd3dWbWjj3OOqqSgpzHQ5IiITLlKhv7G5i+aOHi46VRdkiUg0RSr0V21sJT/PuFBTOyISUZEJfXdn9YZW3veuGUwrLcp0OSIiGRGZ0H+5bR+v7znAMj0hS0QiLDKh//T2PQBccJKmdkQkuiIT+s1v9VBSmMesiuJMlyIikjGRCf2Wzh7mVE3BzDJdiohIxkQn9DtizKmckukyREQyKkKh38OcqpJMlyEiklGRCP2++CDt3b3MqdJIX0SiLRKhv7Mrhjua3hGRyItE6Dd39ABopC8ikReJ0G/tHAp9zemLSLRFIvRbOmIA1Gp6R0QiLhKh39zRw/TSIqYU6SHoIhJtkQj91o4eais1tSMiEonQb+mI6SCuiAiRCf0e5ir0RURSC30zW2ZmW8xsm5ndPMr6Y8zsUTN70cyeMLO6hHXXmtkr4evadBafiq5YP/t645reEREhhdA3s3zgLuAioB642szqkza7A7jP3U8DbgNuD/edDnwNOAtYAnzNzKalr/yxtYZn7mh6R0QktZH+EmCbu2939z7gfuCypG3qgcfC5ccT1n8IWOPue939LWANsOzoy05dS6cuzBIRGZJK6M8FdiS8bwrbEq0HrgiXLwfKzWxGivuOq5YOXZglIjIkXQdybwKWmtnzwFKgGRhIdWczu8HMGs2ssb29PU0lBVo6esjPM2aWK/RFRFIJ/WZgXsL7urBtmLu3uPsV7n4G8OWwrSOVfcNt73b3BndvqKmpeZtdOLLWjhizK0rIz9PDU0REUgn9tcDxZrbQzIqAq4CViRuYWbWZDX2vW4Dl4fLDwAfNbFp4APeDYduEadZ99EVEho0Z+u4eB24kCOuXgAfcfZOZ3WZml4abnQdsMbOtwCzgm+G+e4FvEPziWAvcFrZNmKHHJIqICBSkspG7rwJWJbXdmrC8AlhxmH2Xc3DkP6EGB522zphutCYiEsrpK3J3d/fSP+DM1fSOiAiQ46Hf0qkLs0REEuV26Ifn6Gt6R0QkEInQ183WREQCOR76MaYW5VMxJaXj1SIiOS/HQz84XdNMF2aJiECuh77O0RcROURuh35HjDm6j76IyLCcDf1Y/wC7u3s10hcRSZCzod+mc/RFREbI2dAffniKpndERIblbujrMYkiIiPkbOi3hhdmzdZIX0RkWM6GfktnD9VlRZQU5me6FBGRSSNnQ7+5I6apHRGRJDkb+q0dPdRqakdE5BA5GfruPnwLBhEROSgnQ7+rJ87+vgHdXVNEJElOhv7QOfq6j76IyKFyM/TD0zXn6DGJIiKHyPHQ10hfRCRRToZ+W1eM/Dyjuqw406WIiEwqKYW+mS0zsy1mts3Mbh5l/Xwze9zMnjezF83s4rC90MzuNbMNZvaSmd2S7g6MpqsnTkVJAfl5eniKiEiiMUPfzPKBu4CLgHrgajOrT9rsK8AD7n4GcBXwz2H7R4Fidz8VOBP4jJktSE/ph7e/N05ZiR6RKCKSLJWR/hJgm7tvd/c+4H7gsqRtHKgIlyuBloT2UjMrAKYAfUDXUVc9hn29cUqLFPoiIslSCf25wI6E901hW6KvAx83syZgFfD5sH0FsB9oBd4E7nD3vck/wMxuMLNGM2tsb29/ez0YRXcsTrlG+iIiI6TrQO7VwD3uXgdcDPzUzPII/koYAOYAC4EvmtmxyTu7+93u3uDuDTU1NUddTHdvnLJihb6ISLJUQr8ZmJfwvi5sS3Q98ACAuz8FlADVwDXAQ+7e7+67gP8HNBxt0WPp7o1TVlI43j9GRCTrpBL6a4HjzWyhmRURHKhdmbTNm8AFAGa2iCD028P288P2UuC9wMvpKf3w9sU00hcRGc2Yoe/uceBG4GHgJYKzdDaZ2W1mdmm42ReBT5vZeuDnwHXu7gRn/ZSZ2SaCXx4/cfcXx6Mjifb3ak5fRGQ0KSWju68iOECb2HZrwvJm4JxR9usmOG1zwsQHBunpH9DZOyIio8i5K3L39w4A6Dx9EZFR5Fzo7+vtB6Bcc/oiIiPkXOh398YBjfRFREaTc6G/fyj0NdIXERkh50J/XywI/VKFvojICDkX+kPTOzplU0RkpNwL/Zimd0REDif3Ql8HckVEDitnQ18XZ4mIjJR7oR+LU1qUr6dmiYiMIvdCvzeuM3dERA4j50J/nx6VKCJyWDkX+t2xuG7BICJyGLkX+hrpi4gcVs6F/n49KlFE5LByLvSDp2bpUYkiIqPJudAPHoqen+kyREQmpZwKfXfXnL6IyBHkVOjH+gcZGHRN74iIHEZOhb7uuyMicmQ5Gfo6T19EZHQphb6ZLTOzLWa2zcxuHmX9fDN73MyeN7MXzezihHWnmdlTZrbJzDaYWUk6O5BIt1UWETmyMdPRzPKBu4ALgSZgrZmtdPfNCZt9BXjA3b9vZvXAKmCBmRUAPwM+4e7rzWwG0J/2XoSGHoque++IiIwulZH+EmCbu2939z7gfuCypG0cqAiXK4GWcPmDwIvuvh7A3fe4+8DRlz26oZG+npolIjK6VEJ/LrAj4X1T2Jbo68DHzayJYJT/+bD9BMDN7GEze87MvnSU9R7R/j5N74iIHEm6DuReDdzj7nXAxcBPzSyPYProXOBj4dfLzeyC5J3N7AYzazSzxvb29ndcxPCcvkb6IiKjSiX0m4F5Ce/rwrZE1wMPALj7U0AJUE3wV8Ef3H23ux8g+CtgcfIPcPe73b3B3Rtqamrefi9C+3o10hcROZJUQn8tcLyZLTSzIuAqYGXSNm8CFwCY2SKC0G8HHgZONbOp4UHdpcBmxkl3LE5BnlFckFNnooqIpM2YQ2J3j5vZjQQBng8sd/dNZnYb0OjuK4EvAv9iZn9LcFD3Ond34C0z+zbBLw4HVrn778arM0O3YDDToxJFREaT0jyIu68imJpJbLs1YXkzcM5h9v0ZwWmb4647ptsqi4gcSU7Ng3TrXvoiIkeUc6Gvc/RFRA4v50JfI30RkcPLrdCPxXULBhGRI8ip0N+n6R0RkSPKqdDXQ9FFRI4sZ0J/YNA50Degp2aJiBxBzoS+npolIjK2nAl9HD58Wi3HzyzLdCUiIpNWzgyLK6cWcuc1I+7lJiIiCXJnpC8iImNS6IuIRIhCX0QkQhT6IiIRotAXEYkQhb6ISIQo9EVEIkShLyISIRY8ynbyMLN24I23uVs1sHscyskE9WXyyqX+qC+T09H05Rh3rxlro0kX+u+EmTW6e0Om60gH9WXyyqX+qC+T00T0RdM7IiIRotAXEYmQXAn9uzNdQBqpL5NXLvVHfZmcxr0vOTGnLyIiqcmVkb6IiKQg60PfzJaZ2RYz22ZmN2e6niFmttzMdpnZxoS26Wa2xsxeCb9OC9vNzL4X9uFFM1ucsM+14favmNm1Ce1nmtmGcJ/vmZmNUz/mmdnjZrbZzDaZ2V9na1/Cn1ViZs+a2fqwP38fti80s2fCGn5hZkVhe3H4flu4fkHC97olbN9iZh9KaJ/Qz6SZ5ZvZ82b222zui5m9Hn4OXjCzxrAtWz9nVWa2wsxeNrOXzOzsSdMXd8/aF5APvAocCxQB64H6TNcV1vZnwGJgY0Lbt4Cbw+WbgX8Kly8GVgMGvBd4JmyfDmwPv04Ll6eF654Nt7Vw34vGqR+1wOJwuRzYCtRnY1/Cn2VAWbhcCDwT/uwHgKvC9h8A/zVc/izwg3D5KuAX4XJ9+HkrBhaGn8P8THwmgS8A/wb8NnyflX0BXgeqk9qy9XN2L/CpcLkIqJosfRm3D+JEvICzgYcT3t8C3JLpuhLqWcChob8FqA2Xa4Et4fIPgauTtwOuBn6Y0P7DsK0WeDmh/ZDtxrlPvwEuzJG+TAWeA84iuCCmIPlzBTwMnB0uF4TbWfJnbWi7if5MAnXAo8D5wG/D2rK1L68zMvSz7nMGVAKvER4znWx9yfbpnbnAjoT3TWHbZDXL3VvD5TZgVrh8uH4cqb1plPZxFU4HnEEwOs7avoTTIS8Au4A1BKPZDnePj1LDcN3h+k5gBm+/n+PlO8CXgMHw/Qyyty8OPGJm68zshrAtGz9nC4F24CfhtNuPzKyUSdKXbA/9rOXBr+isOXXKzMqAB4G/cfeuxHXZ1hd3H3D30wlGyUuAkzJc0jtiZh8Gdrn7ukzXkibnuvti4CLgc2b2Z4krs+hzVkAwtft9dz8D2E8wnTMsk33J9tBvBuYlvK8L2yarnWZWCxB+3RW2H64fR2qvG6V9XJhZIUHg/6u7/zJszsq+JHL3DuBxgmmMKjMrGKWG4brD9ZXAHt5+P8fDOcClZvY6cD/BFM93yc6+4O7N4dddwK8IfiFn4+esCWhy92fC9ysIfglMjr6M1/zcRLwIfqNuJ/hzauhA08mZriuhvgUcOqf/Pzn0QM63wuVLOPRAzrNh+3SCucFp4es1YHq4LvlAzsXj1AcD7gO+k9SedX0Jf1YNUBUuTwGeBD4M/DuHHvz8bLj8OQ49+PlAuHwyhx783E5w4DMjn0ngPA4eyM26vgClQHnC8p+AZVn8OXsSODFc/nrYj0nRl3H9IE7Ei+A8N3MdAAAA0UlEQVTI91aCedkvZ7qehLp+DrQC/QS/+a8nmD99FHgF+H3C/0AD7gr7sAFoSPg+nwS2ha+/SmhvADaG+9xJ0kGjNPbjXII/Q18EXghfF2djX8KfdRrwfNifjcCtYfux4T+kbQShWRy2l4Tvt4Xrj034Xl8Oa95CwtkTmfhMcmjoZ11fwprXh69NQz8riz9npwON4efs1wShPSn6oityRUQiJNvn9EVE5G1Q6IuIRIhCX0QkQhT6IiIRotAXEYkQhb6ISIQo9EVEIkShLyISIf8fiyLcaauM4dUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(averages)\n",
    "plt.figure()\n",
    "plt.plot([500, 1000, 2000, 5000, 10000, 20000, 40000, 60000], averages)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 250 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (_x_train.reshape(60000, 784).astype(\"float32\") / 255)[:250,:]\n",
    "x_test = _x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(_y_train, 10)[:250,:]\n",
    "y_test = keras.utils.to_categorical(_y_test, 10)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\\ny_train shape: {y_train.shape}\\nx_test shape: {x_test.shape}\\ny_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation=\"relu\", input_shape=(784,)))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 1\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.9225 - acc: 0.3720 - val_loss: 1.4567 - val_acc: 0.5403\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.9226 - acc: 0.8120 - val_loss: 1.0693 - val_acc: 0.6975\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.5691 - acc: 0.9160 - val_loss: 0.8984 - val_acc: 0.7445\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3904 - acc: 0.9360 - val_loss: 0.8651 - val_acc: 0.7209\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.3106 - acc: 0.9560 - val_loss: 0.8466 - val_acc: 0.7495\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2700 - acc: 0.9680 - val_loss: 0.8022 - val_acc: 0.7521\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2158 - acc: 0.9720 - val_loss: 0.7016 - val_acc: 0.7884\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1615 - acc: 0.9840 - val_loss: 0.7332 - val_acc: 0.7736\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1395 - acc: 0.9840 - val_loss: 0.7017 - val_acc: 0.7843\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1079 - acc: 1.0000 - val_loss: 0.7349 - val_acc: 0.7708\n",
      "Trial number: 2\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0886 - acc: 0.9960 - val_loss: 0.6885 - val_acc: 0.7868\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0736 - acc: 0.9960 - val_loss: 0.6733 - val_acc: 0.7869\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0646 - acc: 1.0000 - val_loss: 0.6693 - val_acc: 0.7935\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0517 - acc: 1.0000 - val_loss: 0.6539 - val_acc: 0.7963\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0436 - acc: 1.0000 - val_loss: 0.6815 - val_acc: 0.7994\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0351 - acc: 1.0000 - val_loss: 0.6777 - val_acc: 0.7998\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0319 - acc: 1.0000 - val_loss: 0.6913 - val_acc: 0.7967\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0239 - acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.8025\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0203 - acc: 1.0000 - val_loss: 0.6885 - val_acc: 0.7975\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6787 - val_acc: 0.7996\n",
      "Trial number: 3\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0147 - acc: 1.0000 - val_loss: 0.6968 - val_acc: 0.8012\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0122 - acc: 1.0000 - val_loss: 0.6998 - val_acc: 0.7956\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0108 - acc: 1.0000 - val_loss: 0.6996 - val_acc: 0.8046\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.7113 - val_acc: 0.7994\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0076 - acc: 1.0000 - val_loss: 0.7158 - val_acc: 0.8008\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7450 - val_acc: 0.7975\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7199 - val_acc: 0.8011\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.7786 - val_acc: 0.7947\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.7534 - val_acc: 0.7993\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.7671 - val_acc: 0.8018\n",
      "Trial number: 4\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7736 - val_acc: 0.7981\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.7992 - val_acc: 0.7964\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.7699 - val_acc: 0.8002\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7975 - val_acc: 0.7993\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8079 - val_acc: 0.7992\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8184 - val_acc: 0.7998\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8279 - val_acc: 0.8033\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8074 - val_acc: 0.8068\n",
      "Epoch 9/10\n",
      " - 0s - loss: 9.2685e-04 - acc: 1.0000 - val_loss: 0.8682 - val_acc: 0.7980\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.0897e-04 - acc: 1.0000 - val_loss: 0.8368 - val_acc: 0.8050\n",
      "Trial number: 5\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 5.9094e-04 - acc: 1.0000 - val_loss: 0.8564 - val_acc: 0.7991\n",
      "Epoch 2/10\n",
      " - 0s - loss: 5.2896e-04 - acc: 1.0000 - val_loss: 0.8590 - val_acc: 0.8037\n",
      "Epoch 3/10\n",
      " - 0s - loss: 4.8441e-04 - acc: 1.0000 - val_loss: 0.8725 - val_acc: 0.8029\n",
      "Epoch 4/10\n",
      " - 0s - loss: 3.8720e-04 - acc: 1.0000 - val_loss: 0.9018 - val_acc: 0.7977\n",
      "Epoch 5/10\n",
      " - 0s - loss: 3.5082e-04 - acc: 1.0000 - val_loss: 0.8834 - val_acc: 0.8046\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.8593e-04 - acc: 1.0000 - val_loss: 0.9112 - val_acc: 0.7987\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.5760e-04 - acc: 1.0000 - val_loss: 0.9027 - val_acc: 0.8039\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.1395e-04 - acc: 1.0000 - val_loss: 0.9244 - val_acc: 0.8011\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.8682e-04 - acc: 1.0000 - val_loss: 0.9562 - val_acc: 0.7987\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.7371e-04 - acc: 1.0000 - val_loss: 0.9773 - val_acc: 0.7966\n",
      "Trial number: 6\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.4393e-04 - acc: 1.0000 - val_loss: 0.9599 - val_acc: 0.7996\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.1841e-04 - acc: 1.0000 - val_loss: 0.9470 - val_acc: 0.8054\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.0462e-04 - acc: 1.0000 - val_loss: 0.9825 - val_acc: 0.8010\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.0144e-04 - acc: 1.0000 - val_loss: 1.0037 - val_acc: 0.7952\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.8223e-04 - acc: 1.0000 - val_loss: 1.1155 - val_acc: 0.7910\n",
      "Epoch 6/10\n",
      " - 0s - loss: 9.9356e-04 - acc: 1.0000 - val_loss: 1.1483 - val_acc: 0.7885\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.1214e-04 - acc: 1.0000 - val_loss: 1.0452 - val_acc: 0.7987\n",
      "Epoch 8/10\n",
      " - 0s - loss: 6.1712e-05 - acc: 1.0000 - val_loss: 1.0397 - val_acc: 0.8010\n",
      "Epoch 9/10\n",
      " - 0s - loss: 5.0159e-05 - acc: 1.0000 - val_loss: 1.0585 - val_acc: 0.7999\n",
      "Epoch 10/10\n",
      " - 0s - loss: 4.3177e-05 - acc: 1.0000 - val_loss: 1.0639 - val_acc: 0.7985\n",
      "Trial number: 7\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 3.8308e-05 - acc: 1.0000 - val_loss: 1.0732 - val_acc: 0.7982\n",
      "Epoch 2/10\n",
      " - 0s - loss: 3.4321e-05 - acc: 1.0000 - val_loss: 1.0641 - val_acc: 0.8002\n",
      "Epoch 3/10\n",
      " - 0s - loss: 3.1192e-05 - acc: 1.0000 - val_loss: 1.0705 - val_acc: 0.8008\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.8036e-05 - acc: 1.0000 - val_loss: 1.0860 - val_acc: 0.7992\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.5113e-05 - acc: 1.0000 - val_loss: 1.0937 - val_acc: 0.7975\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.2852e-05 - acc: 1.0000 - val_loss: 1.0775 - val_acc: 0.8020\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.0527e-05 - acc: 1.0000 - val_loss: 1.1072 - val_acc: 0.7987\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.8272e-05 - acc: 1.0000 - val_loss: 1.0974 - val_acc: 0.8006\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.6398e-05 - acc: 1.0000 - val_loss: 1.1190 - val_acc: 0.7979\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.5024e-05 - acc: 1.0000 - val_loss: 1.1191 - val_acc: 0.7988\n",
      "Trial number: 8\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.3590e-05 - acc: 1.0000 - val_loss: 1.1244 - val_acc: 0.7997\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.1913e-05 - acc: 1.0000 - val_loss: 1.1474 - val_acc: 0.7972\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.1112e-05 - acc: 1.0000 - val_loss: 1.1388 - val_acc: 0.7989\n",
      "Epoch 4/10\n",
      " - 0s - loss: 9.8214e-06 - acc: 1.0000 - val_loss: 1.1378 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 8.8445e-06 - acc: 1.0000 - val_loss: 1.1352 - val_acc: 0.8021\n",
      "Epoch 6/10\n",
      " - 0s - loss: 8.2062e-06 - acc: 1.0000 - val_loss: 1.1775 - val_acc: 0.7977\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.2010e-06 - acc: 1.0000 - val_loss: 1.1598 - val_acc: 0.8017\n",
      "Epoch 8/10\n",
      " - 0s - loss: 6.5325e-06 - acc: 1.0000 - val_loss: 1.1858 - val_acc: 0.7972\n",
      "Epoch 9/10\n",
      " - 0s - loss: 5.8137e-06 - acc: 1.0000 - val_loss: 1.2004 - val_acc: 0.7972\n",
      "Epoch 10/10\n",
      " - 0s - loss: 5.2054e-06 - acc: 1.0000 - val_loss: 1.1947 - val_acc: 0.7982\n",
      "Trial number: 9\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 4.6609e-06 - acc: 1.0000 - val_loss: 1.1941 - val_acc: 0.7992\n",
      "Epoch 2/10\n",
      " - 0s - loss: 4.1642e-06 - acc: 1.0000 - val_loss: 1.2093 - val_acc: 0.7978\n",
      "Epoch 3/10\n",
      " - 0s - loss: 3.7833e-06 - acc: 1.0000 - val_loss: 1.2163 - val_acc: 0.7969\n",
      "Epoch 4/10\n",
      " - 0s - loss: 3.5217e-06 - acc: 1.0000 - val_loss: 1.2243 - val_acc: 0.7983\n",
      "Epoch 5/10\n",
      " - 0s - loss: 3.2089e-06 - acc: 1.0000 - val_loss: 1.2359 - val_acc: 0.7977\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.7847e-06 - acc: 1.0000 - val_loss: 1.2108 - val_acc: 0.8004\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.6231e-06 - acc: 1.0000 - val_loss: 1.2281 - val_acc: 0.7994\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.3108e-06 - acc: 1.0000 - val_loss: 1.2561 - val_acc: 0.7956\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.1360e-06 - acc: 1.0000 - val_loss: 1.2554 - val_acc: 0.7982\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.8044e-06 - acc: 1.0000 - val_loss: 1.2566 - val_acc: 0.7987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 10\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.6639e-06 - acc: 1.0000 - val_loss: 1.2614 - val_acc: 0.7973\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.5576e-06 - acc: 1.0000 - val_loss: 1.2591 - val_acc: 0.7978\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3888e-06 - acc: 1.0000 - val_loss: 1.2716 - val_acc: 0.7969\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.3011e-06 - acc: 1.0000 - val_loss: 1.2800 - val_acc: 0.7974\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1857e-06 - acc: 1.0000 - val_loss: 1.2928 - val_acc: 0.7953\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.0886e-06 - acc: 1.0000 - val_loss: 1.2866 - val_acc: 0.7975\n",
      "Epoch 7/10\n",
      " - 0s - loss: 9.9564e-07 - acc: 1.0000 - val_loss: 1.2884 - val_acc: 0.7986\n",
      "Epoch 8/10\n",
      " - 0s - loss: 9.1601e-07 - acc: 1.0000 - val_loss: 1.2940 - val_acc: 0.7989\n",
      "Epoch 9/10\n",
      " - 0s - loss: 8.4996e-07 - acc: 1.0000 - val_loss: 1.2970 - val_acc: 0.7994\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.8654e-07 - acc: 1.0000 - val_loss: 1.3125 - val_acc: 0.7975\n",
      "Trial number: 11\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.3433e-07 - acc: 1.0000 - val_loss: 1.3138 - val_acc: 0.7964\n",
      "Epoch 2/10\n",
      " - 0s - loss: 6.8998e-07 - acc: 1.0000 - val_loss: 1.3073 - val_acc: 0.7981\n",
      "Epoch 3/10\n",
      " - 0s - loss: 6.3324e-07 - acc: 1.0000 - val_loss: 1.3170 - val_acc: 0.7980\n",
      "Epoch 4/10\n",
      " - 0s - loss: 5.9962e-07 - acc: 1.0000 - val_loss: 1.3288 - val_acc: 0.7971\n",
      "Epoch 5/10\n",
      " - 0s - loss: 5.6529e-07 - acc: 1.0000 - val_loss: 1.3332 - val_acc: 0.7970\n",
      "Epoch 6/10\n",
      " - 0s - loss: 5.2762e-07 - acc: 1.0000 - val_loss: 1.3303 - val_acc: 0.7977\n",
      "Epoch 7/10\n",
      " - 0s - loss: 4.9281e-07 - acc: 1.0000 - val_loss: 1.3309 - val_acc: 0.7968\n",
      "Epoch 8/10\n",
      " - 0s - loss: 4.6563e-07 - acc: 1.0000 - val_loss: 1.3420 - val_acc: 0.7968\n",
      "Epoch 9/10\n",
      " - 0s - loss: 4.3964e-07 - acc: 1.0000 - val_loss: 1.3407 - val_acc: 0.7968\n",
      "Epoch 10/10\n",
      " - 0s - loss: 4.1580e-07 - acc: 1.0000 - val_loss: 1.3433 - val_acc: 0.7973\n",
      "Trial number: 12\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 3.9768e-07 - acc: 1.0000 - val_loss: 1.3468 - val_acc: 0.7965\n",
      "Epoch 2/10\n",
      " - 0s - loss: 3.8409e-07 - acc: 1.0000 - val_loss: 1.3530 - val_acc: 0.7967\n",
      "Epoch 3/10\n",
      " - 0s - loss: 3.7360e-07 - acc: 1.0000 - val_loss: 1.3583 - val_acc: 0.7965\n",
      "Epoch 4/10\n",
      " - 0s - loss: 3.4499e-07 - acc: 1.0000 - val_loss: 1.3554 - val_acc: 0.7965\n",
      "Epoch 5/10\n",
      " - 0s - loss: 3.3212e-07 - acc: 1.0000 - val_loss: 1.3607 - val_acc: 0.7967\n",
      "Epoch 6/10\n",
      " - 0s - loss: 3.1757e-07 - acc: 1.0000 - val_loss: 1.3610 - val_acc: 0.7967\n",
      "Epoch 7/10\n",
      " - 0s - loss: 3.0231e-07 - acc: 1.0000 - val_loss: 1.3626 - val_acc: 0.7975\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.9635e-07 - acc: 1.0000 - val_loss: 1.3613 - val_acc: 0.7976\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.8372e-07 - acc: 1.0000 - val_loss: 1.3621 - val_acc: 0.7983\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.7275e-07 - acc: 1.0000 - val_loss: 1.3674 - val_acc: 0.7975\n",
      "Trial number: 13\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.6441e-07 - acc: 1.0000 - val_loss: 1.3698 - val_acc: 0.7972\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.5773e-07 - acc: 1.0000 - val_loss: 1.3677 - val_acc: 0.7975\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.5105e-07 - acc: 1.0000 - val_loss: 1.3702 - val_acc: 0.7974\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.4509e-07 - acc: 1.0000 - val_loss: 1.3731 - val_acc: 0.7979\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.3794e-07 - acc: 1.0000 - val_loss: 1.3733 - val_acc: 0.7975\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.3317e-07 - acc: 1.0000 - val_loss: 1.3775 - val_acc: 0.7973\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.2507e-07 - acc: 1.0000 - val_loss: 1.3803 - val_acc: 0.7969\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.2173e-07 - acc: 1.0000 - val_loss: 1.3818 - val_acc: 0.7968\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.1625e-07 - acc: 1.0000 - val_loss: 1.3802 - val_acc: 0.7976\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.1195e-07 - acc: 1.0000 - val_loss: 1.3836 - val_acc: 0.7972\n",
      "Trial number: 14\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.0790e-07 - acc: 1.0000 - val_loss: 1.3854 - val_acc: 0.7977\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.0313e-07 - acc: 1.0000 - val_loss: 1.3875 - val_acc: 0.7970\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.0051e-07 - acc: 1.0000 - val_loss: 1.3848 - val_acc: 0.7983\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.9503e-07 - acc: 1.0000 - val_loss: 1.3879 - val_acc: 0.7971\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.9312e-07 - acc: 1.0000 - val_loss: 1.3887 - val_acc: 0.7973\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.9073e-07 - acc: 1.0000 - val_loss: 1.3908 - val_acc: 0.7969\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.8644e-07 - acc: 1.0000 - val_loss: 1.3916 - val_acc: 0.7975\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.8358e-07 - acc: 1.0000 - val_loss: 1.3937 - val_acc: 0.7973\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.8072e-07 - acc: 1.0000 - val_loss: 1.3942 - val_acc: 0.7979\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.7762e-07 - acc: 1.0000 - val_loss: 1.3977 - val_acc: 0.7971\n",
      "Trial number: 15\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.7667e-07 - acc: 1.0000 - val_loss: 1.3991 - val_acc: 0.7969\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.7500e-07 - acc: 1.0000 - val_loss: 1.3983 - val_acc: 0.7978\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.7142e-07 - acc: 1.0000 - val_loss: 1.4003 - val_acc: 0.7967\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.6952e-07 - acc: 1.0000 - val_loss: 1.3994 - val_acc: 0.7976\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.6809e-07 - acc: 1.0000 - val_loss: 1.3989 - val_acc: 0.7978\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.6618e-07 - acc: 1.0000 - val_loss: 1.4001 - val_acc: 0.7980\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.6379e-07 - acc: 1.0000 - val_loss: 1.4029 - val_acc: 0.7975\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.6260e-07 - acc: 1.0000 - val_loss: 1.4044 - val_acc: 0.7977\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.6165e-07 - acc: 1.0000 - val_loss: 1.4066 - val_acc: 0.7970\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.5974e-07 - acc: 1.0000 - val_loss: 1.4071 - val_acc: 0.7971\n",
      "Trial number: 16\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.5926e-07 - acc: 1.0000 - val_loss: 1.4077 - val_acc: 0.7972\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.5664e-07 - acc: 1.0000 - val_loss: 1.4081 - val_acc: 0.7969\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.5569e-07 - acc: 1.0000 - val_loss: 1.4085 - val_acc: 0.7971\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.5450e-07 - acc: 1.0000 - val_loss: 1.4112 - val_acc: 0.7972\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.5473e-07 - acc: 1.0000 - val_loss: 1.4110 - val_acc: 0.7971\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.5163e-07 - acc: 1.0000 - val_loss: 1.4109 - val_acc: 0.7972\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.4925e-07 - acc: 1.0000 - val_loss: 1.4107 - val_acc: 0.7975\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.4853e-07 - acc: 1.0000 - val_loss: 1.4113 - val_acc: 0.7975\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.4710e-07 - acc: 1.0000 - val_loss: 1.4119 - val_acc: 0.7975\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.4687e-07 - acc: 1.0000 - val_loss: 1.4122 - val_acc: 0.7976\n",
      "Trial number: 17\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.4615e-07 - acc: 1.0000 - val_loss: 1.4137 - val_acc: 0.7974\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.4567e-07 - acc: 1.0000 - val_loss: 1.4132 - val_acc: 0.7980\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.4472e-07 - acc: 1.0000 - val_loss: 1.4130 - val_acc: 0.7979\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.4472e-07 - acc: 1.0000 - val_loss: 1.4138 - val_acc: 0.7979\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.4257e-07 - acc: 1.0000 - val_loss: 1.4139 - val_acc: 0.7980\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.4234e-07 - acc: 1.0000 - val_loss: 1.4165 - val_acc: 0.7975\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.4067e-07 - acc: 1.0000 - val_loss: 1.4181 - val_acc: 0.7975\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.4043e-07 - acc: 1.0000 - val_loss: 1.4185 - val_acc: 0.7979\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.3995e-07 - acc: 1.0000 - val_loss: 1.4185 - val_acc: 0.7975\n",
      "Epoch 10/10\n",
      " - 1s - loss: 1.3900e-07 - acc: 1.0000 - val_loss: 1.4190 - val_acc: 0.7979\n",
      "Trial number: 18\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.3828e-07 - acc: 1.0000 - val_loss: 1.4189 - val_acc: 0.7978\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3685e-07 - acc: 1.0000 - val_loss: 1.4190 - val_acc: 0.7979\n",
      "Epoch 3/10\n",
      " - 1s - loss: 1.3638e-07 - acc: 1.0000 - val_loss: 1.4203 - val_acc: 0.7978\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.3590e-07 - acc: 1.0000 - val_loss: 1.4206 - val_acc: 0.7977\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.3566e-07 - acc: 1.0000 - val_loss: 1.4222 - val_acc: 0.7978\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.3518e-07 - acc: 1.0000 - val_loss: 1.4225 - val_acc: 0.7980\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.3447e-07 - acc: 1.0000 - val_loss: 1.4229 - val_acc: 0.7976\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.3423e-07 - acc: 1.0000 - val_loss: 1.4248 - val_acc: 0.7977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      " - 0s - loss: 1.3447e-07 - acc: 1.0000 - val_loss: 1.4258 - val_acc: 0.7974\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.3328e-07 - acc: 1.0000 - val_loss: 1.4250 - val_acc: 0.7976\n",
      "Trial number: 19\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.3232e-07 - acc: 1.0000 - val_loss: 1.4252 - val_acc: 0.7976\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.3185e-07 - acc: 1.0000 - val_loss: 1.4256 - val_acc: 0.7976\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.3256e-07 - acc: 1.0000 - val_loss: 1.4254 - val_acc: 0.7975\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.3113e-07 - acc: 1.0000 - val_loss: 1.4263 - val_acc: 0.7973\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.3137e-07 - acc: 1.0000 - val_loss: 1.4272 - val_acc: 0.7976\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.3089e-07 - acc: 1.0000 - val_loss: 1.4293 - val_acc: 0.7972\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2994e-07 - acc: 1.0000 - val_loss: 1.4297 - val_acc: 0.7974\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2994e-07 - acc: 1.0000 - val_loss: 1.4308 - val_acc: 0.7971\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2946e-07 - acc: 1.0000 - val_loss: 1.4315 - val_acc: 0.7972\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2851e-07 - acc: 1.0000 - val_loss: 1.4320 - val_acc: 0.7972\n",
      "Trial number: 20\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2827e-07 - acc: 1.0000 - val_loss: 1.4322 - val_acc: 0.7970\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2851e-07 - acc: 1.0000 - val_loss: 1.4321 - val_acc: 0.7969\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2803e-07 - acc: 1.0000 - val_loss: 1.4319 - val_acc: 0.7971\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2803e-07 - acc: 1.0000 - val_loss: 1.4331 - val_acc: 0.7973\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2827e-07 - acc: 1.0000 - val_loss: 1.4322 - val_acc: 0.7974\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2803e-07 - acc: 1.0000 - val_loss: 1.4322 - val_acc: 0.7974\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2779e-07 - acc: 1.0000 - val_loss: 1.4328 - val_acc: 0.7972\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2755e-07 - acc: 1.0000 - val_loss: 1.4337 - val_acc: 0.7968\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2779e-07 - acc: 1.0000 - val_loss: 1.4336 - val_acc: 0.7968\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2803e-07 - acc: 1.0000 - val_loss: 1.4345 - val_acc: 0.7967\n",
      "Trial number: 21\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2732e-07 - acc: 1.0000 - val_loss: 1.4356 - val_acc: 0.7968\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2755e-07 - acc: 1.0000 - val_loss: 1.4363 - val_acc: 0.7971\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2732e-07 - acc: 1.0000 - val_loss: 1.4357 - val_acc: 0.7967\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2732e-07 - acc: 1.0000 - val_loss: 1.4356 - val_acc: 0.7972\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2612e-07 - acc: 1.0000 - val_loss: 1.4369 - val_acc: 0.7969\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2636e-07 - acc: 1.0000 - val_loss: 1.4364 - val_acc: 0.7970\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2612e-07 - acc: 1.0000 - val_loss: 1.4359 - val_acc: 0.7974\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2493e-07 - acc: 1.0000 - val_loss: 1.4354 - val_acc: 0.7972\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2493e-07 - acc: 1.0000 - val_loss: 1.4354 - val_acc: 0.7972\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2493e-07 - acc: 1.0000 - val_loss: 1.4370 - val_acc: 0.7970\n",
      "Trial number: 22\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2493e-07 - acc: 1.0000 - val_loss: 1.4369 - val_acc: 0.7971\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2469e-07 - acc: 1.0000 - val_loss: 1.4372 - val_acc: 0.7971\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2469e-07 - acc: 1.0000 - val_loss: 1.4370 - val_acc: 0.7974\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2493e-07 - acc: 1.0000 - val_loss: 1.4368 - val_acc: 0.7972\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2445e-07 - acc: 1.0000 - val_loss: 1.4378 - val_acc: 0.7972\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2493e-07 - acc: 1.0000 - val_loss: 1.4379 - val_acc: 0.7971\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2469e-07 - acc: 1.0000 - val_loss: 1.4370 - val_acc: 0.7973\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2445e-07 - acc: 1.0000 - val_loss: 1.4382 - val_acc: 0.7971\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2469e-07 - acc: 1.0000 - val_loss: 1.4385 - val_acc: 0.7972\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2445e-07 - acc: 1.0000 - val_loss: 1.4387 - val_acc: 0.7973\n",
      "Trial number: 23\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2445e-07 - acc: 1.0000 - val_loss: 1.4385 - val_acc: 0.7974\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2398e-07 - acc: 1.0000 - val_loss: 1.4386 - val_acc: 0.7975\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2422e-07 - acc: 1.0000 - val_loss: 1.4391 - val_acc: 0.7975\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2422e-07 - acc: 1.0000 - val_loss: 1.4399 - val_acc: 0.7971\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2374e-07 - acc: 1.0000 - val_loss: 1.4401 - val_acc: 0.7972\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2398e-07 - acc: 1.0000 - val_loss: 1.4400 - val_acc: 0.7972\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2350e-07 - acc: 1.0000 - val_loss: 1.4403 - val_acc: 0.7973\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2350e-07 - acc: 1.0000 - val_loss: 1.4401 - val_acc: 0.7976\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2279e-07 - acc: 1.0000 - val_loss: 1.4406 - val_acc: 0.7976\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2326e-07 - acc: 1.0000 - val_loss: 1.4404 - val_acc: 0.7976\n",
      "Trial number: 24\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2279e-07 - acc: 1.0000 - val_loss: 1.4405 - val_acc: 0.7974\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2326e-07 - acc: 1.0000 - val_loss: 1.4413 - val_acc: 0.7972\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2279e-07 - acc: 1.0000 - val_loss: 1.4414 - val_acc: 0.7974\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2326e-07 - acc: 1.0000 - val_loss: 1.4414 - val_acc: 0.7973\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2302e-07 - acc: 1.0000 - val_loss: 1.4402 - val_acc: 0.7976\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2326e-07 - acc: 1.0000 - val_loss: 1.4416 - val_acc: 0.7974\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2279e-07 - acc: 1.0000 - val_loss: 1.4419 - val_acc: 0.7974\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2231e-07 - acc: 1.0000 - val_loss: 1.4415 - val_acc: 0.7977\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2279e-07 - acc: 1.0000 - val_loss: 1.4418 - val_acc: 0.7975\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2231e-07 - acc: 1.0000 - val_loss: 1.4422 - val_acc: 0.7976\n",
      "Trial number: 25\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2279e-07 - acc: 1.0000 - val_loss: 1.4420 - val_acc: 0.7976\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2231e-07 - acc: 1.0000 - val_loss: 1.4410 - val_acc: 0.7978\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2231e-07 - acc: 1.0000 - val_loss: 1.4423 - val_acc: 0.7976\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2231e-07 - acc: 1.0000 - val_loss: 1.4425 - val_acc: 0.7977\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2207e-07 - acc: 1.0000 - val_loss: 1.4423 - val_acc: 0.7976\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2231e-07 - acc: 1.0000 - val_loss: 1.4432 - val_acc: 0.7973\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2183e-07 - acc: 1.0000 - val_loss: 1.4437 - val_acc: 0.7977\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2183e-07 - acc: 1.0000 - val_loss: 1.4438 - val_acc: 0.7975\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2183e-07 - acc: 1.0000 - val_loss: 1.4433 - val_acc: 0.7977\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4439 - val_acc: 0.7974\n",
      "Trial number: 26\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4444 - val_acc: 0.7975\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4441 - val_acc: 0.7975\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4448 - val_acc: 0.7974\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4453 - val_acc: 0.7974\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4443 - val_acc: 0.7978\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4445 - val_acc: 0.7977\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4458 - val_acc: 0.7974\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2112e-07 - acc: 1.0000 - val_loss: 1.4453 - val_acc: 0.7974\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4453 - val_acc: 0.7976\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2136e-07 - acc: 1.0000 - val_loss: 1.4462 - val_acc: 0.7975\n",
      "Trial number: 27\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2088e-07 - acc: 1.0000 - val_loss: 1.4460 - val_acc: 0.7977\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2088e-07 - acc: 1.0000 - val_loss: 1.4459 - val_acc: 0.7978\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2088e-07 - acc: 1.0000 - val_loss: 1.4468 - val_acc: 0.7976\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2088e-07 - acc: 1.0000 - val_loss: 1.4473 - val_acc: 0.7978\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2088e-07 - acc: 1.0000 - val_loss: 1.4461 - val_acc: 0.7982\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2088e-07 - acc: 1.0000 - val_loss: 1.4471 - val_acc: 0.7978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 0s - loss: 1.2088e-07 - acc: 1.0000 - val_loss: 1.4475 - val_acc: 0.7976\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2064e-07 - acc: 1.0000 - val_loss: 1.4476 - val_acc: 0.7977\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.2064e-07 - acc: 1.0000 - val_loss: 1.4480 - val_acc: 0.7975\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2064e-07 - acc: 1.0000 - val_loss: 1.4479 - val_acc: 0.7978\n",
      "Trial number: 28\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2064e-07 - acc: 1.0000 - val_loss: 1.4485 - val_acc: 0.7976\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.4484 - val_acc: 0.7976\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2064e-07 - acc: 1.0000 - val_loss: 1.4487 - val_acc: 0.7976\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.4493 - val_acc: 0.7977\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.4492 - val_acc: 0.7978\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4491 - val_acc: 0.7977\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4493 - val_acc: 0.7977\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.4489 - val_acc: 0.7978\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4490 - val_acc: 0.7977\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4496 - val_acc: 0.7976\n",
      "Trial number: 29\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.4491 - val_acc: 0.7979\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4494 - val_acc: 0.7978\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.4495 - val_acc: 0.7977\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4499 - val_acc: 0.7977\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4500 - val_acc: 0.7978\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.4506 - val_acc: 0.7976\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4502 - val_acc: 0.7977\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4508 - val_acc: 0.7977\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4507 - val_acc: 0.7977\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.1969e-07 - acc: 1.0000 - val_loss: 1.4507 - val_acc: 0.7978\n",
      "Trial number: 30\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.4509 - val_acc: 0.7978\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4507 - val_acc: 0.7977\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4516 - val_acc: 0.7978\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4514 - val_acc: 0.7978\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.4512 - val_acc: 0.7977\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4514 - val_acc: 0.7978\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4516 - val_acc: 0.7977\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4524 - val_acc: 0.7977\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.4525 - val_acc: 0.7977\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4521 - val_acc: 0.7976\n",
      "Trial number: 31\n",
      "Train on 250 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4522 - val_acc: 0.7977\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4523 - val_acc: 0.7977\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4521 - val_acc: 0.7978\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4521 - val_acc: 0.7978\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4527 - val_acc: 0.7977\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4526 - val_acc: 0.7977\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.1992e-07 - acc: 1.0000 - val_loss: 1.4527 - val_acc: 0.7974\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4528 - val_acc: 0.7975\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.1945e-07 - acc: 1.0000 - val_loss: 1.4529 - val_acc: 0.7976\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 1.4531 - val_acc: 0.7976\n",
      "| 1 | 0.7708 |\n",
      "| 2 | 0.7996 |\n",
      "| 3 | 0.8018 |\n",
      "| 4 | 0.805 |\n",
      "| 5 | 0.7966 |\n",
      "| 6 | 0.7985 |\n",
      "| 7 | 0.7988 |\n",
      "| 8 | 0.7982 |\n",
      "| 9 | 0.7987 |\n",
      "| 10 | 0.7975 |\n",
      "| 11 | 0.7973 |\n",
      "| 12 | 0.7975 |\n",
      "| 13 | 0.7972 |\n",
      "| 14 | 0.7971 |\n",
      "| 15 | 0.7971 |\n",
      "| 16 | 0.7976 |\n",
      "| 17 | 0.7979 |\n",
      "| 18 | 0.7976 |\n",
      "| 19 | 0.7972 |\n",
      "| 20 | 0.7967 |\n",
      "| 21 | 0.797 |\n",
      "| 22 | 0.7973 |\n",
      "| 23 | 0.7976 |\n",
      "| 24 | 0.7976 |\n",
      "| 25 | 0.7974 |\n",
      "| 26 | 0.7975 |\n",
      "| 27 | 0.7978 |\n",
      "| 28 | 0.7976 |\n",
      "| 29 | 0.7978 |\n",
      "| 30 | 0.7976 |\n",
      "| 31 | 0.7976 |\n",
      "Average: 0.7971451612903223\n"
     ]
    }
   ],
   "source": [
    "x_train = (_x_train.reshape(60000, 784).astype(\"float32\") / 255)[:250,:]\n",
    "x_test = _x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(_y_train, 10)[:250,:]\n",
    "y_test = keras.utils.to_categorical(_y_test, 10)\n",
    "\n",
    "trials = []\n",
    "accs = []\n",
    "accuracies = 0 \n",
    "for i in range(1,32):\n",
    "    print(f\"Trial number: {i}\")\n",
    "    history = model.fit(x_train, y_train,\n",
    "                   batch_size=100,\n",
    "                   epochs=10,\n",
    "                   verbose=2,\n",
    "                   validation_data=(x_test,y_test))\n",
    "    acc = model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "    trial = \"| {0} | {1} |\".format(i,  acc)\n",
    "    accs.append(acc)\n",
    "    accuracies += acc\n",
    "    trials.append(trial)\n",
    "average = accuracies / 31\n",
    "for t in trials:\n",
    "    print(t)\n",
    "print(f\"Average: {average}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network trained on inverted and non-inverted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_x_train, _y_train), (_x_test, _y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784)\n",
      "(1000, 10)\n",
      "x_train shape: (1000, 784)\n",
      "y_train shape: (1000, 10)\n",
      "x_test shape: (10000, 784)\n",
      "y_test shape: (10000, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = (_x_train.reshape(60000, 784).astype(\"float32\") / 255)[:500,:]\n",
    "inverted_x_train = ((255 - _x_train.reshape(60000, 784).astype(\"float32\"))/255)[:500,:]\n",
    "# display_sample(6, inverted=True)\n",
    "x_train = np.concatenate((x_train, inverted_x_train), axis=0)\n",
    "print(x_train.shape)\n",
    "x_test = _x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "y_train = keras.utils.to_categorical(_y_train, 10)[:500,:]\n",
    "y_train =  np.concatenate((y_train, y_train), axis=0)\n",
    "print(y_train.shape)\n",
    "y_test = keras.utils.to_categorical(_y_test, 10)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\\ny_train shape: {y_train.shape}\\nx_test shape: {x_test.shape}\\ny_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_sample(13, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation=\"relu\", input_shape=(784,)))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 1\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 4.0551 - acc: 0.2880 - val_loss: 1.2394 - val_acc: 0.7428\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.7207 - acc: 0.4800 - val_loss: 0.9276 - val_acc: 0.7680\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.4251 - acc: 0.5350 - val_loss: 0.7493 - val_acc: 0.7993\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2436 - acc: 0.5970 - val_loss: 0.6471 - val_acc: 0.8204\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.0783 - acc: 0.6820 - val_loss: 0.5804 - val_acc: 0.8348\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.0026 - acc: 0.6970 - val_loss: 0.5480 - val_acc: 0.8363\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.8049 - acc: 0.7670 - val_loss: 0.5246 - val_acc: 0.8379\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.8529 - acc: 0.7550 - val_loss: 0.4878 - val_acc: 0.8488\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.6334 - acc: 0.8330 - val_loss: 0.4938 - val_acc: 0.8482\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.6751 - acc: 0.8020 - val_loss: 0.5003 - val_acc: 0.8393\n",
      "Trial number: 2\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.5495 - acc: 0.8470 - val_loss: 0.4705 - val_acc: 0.8565\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5529 - acc: 0.8340 - val_loss: 0.4671 - val_acc: 0.8519\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4924 - acc: 0.8710 - val_loss: 0.4726 - val_acc: 0.8540\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.5363 - acc: 0.8460 - val_loss: 0.4817 - val_acc: 0.8535\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4705 - acc: 0.8540 - val_loss: 0.4750 - val_acc: 0.8579\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.4553 - acc: 0.8620 - val_loss: 0.4824 - val_acc: 0.8573\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.3592 - acc: 0.8950 - val_loss: 0.5079 - val_acc: 0.8531\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.4423 - acc: 0.8630 - val_loss: 0.5090 - val_acc: 0.8543\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.3629 - acc: 0.8830 - val_loss: 0.5280 - val_acc: 0.8557\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.3630 - acc: 0.8900 - val_loss: 0.5177 - val_acc: 0.8567\n",
      "Trial number: 3\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.3710 - acc: 0.8800 - val_loss: 0.5288 - val_acc: 0.8569\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.3069 - acc: 0.9080 - val_loss: 0.5348 - val_acc: 0.8607\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.3043 - acc: 0.9040 - val_loss: 0.5756 - val_acc: 0.8515\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3071 - acc: 0.9030 - val_loss: 0.5584 - val_acc: 0.8575\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.3012 - acc: 0.9060 - val_loss: 0.5721 - val_acc: 0.8601\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2575 - acc: 0.9160 - val_loss: 0.5587 - val_acc: 0.8623\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.3415 - acc: 0.8830 - val_loss: 0.5964 - val_acc: 0.8624\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.2593 - acc: 0.9150 - val_loss: 0.6260 - val_acc: 0.8531\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.2121 - acc: 0.9330 - val_loss: 0.5927 - val_acc: 0.8632\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.3302 - acc: 0.9000 - val_loss: 0.6047 - val_acc: 0.8627\n",
      "Trial number: 4\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.2075 - acc: 0.9330 - val_loss: 0.6260 - val_acc: 0.8621\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.3100 - acc: 0.8960 - val_loss: 0.6633 - val_acc: 0.8583\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.2597 - acc: 0.9220 - val_loss: 0.6508 - val_acc: 0.8618\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.2227 - acc: 0.9350 - val_loss: 0.6638 - val_acc: 0.8606\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2135 - acc: 0.9330 - val_loss: 0.6665 - val_acc: 0.8635\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2221 - acc: 0.9200 - val_loss: 0.6775 - val_acc: 0.8626\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1676 - acc: 0.9500 - val_loss: 0.6975 - val_acc: 0.8590\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.2088 - acc: 0.9320 - val_loss: 0.7070 - val_acc: 0.8620\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1839 - acc: 0.9490 - val_loss: 0.7228 - val_acc: 0.8621\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.2133 - acc: 0.9310 - val_loss: 0.7352 - val_acc: 0.8609\n",
      "Trial number: 5\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.1163 - acc: 0.9710 - val_loss: 0.7327 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1714 - acc: 0.9540 - val_loss: 0.7539 - val_acc: 0.8626\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1330 - acc: 0.9620 - val_loss: 0.7638 - val_acc: 0.8603\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.1944 - acc: 0.9370 - val_loss: 0.7640 - val_acc: 0.8642\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1307 - acc: 0.9570 - val_loss: 0.7870 - val_acc: 0.8617\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1474 - acc: 0.9590 - val_loss: 0.7879 - val_acc: 0.8623\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.1378 - acc: 0.9550 - val_loss: 0.8073 - val_acc: 0.8606\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1846 - acc: 0.9430 - val_loss: 0.7993 - val_acc: 0.8628\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0979 - acc: 0.9700 - val_loss: 0.8134 - val_acc: 0.8617\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1650 - acc: 0.9470 - val_loss: 0.8077 - val_acc: 0.8646\n",
      "Trial number: 6\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0787 - acc: 0.9780 - val_loss: 0.8213 - val_acc: 0.8639\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1197 - acc: 0.9640 - val_loss: 0.8255 - val_acc: 0.8628\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0799 - acc: 0.9800 - val_loss: 0.8233 - val_acc: 0.8645\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1055 - acc: 0.9660 - val_loss: 0.8427 - val_acc: 0.8604\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.1282 - acc: 0.9700 - val_loss: 0.8344 - val_acc: 0.8637\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0979 - acc: 0.9700 - val_loss: 0.8533 - val_acc: 0.8620\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.1512 - acc: 0.9540 - val_loss: 0.8551 - val_acc: 0.8627\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1337 - acc: 0.9650 - val_loss: 0.8490 - val_acc: 0.8633\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0688 - acc: 0.9800 - val_loss: 0.8514 - val_acc: 0.8634\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1101 - acc: 0.9670 - val_loss: 0.8549 - val_acc: 0.8644\n",
      "Trial number: 7\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0523 - acc: 0.9840 - val_loss: 0.8575 - val_acc: 0.8639\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0951 - acc: 0.9650 - val_loss: 0.8614 - val_acc: 0.8634\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0957 - acc: 0.9650 - val_loss: 0.8640 - val_acc: 0.8639\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.1176 - acc: 0.9680 - val_loss: 0.8581 - val_acc: 0.8638\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0761 - acc: 0.9770 - val_loss: 0.8594 - val_acc: 0.8644\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0543 - acc: 0.9840 - val_loss: 0.8657 - val_acc: 0.8645\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0656 - acc: 0.9820 - val_loss: 0.8672 - val_acc: 0.8656\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0822 - acc: 0.9750 - val_loss: 0.8754 - val_acc: 0.8636\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0520 - acc: 0.9860 - val_loss: 0.8662 - val_acc: 0.8647\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0309 - acc: 0.9920 - val_loss: 0.8767 - val_acc: 0.8637\n",
      "Trial number: 8\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.1196 - acc: 0.9550 - val_loss: 0.8668 - val_acc: 0.8648\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0249 - acc: 0.9950 - val_loss: 0.8691 - val_acc: 0.8655\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1272 - acc: 0.9680 - val_loss: 0.8774 - val_acc: 0.8646\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0448 - acc: 0.9880 - val_loss: 0.8694 - val_acc: 0.8654\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0589 - acc: 0.9850 - val_loss: 0.8689 - val_acc: 0.8657\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0320 - acc: 0.9910 - val_loss: 0.8742 - val_acc: 0.8646\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.1952 - acc: 0.9400 - val_loss: 0.8690 - val_acc: 0.8659\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0110 - acc: 1.0000 - val_loss: 0.8738 - val_acc: 0.8654\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0121 - acc: 1.0000 - val_loss: 0.8703 - val_acc: 0.8660\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1976 - acc: 0.9620 - val_loss: 0.8695 - val_acc: 0.8663\n",
      "Trial number: 9\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0324 - acc: 0.9890 - val_loss: 0.8696 - val_acc: 0.8659\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0117 - acc: 1.0000 - val_loss: 0.8755 - val_acc: 0.8650\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0835 - acc: 0.9790 - val_loss: 0.8782 - val_acc: 0.8642\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0152 - acc: 0.9980 - val_loss: 0.8751 - val_acc: 0.8663\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0961 - acc: 0.9760 - val_loss: 0.8741 - val_acc: 0.8654\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.8785 - val_acc: 0.8652\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0785 - acc: 0.9820 - val_loss: 0.8704 - val_acc: 0.8669\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0568 - acc: 0.9850 - val_loss: 0.8751 - val_acc: 0.8662\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.8763 - val_acc: 0.8648\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.8754 - val_acc: 0.8655\n",
      "Trial number: 10\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.1219 - acc: 0.9660 - val_loss: 0.8775 - val_acc: 0.8661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " - 1s - loss: 0.1573 - acc: 0.9680 - val_loss: 0.8801 - val_acc: 0.8658\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0102 - acc: 0.9990 - val_loss: 0.8745 - val_acc: 0.8663\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0099 - acc: 0.9990 - val_loss: 0.8769 - val_acc: 0.8662\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0080 - acc: 0.9990 - val_loss: 0.8715 - val_acc: 0.8665\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1379 - acc: 0.9650 - val_loss: 0.8727 - val_acc: 0.8663\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.8743 - val_acc: 0.8663\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1521 - acc: 0.9680 - val_loss: 0.8913 - val_acc: 0.8648\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0584 - acc: 0.9870 - val_loss: 0.8747 - val_acc: 0.8669\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.8766 - val_acc: 0.8665\n",
      "Trial number: 11\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.8776 - val_acc: 0.8660\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1637 - acc: 0.9650 - val_loss: 0.8722 - val_acc: 0.8663\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8711 - val_acc: 0.8662\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.8736 - val_acc: 0.8661\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.1574 - acc: 0.9670 - val_loss: 0.8759 - val_acc: 0.8651\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0064 - acc: 0.9990 - val_loss: 0.8709 - val_acc: 0.8655\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.8747 - val_acc: 0.8661\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.2508 - acc: 0.9550 - val_loss: 0.8737 - val_acc: 0.8654\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.8747 - val_acc: 0.8654\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.8756 - val_acc: 0.8655\n",
      "Trial number: 12\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.8761 - val_acc: 0.8656\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.2329 - acc: 0.9510 - val_loss: 0.8768 - val_acc: 0.8655\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.8769 - val_acc: 0.8663\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8757 - val_acc: 0.8665\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.8774 - val_acc: 0.8660\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.8797 - val_acc: 0.8661\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.8766 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.3396 - acc: 0.9430 - val_loss: 0.8766 - val_acc: 0.8655\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.8751 - val_acc: 0.8658\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.8722 - val_acc: 0.8666\n",
      "Trial number: 13\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0914 - acc: 0.9800 - val_loss: 0.8723 - val_acc: 0.8670\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0286 - acc: 0.9930 - val_loss: 0.8755 - val_acc: 0.8666\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8770 - val_acc: 0.8664\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.8779 - val_acc: 0.8668\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.8824 - val_acc: 0.8660\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1581 - acc: 0.9620 - val_loss: 0.8724 - val_acc: 0.8674\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.8739 - val_acc: 0.8665\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8739 - val_acc: 0.8663\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8740 - val_acc: 0.8664\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0897 - acc: 0.9900 - val_loss: 0.8745 - val_acc: 0.8674\n",
      "Trial number: 14\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.1105 - acc: 0.9690 - val_loss: 0.8695 - val_acc: 0.8672\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.8711 - val_acc: 0.8665\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8722 - val_acc: 0.8671\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8739 - val_acc: 0.8662\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.8645 - val_acc: 0.8674\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2437 - acc: 0.9490 - val_loss: 0.8721 - val_acc: 0.8670\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8716 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8723 - val_acc: 0.8672\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8723 - val_acc: 0.8676\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8710 - val_acc: 0.8677\n",
      "Trial number: 15\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.3262 - acc: 0.9490 - val_loss: 0.8728 - val_acc: 0.8674\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.8736 - val_acc: 0.8670\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8759 - val_acc: 0.8674\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8770 - val_acc: 0.8671\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8747 - val_acc: 0.8671\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8812 - val_acc: 0.8662\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2637 - acc: 0.9590 - val_loss: 0.8687 - val_acc: 0.8670\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8705 - val_acc: 0.8674\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8722 - val_acc: 0.8670\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8742 - val_acc: 0.8668\n",
      "Trial number: 16\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 8.9372e-04 - acc: 1.0000 - val_loss: 0.8757 - val_acc: 0.8669\n",
      "Epoch 2/10\n",
      " - 0s - loss: 9.3361e-04 - acc: 1.0000 - val_loss: 0.8772 - val_acc: 0.8659\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.2659 - acc: 0.9390 - val_loss: 0.8784 - val_acc: 0.8671\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8743 - val_acc: 0.8672\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8749 - val_acc: 0.8673\n",
      "Epoch 6/10\n",
      " - 0s - loss: 8.6705e-04 - acc: 1.0000 - val_loss: 0.8764 - val_acc: 0.8669\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7786e-04 - acc: 1.0000 - val_loss: 0.8766 - val_acc: 0.8668\n",
      "Epoch 8/10\n",
      " - 0s - loss: 8.6600e-04 - acc: 1.0000 - val_loss: 0.8776 - val_acc: 0.8667\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4422 - acc: 0.9470 - val_loss: 0.8666 - val_acc: 0.8685\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8739 - val_acc: 0.8673\n",
      "Trial number: 17\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8750 - val_acc: 0.8673\n",
      "Epoch 2/10\n",
      " - 0s - loss: 9.2626e-04 - acc: 1.0000 - val_loss: 0.8750 - val_acc: 0.8674\n",
      "Epoch 3/10\n",
      " - 0s - loss: 8.1997e-04 - acc: 1.0000 - val_loss: 0.8779 - val_acc: 0.8668\n",
      "Epoch 4/10\n",
      " - 0s - loss: 8.0915e-04 - acc: 1.0000 - val_loss: 0.8791 - val_acc: 0.8666\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0998 - acc: 0.9820 - val_loss: 0.8739 - val_acc: 0.8683\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1866 - acc: 0.9770 - val_loss: 0.8776 - val_acc: 0.8672\n",
      "Epoch 7/10\n",
      " - 0s - loss: 9.3472e-04 - acc: 1.0000 - val_loss: 0.8776 - val_acc: 0.8677\n",
      "Epoch 8/10\n",
      " - 0s - loss: 6.6575e-04 - acc: 1.0000 - val_loss: 0.8783 - val_acc: 0.8671\n",
      "Epoch 9/10\n",
      " - 0s - loss: 6.1293e-04 - acc: 1.0000 - val_loss: 0.8767 - val_acc: 0.8676\n",
      "Epoch 10/10\n",
      " - 0s - loss: 6.2010e-04 - acc: 1.0000 - val_loss: 0.8780 - val_acc: 0.8666\n",
      "Trial number: 18\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.1560 - acc: 0.9780 - val_loss: 0.8650 - val_acc: 0.8690\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0820 - acc: 0.9850 - val_loss: 0.8696 - val_acc: 0.8687\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8720 - val_acc: 0.8676\n",
      "Epoch 4/10\n",
      " - 0s - loss: 8.4660e-04 - acc: 1.0000 - val_loss: 0.8717 - val_acc: 0.8673\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.3713e-04 - acc: 1.0000 - val_loss: 0.8702 - val_acc: 0.8678\n",
      "Epoch 6/10\n",
      " - 0s - loss: 6.6824e-04 - acc: 1.0000 - val_loss: 0.8714 - val_acc: 0.8678\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1909 - acc: 0.9720 - val_loss: 0.8770 - val_acc: 0.8669\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8736 - val_acc: 0.8674\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.0539e-04 - acc: 1.0000 - val_loss: 0.8726 - val_acc: 0.8680\n",
      "Epoch 10/10\n",
      " - 0s - loss: 6.2629e-04 - acc: 1.0000 - val_loss: 0.8706 - val_acc: 0.8683\n",
      "Trial number: 19\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 5.2680e-04 - acc: 1.0000 - val_loss: 0.8730 - val_acc: 0.8678\n",
      "Epoch 2/10\n",
      " - 0s - loss: 4.1269e-04 - acc: 1.0000 - val_loss: 0.8709 - val_acc: 0.8679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      " - 0s - loss: 0.0068 - acc: 0.9970 - val_loss: 0.8892 - val_acc: 0.8680\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.2514 - acc: 0.9510 - val_loss: 0.8685 - val_acc: 0.8689\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8693 - val_acc: 0.8684\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.6407e-04 - acc: 1.0000 - val_loss: 0.8697 - val_acc: 0.8686\n",
      "Epoch 7/10\n",
      " - 1s - loss: 6.5327e-04 - acc: 1.0000 - val_loss: 0.8689 - val_acc: 0.8683\n",
      "Epoch 8/10\n",
      " - 0s - loss: 5.7652e-04 - acc: 1.0000 - val_loss: 0.8701 - val_acc: 0.8677\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.3023 - acc: 0.9480 - val_loss: 0.8611 - val_acc: 0.8697\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8602 - val_acc: 0.8691\n",
      "Trial number: 20\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 5.2632e-04 - acc: 1.0000 - val_loss: 0.8606 - val_acc: 0.8694\n",
      "Epoch 2/10\n",
      " - 0s - loss: 4.2105e-04 - acc: 1.0000 - val_loss: 0.8616 - val_acc: 0.8691\n",
      "Epoch 3/10\n",
      " - 0s - loss: 3.8928e-04 - acc: 1.0000 - val_loss: 0.8637 - val_acc: 0.8692\n",
      "Epoch 4/10\n",
      " - 0s - loss: 3.5797e-04 - acc: 1.0000 - val_loss: 0.8673 - val_acc: 0.8683\n",
      "Epoch 5/10\n",
      " - 0s - loss: 3.3187e-04 - acc: 1.0000 - val_loss: 0.8685 - val_acc: 0.8680\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1685 - acc: 0.9730 - val_loss: 0.9231 - val_acc: 0.8668\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2778 - acc: 0.9620 - val_loss: 0.8696 - val_acc: 0.8670\n",
      "Epoch 8/10\n",
      " - 1s - loss: 8.7245e-04 - acc: 1.0000 - val_loss: 0.8657 - val_acc: 0.8679\n",
      "Epoch 9/10\n",
      " - 0s - loss: 5.6934e-04 - acc: 1.0000 - val_loss: 0.8644 - val_acc: 0.8683\n",
      "Epoch 10/10\n",
      " - 1s - loss: 4.5676e-04 - acc: 1.0000 - val_loss: 0.8637 - val_acc: 0.8683\n",
      "Trial number: 21\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 3.9783e-04 - acc: 1.0000 - val_loss: 0.8645 - val_acc: 0.8686\n",
      "Epoch 2/10\n",
      " - 0s - loss: 3.5150e-04 - acc: 1.0000 - val_loss: 0.8657 - val_acc: 0.8683\n",
      "Epoch 3/10\n",
      " - 0s - loss: 3.0724e-04 - acc: 1.0000 - val_loss: 0.8655 - val_acc: 0.8681\n",
      "Epoch 4/10\n",
      " - 1s - loss: 3.0552e-04 - acc: 1.0000 - val_loss: 0.8689 - val_acc: 0.8675\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2029 - acc: 0.9600 - val_loss: 0.8609 - val_acc: 0.8678\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0023 - acc: 0.9990 - val_loss: 0.8671 - val_acc: 0.8679\n",
      "Epoch 7/10\n",
      " - 1s - loss: 8.7365e-04 - acc: 1.0000 - val_loss: 0.8648 - val_acc: 0.8684\n",
      "Epoch 8/10\n",
      " - 0s - loss: 4.8512e-04 - acc: 1.0000 - val_loss: 0.8655 - val_acc: 0.8688\n",
      "Epoch 9/10\n",
      " - 0s - loss: 4.1209e-04 - acc: 1.0000 - val_loss: 0.8661 - val_acc: 0.8690\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0024 - acc: 0.9990 - val_loss: 0.8842 - val_acc: 0.8682\n",
      "Trial number: 22\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.2687 - acc: 0.9570 - val_loss: 0.8672 - val_acc: 0.8673\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8651 - val_acc: 0.8688\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.3698e-04 - acc: 1.0000 - val_loss: 0.8678 - val_acc: 0.8684\n",
      "Epoch 4/10\n",
      " - 0s - loss: 5.6444e-04 - acc: 1.0000 - val_loss: 0.8700 - val_acc: 0.8679\n",
      "Epoch 5/10\n",
      " - 0s - loss: 4.9953e-04 - acc: 1.0000 - val_loss: 0.8713 - val_acc: 0.8673\n",
      "Epoch 6/10\n",
      " - 0s - loss: 5.8588e-04 - acc: 1.0000 - val_loss: 0.8728 - val_acc: 0.8673\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2401 - acc: 0.9710 - val_loss: 0.8642 - val_acc: 0.8680\n",
      "Epoch 8/10\n",
      " - 0s - loss: 9.1148e-04 - acc: 1.0000 - val_loss: 0.8648 - val_acc: 0.8685\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7830e-04 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.8686\n",
      "Epoch 10/10\n",
      " - 0s - loss: 5.3341e-04 - acc: 1.0000 - val_loss: 0.8632 - val_acc: 0.8690\n",
      "Trial number: 23\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 4.3338e-04 - acc: 1.0000 - val_loss: 0.8632 - val_acc: 0.8693\n",
      "Epoch 2/10\n",
      " - 0s - loss: 3.2675e-04 - acc: 1.0000 - val_loss: 0.8653 - val_acc: 0.8691\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.3071 - acc: 0.9560 - val_loss: 0.8634 - val_acc: 0.8699\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8599 - val_acc: 0.8699\n",
      "Epoch 5/10\n",
      " - 0s - loss: 3.3955e-04 - acc: 1.0000 - val_loss: 0.8614 - val_acc: 0.8693\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.6502e-04 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.8695\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.1848e-04 - acc: 1.0000 - val_loss: 0.8639 - val_acc: 0.8699\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.9497e-04 - acc: 1.0000 - val_loss: 0.8661 - val_acc: 0.8694\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.9907e-04 - acc: 1.0000 - val_loss: 0.8670 - val_acc: 0.8696\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.6095e-04 - acc: 1.0000 - val_loss: 0.8667 - val_acc: 0.8690\n",
      "Trial number: 24\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.4007 - acc: 0.9480 - val_loss: 0.8559 - val_acc: 0.8698\n",
      "Epoch 2/10\n",
      " - 0s - loss: 8.2818e-04 - acc: 1.0000 - val_loss: 0.8569 - val_acc: 0.8691\n",
      "Epoch 3/10\n",
      " - 0s - loss: 3.4422e-04 - acc: 1.0000 - val_loss: 0.8578 - val_acc: 0.8687\n",
      "Epoch 4/10\n",
      " - 1s - loss: 2.5240e-04 - acc: 1.0000 - val_loss: 0.8588 - val_acc: 0.8685\n",
      "Epoch 5/10\n",
      " - 1s - loss: 2.0205e-04 - acc: 1.0000 - val_loss: 0.8598 - val_acc: 0.8688\n",
      "Epoch 6/10\n",
      " - 1s - loss: 1.8622e-04 - acc: 1.0000 - val_loss: 0.8600 - val_acc: 0.8691\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.8088e-04 - acc: 1.0000 - val_loss: 0.8619 - val_acc: 0.8686\n",
      "Epoch 8/10\n",
      " - 1s - loss: 1.6903e-04 - acc: 1.0000 - val_loss: 0.8631 - val_acc: 0.8690\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.7384e-04 - acc: 1.0000 - val_loss: 0.8595 - val_acc: 0.8689\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.4389 - acc: 0.9390 - val_loss: 0.8550 - val_acc: 0.8702\n",
      "Trial number: 25\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 4.9336e-04 - acc: 1.0000 - val_loss: 0.8540 - val_acc: 0.8697\n",
      "Epoch 2/10\n",
      " - 0s - loss: 3.1341e-04 - acc: 1.0000 - val_loss: 0.8543 - val_acc: 0.8694\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.3500e-04 - acc: 1.0000 - val_loss: 0.8553 - val_acc: 0.8700\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.0008e-04 - acc: 1.0000 - val_loss: 0.8557 - val_acc: 0.8694\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.6911e-04 - acc: 1.0000 - val_loss: 0.8562 - val_acc: 0.8702\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.5577e-04 - acc: 1.0000 - val_loss: 0.8581 - val_acc: 0.8701\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.4657e-04 - acc: 1.0000 - val_loss: 0.8574 - val_acc: 0.8697\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.2736e-04 - acc: 1.0000 - val_loss: 0.8649 - val_acc: 0.8691\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.4459 - acc: 0.9380 - val_loss: 0.8523 - val_acc: 0.8711\n",
      "Epoch 10/10\n",
      " - 0s - loss: 9.6972e-04 - acc: 1.0000 - val_loss: 0.8545 - val_acc: 0.8709\n",
      "Trial number: 26\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 3.7959e-04 - acc: 1.0000 - val_loss: 0.8556 - val_acc: 0.8710\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.8417e-04 - acc: 1.0000 - val_loss: 0.8559 - val_acc: 0.8710\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.3928e-04 - acc: 1.0000 - val_loss: 0.8569 - val_acc: 0.8710\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.0454e-04 - acc: 1.0000 - val_loss: 0.8557 - val_acc: 0.8716\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.3137 - acc: 0.9690 - val_loss: 0.8588 - val_acc: 0.8713\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1024 - acc: 0.9800 - val_loss: 0.8644 - val_acc: 0.8691\n",
      "Epoch 7/10\n",
      " - 0s - loss: 3.3670e-04 - acc: 1.0000 - val_loss: 0.8632 - val_acc: 0.8695\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.6615e-04 - acc: 1.0000 - val_loss: 0.8626 - val_acc: 0.8697\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.3073e-04 - acc: 1.0000 - val_loss: 0.8623 - val_acc: 0.8701\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.2456e-04 - acc: 1.0000 - val_loss: 0.8621 - val_acc: 0.8706\n",
      "Trial number: 27\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.9452e-04 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.8703\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.5167e-04 - acc: 1.0000 - val_loss: 0.8647 - val_acc: 0.8705\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.3712 - acc: 0.9490 - val_loss: 0.8554 - val_acc: 0.8700\n",
      "Epoch 4/10\n",
      " - 0s - loss: 3.8463e-04 - acc: 1.0000 - val_loss: 0.8609 - val_acc: 0.8694\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.6022e-04 - acc: 1.0000 - val_loss: 0.8621 - val_acc: 0.8689\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.1593e-04 - acc: 1.0000 - val_loss: 0.8618 - val_acc: 0.8689\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.0982e-04 - acc: 1.0000 - val_loss: 0.8639 - val_acc: 0.8686\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.8703e-04 - acc: 1.0000 - val_loss: 0.8625 - val_acc: 0.8690\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.7058e-04 - acc: 1.0000 - val_loss: 0.8623 - val_acc: 0.8695\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.4792e-04 - acc: 1.0000 - val_loss: 0.8643 - val_acc: 0.8693\n",
      "Trial number: 28\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.4982e-04 - acc: 1.0000 - val_loss: 0.8620 - val_acc: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " - 0s - loss: 0.5291 - acc: 0.9340 - val_loss: 0.8668 - val_acc: 0.8685\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0023 - acc: 0.9990 - val_loss: 0.8583 - val_acc: 0.8698\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.8362e-04 - acc: 1.0000 - val_loss: 0.8586 - val_acc: 0.8705\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.8256e-04 - acc: 1.0000 - val_loss: 0.8596 - val_acc: 0.8705\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.5332e-04 - acc: 1.0000 - val_loss: 0.8600 - val_acc: 0.8698\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2977e-04 - acc: 1.0000 - val_loss: 0.8606 - val_acc: 0.8699\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.2151e-04 - acc: 1.0000 - val_loss: 0.8619 - val_acc: 0.8701\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.0794e-04 - acc: 1.0000 - val_loss: 0.8632 - val_acc: 0.8700\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2692e-04 - acc: 1.0000 - val_loss: 0.8616 - val_acc: 0.8692\n",
      "Trial number: 29\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.6340 - acc: 0.9290 - val_loss: 0.8678 - val_acc: 0.8699\n",
      "Epoch 2/10\n",
      " - 0s - loss: 6.2341e-04 - acc: 1.0000 - val_loss: 0.8625 - val_acc: 0.8701\n",
      "Epoch 3/10\n",
      " - 0s - loss: 4.0181e-04 - acc: 1.0000 - val_loss: 0.8625 - val_acc: 0.8699\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.4465e-04 - acc: 1.0000 - val_loss: 0.8607 - val_acc: 0.8703\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.0899e-04 - acc: 1.0000 - val_loss: 0.8598 - val_acc: 0.8704\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.7861e-04 - acc: 1.0000 - val_loss: 0.8570 - val_acc: 0.8705\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.3792e-04 - acc: 1.0000 - val_loss: 0.8586 - val_acc: 0.8708\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0055 - acc: 0.9980 - val_loss: 0.8815 - val_acc: 0.8693\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.1935 - acc: 0.9000 - val_loss: 0.8626 - val_acc: 0.8677\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8570 - val_acc: 0.8680\n",
      "Trial number: 30\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.8995e-04 - acc: 1.0000 - val_loss: 0.8546 - val_acc: 0.8692\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.1734e-04 - acc: 1.0000 - val_loss: 0.8544 - val_acc: 0.8690\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.7913e-04 - acc: 1.0000 - val_loss: 0.8545 - val_acc: 0.8693\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.6122e-04 - acc: 1.0000 - val_loss: 0.8539 - val_acc: 0.8701\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.5174e-04 - acc: 1.0000 - val_loss: 0.8532 - val_acc: 0.8697\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2022e-04 - acc: 1.0000 - val_loss: 0.8561 - val_acc: 0.8691\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2211 - acc: 0.9740 - val_loss: 0.9046 - val_acc: 0.8633\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.2493 - acc: 0.9670 - val_loss: 0.8654 - val_acc: 0.8693\n",
      "Epoch 9/10\n",
      " - 0s - loss: 3.4287e-04 - acc: 1.0000 - val_loss: 0.8601 - val_acc: 0.8697\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.0232e-04 - acc: 1.0000 - val_loss: 0.8577 - val_acc: 0.8699\n",
      "Trial number: 31\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.5611e-04 - acc: 1.0000 - val_loss: 0.8569 - val_acc: 0.8703\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.2764e-04 - acc: 1.0000 - val_loss: 0.8566 - val_acc: 0.8705\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.2142e-04 - acc: 1.0000 - val_loss: 0.8562 - val_acc: 0.8703\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.2199e-04 - acc: 1.0000 - val_loss: 0.8566 - val_acc: 0.8700\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7378e-05 - acc: 1.0000 - val_loss: 0.8527 - val_acc: 0.8708\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.3118 - acc: 0.9650 - val_loss: 0.8887 - val_acc: 0.8713\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.4356 - acc: 0.9600 - val_loss: 0.8448 - val_acc: 0.8695\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.8251e-04 - acc: 1.0000 - val_loss: 0.8469 - val_acc: 0.8698\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.5905e-04 - acc: 1.0000 - val_loss: 0.8480 - val_acc: 0.8700\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.2072e-04 - acc: 1.0000 - val_loss: 0.8494 - val_acc: 0.8702\n",
      "| 1 | 0.8393 |\n",
      "| 2 | 0.8567 |\n",
      "| 3 | 0.8627 |\n",
      "| 4 | 0.8609 |\n",
      "| 5 | 0.8646 |\n",
      "| 6 | 0.8644 |\n",
      "| 7 | 0.8637 |\n",
      "| 8 | 0.8663 |\n",
      "| 9 | 0.8655 |\n",
      "| 10 | 0.8665 |\n",
      "| 11 | 0.8655 |\n",
      "| 12 | 0.8666 |\n",
      "| 13 | 0.8674 |\n",
      "| 14 | 0.8677 |\n",
      "| 15 | 0.8668 |\n",
      "| 16 | 0.8673 |\n",
      "| 17 | 0.8666 |\n",
      "| 18 | 0.8683 |\n",
      "| 19 | 0.8691 |\n",
      "| 20 | 0.8683 |\n",
      "| 21 | 0.8682 |\n",
      "| 22 | 0.869 |\n",
      "| 23 | 0.869 |\n",
      "| 24 | 0.8702 |\n",
      "| 25 | 0.8709 |\n",
      "| 26 | 0.8706 |\n",
      "| 27 | 0.8693 |\n",
      "| 28 | 0.8692 |\n",
      "| 29 | 0.868 |\n",
      "| 30 | 0.8699 |\n",
      "| 31 | 0.8702 |\n",
      "Average: 0.8660870967741936\n",
      "Trial number: 1\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.9373 - acc: 0.8705 - val_loss: 0.8270 - val_acc: 0.8726\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.5723 - acc: 0.9020 - val_loss: 0.8216 - val_acc: 0.8666\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.4168 - acc: 0.9280 - val_loss: 0.7048 - val_acc: 0.8825\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3604 - acc: 0.9350 - val_loss: 0.7052 - val_acc: 0.8797\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.4387 - acc: 0.9310 - val_loss: 0.7062 - val_acc: 0.8808\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2836 - acc: 0.9515 - val_loss: 0.6093 - val_acc: 0.8917\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.3157 - acc: 0.9390 - val_loss: 0.6288 - val_acc: 0.8881\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.2900 - acc: 0.9445 - val_loss: 0.6445 - val_acc: 0.8854\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.2175 - acc: 0.9570 - val_loss: 0.6020 - val_acc: 0.8930\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.2204 - acc: 0.9570 - val_loss: 0.5847 - val_acc: 0.8928\n",
      "Trial number: 2\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.2403 - acc: 0.9545 - val_loss: 0.5803 - val_acc: 0.8954\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.2332 - acc: 0.9520 - val_loss: 0.6206 - val_acc: 0.8908\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1839 - acc: 0.9585 - val_loss: 0.5788 - val_acc: 0.8963\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1974 - acc: 0.9555 - val_loss: 0.6212 - val_acc: 0.8944\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2202 - acc: 0.9560 - val_loss: 0.6289 - val_acc: 0.8941\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1908 - acc: 0.9535 - val_loss: 0.6122 - val_acc: 0.8981\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1564 - acc: 0.9595 - val_loss: 0.6479 - val_acc: 0.8950\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1810 - acc: 0.9620 - val_loss: 0.6096 - val_acc: 0.8997\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.2224 - acc: 0.9580 - val_loss: 0.6636 - val_acc: 0.8936\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1899 - acc: 0.9570 - val_loss: 0.6430 - val_acc: 0.8948\n",
      "Trial number: 3\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.1352 - acc: 0.9685 - val_loss: 0.6365 - val_acc: 0.8984\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1695 - acc: 0.9575 - val_loss: 0.6691 - val_acc: 0.8973\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1342 - acc: 0.9670 - val_loss: 0.6380 - val_acc: 0.9001\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.1346 - acc: 0.9710 - val_loss: 0.6547 - val_acc: 0.8964\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1124 - acc: 0.9725 - val_loss: 0.6886 - val_acc: 0.8947\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1853 - acc: 0.9580 - val_loss: 0.6599 - val_acc: 0.9004\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0831 - acc: 0.9790 - val_loss: 0.6598 - val_acc: 0.8982\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1428 - acc: 0.9670 - val_loss: 0.6507 - val_acc: 0.9010\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.1384 - acc: 0.9710 - val_loss: 0.6612 - val_acc: 0.8990\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1633 - acc: 0.9660 - val_loss: 0.6728 - val_acc: 0.8986\n",
      "Trial number: 4\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0949 - acc: 0.9780 - val_loss: 0.6473 - val_acc: 0.9003\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1231 - acc: 0.9720 - val_loss: 0.6668 - val_acc: 0.9006\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0875 - acc: 0.9840 - val_loss: 0.6634 - val_acc: 0.9015\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.1452 - acc: 0.9705 - val_loss: 0.6791 - val_acc: 0.8994\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1005 - acc: 0.9790 - val_loss: 0.6733 - val_acc: 0.9012\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0825 - acc: 0.9825 - val_loss: 0.7234 - val_acc: 0.8961\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0980 - acc: 0.9800 - val_loss: 0.6788 - val_acc: 0.9018\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1067 - acc: 0.9765 - val_loss: 0.6853 - val_acc: 0.9022\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0966 - acc: 0.9820 - val_loss: 0.6841 - val_acc: 0.9011\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0996 - acc: 0.9785 - val_loss: 0.6939 - val_acc: 0.9011\n",
      "Trial number: 5\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0651 - acc: 0.9850 - val_loss: 0.7524 - val_acc: 0.8961\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1171 - acc: 0.9790 - val_loss: 0.7018 - val_acc: 0.9016\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1255 - acc: 0.9755 - val_loss: 0.7037 - val_acc: 0.9004\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0586 - acc: 0.9875 - val_loss: 0.6981 - val_acc: 0.9020\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1701 - acc: 0.9740 - val_loss: 0.6915 - val_acc: 0.9012\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0631 - acc: 0.9880 - val_loss: 0.7184 - val_acc: 0.9013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 0s - loss: 0.0963 - acc: 0.9780 - val_loss: 0.7048 - val_acc: 0.9004\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0379 - acc: 0.9930 - val_loss: 0.6946 - val_acc: 0.9024\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1277 - acc: 0.9785 - val_loss: 0.6975 - val_acc: 0.9023\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0641 - acc: 0.9880 - val_loss: 0.7007 - val_acc: 0.9014\n",
      "Trial number: 6\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0757 - acc: 0.9845 - val_loss: 0.6938 - val_acc: 0.9036\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1047 - acc: 0.9845 - val_loss: 0.7016 - val_acc: 0.9028\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0749 - acc: 0.9845 - val_loss: 0.7043 - val_acc: 0.9032\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0266 - acc: 0.9980 - val_loss: 0.7088 - val_acc: 0.9024\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0860 - acc: 0.9875 - val_loss: 0.7120 - val_acc: 0.9015\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0592 - acc: 0.9895 - val_loss: 0.7059 - val_acc: 0.9025\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0254 - acc: 0.9985 - val_loss: 0.7013 - val_acc: 0.9035\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1495 - acc: 0.9800 - val_loss: 0.7081 - val_acc: 0.9022\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0936 - acc: 0.9825 - val_loss: 0.7018 - val_acc: 0.9031\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0417 - acc: 0.9945 - val_loss: 0.7007 - val_acc: 0.9040\n",
      "Trial number: 7\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0727 - acc: 0.9870 - val_loss: 0.7112 - val_acc: 0.9030\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0264 - acc: 0.9985 - val_loss: 0.7103 - val_acc: 0.9033\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0891 - acc: 0.9835 - val_loss: 0.7158 - val_acc: 0.9022\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0512 - acc: 0.9915 - val_loss: 0.7105 - val_acc: 0.9028\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0266 - acc: 0.9985 - val_loss: 0.7100 - val_acc: 0.9034\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1275 - acc: 0.9745 - val_loss: 0.7193 - val_acc: 0.9030\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0954 - acc: 0.9835 - val_loss: 0.7229 - val_acc: 0.9042\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0264 - acc: 0.9980 - val_loss: 0.7275 - val_acc: 0.9026\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1114 - acc: 0.9835 - val_loss: 0.7134 - val_acc: 0.9035\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0256 - acc: 0.9985 - val_loss: 0.7096 - val_acc: 0.9045\n",
      "Trial number: 8\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0614 - acc: 0.9900 - val_loss: 0.7608 - val_acc: 0.8986\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0924 - acc: 0.9805 - val_loss: 0.7161 - val_acc: 0.9029\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0532 - acc: 0.9885 - val_loss: 0.7141 - val_acc: 0.9043\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0847 - acc: 0.9900 - val_loss: 0.7103 - val_acc: 0.9046\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0710 - acc: 0.9915 - val_loss: 0.7169 - val_acc: 0.9030\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0249 - acc: 0.9985 - val_loss: 0.7184 - val_acc: 0.9036\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0268 - acc: 0.9975 - val_loss: 0.7321 - val_acc: 0.9020\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1082 - acc: 0.9825 - val_loss: 0.7105 - val_acc: 0.9034\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0249 - acc: 0.9985 - val_loss: 0.7100 - val_acc: 0.9040\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1191 - acc: 0.9855 - val_loss: 0.7034 - val_acc: 0.9045\n",
      "Trial number: 9\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.1069 - acc: 0.9850 - val_loss: 0.6969 - val_acc: 0.9061\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0248 - acc: 0.9985 - val_loss: 0.7041 - val_acc: 0.9051\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0245 - acc: 0.9985 - val_loss: 0.7058 - val_acc: 0.9049\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1302 - acc: 0.9825 - val_loss: 0.7042 - val_acc: 0.9039\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0248 - acc: 0.9985 - val_loss: 0.7075 - val_acc: 0.9042\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1623 - acc: 0.9785 - val_loss: 0.7147 - val_acc: 0.9037\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0308 - acc: 0.9960 - val_loss: 0.7226 - val_acc: 0.9021\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0265 - acc: 0.9980 - val_loss: 0.7038 - val_acc: 0.9045\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1463 - acc: 0.9780 - val_loss: 0.7066 - val_acc: 0.9047\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0252 - acc: 0.9985 - val_loss: 0.7154 - val_acc: 0.9045\n",
      "Trial number: 10\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7149 - val_acc: 0.9043\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1797 - acc: 0.9790 - val_loss: 0.7195 - val_acc: 0.9024\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0253 - acc: 0.9985 - val_loss: 0.7131 - val_acc: 0.9033\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0245 - acc: 0.9985 - val_loss: 0.7097 - val_acc: 0.9047\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7166 - val_acc: 0.9037\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2237 - acc: 0.9740 - val_loss: 0.7178 - val_acc: 0.9027\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0245 - acc: 0.9985 - val_loss: 0.7163 - val_acc: 0.9032\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1509 - acc: 0.9820 - val_loss: 0.7185 - val_acc: 0.9040\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0558 - acc: 0.9930 - val_loss: 0.7048 - val_acc: 0.9040\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0245 - acc: 0.9985 - val_loss: 0.7002 - val_acc: 0.9050\n",
      "Trial number: 11\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.2464 - acc: 0.9735 - val_loss: 0.7262 - val_acc: 0.9013\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0325 - acc: 0.9960 - val_loss: 0.7063 - val_acc: 0.9040\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0374 - acc: 0.9945 - val_loss: 0.7287 - val_acc: 0.9010\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0993 - acc: 0.9840 - val_loss: 0.7136 - val_acc: 0.9038\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0658 - acc: 0.9915 - val_loss: 0.7111 - val_acc: 0.9033\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7143 - val_acc: 0.9032\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.7013 - val_acc: 0.9052\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1070 - acc: 0.9855 - val_loss: 0.7070 - val_acc: 0.9049\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0245 - acc: 0.9985 - val_loss: 0.7077 - val_acc: 0.9047\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1035 - acc: 0.9860 - val_loss: 0.7196 - val_acc: 0.9021\n",
      "Trial number: 12\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0969 - acc: 0.9805 - val_loss: 0.7176 - val_acc: 0.9026\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7064 - val_acc: 0.9034\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0245 - acc: 0.9985 - val_loss: 0.7046 - val_acc: 0.9040\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1253 - acc: 0.9880 - val_loss: 0.7071 - val_acc: 0.9036\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0947 - acc: 0.9865 - val_loss: 0.7008 - val_acc: 0.9041\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.7070 - val_acc: 0.9041\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7069 - val_acc: 0.9037\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7265 - val_acc: 0.9023\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.3431 - acc: 0.9675 - val_loss: 0.7096 - val_acc: 0.9045\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7155 - val_acc: 0.9021\n",
      "Trial number: 13\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7157 - val_acc: 0.9029\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.2296 - acc: 0.9725 - val_loss: 0.7118 - val_acc: 0.9023\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0248 - acc: 0.9985 - val_loss: 0.7036 - val_acc: 0.9036\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7080 - val_acc: 0.9037\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7005 - val_acc: 0.9040\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1810 - acc: 0.9795 - val_loss: 0.7122 - val_acc: 0.9030\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1093 - acc: 0.9830 - val_loss: 0.7387 - val_acc: 0.9026\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0421 - acc: 0.9965 - val_loss: 0.7201 - val_acc: 0.9029\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7143 - val_acc: 0.9039\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7163 - val_acc: 0.9037\n",
      "Trial number: 14\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.2329 - acc: 0.9735 - val_loss: 0.7082 - val_acc: 0.9040\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7109 - val_acc: 0.9030\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7071 - val_acc: 0.9040\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.2981 - acc: 0.9680 - val_loss: 0.6944 - val_acc: 0.9038\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0250 - acc: 0.9985 - val_loss: 0.7054 - val_acc: 0.9042\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7029 - val_acc: 0.9046\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7072 - val_acc: 0.9039\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.2868 - acc: 0.9665 - val_loss: 0.7215 - val_acc: 0.9025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      " - 0s - loss: 0.0251 - acc: 0.9980 - val_loss: 0.7049 - val_acc: 0.9044\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7023 - val_acc: 0.9040\n",
      "Trial number: 15\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7017 - val_acc: 0.9043\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.3711 - acc: 0.9675 - val_loss: 0.7071 - val_acc: 0.9053\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1425 - acc: 0.9840 - val_loss: 0.7206 - val_acc: 0.9040\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0266 - acc: 0.9970 - val_loss: 0.6986 - val_acc: 0.9061\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7001 - val_acc: 0.9068\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1785 - acc: 0.9700 - val_loss: 0.7158 - val_acc: 0.9052\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.7108 - val_acc: 0.9057\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7037 - val_acc: 0.9057\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.2513 - acc: 0.9705 - val_loss: 0.7153 - val_acc: 0.9048\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0264 - acc: 0.9980 - val_loss: 0.6987 - val_acc: 0.9048\n",
      "Trial number: 16\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.1640 - acc: 0.9825 - val_loss: 0.7235 - val_acc: 0.9031\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7206 - val_acc: 0.9027\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1568 - acc: 0.9795 - val_loss: 0.7177 - val_acc: 0.9048\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7155 - val_acc: 0.9048\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7142 - val_acc: 0.9047\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1421 - acc: 0.9830 - val_loss: 0.7238 - val_acc: 0.9042\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0355 - acc: 0.9965 - val_loss: 0.7183 - val_acc: 0.9050\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7209 - val_acc: 0.9051\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7212 - val_acc: 0.9052\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.4771 - acc: 0.9600 - val_loss: 0.7349 - val_acc: 0.9016\n",
      "Trial number: 17\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0801 - acc: 0.9880 - val_loss: 0.7181 - val_acc: 0.9037\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7165 - val_acc: 0.9038\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1641 - acc: 0.9845 - val_loss: 0.7229 - val_acc: 0.9040\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0245 - acc: 0.9985 - val_loss: 0.7133 - val_acc: 0.9040\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7112 - val_acc: 0.9043\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7094 - val_acc: 0.9057\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2030 - acc: 0.9795 - val_loss: 0.7323 - val_acc: 0.9035\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1112 - acc: 0.9835 - val_loss: 0.7298 - val_acc: 0.9016\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0245 - acc: 0.9985 - val_loss: 0.7186 - val_acc: 0.9040\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7086 - val_acc: 0.9051\n",
      "Trial number: 18\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.2342 - acc: 0.9780 - val_loss: 0.7053 - val_acc: 0.9041\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0262 - acc: 0.9980 - val_loss: 0.7153 - val_acc: 0.9033\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1012 - acc: 0.9820 - val_loss: 0.7319 - val_acc: 0.9026\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0446 - acc: 0.9950 - val_loss: 0.7497 - val_acc: 0.9012\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1253 - acc: 0.9840 - val_loss: 0.7154 - val_acc: 0.9045\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1021 - acc: 0.9860 - val_loss: 0.7175 - val_acc: 0.9040\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0301 - acc: 0.9950 - val_loss: 0.6998 - val_acc: 0.9056\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1876 - acc: 0.9785 - val_loss: 0.7034 - val_acc: 0.9066\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0269 - acc: 0.9975 - val_loss: 0.7090 - val_acc: 0.9060\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7134 - val_acc: 0.9051\n",
      "Trial number: 19\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7175 - val_acc: 0.9050\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7207 - val_acc: 0.9051\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1902 - acc: 0.9785 - val_loss: 0.7211 - val_acc: 0.9035\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7133 - val_acc: 0.9046\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7164 - val_acc: 0.9044\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7136 - val_acc: 0.9050\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2491 - acc: 0.9700 - val_loss: 0.7096 - val_acc: 0.9043\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0258 - acc: 0.9980 - val_loss: 0.7092 - val_acc: 0.9047\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7094 - val_acc: 0.9050\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7124 - val_acc: 0.9045\n",
      "Trial number: 20\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7113 - val_acc: 0.9046\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.2251 - acc: 0.9710 - val_loss: 0.7000 - val_acc: 0.9061\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7012 - val_acc: 0.9059\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7034 - val_acc: 0.9050\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7045 - val_acc: 0.9056\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.2098 - acc: 0.9770 - val_loss: 0.6942 - val_acc: 0.9071\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0770 - acc: 0.9880 - val_loss: 0.7185 - val_acc: 0.9057\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0281 - acc: 0.9975 - val_loss: 0.7050 - val_acc: 0.9064\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7064 - val_acc: 0.9067\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7066 - val_acc: 0.9067\n",
      "Trial number: 21\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7043 - val_acc: 0.9061\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.2452 - acc: 0.9760 - val_loss: 0.6801 - val_acc: 0.9089\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0274 - acc: 0.9980 - val_loss: 0.6945 - val_acc: 0.9071\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6902 - val_acc: 0.9078\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6934 - val_acc: 0.9076\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7002 - val_acc: 0.9070\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1813 - acc: 0.9755 - val_loss: 0.7060 - val_acc: 0.9047\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.6982 - val_acc: 0.9069\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6978 - val_acc: 0.9069\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7008 - val_acc: 0.9070\n",
      "Trial number: 22\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.2181 - acc: 0.9775 - val_loss: 0.6939 - val_acc: 0.9076\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0535 - acc: 0.9900 - val_loss: 0.7162 - val_acc: 0.9054\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7027 - val_acc: 0.9066\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0267 - acc: 0.9975 - val_loss: 0.8035 - val_acc: 0.8964\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2534 - acc: 0.9715 - val_loss: 0.6916 - val_acc: 0.9080\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0583 - acc: 0.9870 - val_loss: 0.6937 - val_acc: 0.9083\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0248 - acc: 0.9985 - val_loss: 0.6964 - val_acc: 0.9082\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.6972 - val_acc: 0.9081\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.2065 - acc: 0.9805 - val_loss: 0.7007 - val_acc: 0.9069\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7006 - val_acc: 0.9071\n",
      "Trial number: 23\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7018 - val_acc: 0.9071\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7068 - val_acc: 0.9072\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.3157 - acc: 0.9660 - val_loss: 0.6986 - val_acc: 0.9057\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.6968 - val_acc: 0.9057\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6980 - val_acc: 0.9063\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7001 - val_acc: 0.9066\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1896 - acc: 0.9735 - val_loss: 0.6943 - val_acc: 0.9073\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0730 - acc: 0.9870 - val_loss: 0.6959 - val_acc: 0.9061\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0245 - acc: 0.9985 - val_loss: 0.6912 - val_acc: 0.9070\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.6922 - val_acc: 0.9075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 24\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6927 - val_acc: 0.9072\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6920 - val_acc: 0.9080\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.2186 - acc: 0.9680 - val_loss: 0.6880 - val_acc: 0.9083\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.6842 - val_acc: 0.9088\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6915 - val_acc: 0.9082\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6919 - val_acc: 0.9079\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6918 - val_acc: 0.9084\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6887 - val_acc: 0.9084\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.2792 - acc: 0.9700 - val_loss: 0.6910 - val_acc: 0.9085\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0310 - acc: 0.9965 - val_loss: 0.6955 - val_acc: 0.9082\n",
      "Trial number: 25\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6956 - val_acc: 0.9083\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7041 - val_acc: 0.9069\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.2900 - acc: 0.9725 - val_loss: 0.7303 - val_acc: 0.9036\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.6960 - val_acc: 0.9078\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6933 - val_acc: 0.9084\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6858 - val_acc: 0.9100\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6880 - val_acc: 0.9098\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.5056 - acc: 0.9505 - val_loss: 0.7339 - val_acc: 0.9038\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0244 - acc: 0.9985 - val_loss: 0.7177 - val_acc: 0.9049\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1752 - acc: 0.9785 - val_loss: 0.7239 - val_acc: 0.9046\n",
      "Trial number: 26\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7158 - val_acc: 0.9050\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7108 - val_acc: 0.9053\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6983 - val_acc: 0.9073\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.4577 - acc: 0.9550 - val_loss: 0.7251 - val_acc: 0.9044\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7040 - val_acc: 0.9073\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7008 - val_acc: 0.9079\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7032 - val_acc: 0.9078\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.3310 - acc: 0.9670 - val_loss: 0.7222 - val_acc: 0.9039\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0249 - acc: 0.9985 - val_loss: 0.7001 - val_acc: 0.9073\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7002 - val_acc: 0.9077\n",
      "Trial number: 27\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7004 - val_acc: 0.9074\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7005 - val_acc: 0.9083\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.3696 - acc: 0.9650 - val_loss: 0.7171 - val_acc: 0.9066\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0684 - acc: 0.9915 - val_loss: 0.7260 - val_acc: 0.9055\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0938 - acc: 0.9840 - val_loss: 0.7069 - val_acc: 0.9077\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7000 - val_acc: 0.9088\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6998 - val_acc: 0.9092\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6954 - val_acc: 0.9098\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6986 - val_acc: 0.9099\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.6195 - acc: 0.9475 - val_loss: 0.7734 - val_acc: 0.8975\n",
      "Trial number: 28\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0864 - acc: 0.9890 - val_loss: 0.6905 - val_acc: 0.9072\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.6934 - val_acc: 0.9077\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1749 - acc: 0.9840 - val_loss: 0.7501 - val_acc: 0.9033\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0858 - acc: 0.9860 - val_loss: 0.6891 - val_acc: 0.9101\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.6867 - val_acc: 0.9099\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6890 - val_acc: 0.9097\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6911 - val_acc: 0.9100\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.6899 - val_acc: 0.9098\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.2027 - acc: 0.9760 - val_loss: 0.7070 - val_acc: 0.9076\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0357 - acc: 0.9965 - val_loss: 0.7041 - val_acc: 0.9085\n",
      "Trial number: 29\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7065 - val_acc: 0.9085\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7071 - val_acc: 0.9083\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7100 - val_acc: 0.9083\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7095 - val_acc: 0.9084\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.3023 - acc: 0.9685 - val_loss: 0.7078 - val_acc: 0.9072\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0285 - acc: 0.9960 - val_loss: 0.7058 - val_acc: 0.9082\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7094 - val_acc: 0.9076\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7076 - val_acc: 0.9079\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7051 - val_acc: 0.9085\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7040 - val_acc: 0.9086\n",
      "Trial number: 30\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.1164 - acc: 0.9875 - val_loss: 0.7831 - val_acc: 0.8995\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1394 - acc: 0.9820 - val_loss: 0.7028 - val_acc: 0.9073\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7014 - val_acc: 0.9080\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7033 - val_acc: 0.9077\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7072 - val_acc: 0.9076\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7070 - val_acc: 0.9082\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2345 - acc: 0.9755 - val_loss: 0.7158 - val_acc: 0.9051\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.0246 - acc: 0.9985 - val_loss: 0.7069 - val_acc: 0.9076\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7014 - val_acc: 0.9089\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7008 - val_acc: 0.9088\n",
      "Trial number: 31\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7040 - val_acc: 0.9083\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6901 - acc: 0.9400 - val_loss: 0.7238 - val_acc: 0.9056\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.0254 - acc: 0.9980 - val_loss: 0.7152 - val_acc: 0.9076\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7123 - val_acc: 0.9081\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7188 - val_acc: 0.9080\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7137 - val_acc: 0.9084\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7098 - val_acc: 0.9093\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.2284 - acc: 0.9770 - val_loss: 0.7034 - val_acc: 0.9098\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.7070 - val_acc: 0.9095\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.7063 - val_acc: 0.9097\n",
      "| 1 | 0.8393 |\n",
      "| 2 | 0.8567 |\n",
      "| 3 | 0.8627 |\n",
      "| 4 | 0.8609 |\n",
      "| 5 | 0.8646 |\n",
      "| 6 | 0.8644 |\n",
      "| 7 | 0.8637 |\n",
      "| 8 | 0.8663 |\n",
      "| 9 | 0.8655 |\n",
      "| 10 | 0.8665 |\n",
      "| 11 | 0.8655 |\n",
      "| 12 | 0.8666 |\n",
      "| 13 | 0.8674 |\n",
      "| 14 | 0.8677 |\n",
      "| 15 | 0.8668 |\n",
      "| 16 | 0.8673 |\n",
      "| 17 | 0.8666 |\n",
      "| 18 | 0.8683 |\n",
      "| 19 | 0.8691 |\n",
      "| 20 | 0.8683 |\n",
      "| 21 | 0.8682 |\n",
      "| 22 | 0.869 |\n",
      "| 23 | 0.869 |\n",
      "| 24 | 0.8702 |\n",
      "| 25 | 0.8709 |\n",
      "| 26 | 0.8706 |\n",
      "| 27 | 0.8693 |\n",
      "| 28 | 0.8692 |\n",
      "| 29 | 0.868 |\n",
      "| 30 | 0.8699 |\n",
      "| 31 | 0.8702 |\n",
      "| 1 | 0.8928 |\n",
      "| 2 | 0.8948 |\n",
      "| 3 | 0.8986 |\n",
      "| 4 | 0.9011 |\n",
      "| 5 | 0.9014 |\n",
      "| 6 | 0.904 |\n",
      "| 7 | 0.9045 |\n",
      "| 8 | 0.9045 |\n",
      "| 9 | 0.9045 |\n",
      "| 10 | 0.905 |\n",
      "| 11 | 0.9021 |\n",
      "| 12 | 0.9021 |\n",
      "| 13 | 0.9037 |\n",
      "| 14 | 0.904 |\n",
      "| 15 | 0.9048 |\n",
      "| 16 | 0.9016 |\n",
      "| 17 | 0.9051 |\n",
      "| 18 | 0.9051 |\n",
      "| 19 | 0.9045 |\n",
      "| 20 | 0.9067 |\n",
      "| 21 | 0.907 |\n",
      "| 22 | 0.9071 |\n",
      "| 23 | 0.9075 |\n",
      "| 24 | 0.9082 |\n",
      "| 25 | 0.9046 |\n",
      "| 26 | 0.9077 |\n",
      "| 27 | 0.8975 |\n",
      "| 28 | 0.9085 |\n",
      "| 29 | 0.9086 |\n",
      "| 30 | 0.9088 |\n",
      "| 31 | 0.9097 |\n",
      "Average: 0.9040677419354839\n",
      "Trial number: 1\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.6683 - acc: 0.9197 - val_loss: 0.6369 - val_acc: 0.9137\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.4181 - acc: 0.9410 - val_loss: 0.7340 - val_acc: 0.8983\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.3734 - acc: 0.9478 - val_loss: 0.7038 - val_acc: 0.9023\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.3272 - acc: 0.9538 - val_loss: 0.5805 - val_acc: 0.9138\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.2920 - acc: 0.9560 - val_loss: 0.6066 - val_acc: 0.9099\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.2484 - acc: 0.9620 - val_loss: 0.5290 - val_acc: 0.9237\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.2805 - acc: 0.9598 - val_loss: 0.6052 - val_acc: 0.9134\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.2121 - acc: 0.9683 - val_loss: 0.5814 - val_acc: 0.9102\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.2276 - acc: 0.9633 - val_loss: 0.5213 - val_acc: 0.9238\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1985 - acc: 0.9690 - val_loss: 0.5235 - val_acc: 0.9252\n",
      "Trial number: 2\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.2213 - acc: 0.9660 - val_loss: 0.5379 - val_acc: 0.9245\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1979 - acc: 0.9670 - val_loss: 0.5521 - val_acc: 0.9191\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1632 - acc: 0.9730 - val_loss: 0.5661 - val_acc: 0.9170\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.1392 - acc: 0.9735 - val_loss: 0.5234 - val_acc: 0.9237\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.1401 - acc: 0.9743 - val_loss: 0.5554 - val_acc: 0.9179\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.1704 - acc: 0.9720 - val_loss: 0.5380 - val_acc: 0.9235\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.1503 - acc: 0.9748 - val_loss: 0.5238 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1355 - acc: 0.9805 - val_loss: 0.5269 - val_acc: 0.9271\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.1726 - acc: 0.9710 - val_loss: 0.5301 - val_acc: 0.9237\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1504 - acc: 0.9723 - val_loss: 0.5706 - val_acc: 0.9221\n",
      "Trial number: 3\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.1175 - acc: 0.9798 - val_loss: 0.5561 - val_acc: 0.9226\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1224 - acc: 0.9803 - val_loss: 0.5657 - val_acc: 0.9213\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1595 - acc: 0.9755 - val_loss: 0.5046 - val_acc: 0.9302\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.1197 - acc: 0.9815 - val_loss: 0.5448 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.1304 - acc: 0.9763 - val_loss: 0.5167 - val_acc: 0.9285\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.1187 - acc: 0.9778 - val_loss: 0.5066 - val_acc: 0.9290\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0957 - acc: 0.9815 - val_loss: 0.5174 - val_acc: 0.9296\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1050 - acc: 0.9800 - val_loss: 0.5145 - val_acc: 0.9280\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.1075 - acc: 0.9825 - val_loss: 0.5237 - val_acc: 0.9299\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1211 - acc: 0.9785 - val_loss: 0.5083 - val_acc: 0.9290\n",
      "Trial number: 4\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0873 - acc: 0.9845 - val_loss: 0.5179 - val_acc: 0.9282\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1231 - acc: 0.9803 - val_loss: 0.5215 - val_acc: 0.9307\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1069 - acc: 0.9833 - val_loss: 0.5293 - val_acc: 0.9298\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0966 - acc: 0.9848 - val_loss: 0.5204 - val_acc: 0.9284\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0846 - acc: 0.9855 - val_loss: 0.5167 - val_acc: 0.9288\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0864 - acc: 0.9853 - val_loss: 0.5285 - val_acc: 0.9277\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0880 - acc: 0.9860 - val_loss: 0.5114 - val_acc: 0.9311\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1102 - acc: 0.9828 - val_loss: 0.5150 - val_acc: 0.9317\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0786 - acc: 0.9888 - val_loss: 0.5695 - val_acc: 0.9255\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1223 - acc: 0.9818 - val_loss: 0.5223 - val_acc: 0.9285\n",
      "Trial number: 5\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0807 - acc: 0.9845 - val_loss: 0.5272 - val_acc: 0.9319\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0927 - acc: 0.9843 - val_loss: 0.5283 - val_acc: 0.9283\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0755 - acc: 0.9893 - val_loss: 0.5251 - val_acc: 0.9309\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0887 - acc: 0.9855 - val_loss: 0.5222 - val_acc: 0.9328\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0779 - acc: 0.9883 - val_loss: 0.5210 - val_acc: 0.9334\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0845 - acc: 0.9873 - val_loss: 0.5551 - val_acc: 0.9299\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0792 - acc: 0.9888 - val_loss: 0.5426 - val_acc: 0.9322\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0773 - acc: 0.9868 - val_loss: 0.5415 - val_acc: 0.9320\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0649 - acc: 0.9905 - val_loss: 0.5317 - val_acc: 0.9320\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0784 - acc: 0.9868 - val_loss: 0.5333 - val_acc: 0.9325\n",
      "Trial number: 6\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0591 - acc: 0.9900 - val_loss: 0.5258 - val_acc: 0.9335\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0967 - acc: 0.9873 - val_loss: 0.5308 - val_acc: 0.9335\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0861 - acc: 0.9890 - val_loss: 0.5394 - val_acc: 0.9323\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0655 - acc: 0.9890 - val_loss: 0.5385 - val_acc: 0.9327\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0570 - acc: 0.9923 - val_loss: 0.5330 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0919 - acc: 0.9855 - val_loss: 0.5377 - val_acc: 0.9325\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0927 - acc: 0.9883 - val_loss: 0.5265 - val_acc: 0.9344\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0734 - acc: 0.9918 - val_loss: 0.5449 - val_acc: 0.9320\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0727 - acc: 0.9895 - val_loss: 0.5367 - val_acc: 0.9338\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1056 - acc: 0.9865 - val_loss: 0.5432 - val_acc: 0.9314\n",
      "Trial number: 7\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0492 - acc: 0.9933 - val_loss: 0.5318 - val_acc: 0.9332\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0924 - acc: 0.9865 - val_loss: 0.5300 - val_acc: 0.9338\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0951 - acc: 0.9878 - val_loss: 0.5479 - val_acc: 0.9320\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0749 - acc: 0.9895 - val_loss: 0.5288 - val_acc: 0.9348\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0889 - acc: 0.9895 - val_loss: 0.5341 - val_acc: 0.9338\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0644 - acc: 0.9915 - val_loss: 0.5318 - val_acc: 0.9342\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0706 - acc: 0.9898 - val_loss: 0.5317 - val_acc: 0.9347\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0859 - acc: 0.9868 - val_loss: 0.5359 - val_acc: 0.9327\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0507 - acc: 0.9950 - val_loss: 0.5319 - val_acc: 0.9347\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0806 - acc: 0.9873 - val_loss: 0.5349 - val_acc: 0.9341\n",
      "Trial number: 8\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0605 - acc: 0.9940 - val_loss: 0.5417 - val_acc: 0.9329\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0760 - acc: 0.9913 - val_loss: 0.5427 - val_acc: 0.9326\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1016 - acc: 0.9858 - val_loss: 0.5354 - val_acc: 0.9332\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0729 - acc: 0.9900 - val_loss: 0.5468 - val_acc: 0.9323\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0508 - acc: 0.9938 - val_loss: 0.5355 - val_acc: 0.9339\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0678 - acc: 0.9915 - val_loss: 0.5356 - val_acc: 0.9329\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0588 - acc: 0.9913 - val_loss: 0.5461 - val_acc: 0.9319\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0613 - acc: 0.9923 - val_loss: 0.5362 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0690 - acc: 0.9880 - val_loss: 0.5337 - val_acc: 0.9327\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0520 - acc: 0.9940 - val_loss: 0.5420 - val_acc: 0.9318\n",
      "Trial number: 9\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0618 - acc: 0.9903 - val_loss: 0.5344 - val_acc: 0.9339\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0793 - acc: 0.9883 - val_loss: 0.5348 - val_acc: 0.9334\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0535 - acc: 0.9933 - val_loss: 0.5393 - val_acc: 0.9347\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0820 - acc: 0.9905 - val_loss: 0.5411 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0697 - acc: 0.9915 - val_loss: 0.5469 - val_acc: 0.9325\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0647 - acc: 0.9895 - val_loss: 0.5463 - val_acc: 0.9329\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0667 - acc: 0.9925 - val_loss: 0.5455 - val_acc: 0.9329\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0376 - acc: 0.9950 - val_loss: 0.5385 - val_acc: 0.9340\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0955 - acc: 0.9845 - val_loss: 0.5594 - val_acc: 0.9316\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0342 - acc: 0.9968 - val_loss: 0.5426 - val_acc: 0.9335\n",
      "Trial number: 10\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0646 - acc: 0.9920 - val_loss: 0.5404 - val_acc: 0.9344\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0449 - acc: 0.9953 - val_loss: 0.5423 - val_acc: 0.9337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      " - 1s - loss: 0.0579 - acc: 0.9908 - val_loss: 0.5438 - val_acc: 0.9323\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0332 - acc: 0.9960 - val_loss: 0.5436 - val_acc: 0.9339\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0652 - acc: 0.9930 - val_loss: 0.5776 - val_acc: 0.9301\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0586 - acc: 0.9898 - val_loss: 0.5518 - val_acc: 0.9318\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0396 - acc: 0.9945 - val_loss: 0.5447 - val_acc: 0.9332\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0535 - acc: 0.9928 - val_loss: 0.5431 - val_acc: 0.9322\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0619 - acc: 0.9885 - val_loss: 0.5427 - val_acc: 0.9338\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0254 - acc: 0.9983 - val_loss: 0.5436 - val_acc: 0.9346\n",
      "Trial number: 11\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0493 - acc: 0.9928 - val_loss: 0.5365 - val_acc: 0.9338\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0870 - acc: 0.9900 - val_loss: 0.5576 - val_acc: 0.9307\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0607 - acc: 0.9905 - val_loss: 0.5410 - val_acc: 0.9335\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0585 - acc: 0.9913 - val_loss: 0.5415 - val_acc: 0.9334\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0457 - acc: 0.9923 - val_loss: 0.5384 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.5411 - val_acc: 0.9335\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5390 - val_acc: 0.9345\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0695 - acc: 0.9925 - val_loss: 0.5361 - val_acc: 0.9329\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5367 - val_acc: 0.9348\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0686 - acc: 0.9925 - val_loss: 0.5472 - val_acc: 0.9317\n",
      "Trial number: 12\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0301 - acc: 0.9970 - val_loss: 0.5410 - val_acc: 0.9336\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0658 - acc: 0.9908 - val_loss: 0.5464 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0850 - acc: 0.9890 - val_loss: 0.5574 - val_acc: 0.9321\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0599 - acc: 0.9923 - val_loss: 0.5411 - val_acc: 0.9335\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0252 - acc: 0.9980 - val_loss: 0.5376 - val_acc: 0.9336\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0539 - acc: 0.9943 - val_loss: 0.5346 - val_acc: 0.9334\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0496 - acc: 0.9933 - val_loss: 0.5432 - val_acc: 0.9318\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0534 - acc: 0.9900 - val_loss: 0.5463 - val_acc: 0.9328\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0440 - acc: 0.9943 - val_loss: 0.5424 - val_acc: 0.9343\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0766 - acc: 0.9905 - val_loss: 0.5544 - val_acc: 0.9324\n",
      "Trial number: 13\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0880 - acc: 0.9895 - val_loss: 0.5577 - val_acc: 0.9312\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0331 - acc: 0.9965 - val_loss: 0.5466 - val_acc: 0.9324\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5449 - val_acc: 0.9324\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0711 - acc: 0.9903 - val_loss: 0.5477 - val_acc: 0.9321\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0555 - acc: 0.9923 - val_loss: 0.5417 - val_acc: 0.9320\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0568 - acc: 0.9940 - val_loss: 0.5552 - val_acc: 0.9310\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0412 - acc: 0.9963 - val_loss: 0.5553 - val_acc: 0.9325\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0517 - acc: 0.9925 - val_loss: 0.5577 - val_acc: 0.9311\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0271 - acc: 0.9975 - val_loss: 0.5548 - val_acc: 0.9324\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0575 - acc: 0.9928 - val_loss: 0.5447 - val_acc: 0.9331\n",
      "Trial number: 14\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0532 - acc: 0.9950 - val_loss: 0.5455 - val_acc: 0.9326\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0531 - acc: 0.9933 - val_loss: 0.5381 - val_acc: 0.9350\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0508 - acc: 0.9923 - val_loss: 0.5435 - val_acc: 0.9338\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0332 - acc: 0.9973 - val_loss: 0.5395 - val_acc: 0.9340\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5406 - val_acc: 0.9338\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0715 - acc: 0.9910 - val_loss: 0.5382 - val_acc: 0.9334\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0339 - acc: 0.9958 - val_loss: 0.5357 - val_acc: 0.9345\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5388 - val_acc: 0.9340\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5374 - val_acc: 0.9348\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0662 - acc: 0.9913 - val_loss: 0.5473 - val_acc: 0.9334\n",
      "Trial number: 15\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0533 - acc: 0.9935 - val_loss: 0.5424 - val_acc: 0.9338\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0451 - acc: 0.9930 - val_loss: 0.5398 - val_acc: 0.9338\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0485 - acc: 0.9945 - val_loss: 0.5411 - val_acc: 0.9329\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0630 - acc: 0.9923 - val_loss: 0.5437 - val_acc: 0.9335\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0370 - acc: 0.9960 - val_loss: 0.5514 - val_acc: 0.9323\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0458 - acc: 0.9948 - val_loss: 0.5467 - val_acc: 0.9340\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0434 - acc: 0.9940 - val_loss: 0.5386 - val_acc: 0.9326\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0592 - acc: 0.9935 - val_loss: 0.5362 - val_acc: 0.9328\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0636 - acc: 0.9908 - val_loss: 0.5393 - val_acc: 0.9326\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0559 - acc: 0.9915 - val_loss: 0.5636 - val_acc: 0.9302\n",
      "Trial number: 16\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0249 - acc: 0.9983 - val_loss: 0.5360 - val_acc: 0.9339\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0601 - acc: 0.9908 - val_loss: 0.5526 - val_acc: 0.9321\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0248 - acc: 0.9983 - val_loss: 0.5446 - val_acc: 0.9332\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5433 - val_acc: 0.9329\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0632 - acc: 0.9935 - val_loss: 0.5467 - val_acc: 0.9337\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0263 - acc: 0.9975 - val_loss: 0.5479 - val_acc: 0.9324\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0582 - acc: 0.9930 - val_loss: 0.5440 - val_acc: 0.9326\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0385 - acc: 0.9953 - val_loss: 0.5422 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0334 - acc: 0.9958 - val_loss: 0.5420 - val_acc: 0.9338\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0626 - acc: 0.9923 - val_loss: 0.5545 - val_acc: 0.9321\n",
      "Trial number: 17\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0632 - acc: 0.9938 - val_loss: 0.5476 - val_acc: 0.9304\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0517 - acc: 0.9925 - val_loss: 0.5471 - val_acc: 0.9332\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0293 - acc: 0.9965 - val_loss: 0.5436 - val_acc: 0.9328\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0680 - acc: 0.9920 - val_loss: 0.5514 - val_acc: 0.9324\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0506 - acc: 0.9925 - val_loss: 0.5524 - val_acc: 0.9323\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0460 - acc: 0.9955 - val_loss: 0.5500 - val_acc: 0.9325\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0557 - acc: 0.9943 - val_loss: 0.5557 - val_acc: 0.9317\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0513 - acc: 0.9950 - val_loss: 0.5517 - val_acc: 0.9318\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0429 - acc: 0.9953 - val_loss: 0.5493 - val_acc: 0.9324\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5521 - val_acc: 0.9311\n",
      "Trial number: 18\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0526 - acc: 0.9940 - val_loss: 0.5441 - val_acc: 0.9339\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0291 - acc: 0.9975 - val_loss: 0.5706 - val_acc: 0.9310\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0601 - acc: 0.9930 - val_loss: 0.5474 - val_acc: 0.9326\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5464 - val_acc: 0.9331\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5465 - val_acc: 0.9330\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0710 - acc: 0.9925 - val_loss: 0.5532 - val_acc: 0.9324\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0906 - acc: 0.9910 - val_loss: 0.5494 - val_acc: 0.9327\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0494 - acc: 0.9948 - val_loss: 0.5606 - val_acc: 0.9322\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0300 - acc: 0.9973 - val_loss: 0.5449 - val_acc: 0.9336\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5454 - val_acc: 0.9334\n",
      "Trial number: 19\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5486 - val_acc: 0.9334\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0779 - acc: 0.9905 - val_loss: 0.5556 - val_acc: 0.9337\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5499 - val_acc: 0.9345\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5476 - val_acc: 0.9348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      " - 1s - loss: 0.0661 - acc: 0.9935 - val_loss: 0.5549 - val_acc: 0.9319\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5506 - val_acc: 0.9328\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5492 - val_acc: 0.9334\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0597 - acc: 0.9925 - val_loss: 0.5494 - val_acc: 0.9337\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0485 - acc: 0.9940 - val_loss: 0.5508 - val_acc: 0.9329\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0497 - acc: 0.9938 - val_loss: 0.5535 - val_acc: 0.9329\n",
      "Trial number: 20\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5490 - val_acc: 0.9338\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5512 - val_acc: 0.9332\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1194 - acc: 0.9885 - val_loss: 0.5551 - val_acc: 0.9327\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0417 - acc: 0.9943 - val_loss: 0.5572 - val_acc: 0.9326\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0803 - acc: 0.9910 - val_loss: 0.5823 - val_acc: 0.9296\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.5523 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5532 - val_acc: 0.9330\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1005 - acc: 0.9903 - val_loss: 0.5464 - val_acc: 0.9337\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0763 - acc: 0.9908 - val_loss: 0.5459 - val_acc: 0.9335\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0282 - acc: 0.9980 - val_loss: 0.5505 - val_acc: 0.9326\n",
      "Trial number: 21\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5509 - val_acc: 0.9324\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0521 - acc: 0.9953 - val_loss: 0.5852 - val_acc: 0.9294\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0675 - acc: 0.9910 - val_loss: 0.5546 - val_acc: 0.9345\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0480 - acc: 0.9933 - val_loss: 0.5543 - val_acc: 0.9332\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0541 - acc: 0.9930 - val_loss: 0.5591 - val_acc: 0.9325\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0277 - acc: 0.9970 - val_loss: 0.5464 - val_acc: 0.9338\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0438 - acc: 0.9955 - val_loss: 0.5491 - val_acc: 0.9328\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0696 - acc: 0.9927 - val_loss: 0.5665 - val_acc: 0.9314\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0534 - acc: 0.9938 - val_loss: 0.6551 - val_acc: 0.9222\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0495 - acc: 0.9943 - val_loss: 0.5507 - val_acc: 0.9339\n",
      "Trial number: 22\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0258 - acc: 0.9980 - val_loss: 0.5527 - val_acc: 0.9342\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5531 - val_acc: 0.9343\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5578 - val_acc: 0.9340\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0969 - acc: 0.9910 - val_loss: 0.5546 - val_acc: 0.9329\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5517 - val_acc: 0.9330\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0653 - acc: 0.9915 - val_loss: 0.5568 - val_acc: 0.9310\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0452 - acc: 0.9945 - val_loss: 0.5771 - val_acc: 0.9299\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0390 - acc: 0.9955 - val_loss: 0.5517 - val_acc: 0.9341\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0637 - acc: 0.9918 - val_loss: 0.5645 - val_acc: 0.9331\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0448 - acc: 0.9955 - val_loss: 0.5555 - val_acc: 0.9332\n",
      "Trial number: 23\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0530 - acc: 0.9945 - val_loss: 0.5591 - val_acc: 0.9330\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0629 - acc: 0.9918 - val_loss: 0.5646 - val_acc: 0.9323\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0252 - acc: 0.9980 - val_loss: 0.5556 - val_acc: 0.9332\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5529 - val_acc: 0.9343\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5594 - val_acc: 0.9329\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0702 - acc: 0.9913 - val_loss: 0.5629 - val_acc: 0.9325\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0405 - acc: 0.9955 - val_loss: 0.5609 - val_acc: 0.9318\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0564 - acc: 0.9928 - val_loss: 0.5498 - val_acc: 0.9341\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5489 - val_acc: 0.9340\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5477 - val_acc: 0.9344\n",
      "Trial number: 24\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0789 - acc: 0.9905 - val_loss: 0.5644 - val_acc: 0.9318\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5589 - val_acc: 0.9331\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0614 - acc: 0.9943 - val_loss: 0.5764 - val_acc: 0.9298\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0271 - acc: 0.9975 - val_loss: 0.5670 - val_acc: 0.9317\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0603 - acc: 0.9930 - val_loss: 0.5587 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0564 - acc: 0.9943 - val_loss: 0.5514 - val_acc: 0.9342\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.5531 - val_acc: 0.9342\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0550 - acc: 0.9930 - val_loss: 0.5569 - val_acc: 0.9335\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0469 - acc: 0.9953 - val_loss: 0.5572 - val_acc: 0.9341\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5545 - val_acc: 0.9340\n",
      "Trial number: 25\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0576 - acc: 0.9933 - val_loss: 0.5639 - val_acc: 0.9327\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0603 - acc: 0.9930 - val_loss: 0.5640 - val_acc: 0.9331\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0247 - acc: 0.9985 - val_loss: 0.5574 - val_acc: 0.9340\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5576 - val_acc: 0.9337\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5578 - val_acc: 0.9344\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0557 - acc: 0.9948 - val_loss: 0.5495 - val_acc: 0.9360\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5582 - val_acc: 0.9353\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0266 - acc: 0.9980 - val_loss: 0.6044 - val_acc: 0.9277\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0548 - acc: 0.9948 - val_loss: 0.5553 - val_acc: 0.9339\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5576 - val_acc: 0.9338\n",
      "Trial number: 26\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5590 - val_acc: 0.9337\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5599 - val_acc: 0.9332\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0743 - acc: 0.9923 - val_loss: 0.5595 - val_acc: 0.9326\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.5609 - val_acc: 0.9328\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5585 - val_acc: 0.9328\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0712 - acc: 0.9925 - val_loss: 0.5849 - val_acc: 0.9310\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0263 - acc: 0.9980 - val_loss: 0.5566 - val_acc: 0.9327\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5570 - val_acc: 0.9330\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0650 - acc: 0.9943 - val_loss: 0.5659 - val_acc: 0.9319\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0505 - acc: 0.9930 - val_loss: 0.5788 - val_acc: 0.9292\n",
      "Trial number: 27\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5713 - val_acc: 0.9302\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5679 - val_acc: 0.9310\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0883 - acc: 0.9903 - val_loss: 0.5764 - val_acc: 0.9307\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0604 - acc: 0.9943 - val_loss: 0.5736 - val_acc: 0.9303\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0301 - acc: 0.9970 - val_loss: 0.5901 - val_acc: 0.9309\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0654 - acc: 0.9913 - val_loss: 0.5637 - val_acc: 0.9322\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0476 - acc: 0.9943 - val_loss: 0.5619 - val_acc: 0.9328\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5635 - val_acc: 0.9328\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5624 - val_acc: 0.9324\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5643 - val_acc: 0.9326\n",
      "Trial number: 28\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0577 - acc: 0.9923 - val_loss: 0.5606 - val_acc: 0.9323\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0318 - acc: 0.9955 - val_loss: 0.5718 - val_acc: 0.9301\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5695 - val_acc: 0.9309\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5681 - val_acc: 0.9313\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0559 - acc: 0.9940 - val_loss: 0.5804 - val_acc: 0.9308\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5750 - val_acc: 0.9307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 1s - loss: 0.0644 - acc: 0.9928 - val_loss: 0.5781 - val_acc: 0.9311\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5733 - val_acc: 0.9316\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5726 - val_acc: 0.9316\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0680 - acc: 0.9915 - val_loss: 0.5711 - val_acc: 0.9330\n",
      "Trial number: 29\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5703 - val_acc: 0.9321\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5690 - val_acc: 0.9330\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5641 - val_acc: 0.9330\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0549 - acc: 0.9948 - val_loss: 0.5717 - val_acc: 0.9325\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0484 - acc: 0.9945 - val_loss: 0.5797 - val_acc: 0.9321\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0512 - acc: 0.9940 - val_loss: 0.5727 - val_acc: 0.9330\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0512 - acc: 0.9940 - val_loss: 0.5690 - val_acc: 0.9340\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5668 - val_acc: 0.9344\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5664 - val_acc: 0.9347\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5678 - val_acc: 0.9342\n",
      "Trial number: 30\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0805 - acc: 0.9915 - val_loss: 0.5595 - val_acc: 0.9339\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0723 - acc: 0.9925 - val_loss: 0.5793 - val_acc: 0.9297\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0300 - acc: 0.9965 - val_loss: 0.5657 - val_acc: 0.9324\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0462 - acc: 0.9968 - val_loss: 0.5827 - val_acc: 0.9303\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0413 - acc: 0.9948 - val_loss: 0.5751 - val_acc: 0.9322\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0571 - acc: 0.9930 - val_loss: 0.5952 - val_acc: 0.9284\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0243 - acc: 0.9985 - val_loss: 0.5741 - val_acc: 0.9325\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5716 - val_acc: 0.9318\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5728 - val_acc: 0.9319\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5730 - val_acc: 0.9322\n",
      "Trial number: 31\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5711 - val_acc: 0.9326\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0653 - acc: 0.9938 - val_loss: 0.5753 - val_acc: 0.9325\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0523 - acc: 0.9915 - val_loss: 0.5721 - val_acc: 0.9310\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0336 - acc: 0.9965 - val_loss: 0.5741 - val_acc: 0.9320\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5676 - val_acc: 0.9326\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0242 - acc: 0.9985 - val_loss: 0.5654 - val_acc: 0.9328\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0362 - acc: 0.9970 - val_loss: 0.5861 - val_acc: 0.9315\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0629 - acc: 0.9938 - val_loss: 0.5616 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0469 - acc: 0.9965 - val_loss: 0.5715 - val_acc: 0.9325\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0521 - acc: 0.9943 - val_loss: 0.5685 - val_acc: 0.9315\n",
      "| 1 | 0.8393 |\n",
      "| 2 | 0.8567 |\n",
      "| 3 | 0.8627 |\n",
      "| 4 | 0.8609 |\n",
      "| 5 | 0.8646 |\n",
      "| 6 | 0.8644 |\n",
      "| 7 | 0.8637 |\n",
      "| 8 | 0.8663 |\n",
      "| 9 | 0.8655 |\n",
      "| 10 | 0.8665 |\n",
      "| 11 | 0.8655 |\n",
      "| 12 | 0.8666 |\n",
      "| 13 | 0.8674 |\n",
      "| 14 | 0.8677 |\n",
      "| 15 | 0.8668 |\n",
      "| 16 | 0.8673 |\n",
      "| 17 | 0.8666 |\n",
      "| 18 | 0.8683 |\n",
      "| 19 | 0.8691 |\n",
      "| 20 | 0.8683 |\n",
      "| 21 | 0.8682 |\n",
      "| 22 | 0.869 |\n",
      "| 23 | 0.869 |\n",
      "| 24 | 0.8702 |\n",
      "| 25 | 0.8709 |\n",
      "| 26 | 0.8706 |\n",
      "| 27 | 0.8693 |\n",
      "| 28 | 0.8692 |\n",
      "| 29 | 0.868 |\n",
      "| 30 | 0.8699 |\n",
      "| 31 | 0.8702 |\n",
      "| 1 | 0.8928 |\n",
      "| 2 | 0.8948 |\n",
      "| 3 | 0.8986 |\n",
      "| 4 | 0.9011 |\n",
      "| 5 | 0.9014 |\n",
      "| 6 | 0.904 |\n",
      "| 7 | 0.9045 |\n",
      "| 8 | 0.9045 |\n",
      "| 9 | 0.9045 |\n",
      "| 10 | 0.905 |\n",
      "| 11 | 0.9021 |\n",
      "| 12 | 0.9021 |\n",
      "| 13 | 0.9037 |\n",
      "| 14 | 0.904 |\n",
      "| 15 | 0.9048 |\n",
      "| 16 | 0.9016 |\n",
      "| 17 | 0.9051 |\n",
      "| 18 | 0.9051 |\n",
      "| 19 | 0.9045 |\n",
      "| 20 | 0.9067 |\n",
      "| 21 | 0.907 |\n",
      "| 22 | 0.9071 |\n",
      "| 23 | 0.9075 |\n",
      "| 24 | 0.9082 |\n",
      "| 25 | 0.9046 |\n",
      "| 26 | 0.9077 |\n",
      "| 27 | 0.8975 |\n",
      "| 28 | 0.9085 |\n",
      "| 29 | 0.9086 |\n",
      "| 30 | 0.9088 |\n",
      "| 31 | 0.9097 |\n",
      "| 1 | 0.9252 |\n",
      "| 2 | 0.9221 |\n",
      "| 3 | 0.929 |\n",
      "| 4 | 0.9285 |\n",
      "| 5 | 0.9325 |\n",
      "| 6 | 0.9314 |\n",
      "| 7 | 0.9341 |\n",
      "| 8 | 0.9318 |\n",
      "| 9 | 0.9335 |\n",
      "| 10 | 0.9346 |\n",
      "| 11 | 0.9317 |\n",
      "| 12 | 0.9324 |\n",
      "| 13 | 0.9331 |\n",
      "| 14 | 0.9334 |\n",
      "| 15 | 0.9302 |\n",
      "| 16 | 0.9321 |\n",
      "| 17 | 0.9311 |\n",
      "| 18 | 0.9334 |\n",
      "| 19 | 0.9329 |\n",
      "| 20 | 0.9326 |\n",
      "| 21 | 0.9339 |\n",
      "| 22 | 0.9332 |\n",
      "| 23 | 0.9344 |\n",
      "| 24 | 0.934 |\n",
      "| 25 | 0.9338 |\n",
      "| 26 | 0.9292 |\n",
      "| 27 | 0.9326 |\n",
      "| 28 | 0.933 |\n",
      "| 29 | 0.9342 |\n",
      "| 30 | 0.9322 |\n",
      "| 31 | 0.9315 |\n",
      "Average: 0.9318580645161292\n",
      "Trial number: 1\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.4291 - acc: 0.9495 - val_loss: 0.6544 - val_acc: 0.9235\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.3230 - acc: 0.9609 - val_loss: 0.4971 - val_acc: 0.9426\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.2542 - acc: 0.9668 - val_loss: 0.5174 - val_acc: 0.9373\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.2321 - acc: 0.9682 - val_loss: 0.5199 - val_acc: 0.9368\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.2083 - acc: 0.9717 - val_loss: 0.4805 - val_acc: 0.9419\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.1859 - acc: 0.9740 - val_loss: 0.5162 - val_acc: 0.9392\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.1673 - acc: 0.9780 - val_loss: 0.4591 - val_acc: 0.9430\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1526 - acc: 0.9764 - val_loss: 0.4847 - val_acc: 0.9396\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.1338 - acc: 0.9795 - val_loss: 0.4564 - val_acc: 0.9447\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.1355 - acc: 0.9812 - val_loss: 0.4644 - val_acc: 0.9420\n",
      "Trial number: 2\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.1313 - acc: 0.9820 - val_loss: 0.5364 - val_acc: 0.9367\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1248 - acc: 0.9820 - val_loss: 0.4472 - val_acc: 0.9463\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1195 - acc: 0.9816 - val_loss: 0.4287 - val_acc: 0.9481\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.1066 - acc: 0.9853 - val_loss: 0.4238 - val_acc: 0.9474\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.1050 - acc: 0.9831 - val_loss: 0.4319 - val_acc: 0.9472\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0987 - acc: 0.9847 - val_loss: 0.4397 - val_acc: 0.9459\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0970 - acc: 0.9853 - val_loss: 0.4326 - val_acc: 0.9474\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0992 - acc: 0.9842 - val_loss: 0.4348 - val_acc: 0.9490\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0984 - acc: 0.9859 - val_loss: 0.4326 - val_acc: 0.9484\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0931 - acc: 0.9868 - val_loss: 0.4308 - val_acc: 0.9483\n",
      "Trial number: 3\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0951 - acc: 0.9851 - val_loss: 0.4290 - val_acc: 0.9511\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.1063 - acc: 0.9857 - val_loss: 0.4252 - val_acc: 0.9502\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0997 - acc: 0.9864 - val_loss: 0.4049 - val_acc: 0.9498\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0855 - acc: 0.9868 - val_loss: 0.4037 - val_acc: 0.9500\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0922 - acc: 0.9859 - val_loss: 0.4310 - val_acc: 0.9502\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0855 - acc: 0.9861 - val_loss: 0.4130 - val_acc: 0.9503\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0979 - acc: 0.9863 - val_loss: 0.4145 - val_acc: 0.9507\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0814 - acc: 0.9879 - val_loss: 0.4269 - val_acc: 0.9493\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0750 - acc: 0.9888 - val_loss: 0.4136 - val_acc: 0.9511\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0790 - acc: 0.9876 - val_loss: 0.4173 - val_acc: 0.9508\n",
      "Trial number: 4\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0730 - acc: 0.9893 - val_loss: 0.4058 - val_acc: 0.9503\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0768 - acc: 0.9885 - val_loss: 0.4116 - val_acc: 0.9522\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0765 - acc: 0.9886 - val_loss: 0.4081 - val_acc: 0.9517\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0737 - acc: 0.9890 - val_loss: 0.4056 - val_acc: 0.9527\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0684 - acc: 0.9893 - val_loss: 0.4173 - val_acc: 0.9508\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0758 - acc: 0.9892 - val_loss: 0.4303 - val_acc: 0.9503\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0834 - acc: 0.9888 - val_loss: 0.4011 - val_acc: 0.9505\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0643 - acc: 0.9915 - val_loss: 0.3974 - val_acc: 0.9512\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0664 - acc: 0.9899 - val_loss: 0.4039 - val_acc: 0.9525\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0672 - acc: 0.9895 - val_loss: 0.4097 - val_acc: 0.9516\n",
      "Trial number: 5\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0706 - acc: 0.9906 - val_loss: 0.4103 - val_acc: 0.9523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " - 1s - loss: 0.0656 - acc: 0.9911 - val_loss: 0.3978 - val_acc: 0.9525\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0632 - acc: 0.9909 - val_loss: 0.3972 - val_acc: 0.9534\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0587 - acc: 0.9904 - val_loss: 0.3959 - val_acc: 0.9520\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0649 - acc: 0.9901 - val_loss: 0.3957 - val_acc: 0.9528\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0580 - acc: 0.9911 - val_loss: 0.3998 - val_acc: 0.9521\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0586 - acc: 0.9904 - val_loss: 0.4163 - val_acc: 0.9498\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0505 - acc: 0.9926 - val_loss: 0.3986 - val_acc: 0.9526\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0496 - acc: 0.9922 - val_loss: 0.3937 - val_acc: 0.9518\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0500 - acc: 0.9928 - val_loss: 0.4005 - val_acc: 0.9508\n",
      "Trial number: 6\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0553 - acc: 0.9909 - val_loss: 0.3990 - val_acc: 0.9520\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0580 - acc: 0.9902 - val_loss: 0.3981 - val_acc: 0.9526\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0597 - acc: 0.9923 - val_loss: 0.3973 - val_acc: 0.9537\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0620 - acc: 0.9904 - val_loss: 0.4040 - val_acc: 0.9525\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0468 - acc: 0.9935 - val_loss: 0.4100 - val_acc: 0.9538\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0564 - acc: 0.9925 - val_loss: 0.3958 - val_acc: 0.9528\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0486 - acc: 0.9939 - val_loss: 0.3943 - val_acc: 0.9534\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0426 - acc: 0.9938 - val_loss: 0.4015 - val_acc: 0.9532\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0452 - acc: 0.9927 - val_loss: 0.3985 - val_acc: 0.9540\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0491 - acc: 0.9937 - val_loss: 0.3999 - val_acc: 0.9537\n",
      "Trial number: 7\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0448 - acc: 0.9932 - val_loss: 0.3999 - val_acc: 0.9526\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0558 - acc: 0.9920 - val_loss: 0.4007 - val_acc: 0.9540\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0492 - acc: 0.9929 - val_loss: 0.3958 - val_acc: 0.9538\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0469 - acc: 0.9925 - val_loss: 0.3963 - val_acc: 0.9547\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0417 - acc: 0.9943 - val_loss: 0.3925 - val_acc: 0.9549\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0422 - acc: 0.9934 - val_loss: 0.3984 - val_acc: 0.9531\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0448 - acc: 0.9948 - val_loss: 0.3965 - val_acc: 0.9543\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0511 - acc: 0.9928 - val_loss: 0.4045 - val_acc: 0.9532\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0427 - acc: 0.9938 - val_loss: 0.4095 - val_acc: 0.9528\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0433 - acc: 0.9939 - val_loss: 0.4041 - val_acc: 0.9532\n",
      "Trial number: 8\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0478 - acc: 0.9934 - val_loss: 0.4000 - val_acc: 0.9545\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0537 - acc: 0.9923 - val_loss: 0.4096 - val_acc: 0.9535\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0428 - acc: 0.9945 - val_loss: 0.4057 - val_acc: 0.9533\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0441 - acc: 0.9945 - val_loss: 0.4136 - val_acc: 0.9528\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0431 - acc: 0.9942 - val_loss: 0.4054 - val_acc: 0.9537\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0506 - acc: 0.9921 - val_loss: 0.4029 - val_acc: 0.9539\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0349 - acc: 0.9948 - val_loss: 0.4142 - val_acc: 0.9524\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0457 - acc: 0.9942 - val_loss: 0.4074 - val_acc: 0.9538\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0484 - acc: 0.9945 - val_loss: 0.4176 - val_acc: 0.9527\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0406 - acc: 0.9949 - val_loss: 0.4065 - val_acc: 0.9543\n",
      "Trial number: 9\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0435 - acc: 0.9931 - val_loss: 0.4014 - val_acc: 0.9532\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0544 - acc: 0.9936 - val_loss: 0.4034 - val_acc: 0.9549\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0433 - acc: 0.9941 - val_loss: 0.4033 - val_acc: 0.9537\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0399 - acc: 0.9950 - val_loss: 0.4091 - val_acc: 0.9536\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0372 - acc: 0.9949 - val_loss: 0.4032 - val_acc: 0.9557\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0414 - acc: 0.9948 - val_loss: 0.4077 - val_acc: 0.9555\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0388 - acc: 0.9946 - val_loss: 0.3969 - val_acc: 0.9552\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0451 - acc: 0.9940 - val_loss: 0.4026 - val_acc: 0.9545\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0418 - acc: 0.9945 - val_loss: 0.3987 - val_acc: 0.9559\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0437 - acc: 0.9937 - val_loss: 0.3997 - val_acc: 0.9538\n",
      "Trial number: 10\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.0457 - acc: 0.9943 - val_loss: 0.4020 - val_acc: 0.9555\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0474 - acc: 0.9934 - val_loss: 0.4022 - val_acc: 0.9549\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0413 - acc: 0.9955 - val_loss: 0.4096 - val_acc: 0.9531\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0378 - acc: 0.9956 - val_loss: 0.3995 - val_acc: 0.9546\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0388 - acc: 0.9949 - val_loss: 0.4026 - val_acc: 0.9542\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0393 - acc: 0.9950 - val_loss: 0.4092 - val_acc: 0.9548\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0403 - acc: 0.9961 - val_loss: 0.4036 - val_acc: 0.9546\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0398 - acc: 0.9948 - val_loss: 0.4038 - val_acc: 0.9551\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0478 - acc: 0.9945 - val_loss: 0.4143 - val_acc: 0.9540\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0471 - acc: 0.9940 - val_loss: 0.4092 - val_acc: 0.9552\n",
      "Trial number: 11\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0381 - acc: 0.9946 - val_loss: 0.4145 - val_acc: 0.9541\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0377 - acc: 0.9957 - val_loss: 0.4181 - val_acc: 0.9530\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0379 - acc: 0.9954 - val_loss: 0.4153 - val_acc: 0.9555\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.0384 - acc: 0.9951 - val_loss: 0.4084 - val_acc: 0.9553\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0355 - acc: 0.9947 - val_loss: 0.4041 - val_acc: 0.9553\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0473 - acc: 0.9937 - val_loss: 0.4211 - val_acc: 0.9538\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0392 - acc: 0.9951 - val_loss: 0.4128 - val_acc: 0.9550\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0366 - acc: 0.9948 - val_loss: 0.4110 - val_acc: 0.9533\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0397 - acc: 0.9955 - val_loss: 0.4102 - val_acc: 0.9543\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0499 - acc: 0.9938 - val_loss: 0.4067 - val_acc: 0.9542\n",
      "Trial number: 12\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0398 - acc: 0.9956 - val_loss: 0.4122 - val_acc: 0.9545\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0406 - acc: 0.9957 - val_loss: 0.4246 - val_acc: 0.9527\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0369 - acc: 0.9957 - val_loss: 0.4114 - val_acc: 0.9542\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0431 - acc: 0.9945 - val_loss: 0.4106 - val_acc: 0.9538\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0456 - acc: 0.9939 - val_loss: 0.4023 - val_acc: 0.9539\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0340 - acc: 0.9948 - val_loss: 0.4042 - val_acc: 0.9547\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0398 - acc: 0.9947 - val_loss: 0.4180 - val_acc: 0.9535\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0341 - acc: 0.9954 - val_loss: 0.4079 - val_acc: 0.9543\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0422 - acc: 0.9947 - val_loss: 0.4054 - val_acc: 0.9544\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0326 - acc: 0.9969 - val_loss: 0.3993 - val_acc: 0.9553\n",
      "Trial number: 13\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0345 - acc: 0.9964 - val_loss: 0.4170 - val_acc: 0.9540\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0416 - acc: 0.9950 - val_loss: 0.4132 - val_acc: 0.9541\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0375 - acc: 0.9953 - val_loss: 0.4144 - val_acc: 0.9542\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0298 - acc: 0.9970 - val_loss: 0.4200 - val_acc: 0.9535\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0361 - acc: 0.9966 - val_loss: 0.4217 - val_acc: 0.9545\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0372 - acc: 0.9956 - val_loss: 0.4148 - val_acc: 0.9548\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0369 - acc: 0.9959 - val_loss: 0.4192 - val_acc: 0.9548\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0460 - acc: 0.9946 - val_loss: 0.4251 - val_acc: 0.9541\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0328 - acc: 0.9968 - val_loss: 0.4103 - val_acc: 0.9544\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0505 - acc: 0.9925 - val_loss: 0.4230 - val_acc: 0.9525\n",
      "Trial number: 14\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0319 - acc: 0.9959 - val_loss: 0.4119 - val_acc: 0.9532\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0392 - acc: 0.9954 - val_loss: 0.4177 - val_acc: 0.9539\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0368 - acc: 0.9958 - val_loss: 0.4225 - val_acc: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      " - 1s - loss: 0.0308 - acc: 0.9965 - val_loss: 0.4153 - val_acc: 0.9539\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0338 - acc: 0.9957 - val_loss: 0.4144 - val_acc: 0.9541\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0380 - acc: 0.9956 - val_loss: 0.4149 - val_acc: 0.9545\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0376 - acc: 0.9966 - val_loss: 0.4235 - val_acc: 0.9539\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0378 - acc: 0.9966 - val_loss: 0.4219 - val_acc: 0.9548\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0391 - acc: 0.9962 - val_loss: 0.4256 - val_acc: 0.9537\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0450 - acc: 0.9949 - val_loss: 0.4204 - val_acc: 0.9537\n",
      "Trial number: 15\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0402 - acc: 0.9958 - val_loss: 0.4278 - val_acc: 0.9541\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0441 - acc: 0.9955 - val_loss: 0.4316 - val_acc: 0.9530\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0327 - acc: 0.9962 - val_loss: 0.4227 - val_acc: 0.9524\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0401 - acc: 0.9947 - val_loss: 0.4210 - val_acc: 0.9539\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0296 - acc: 0.9976 - val_loss: 0.4275 - val_acc: 0.9538\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0406 - acc: 0.9957 - val_loss: 0.4181 - val_acc: 0.9547\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0377 - acc: 0.9957 - val_loss: 0.4279 - val_acc: 0.9517\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0468 - acc: 0.9941 - val_loss: 0.4232 - val_acc: 0.9532\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0400 - acc: 0.9944 - val_loss: 0.4291 - val_acc: 0.9532\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0427 - acc: 0.9936 - val_loss: 0.4178 - val_acc: 0.9543\n",
      "Trial number: 16\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0401 - acc: 0.9960 - val_loss: 0.4190 - val_acc: 0.9540\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0321 - acc: 0.9962 - val_loss: 0.4199 - val_acc: 0.9541\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0364 - acc: 0.9966 - val_loss: 0.4163 - val_acc: 0.9543\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9968 - val_loss: 0.4391 - val_acc: 0.9512\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0418 - acc: 0.9946 - val_loss: 0.4267 - val_acc: 0.9549\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0382 - acc: 0.9956 - val_loss: 0.4239 - val_acc: 0.9543\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0464 - acc: 0.9952 - val_loss: 0.4236 - val_acc: 0.9536\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0237 - acc: 0.9983 - val_loss: 0.4173 - val_acc: 0.9541\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0375 - acc: 0.9962 - val_loss: 0.4210 - val_acc: 0.9530\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0419 - acc: 0.9948 - val_loss: 0.4274 - val_acc: 0.9524\n",
      "Trial number: 17\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0433 - acc: 0.9950 - val_loss: 0.4237 - val_acc: 0.9530\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0389 - acc: 0.9959 - val_loss: 0.4279 - val_acc: 0.9529\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0320 - acc: 0.9967 - val_loss: 0.4286 - val_acc: 0.9531\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0351 - acc: 0.9957 - val_loss: 0.4431 - val_acc: 0.9530\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0276 - acc: 0.9974 - val_loss: 0.4257 - val_acc: 0.9536\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0348 - acc: 0.9964 - val_loss: 0.4263 - val_acc: 0.9536\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0371 - acc: 0.9958 - val_loss: 0.4304 - val_acc: 0.9533\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0272 - acc: 0.9971 - val_loss: 0.4319 - val_acc: 0.9530\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0366 - acc: 0.9960 - val_loss: 0.4380 - val_acc: 0.9533\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0403 - acc: 0.9954 - val_loss: 0.4422 - val_acc: 0.9511\n",
      "Trial number: 18\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0363 - acc: 0.9965 - val_loss: 0.4306 - val_acc: 0.9514\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0386 - acc: 0.9956 - val_loss: 0.4411 - val_acc: 0.9527\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0394 - acc: 0.9950 - val_loss: 0.4233 - val_acc: 0.9541\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0388 - acc: 0.9958 - val_loss: 0.4262 - val_acc: 0.9536\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0377 - acc: 0.9960 - val_loss: 0.4216 - val_acc: 0.9532\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0334 - acc: 0.9970 - val_loss: 0.4230 - val_acc: 0.9536\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0438 - acc: 0.9953 - val_loss: 0.4202 - val_acc: 0.9534\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0332 - acc: 0.9961 - val_loss: 0.4169 - val_acc: 0.9544\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0353 - acc: 0.9962 - val_loss: 0.4316 - val_acc: 0.9522\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0276 - acc: 0.9975 - val_loss: 0.4335 - val_acc: 0.9541\n",
      "Trial number: 19\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0361 - acc: 0.9966 - val_loss: 0.4281 - val_acc: 0.9536\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0281 - acc: 0.9971 - val_loss: 0.4387 - val_acc: 0.9515\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0422 - acc: 0.9950 - val_loss: 0.4461 - val_acc: 0.9512\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0356 - acc: 0.9966 - val_loss: 0.4327 - val_acc: 0.9520\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0424 - acc: 0.9952 - val_loss: 0.4421 - val_acc: 0.9528\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0297 - acc: 0.9972 - val_loss: 0.4253 - val_acc: 0.9536\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0338 - acc: 0.9967 - val_loss: 0.4437 - val_acc: 0.9515\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0412 - acc: 0.9952 - val_loss: 0.4327 - val_acc: 0.9527\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0373 - acc: 0.9953 - val_loss: 0.4327 - val_acc: 0.9532\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0354 - acc: 0.9968 - val_loss: 0.4311 - val_acc: 0.9521\n",
      "Trial number: 20\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0358 - acc: 0.9967 - val_loss: 0.4303 - val_acc: 0.9530\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0282 - acc: 0.9978 - val_loss: 0.4288 - val_acc: 0.9534\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0336 - acc: 0.9972 - val_loss: 0.4368 - val_acc: 0.9526\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0378 - acc: 0.9962 - val_loss: 0.4364 - val_acc: 0.9536\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0409 - acc: 0.9943 - val_loss: 0.4443 - val_acc: 0.9519\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0323 - acc: 0.9964 - val_loss: 0.4485 - val_acc: 0.9522\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0346 - acc: 0.9967 - val_loss: 0.4320 - val_acc: 0.9535\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0363 - acc: 0.9966 - val_loss: 0.4259 - val_acc: 0.9537\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0431 - acc: 0.9954 - val_loss: 0.4397 - val_acc: 0.9531\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0346 - acc: 0.9960 - val_loss: 0.4440 - val_acc: 0.9527\n",
      "Trial number: 21\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0360 - acc: 0.9958 - val_loss: 0.4350 - val_acc: 0.9531\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0264 - acc: 0.9979 - val_loss: 0.4279 - val_acc: 0.9547\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0368 - acc: 0.9971 - val_loss: 0.4289 - val_acc: 0.9536\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0322 - acc: 0.9971 - val_loss: 0.4250 - val_acc: 0.9534\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0332 - acc: 0.9958 - val_loss: 0.4236 - val_acc: 0.9544\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0419 - acc: 0.9957 - val_loss: 0.4467 - val_acc: 0.9519\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0376 - acc: 0.9959 - val_loss: 0.4386 - val_acc: 0.9529\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0407 - acc: 0.9954 - val_loss: 0.4423 - val_acc: 0.9539\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0376 - acc: 0.9957 - val_loss: 0.4415 - val_acc: 0.9534\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0362 - acc: 0.9958 - val_loss: 0.4384 - val_acc: 0.9528\n",
      "Trial number: 22\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0314 - acc: 0.9970 - val_loss: 0.4701 - val_acc: 0.9491\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0330 - acc: 0.9969 - val_loss: 0.4254 - val_acc: 0.9556\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0371 - acc: 0.9959 - val_loss: 0.4219 - val_acc: 0.9546\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0360 - acc: 0.9966 - val_loss: 0.4170 - val_acc: 0.9552\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0412 - acc: 0.9951 - val_loss: 0.4195 - val_acc: 0.9549\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0359 - acc: 0.9962 - val_loss: 0.4250 - val_acc: 0.9538\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0336 - acc: 0.9970 - val_loss: 0.4270 - val_acc: 0.9548\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0288 - acc: 0.9973 - val_loss: 0.4197 - val_acc: 0.9556\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0418 - acc: 0.9947 - val_loss: 0.4257 - val_acc: 0.9536\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0351 - acc: 0.9954 - val_loss: 0.4201 - val_acc: 0.9554\n",
      "Trial number: 23\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0241 - acc: 0.9978 - val_loss: 0.4222 - val_acc: 0.9551\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0368 - acc: 0.9958 - val_loss: 0.4287 - val_acc: 0.9537\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0213 - acc: 0.9986 - val_loss: 0.4204 - val_acc: 0.9549\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0345 - acc: 0.9965 - val_loss: 0.4224 - val_acc: 0.9553\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0388 - acc: 0.9959 - val_loss: 0.4224 - val_acc: 0.9557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      " - 1s - loss: 0.0271 - acc: 0.9977 - val_loss: 0.4158 - val_acc: 0.9550\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0340 - acc: 0.9963 - val_loss: 0.4183 - val_acc: 0.9536\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0369 - acc: 0.9962 - val_loss: 0.4278 - val_acc: 0.9535\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0254 - acc: 0.9977 - val_loss: 0.4305 - val_acc: 0.9547\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.0439 - acc: 0.9947 - val_loss: 0.4243 - val_acc: 0.9540\n",
      "Trial number: 24\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0313 - acc: 0.9967 - val_loss: 0.4223 - val_acc: 0.9538\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0304 - acc: 0.9964 - val_loss: 0.4440 - val_acc: 0.9526\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0316 - acc: 0.9965 - val_loss: 0.4295 - val_acc: 0.9543\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0275 - acc: 0.9971 - val_loss: 0.4206 - val_acc: 0.9547\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0282 - acc: 0.9972 - val_loss: 0.4277 - val_acc: 0.9541\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9963 - val_loss: 0.4184 - val_acc: 0.9551\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0347 - acc: 0.9965 - val_loss: 0.4258 - val_acc: 0.9552\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0208 - acc: 0.9987 - val_loss: 0.4212 - val_acc: 0.9549\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0387 - acc: 0.9958 - val_loss: 0.4405 - val_acc: 0.9533\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0390 - acc: 0.9956 - val_loss: 0.4400 - val_acc: 0.9545\n",
      "Trial number: 25\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0267 - acc: 0.9978 - val_loss: 0.4363 - val_acc: 0.9526\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0329 - acc: 0.9969 - val_loss: 0.4293 - val_acc: 0.9538\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.0379 - acc: 0.9968 - val_loss: 0.4387 - val_acc: 0.9532\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0338 - acc: 0.9965 - val_loss: 0.4248 - val_acc: 0.9545\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0206 - acc: 0.9986 - val_loss: 0.4221 - val_acc: 0.9548\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0339 - acc: 0.9965 - val_loss: 0.4326 - val_acc: 0.9534\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0348 - acc: 0.9958 - val_loss: 0.4376 - val_acc: 0.9534\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0344 - acc: 0.9968 - val_loss: 0.4259 - val_acc: 0.9556\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0412 - acc: 0.9963 - val_loss: 0.4277 - val_acc: 0.9556\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0312 - acc: 0.9965 - val_loss: 0.4203 - val_acc: 0.9552\n",
      "Trial number: 26\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0366 - acc: 0.9960 - val_loss: 0.4277 - val_acc: 0.9549\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0317 - acc: 0.9971 - val_loss: 0.4204 - val_acc: 0.9561\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0298 - acc: 0.9972 - val_loss: 0.4243 - val_acc: 0.9558\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0322 - acc: 0.9967 - val_loss: 0.4337 - val_acc: 0.9533\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0287 - acc: 0.9972 - val_loss: 0.4421 - val_acc: 0.9549\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0398 - acc: 0.9955 - val_loss: 0.4322 - val_acc: 0.9552\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0352 - acc: 0.9965 - val_loss: 0.4454 - val_acc: 0.9526\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0305 - acc: 0.9970 - val_loss: 0.4392 - val_acc: 0.9553\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0223 - acc: 0.9983 - val_loss: 0.4301 - val_acc: 0.9541\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0354 - acc: 0.9950 - val_loss: 0.4367 - val_acc: 0.9546\n",
      "Trial number: 27\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0504 - acc: 0.9948 - val_loss: 0.4280 - val_acc: 0.9563\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.0415 - acc: 0.9954 - val_loss: 0.4328 - val_acc: 0.9538\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0334 - acc: 0.9966 - val_loss: 0.4343 - val_acc: 0.9559\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0327 - acc: 0.9966 - val_loss: 0.4458 - val_acc: 0.9535\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0229 - acc: 0.9984 - val_loss: 0.4464 - val_acc: 0.9525\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0446 - acc: 0.9941 - val_loss: 0.4302 - val_acc: 0.9546\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0349 - acc: 0.9957 - val_loss: 0.4320 - val_acc: 0.9540\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0294 - acc: 0.9972 - val_loss: 0.4270 - val_acc: 0.9546\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0281 - acc: 0.9974 - val_loss: 0.4347 - val_acc: 0.9534\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0314 - acc: 0.9969 - val_loss: 0.4225 - val_acc: 0.9536\n",
      "Trial number: 28\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0329 - acc: 0.9967 - val_loss: 0.4346 - val_acc: 0.9550\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0398 - acc: 0.9951 - val_loss: 0.4315 - val_acc: 0.9541\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0399 - acc: 0.9960 - val_loss: 0.4397 - val_acc: 0.9534\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0332 - acc: 0.9962 - val_loss: 0.4426 - val_acc: 0.9532\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0289 - acc: 0.9966 - val_loss: 0.4344 - val_acc: 0.9557\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0368 - acc: 0.9962 - val_loss: 0.4468 - val_acc: 0.9539\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0288 - acc: 0.9972 - val_loss: 0.4550 - val_acc: 0.9521\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0204 - acc: 0.9984 - val_loss: 0.4445 - val_acc: 0.9529\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0359 - acc: 0.9961 - val_loss: 0.4451 - val_acc: 0.9517\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0359 - acc: 0.9969 - val_loss: 0.4393 - val_acc: 0.9527\n",
      "Trial number: 29\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0363 - acc: 0.9963 - val_loss: 0.4452 - val_acc: 0.9522\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0352 - acc: 0.9961 - val_loss: 0.4447 - val_acc: 0.9526\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0264 - acc: 0.9977 - val_loss: 0.4543 - val_acc: 0.9512\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0330 - acc: 0.9970 - val_loss: 0.4621 - val_acc: 0.9532\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0326 - acc: 0.9967 - val_loss: 0.4449 - val_acc: 0.9541\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0234 - acc: 0.9981 - val_loss: 0.4448 - val_acc: 0.9529\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0255 - acc: 0.9975 - val_loss: 0.4614 - val_acc: 0.9511\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0331 - acc: 0.9967 - val_loss: 0.4460 - val_acc: 0.9527\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0275 - acc: 0.9974 - val_loss: 0.4482 - val_acc: 0.9535\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0211 - acc: 0.9984 - val_loss: 0.4439 - val_acc: 0.9536\n",
      "Trial number: 30\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0293 - acc: 0.9972 - val_loss: 0.4391 - val_acc: 0.9548\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0312 - acc: 0.9972 - val_loss: 0.4427 - val_acc: 0.9547\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0306 - acc: 0.9973 - val_loss: 0.4506 - val_acc: 0.9521\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0310 - acc: 0.9971 - val_loss: 0.4413 - val_acc: 0.9542\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0329 - acc: 0.9966 - val_loss: 0.4532 - val_acc: 0.9534\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0342 - acc: 0.9970 - val_loss: 0.4625 - val_acc: 0.9526\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0335 - acc: 0.9970 - val_loss: 0.4616 - val_acc: 0.9524\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0387 - acc: 0.9960 - val_loss: 0.4455 - val_acc: 0.9538\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0275 - acc: 0.9976 - val_loss: 0.4439 - val_acc: 0.9535\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0371 - acc: 0.9960 - val_loss: 0.4395 - val_acc: 0.9541\n",
      "Trial number: 31\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 0.0344 - acc: 0.9966 - val_loss: 0.4429 - val_acc: 0.9546\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.0328 - acc: 0.9963 - val_loss: 0.4447 - val_acc: 0.9548\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.0225 - acc: 0.9980 - val_loss: 0.4401 - val_acc: 0.9540\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0261 - acc: 0.9970 - val_loss: 0.4527 - val_acc: 0.9540\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0213 - acc: 0.9985 - val_loss: 0.4463 - val_acc: 0.9543\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0283 - acc: 0.9967 - val_loss: 0.4519 - val_acc: 0.9530\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0264 - acc: 0.9979 - val_loss: 0.4414 - val_acc: 0.9560\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0259 - acc: 0.9973 - val_loss: 0.4438 - val_acc: 0.9525\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0287 - acc: 0.9979 - val_loss: 0.4402 - val_acc: 0.9529\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0298 - acc: 0.9968 - val_loss: 0.4491 - val_acc: 0.9528\n",
      "| 1 | 0.8393 |\n",
      "| 2 | 0.8567 |\n",
      "| 3 | 0.8627 |\n",
      "| 4 | 0.8609 |\n",
      "| 5 | 0.8646 |\n",
      "| 6 | 0.8644 |\n",
      "| 7 | 0.8637 |\n",
      "| 8 | 0.8663 |\n",
      "| 9 | 0.8655 |\n",
      "| 10 | 0.8665 |\n",
      "| 11 | 0.8655 |\n",
      "| 12 | 0.8666 |\n",
      "| 13 | 0.8674 |\n",
      "| 14 | 0.8677 |\n",
      "| 15 | 0.8668 |\n",
      "| 16 | 0.8673 |\n",
      "| 17 | 0.8666 |\n",
      "| 18 | 0.8683 |\n",
      "| 19 | 0.8691 |\n",
      "| 20 | 0.8683 |\n",
      "| 21 | 0.8682 |\n",
      "| 22 | 0.869 |\n",
      "| 23 | 0.869 |\n",
      "| 24 | 0.8702 |\n",
      "| 25 | 0.8709 |\n",
      "| 26 | 0.8706 |\n",
      "| 27 | 0.8693 |\n",
      "| 28 | 0.8692 |\n",
      "| 29 | 0.868 |\n",
      "| 30 | 0.8699 |\n",
      "| 31 | 0.8702 |\n",
      "| 1 | 0.8928 |\n",
      "| 2 | 0.8948 |\n",
      "| 3 | 0.8986 |\n",
      "| 4 | 0.9011 |\n",
      "| 5 | 0.9014 |\n",
      "| 6 | 0.904 |\n",
      "| 7 | 0.9045 |\n",
      "| 8 | 0.9045 |\n",
      "| 9 | 0.9045 |\n",
      "| 10 | 0.905 |\n",
      "| 11 | 0.9021 |\n",
      "| 12 | 0.9021 |\n",
      "| 13 | 0.9037 |\n",
      "| 14 | 0.904 |\n",
      "| 15 | 0.9048 |\n",
      "| 16 | 0.9016 |\n",
      "| 17 | 0.9051 |\n",
      "| 18 | 0.9051 |\n",
      "| 19 | 0.9045 |\n",
      "| 20 | 0.9067 |\n",
      "| 21 | 0.907 |\n",
      "| 22 | 0.9071 |\n",
      "| 23 | 0.9075 |\n",
      "| 24 | 0.9082 |\n",
      "| 25 | 0.9046 |\n",
      "| 26 | 0.9077 |\n",
      "| 27 | 0.8975 |\n",
      "| 28 | 0.9085 |\n",
      "| 29 | 0.9086 |\n",
      "| 30 | 0.9088 |\n",
      "| 31 | 0.9097 |\n",
      "| 1 | 0.9252 |\n",
      "| 2 | 0.9221 |\n",
      "| 3 | 0.929 |\n",
      "| 4 | 0.9285 |\n",
      "| 5 | 0.9325 |\n",
      "| 6 | 0.9314 |\n",
      "| 7 | 0.9341 |\n",
      "| 8 | 0.9318 |\n",
      "| 9 | 0.9335 |\n",
      "| 10 | 0.9346 |\n",
      "| 11 | 0.9317 |\n",
      "| 12 | 0.9324 |\n",
      "| 13 | 0.9331 |\n",
      "| 14 | 0.9334 |\n",
      "| 15 | 0.9302 |\n",
      "| 16 | 0.9321 |\n",
      "| 17 | 0.9311 |\n",
      "| 18 | 0.9334 |\n",
      "| 19 | 0.9329 |\n",
      "| 20 | 0.9326 |\n",
      "| 21 | 0.9339 |\n",
      "| 22 | 0.9332 |\n",
      "| 23 | 0.9344 |\n",
      "| 24 | 0.934 |\n",
      "| 25 | 0.9338 |\n",
      "| 26 | 0.9292 |\n",
      "| 27 | 0.9326 |\n",
      "| 28 | 0.933 |\n",
      "| 29 | 0.9342 |\n",
      "| 30 | 0.9322 |\n",
      "| 31 | 0.9315 |\n",
      "| 1 | 0.942 |\n",
      "| 2 | 0.9483 |\n",
      "| 3 | 0.9508 |\n",
      "| 4 | 0.9516 |\n",
      "| 5 | 0.9508 |\n",
      "| 6 | 0.9537 |\n",
      "| 7 | 0.9532 |\n",
      "| 8 | 0.9543 |\n",
      "| 9 | 0.9538 |\n",
      "| 10 | 0.9552 |\n",
      "| 11 | 0.9542 |\n",
      "| 12 | 0.9553 |\n",
      "| 13 | 0.9525 |\n",
      "| 14 | 0.9537 |\n",
      "| 15 | 0.9543 |\n",
      "| 16 | 0.9524 |\n",
      "| 17 | 0.9511 |\n",
      "| 18 | 0.9541 |\n",
      "| 19 | 0.9521 |\n",
      "| 20 | 0.9527 |\n",
      "| 21 | 0.9528 |\n",
      "| 22 | 0.9554 |\n",
      "| 23 | 0.954 |\n",
      "| 24 | 0.9545 |\n",
      "| 25 | 0.9552 |\n",
      "| 26 | 0.9546 |\n",
      "| 27 | 0.9536 |\n",
      "| 28 | 0.9527 |\n",
      "| 29 | 0.9536 |\n",
      "| 30 | 0.9541 |\n",
      "| 31 | 0.9528 |\n",
      "Average: 0.9528838709677422\n"
     ]
    }
   ],
   "source": [
    "trialsInv = []\n",
    "accsInv = []\n",
    "accuraciesInv = 0\n",
    "examples = 500\n",
    "counts = [1000, 2000, 5000, 10000, 20000, 40000, 60000]\n",
    "k = 0\n",
    "averagesInv = []\n",
    "while examples <= 80000:\n",
    "    x_train = (_x_train.reshape(60000, 784).astype(\"float32\") / 255)[:examples,:]\n",
    "    inverted_x_train = ((255 - _x_train.reshape(60000, 784).astype(\"float32\"))/255)[:examples,:]\n",
    "    x_train = np.concatenate((x_train, inverted_x_train), axis=0)\n",
    "    y_train = keras.utils.to_categorical(_y_train, 10)[:examples,:]\n",
    "    y_train = np.concatenate((y_train, y_train), axis=0)\n",
    "    for i in range(1,32):\n",
    "        print(f\"Trial number: {i}\")\n",
    "        history = model.fit(x_train, y_train,\n",
    "                       batch_size=100,\n",
    "                       epochs=10,\n",
    "                       verbose=2,\n",
    "                       validation_data=(x_test,y_test))\n",
    "        acc = model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "        trial = \"| {0} | {1} |\".format(i,  acc)\n",
    "        accsInv.append(acc)\n",
    "        accuraciesInv += acc\n",
    "        trialsInv.append(trial)\n",
    "    average = accuraciesInv / 31\n",
    "    averagesInv.append(average)\n",
    "    accuraciesInv = 0\n",
    "    for t in trialsInv:\n",
    "        print(t)\n",
    "    print(f\"Average: {average}\")\n",
    "    examples = counts[k]\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8676161290322577, 0.9078258064516129, 0.9303193548387099, 0.9508741935483871, 0.9606064516129031, 0.9720838709677418, 0.9787870967741935, 0.9804806451612905]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avgInv = [0.8676161290322577, 0.9078258064516129, 0.9303193548387099, 0.9508741935483871, 0.9606064516129031, 0.9720838709677418,0.9787870967741935,0.9804806451612905]\n",
    "print(avgInv)\n",
    "plt.figure()\n",
    "plt.plot([500, 1000, 2000, 5000, 10000, 20000, 40000, 60000], averages)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averages: [0.8511548387096777, 0.8823999999999996, 0.9115645161290319, 0.9426000000000007, 0.957812903225807, 0.9704290322580648, 0.9779645161290328, 0.9815387096774097]\n",
      "\n",
      "inverted averages: [0.8676161290322577, 0.9078258064516129, 0.9303193548387099, 0.9508741935483871, 0.9606064516129031, 0.9720838709677418, 0.9787870967741935, 0.9804806451612905]\n",
      "\n",
      "1.65%\n",
      "2.54%\n",
      "1.88%\n",
      "0.83%\n",
      "0.28%\n",
      "0.17%\n",
      "0.08%\n",
      "-0.11%\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot([500, 1000, 2000, 5000, 10000, 20000, 40000, 60000], averages)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([500, 1000, 2000, 5000, 10000, 20000, 40000, 60000], avgInv)\n",
    "plt.show()\n",
    "\n",
    "diff = []\n",
    "for i in range(len(averages)):\n",
    "    diff.append((avgInv[i] - averages[i])*100)\n",
    "\n",
    "print(f\"averages: {averages}\\n\")\n",
    "print(f\"inverted averages: {avgInv}\\n\")\n",
    "for perc in diff:\n",
    "    print(f'{round(perc,2)}%',)\n",
    "# print([0.8676161290322577, 0.9078258064516129, 0.9303193548387099, 0.9508741935483871, 0.9606064516129031, 0.9720838709677418,0.9787870967741935,0.9804806451612905])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal and inverted images one of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_x_train, _y_train), (_x_test, _y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = (_x_train.reshape(60000, 784).astype(\"float32\") / 255)[:500,:]\n",
    "inverted_x_train = ((255 - _x_train.reshape(60000, 784).astype(\"float32\"))/255)[:500,:]\n",
    "merged_array = np.vstack((x_train[0], inverted_x_train[0]))\n",
    "merged_targets = np.vstack((_y_train[0], _y_train[0]))\n",
    "for i in range(1, len(x_train)):\n",
    "    merged_array = np.concatenate((merged_array, np.vstack((x_train[i], inverted_x_train[i]))))\n",
    "    merged_targets = np.concatenate((merged_targets, np.vstack((_y_train[i], _y_train[i]))))\n",
    "\n",
    "merged_targets = keras.utils.to_categorical(merged_targets, 10)\n",
    "\n",
    "print(merged_targets.shape)\n",
    "\n",
    "num = 257\n",
    "\n",
    "digit = merged_array[num].reshape(28,28)\n",
    "# if inverted:\n",
    "#     digit = inverted_x_train[num].reshape(28,28)\n",
    "plt.figure()\n",
    "plt.title(f\"Training example number: {num}, Label: {merged_targets[num].argmax(axis=0)}\")\n",
    "plt.imshow(digit, cmap = plt.get_cmap(\"gray_r\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28) (10000,)\n",
      "rearranging samples...\n",
      "Trial number: 1\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 13.6049 - acc: 0.1210 - val_loss: 9.4647 - val_acc: 0.2768\n",
      "Epoch 2/10\n",
      " - 0s - loss: 11.8587 - acc: 0.2290 - val_loss: 8.1981 - val_acc: 0.3745\n",
      "Epoch 3/10\n",
      " - 0s - loss: 10.9219 - acc: 0.2890 - val_loss: 7.2525 - val_acc: 0.4505\n",
      "Epoch 4/10\n",
      " - 0s - loss: 10.3548 - acc: 0.3360 - val_loss: 6.7894 - val_acc: 0.4811\n",
      "Epoch 5/10\n",
      " - 0s - loss: 10.0364 - acc: 0.3650 - val_loss: 6.3966 - val_acc: 0.5037\n",
      "Epoch 6/10\n",
      " - 0s - loss: 9.7846 - acc: 0.3780 - val_loss: 5.9130 - val_acc: 0.5342\n",
      "Epoch 7/10\n",
      " - 0s - loss: 9.4854 - acc: 0.3990 - val_loss: 5.4932 - val_acc: 0.5612\n",
      "Epoch 8/10\n",
      " - 0s - loss: 9.3144 - acc: 0.4160 - val_loss: 5.3276 - val_acc: 0.5730\n",
      "Epoch 9/10\n",
      " - 0s - loss: 9.1874 - acc: 0.4250 - val_loss: 5.0541 - val_acc: 0.5887\n",
      "Epoch 10/10\n",
      " - 0s - loss: 9.0741 - acc: 0.4340 - val_loss: 4.7630 - val_acc: 0.6083\n",
      "Trial number: 2\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 8.9150 - acc: 0.4380 - val_loss: 4.4451 - val_acc: 0.6282\n",
      "Epoch 2/10\n",
      " - 0s - loss: 8.7059 - acc: 0.4550 - val_loss: 4.3361 - val_acc: 0.6336\n",
      "Epoch 3/10\n",
      " - 1s - loss: 8.5415 - acc: 0.4620 - val_loss: 4.2175 - val_acc: 0.6467\n",
      "Epoch 4/10\n",
      " - 0s - loss: 8.4741 - acc: 0.4720 - val_loss: 4.1499 - val_acc: 0.6498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 8.4544 - acc: 0.4750 - val_loss: 4.1481 - val_acc: 0.6501\n",
      "Epoch 6/10\n",
      " - 1s - loss: 8.4241 - acc: 0.4750 - val_loss: 4.1297 - val_acc: 0.6526\n",
      "Epoch 7/10\n",
      " - 1s - loss: 8.4141 - acc: 0.4780 - val_loss: 4.0855 - val_acc: 0.6556\n",
      "Epoch 8/10\n",
      " - 0s - loss: 8.3977 - acc: 0.4790 - val_loss: 4.0904 - val_acc: 0.6543\n",
      "Epoch 9/10\n",
      " - 0s - loss: 8.3976 - acc: 0.4790 - val_loss: 4.0694 - val_acc: 0.6564\n",
      "Epoch 10/10\n",
      " - 0s - loss: 8.3976 - acc: 0.4790 - val_loss: 4.0587 - val_acc: 0.6574\n",
      "Trial number: 3\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 8.3976 - acc: 0.4790 - val_loss: 4.0474 - val_acc: 0.6581\n",
      "Epoch 2/10\n",
      " - 0s - loss: 8.3975 - acc: 0.4790 - val_loss: 4.0361 - val_acc: 0.6591\n",
      "Epoch 3/10\n",
      " - 1s - loss: 8.3975 - acc: 0.4790 - val_loss: 4.0241 - val_acc: 0.6600\n",
      "Epoch 4/10\n",
      " - 0s - loss: 8.3975 - acc: 0.4790 - val_loss: 4.0117 - val_acc: 0.6615\n",
      "Epoch 5/10\n",
      " - 0s - loss: 8.3974 - acc: 0.4790 - val_loss: 3.9885 - val_acc: 0.6640\n",
      "Epoch 6/10\n",
      " - 0s - loss: 8.3847 - acc: 0.4790 - val_loss: 3.9935 - val_acc: 0.6628\n",
      "Epoch 7/10\n",
      " - 0s - loss: 8.3814 - acc: 0.4800 - val_loss: 3.9670 - val_acc: 0.6671\n",
      "Epoch 8/10\n",
      " - 0s - loss: 8.3814 - acc: 0.4800 - val_loss: 3.9510 - val_acc: 0.6684\n",
      "Epoch 9/10\n",
      " - 0s - loss: 8.3814 - acc: 0.4800 - val_loss: 3.9344 - val_acc: 0.6701\n",
      "Epoch 10/10\n",
      " - 0s - loss: 8.3814 - acc: 0.4800 - val_loss: 3.9237 - val_acc: 0.6708\n",
      "Trial number: 4\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 8.3814 - acc: 0.4800 - val_loss: 3.9115 - val_acc: 0.6721\n",
      "Epoch 2/10\n",
      " - 0s - loss: 8.3814 - acc: 0.4800 - val_loss: 3.8952 - val_acc: 0.6730\n",
      "Epoch 3/10\n",
      " - 0s - loss: 8.3697 - acc: 0.4800 - val_loss: 3.5930 - val_acc: 0.6804\n",
      "Epoch 4/10\n",
      " - 1s - loss: 8.1725 - acc: 0.4870 - val_loss: 3.1582 - val_acc: 0.7046\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.9443 - acc: 0.5010 - val_loss: 3.3183 - val_acc: 0.6942\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.8151 - acc: 0.5090 - val_loss: 3.0026 - val_acc: 0.7196\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7691 - acc: 0.5180 - val_loss: 2.9933 - val_acc: 0.7202\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7690 - acc: 0.5180 - val_loss: 2.9877 - val_acc: 0.7208\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7690 - acc: 0.5180 - val_loss: 2.9811 - val_acc: 0.7222\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7690 - acc: 0.5180 - val_loss: 2.9741 - val_acc: 0.7231\n",
      "Trial number: 5\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7690 - acc: 0.5180 - val_loss: 2.9681 - val_acc: 0.7237\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7689 - acc: 0.5180 - val_loss: 2.9622 - val_acc: 0.7242\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7689 - acc: 0.5180 - val_loss: 2.9528 - val_acc: 0.7248\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7689 - acc: 0.5180 - val_loss: 2.9438 - val_acc: 0.7250\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7689 - acc: 0.5180 - val_loss: 2.9364 - val_acc: 0.7254\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7680 - acc: 0.5180 - val_loss: 2.9619 - val_acc: 0.7251\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7363 - acc: 0.5200 - val_loss: 2.8725 - val_acc: 0.7307\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8728 - val_acc: 0.7305\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8685 - val_acc: 0.7318\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8624 - val_acc: 0.7332\n",
      "Trial number: 6\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8576 - val_acc: 0.7342\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8503 - val_acc: 0.7345\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8446 - val_acc: 0.7350\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8394 - val_acc: 0.7363\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8332 - val_acc: 0.7368\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8261 - val_acc: 0.7379\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8184 - val_acc: 0.7393\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8141 - val_acc: 0.7403\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8099 - val_acc: 0.7405\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.8034 - val_acc: 0.7415\n",
      "Trial number: 7\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7996 - val_acc: 0.7421\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7955 - val_acc: 0.7424\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7919 - val_acc: 0.7427\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7892 - val_acc: 0.7435\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7862 - val_acc: 0.7438\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7839 - val_acc: 0.7441\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7821 - val_acc: 0.7442\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7804 - val_acc: 0.7443\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7786 - val_acc: 0.7444\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7769 - val_acc: 0.7444\n",
      "Trial number: 8\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7755 - val_acc: 0.7446\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7748 - val_acc: 0.7447\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7736 - val_acc: 0.7450\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7738 - val_acc: 0.7450\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7737 - val_acc: 0.7450\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7733 - val_acc: 0.7452\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7730 - val_acc: 0.7453\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7728 - val_acc: 0.7453\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7721 - val_acc: 0.7455\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7716 - val_acc: 0.7455\n",
      "Trial number: 9\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7720 - val_acc: 0.7454\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7723 - val_acc: 0.7453\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7720 - val_acc: 0.7454\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7723 - val_acc: 0.7451\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7722 - val_acc: 0.7452\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7206 - acc: 0.5210 - val_loss: 2.7721 - val_acc: 0.7451\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7205 - acc: 0.5210 - val_loss: 2.7853 - val_acc: 0.7447\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7045 - acc: 0.5220 - val_loss: 2.7682 - val_acc: 0.7464\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7045 - acc: 0.5220 - val_loss: 2.7597 - val_acc: 0.7476\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7045 - acc: 0.5220 - val_loss: 2.7543 - val_acc: 0.7477\n",
      "Trial number: 10\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 7.7045 - acc: 0.5220 - val_loss: 2.7504 - val_acc: 0.7478\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7045 - acc: 0.5220 - val_loss: 2.7466 - val_acc: 0.7482\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7045 - acc: 0.5220 - val_loss: 2.7437 - val_acc: 0.7486\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7045 - acc: 0.5220 - val_loss: 2.7423 - val_acc: 0.7486\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7409 - val_acc: 0.7485\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7399 - val_acc: 0.7488\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7390 - val_acc: 0.7490\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7385 - val_acc: 0.7493\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7381 - val_acc: 0.7494\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7378 - val_acc: 0.7493\n",
      "Trial number: 11\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7380 - val_acc: 0.7492\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7382 - val_acc: 0.7493\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7381 - val_acc: 0.7494\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7377 - val_acc: 0.7496\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7381 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7378 - val_acc: 0.7499\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7382 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7383 - val_acc: 0.7501\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7380 - val_acc: 0.7502\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7382 - val_acc: 0.7501\n",
      "Trial number: 12\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7382 - val_acc: 0.7502\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7384 - val_acc: 0.7497\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7383 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7380 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7380 - val_acc: 0.7500\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7379 - val_acc: 0.7499\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7378 - val_acc: 0.7499\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7377 - val_acc: 0.7499\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7372 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7372 - val_acc: 0.7496\n",
      "Trial number: 13\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7372 - val_acc: 0.7496\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7372 - val_acc: 0.7496\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7370 - val_acc: 0.7496\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7495\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 14\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 15\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 16\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 17\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 18\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 19\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 20\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 21\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 22\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 23\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 24\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 25\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 26\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7045 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 27\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 28\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 29\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 30\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Trial number: 31\n",
      "Train on 1000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7044 - acc: 0.5220 - val_loss: 2.7369 - val_acc: 0.7498\n",
      "Average: 0.7376483870967745\n",
      "rearranging samples...\n",
      "Trial number: 1\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 8.2047 - acc: 0.4710 - val_loss: 2.1656 - val_acc: 0.7909\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.8942 - acc: 0.5020 - val_loss: 2.0870 - val_acc: 0.7998\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.8145 - acc: 0.5125 - val_loss: 2.0392 - val_acc: 0.8057\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7935 - acc: 0.5165 - val_loss: 2.0922 - val_acc: 0.8017\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7859 - acc: 0.5165 - val_loss: 2.0627 - val_acc: 0.8047\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7851 - acc: 0.5170 - val_loss: 2.0596 - val_acc: 0.8045\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7851 - acc: 0.5170 - val_loss: 2.0512 - val_acc: 0.8053\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7850 - acc: 0.5170 - val_loss: 2.0334 - val_acc: 0.8074\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7850 - acc: 0.5170 - val_loss: 2.0314 - val_acc: 0.8066\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7850 - acc: 0.5170 - val_loss: 1.9712 - val_acc: 0.8112\n",
      "Trial number: 2\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7770 - acc: 0.5175 - val_loss: 1.9883 - val_acc: 0.8104\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7766 - acc: 0.5175 - val_loss: 1.9809 - val_acc: 0.8103\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7689 - acc: 0.5180 - val_loss: 1.9601 - val_acc: 0.8125\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7689 - acc: 0.5180 - val_loss: 1.9477 - val_acc: 0.8141\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7689 - acc: 0.5180 - val_loss: 1.9462 - val_acc: 0.8143\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7689 - acc: 0.5180 - val_loss: 1.9421 - val_acc: 0.8147\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7689 - acc: 0.5180 - val_loss: 1.9401 - val_acc: 0.8153\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7689 - acc: 0.5180 - val_loss: 1.9385 - val_acc: 0.8154\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7689 - acc: 0.5180 - val_loss: 1.9468 - val_acc: 0.8137\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9459 - val_acc: 0.8145\n",
      "Trial number: 3\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9431 - val_acc: 0.8138\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9406 - val_acc: 0.8143\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9397 - val_acc: 0.8150\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9393 - val_acc: 0.8145\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9381 - val_acc: 0.8147\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9375 - val_acc: 0.8149\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9366 - val_acc: 0.8151\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9365 - val_acc: 0.8152\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9364 - val_acc: 0.8153\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9369 - val_acc: 0.8153\n",
      "Trial number: 4\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9355 - val_acc: 0.8156\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9358 - val_acc: 0.8156\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9359 - val_acc: 0.8157\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9358 - val_acc: 0.8158\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9357 - val_acc: 0.8156\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9361 - val_acc: 0.8156\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9357 - val_acc: 0.8158\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9361 - val_acc: 0.8157\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9362 - val_acc: 0.8155\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9362 - val_acc: 0.8157\n",
      "Trial number: 5\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9363 - val_acc: 0.8157\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9365 - val_acc: 0.8157\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9366 - val_acc: 0.8157\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9367 - val_acc: 0.8159\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9367 - val_acc: 0.8159\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8159\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9366 - val_acc: 0.8159\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8157\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8157\n",
      "Trial number: 6\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9366 - val_acc: 0.8158\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 7\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 8\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 9\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 10\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 11\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 12\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 13\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 14\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 15\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 16\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 17\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 18\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 19\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 20\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 21\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 22\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 23\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 24\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 25\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 26\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 27\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 28\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 29\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 30\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Trial number: 31\n",
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 3/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 4/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 5/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 6/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 7/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 8/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 9/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Epoch 10/10\n",
      " - 0s - loss: 7.7609 - acc: 0.5185 - val_loss: 1.9368 - val_acc: 0.8160\n",
      "Average: 0.8157548387096772\n",
      "rearranging samples...\n",
      "Trial number: 1\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.9395 - acc: 0.4927 - val_loss: 1.5753 - val_acc: 0.8513\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.7327 - acc: 0.5140 - val_loss: 1.5847 - val_acc: 0.8516\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.6732 - acc: 0.5217 - val_loss: 1.5802 - val_acc: 0.8525\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.6481 - acc: 0.5242 - val_loss: 1.5346 - val_acc: 0.8583\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.6321 - acc: 0.5260 - val_loss: 1.4936 - val_acc: 0.8603\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5807 - acc: 0.5282 - val_loss: 1.5396 - val_acc: 0.8578\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5716 - acc: 0.5287 - val_loss: 1.4272 - val_acc: 0.8681\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5519 - acc: 0.5312 - val_loss: 1.3904 - val_acc: 0.8704\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5388 - acc: 0.5322 - val_loss: 1.3612 - val_acc: 0.8730\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5352 - acc: 0.5325 - val_loss: 1.3571 - val_acc: 0.8738\n",
      "Trial number: 2\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5350 - acc: 0.5325 - val_loss: 1.3558 - val_acc: 0.8759\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5312 - acc: 0.5327 - val_loss: 1.3276 - val_acc: 0.8782\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5312 - acc: 0.5327 - val_loss: 1.3205 - val_acc: 0.8781\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5312 - acc: 0.5327 - val_loss: 1.3135 - val_acc: 0.8791\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5311 - acc: 0.5327 - val_loss: 1.3086 - val_acc: 0.8799\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2959 - val_acc: 0.8809\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2975 - val_acc: 0.8814\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2961 - val_acc: 0.8813\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2953 - val_acc: 0.8817\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2936 - val_acc: 0.8818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 3\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2927 - val_acc: 0.8818\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2918 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2911 - val_acc: 0.8817\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2905 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2896 - val_acc: 0.8817\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2891 - val_acc: 0.8816\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2887 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2885 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2880 - val_acc: 0.8816\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2880 - val_acc: 0.8815\n",
      "Trial number: 4\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2878 - val_acc: 0.8818\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2877 - val_acc: 0.8818\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2876 - val_acc: 0.8818\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8820\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2872 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2874 - val_acc: 0.8820\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2872 - val_acc: 0.8822\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2873 - val_acc: 0.8822\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2873 - val_acc: 0.8822\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2873 - val_acc: 0.8821\n",
      "Trial number: 5\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2874 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2874 - val_acc: 0.8820\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2874 - val_acc: 0.8820\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2874 - val_acc: 0.8820\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2874 - val_acc: 0.8822\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2874 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 6\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 7\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 8\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 9\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 10\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 11\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 12\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 13\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 14\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 15\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 16\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 17\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 18\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 19\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 20\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 21\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 22\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 23\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 24\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 25\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 26\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 27\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 28\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 29\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 30\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Trial number: 31\n",
      "Train on 4000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.5272 - acc: 0.5330 - val_loss: 1.2875 - val_acc: 0.8821\n",
      "Average: 0.881803225806452\n",
      "rearranging samples...\n",
      "Trial number: 1\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.6540 - acc: 0.5148 - val_loss: 1.0537 - val_acc: 0.9031\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.5340 - acc: 0.5276 - val_loss: 1.0176 - val_acc: 0.9059\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.4702 - acc: 0.5335 - val_loss: 0.9897 - val_acc: 0.9093\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.4392 - acc: 0.5371 - val_loss: 0.9165 - val_acc: 0.9148\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.4271 - acc: 0.5388 - val_loss: 0.8885 - val_acc: 0.9176\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.4230 - acc: 0.5391 - val_loss: 0.9063 - val_acc: 0.9170\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.4175 - acc: 0.5393 - val_loss: 0.8895 - val_acc: 0.9169\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.4127 - acc: 0.5399 - val_loss: 0.8832 - val_acc: 0.9193\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.4099 - acc: 0.5401 - val_loss: 0.8673 - val_acc: 0.9202\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.4094 - acc: 0.5403 - val_loss: 0.9165 - val_acc: 0.9170\n",
      "Trial number: 2\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.4081 - acc: 0.5402 - val_loss: 0.8876 - val_acc: 0.9214\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.4063 - acc: 0.5404 - val_loss: 0.8743 - val_acc: 0.9216\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.4016 - acc: 0.5406 - val_loss: 0.8762 - val_acc: 0.9212\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3957 - acc: 0.5409 - val_loss: 0.8468 - val_acc: 0.9238\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3919 - acc: 0.5414 - val_loss: 0.8905 - val_acc: 0.9197\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3902 - acc: 0.5412 - val_loss: 0.8397 - val_acc: 0.9218\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3854 - acc: 0.5417 - val_loss: 0.8457 - val_acc: 0.9214\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8694 - val_acc: 0.9209\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8362 - val_acc: 0.9233\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8316 - val_acc: 0.9247\n",
      "Trial number: 3\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8313 - val_acc: 0.9249\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8302 - val_acc: 0.9252\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8295 - val_acc: 0.9251\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8290 - val_acc: 0.9251\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8286 - val_acc: 0.9255\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8283 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8282 - val_acc: 0.9256\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8281 - val_acc: 0.9258\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8280 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8279 - val_acc: 0.9257\n",
      "Trial number: 4\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8278 - val_acc: 0.9256\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8278 - val_acc: 0.9256\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8278 - val_acc: 0.9258\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8279 - val_acc: 0.9255\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8278 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8278 - val_acc: 0.9255\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8278 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8277 - val_acc: 0.9256\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8277 - val_acc: 0.9256\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9256\n",
      "Trial number: 5\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8275 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8275 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8275 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8275 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 6\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8275 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8275 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 7\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 8\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 9\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 10\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 11\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 12\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 13\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 14\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 15\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 16\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 17\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 18\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 19\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 20\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 21\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 22\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 23\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 24\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 25\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 26\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number: 27\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 28\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 29\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 30\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Trial number: 31\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 2/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 5/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 6/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 7/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 8/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 9/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Epoch 10/10\n",
      " - 1s - loss: 7.3853 - acc: 0.5418 - val_loss: 0.8276 - val_acc: 0.9257\n",
      "Average: 0.9253838709677413\n",
      "rearranging samples...\n",
      "Trial number: 1\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.4861 - acc: 0.5295 - val_loss: 0.7781 - val_acc: 0.9299\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.4187 - acc: 0.5362 - val_loss: 0.7363 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3921 - acc: 0.5391 - val_loss: 0.6993 - val_acc: 0.9359\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3710 - acc: 0.5412 - val_loss: 0.6939 - val_acc: 0.9366\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3648 - acc: 0.5418 - val_loss: 0.6972 - val_acc: 0.9361\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3529 - acc: 0.5429 - val_loss: 0.6747 - val_acc: 0.9393\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3476 - acc: 0.5437 - val_loss: 0.6373 - val_acc: 0.9409\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3438 - acc: 0.5443 - val_loss: 0.6382 - val_acc: 0.9437\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3430 - acc: 0.5441 - val_loss: 0.6514 - val_acc: 0.9401\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3396 - acc: 0.5445 - val_loss: 0.6456 - val_acc: 0.9412\n",
      "Trial number: 2\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3385 - acc: 0.5447 - val_loss: 0.6609 - val_acc: 0.9387\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3371 - acc: 0.5446 - val_loss: 0.6346 - val_acc: 0.9429\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3347 - acc: 0.5449 - val_loss: 0.6110 - val_acc: 0.9443\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3340 - acc: 0.5449 - val_loss: 0.6362 - val_acc: 0.9419\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3329 - acc: 0.5450 - val_loss: 0.6439 - val_acc: 0.9416\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3322 - acc: 0.5450 - val_loss: 0.6302 - val_acc: 0.9437\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3320 - acc: 0.5451 - val_loss: 0.6190 - val_acc: 0.9446\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.6269 - val_acc: 0.9443\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.6080 - val_acc: 0.9456\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.6223 - val_acc: 0.9434\n",
      "Trial number: 3\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.6015 - val_acc: 0.9457\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.6014 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.6004 - val_acc: 0.9451\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.6000 - val_acc: 0.9451\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5999 - val_acc: 0.9451\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5999 - val_acc: 0.9452\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5999 - val_acc: 0.9452\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5999 - val_acc: 0.9452\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5998 - val_acc: 0.9451\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5998 - val_acc: 0.9451\n",
      "Trial number: 4\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5998 - val_acc: 0.9451\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5998 - val_acc: 0.9451\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5998 - val_acc: 0.9451\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5998 - val_acc: 0.9451\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5998 - val_acc: 0.9451\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9449\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9449\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9449\n",
      "Trial number: 5\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9449\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9449\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9449\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9449\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9449\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5997 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 6\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 7\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 8\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 9\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 10\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 11\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 12\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 13\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 14\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 15\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 16\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 17\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 18\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 19\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 20\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 21\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 22\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 23\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 24\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 25\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 26\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 27\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 28\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 29\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 30\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Trial number: 31\n",
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 2/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 4/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 5/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 6/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 8/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 9/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Epoch 10/10\n",
      " - 2s - loss: 7.3305 - acc: 0.5452 - val_loss: 0.5996 - val_acc: 0.9450\n",
      "Average: 0.9448258064516132\n",
      "rearranging samples...\n",
      "Trial number: 1\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.4469 - acc: 0.5331 - val_loss: 0.5933 - val_acc: 0.9465\n",
      "Epoch 2/10\n",
      " - 6s - loss: 7.3981 - acc: 0.5377 - val_loss: 0.6083 - val_acc: 0.9465\n",
      "Epoch 3/10\n",
      " - 5s - loss: 7.3755 - acc: 0.5402 - val_loss: 0.5470 - val_acc: 0.9512\n",
      "Epoch 4/10\n",
      " - 5s - loss: 7.3578 - acc: 0.5416 - val_loss: 0.5633 - val_acc: 0.9496\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3482 - acc: 0.5428 - val_loss: 0.5321 - val_acc: 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      " - 4s - loss: 7.3402 - acc: 0.5436 - val_loss: 0.5037 - val_acc: 0.9548\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3337 - acc: 0.5443 - val_loss: 0.4960 - val_acc: 0.9565\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3321 - acc: 0.5445 - val_loss: 0.4743 - val_acc: 0.9563\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3303 - acc: 0.5445 - val_loss: 0.4791 - val_acc: 0.9567\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3275 - acc: 0.5450 - val_loss: 0.4896 - val_acc: 0.9577\n",
      "Trial number: 2\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3260 - acc: 0.5452 - val_loss: 0.4839 - val_acc: 0.9579\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3244 - acc: 0.5454 - val_loss: 0.4598 - val_acc: 0.9607\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3229 - acc: 0.5455 - val_loss: 0.4818 - val_acc: 0.9581\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3222 - acc: 0.5456 - val_loss: 0.4687 - val_acc: 0.9586\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3223 - acc: 0.5456 - val_loss: 0.4850 - val_acc: 0.9578\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3216 - acc: 0.5456 - val_loss: 0.4731 - val_acc: 0.9590\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3209 - acc: 0.5458 - val_loss: 0.4875 - val_acc: 0.9560\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3201 - acc: 0.5458 - val_loss: 0.4664 - val_acc: 0.9609\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3192 - acc: 0.5458 - val_loss: 0.4702 - val_acc: 0.9593\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3181 - acc: 0.5459 - val_loss: 0.4825 - val_acc: 0.9579\n",
      "Trial number: 3\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3182 - acc: 0.5459 - val_loss: 0.4743 - val_acc: 0.9593\n",
      "Epoch 2/10\n",
      " - 5s - loss: 7.3169 - acc: 0.5460 - val_loss: 0.4613 - val_acc: 0.9606\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4508 - val_acc: 0.9600\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4636 - val_acc: 0.9602\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4440 - val_acc: 0.9606\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4377 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4414 - val_acc: 0.9617\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4450 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4437 - val_acc: 0.9615\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9615\n",
      "Trial number: 4\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4436 - val_acc: 0.9615\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4436 - val_acc: 0.9615\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4436 - val_acc: 0.9615\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4436 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4436 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4436 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4436 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 5\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 6\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 7\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 8\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 9\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 10\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 11\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 12\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 13\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 14\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 15\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 16\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 17\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 6s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 6s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 18\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 6s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 19\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 20\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 21\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 22\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 23\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 24\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 25\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 26\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 27\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 28\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 29\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 30\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Trial number: 31\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 2/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 3/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 4/10\n",
      " - 4s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 5/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 6/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 8/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 9/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Epoch 10/10\n",
      " - 3s - loss: 7.3168 - acc: 0.5460 - val_loss: 0.4435 - val_acc: 0.9614\n",
      "Average: 0.9611709677419359\n",
      "rearranging samples...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-2e21598a7a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rearranging samples...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmerged_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverted_x_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mmerged_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_y_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trialsConcat = []\n",
    "accsConcat = []\n",
    "accuraciesConcat = 0\n",
    "examples = 500\n",
    "counts = [1000, 2000, 5000, 10000, 20000, 40000, 60000]\n",
    "k = 0\n",
    "averagesConcat = []\n",
    "x_test = _x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "y_test = keras.utils.to_categorical(_y_test, 10)\n",
    "print(_x_test.shape, _y_test.shape)\n",
    "while examples <= 80000:\n",
    "    x_train = (_x_train.reshape(60000, 784).astype(\"float32\") / 255)[:examples,:]\n",
    "    inverted_x_train = ((255 - _x_train.reshape(60000, 784).astype(\"float32\"))/255)[:examples,:]\n",
    "    merged_array = np.vstack((x_train[0], inverted_x_train[0]))\n",
    "    merged_targets = np.vstack((_y_train[0], _y_train[0]))\n",
    "    print(\"rearranging samples...\")\n",
    "    for i in range(1, examples):\n",
    "        merged_array = np.concatenate((merged_array, np.vstack((x_train[i], inverted_x_train[i]))))\n",
    "        merged_targets = np.concatenate((merged_targets, np.vstack((_y_train[i], _y_train[i]))))\n",
    "    x_train = merged_array\n",
    "    y_train = keras.utils.to_categorical(merged_targets, 10) \n",
    "    for i in range(1,32):\n",
    "        print(f\"Trial number: {i}\")\n",
    "        history = model.fit(x_train, y_train,\n",
    "                       batch_size=100,\n",
    "                       epochs=10,\n",
    "                       verbose=2,\n",
    "                       validation_data=(x_test,y_test))\n",
    "        acc = model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "        trial = \"| {0} | {1} |\".format(i,  acc)\n",
    "        accsConcat.append(acc)\n",
    "        accuraciesConcat += acc\n",
    "        trialsConcat.append(trial)\n",
    "    average = accuraciesConcat / 31\n",
    "    averagesConcat.append(average)\n",
    "    accuraciesConcat = 0\n",
    "#     for t in trialsConcat:\n",
    "#         print(t)\n",
    "    print(f\"Average: {average}\")\n",
    "    examples = counts[k]\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (_x_train.reshape(60000, 784).astype(\"float32\") / 255)[:500,:]\n",
    "inverted_x_train = ((255 - _x_train.reshape(60000, 784).astype(\"float32\"))/255)[:500,:]\n",
    "# display_sample(6, inverted=True)\n",
    "x_train = np.concatenate((x_train, inverted_x_train), axis=0)\n",
    "print(x_train.shape)\n",
    "x_test = _x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "y_train = keras.utils.to_categorical(_y_train, 10)[:500,:]\n",
    "y_train =  np.concatenate((y_train, y_train), axis=0)\n",
    "print(y_train.shape)\n",
    "y_test = keras.utils.to_categorical(_y_test, 10)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\\ny_train shape: {y_train.shape}\\nx_test shape: {x_test.shape}\\ny_test shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averages: [0.8511548387096777, 0.8823999999999996, 0.9115645161290319, 0.9426000000000007, 0.957812903225807, 0.9704290322580648, 0.9779645161290328, 0.9815387096774097]\n",
      "one of each: [0.7376483870967745, 0.8157548387096772, 0.881803225806452, 0.9253838709677413, 0.9448258064516132, 0.9611709677419359]\n"
     ]
    }
   ],
   "source": [
    "print(\"averages: [0.8511548387096777, 0.8823999999999996, 0.9115645161290319, 0.9426000000000007, 0.957812903225807, 0.9704290322580648, 0.9779645161290328, 0.9815387096774097]\")\n",
    "print(f\"one of each: {averagesConcat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
